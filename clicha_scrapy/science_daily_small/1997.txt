0-> Los Alamos Instruments To Prospect For Water On The Moon
LOS ALAMOS, N.M., Dec. 30, 1997 -- Sometime in the next month or so, Los Alamos National Laboratory scientists will gather information bearing on a major question impacting the future of space colonization: does the moon have water? Three Los Alamos instruments on the National Aeronautics and Space Administration's Lunar Prospector, scheduled for a Jan. 5, 1998, launch, will look for water, map the location of valuable elements and gather data on events that release gases from below the surface of Earth's nearest neighbor. "If we can find sufficient water, it's going to be a land rush like the Oklahoma Sooners," said Bill Feldman, project leader for the Los Alamos instrument package. Los Alamos is a Department of Energy laboratory. Feldman is confident that Los Alamos' neutron spectrometer will find water if it is there -- even if it occurs in a very small amount -- most likely in the form of dirty ice in permanently shaded craters near the moon's poles. The instrument, which detects and distinguishes neutrons of different energies, should find even faint traces of any ice that is within three feet of the lunar surface. Ever since last year, when radar mapping instruments on the Clementine probe suggested the possible presence of water on the moon, the importance of Lunar Prospector has grown. Ice, likely deposited by comet and meteoroid impacts, would open the way to interplanetary colonization. "Water is the key resource that will support life as well as travel from the moon to the planets. Besides sustaining life for moon colonies, hydrogen from the ice can be extracted for rocket fuel," Feldman said. "I am sure that there are people who would colonize the moon once sufficient water is available," he continued. "The moon is one of the best environments you could possibly have for any number of scientific and commercial enterprises." In addition to serving as a fueling station for interplanetary travel, a moon colony could provide a base for important research in radio, ultraviolet and infrared astronomy. Lunar Prospector will take four and one-half days to reach the moon, but Los Alamos scientists will turn on their three instruments -- the neutron spectrometer, an alpha particle detector and a gamma ray spectrometer -- 90 minutes after launch. They want to calibrate the sensors in transit to the moon and make sure everything is working perfectly when the spacecraft reaches its polar orbit around the moon. After three high-altitude orbital maneuvers at the moon and about a week after launch, Lunar Prospector will settle into its mapping orbit, skimming about 60 miles above the lunar surface. The neutron spectrometer, the latest in a long line of such instruments built for Los Alamos' nonproliferation programs for the past 35 years, detects neutrons that escape into space when cosmic rays strike the upper layers of the moon's surface. The spectrometer measures neutrons it encounters in three different ranges of speed, or energy. Neutrons that strike heavy elements bounce around like a ping-pong ball without losing much energy, whereas neutrons bouncing against hydrogen -- the lightest element and a principal component of water -- give up their energy to the hydrogen relatively quickly. The detector will see very few medium-energy neutrons in an area with hydrogen, because the high-energy neutrons generated by cosmic rays quickly become lower energy neutrons. If the detector sees few or no medium-energy neutrons, water must be present. Feldman said the instrument could give indications of water within a few days of beginning its mapping work, if a lot of water is present, or it could take weeks to make a determination. "If it's a small spot of ice in a large field of view, it will produce only a small dip in the data," he explained. "That will take a lot of tweaking and a lot of interpretation, and I'll be loath to say anything definite until we're really sure." Prospector also will carry a Los Alamos gamma ray spectrometer experiment that will provide global maps of the major rock-forming elements on the lunar surface. The instrument records the spectrum of gamma rays and neutrons emitted by elements contained in the moon's crust. The map of certain elements will provide clues to lunar evolution, and tell future lunar '49ers where to look for such valuable elements as aluminum, iron, uranium and titanium. The moon was sampled during Apollo missions 25 years ago, but along a near-equatorial orbit that covered only 20 percent of the moon. Lunar Prosepctor will map the elements over the remainder of the moon's surface. An alpha particle spectrometer from Los Alamos will give scientists more information about the moon's minor -- by Earth standards -- seismic activity. Lunar magma that cooled just beneath the outer crust contains uranium, and as uranium-238 decays it produces radon. If moonquakes vent radon to the surface, the spectrometer will capture the evidence by recording the alpha particle signatures of radon's radioactive decay . The three spectrometers were tested for a year and integrated with Lunar Prospector by Lockheed Martin, which built the spacecraft. The mission is scheduled to last one year. Lunar Prospector is part of NASA's Discovery Mission series. Alan Binder of Lockheed-Martin Missile and Space Corporation is the principal investigator. Southwest Research Institute in Texas provided electronics for the Los Alamos instruments. Los Alamos staff members Bruce Barraclough and Dick Belian are scientific collaborators on the project and Ken Fuller of Los Alamos' Space Engineering Group was the principal engineer. Los Alamos National Laboratory is operated by the University of California for the U.S. Department of Energy.
--------
1-> Researchers Search For Basic Building Blocks Of Matter
IOWA CITY, Iowa -- The world's most advanced search for the basic building blocks of matter -- a quest begun in ancient Greece -- will be conducted with the help of physicists from the University of Iowa and Iowa State University. The Iowa research connection, valued at more than $5 million, is the result of a recent announcement by the U.S. Department of Energy and the National Science Foundation that it will contribute $531 million over the next eight years to a $6 billion international project to construct the world's largest atom-smasher. The apparatus, to be built at the CERN particle physics laboratory on the border between France and Switzerland by 2005, will draw upon the work of researchers from nearly 100 international universities, such as Harvard and MIT, and will include particle detection devices built at the University of Iowa. To understand where the Iowa research fits into the project, one need only know that the atom-smasher will use magnets to accelerate two beams of protons so that they race around a 16.5-mile oval track in opposite directions. When they meet in a head-on collision, the protons will break apart, spraying particles in different directions. The job of detecting those particles will fall, in part, to UI physics professors Yasar Onel and Edward McCliment and researcher Nural Akchurin, together with ISU physics and astronomy professors John Hauptman and E. Walter Anderson, who will design a part of one of the particle detectors. In addition to their design work, Onel serves as U.S. coordinator and Akchurin is the technical manager for the international project. The detector itself, called the forward calorimeter, will measure the energy of particles moving in a forward direction after the proton collision has taken place at the center of an energy mass of 14 TeV, or 14 trillion electron volts -- enough energy to replicate, in miniature, conditions present in the early universe. The calorimeter's quartz fibers will give off light, called Cherenkov radiation, when struck by particles from the proton collisions. According to Onel: "We don't need to see the particles themselves to know that they're there, only to measure the light they give off." He adds that the field of elementary particle physics is very exciting, as one tries to unravel the building blocks of nature. Scientists know that atoms are composed of electrons and nuclei, and that the nuclei are made up of protons and neutrons. Neutrons are constructed of quarks. But that is where things end, at present. "It may be that quarks and electrons are the fundamental building blocks, or they may be composed of something even more basic. No one knows," Onel says. "Or we may discover a totally new physics," he adds. "There is enormous potential for discovery with this new machine."
--------
2-> How Will Increased Ultraviolet Radiation Affect Forests?
Consider these few facts: Forests occupy about 31 percent of the Earth's land area. Forests make up over 90 percent of the Earth's biomass. Forests account for two-thirds of the carbon that is "fixed" or withdrawn from the atmosphere. Forests thus play a major role in how much carbon is free in the atmosphere, which in turn affects the magnitude of the "greenhouse effect." Forests regulate not only the flow of water, but local, regional and global climate. Now add another fact: We know next to nothing about what effect increased ultraviolet-B radiation will have on forests as the stratospheric ozone shield continues to disintegrate over the next century. Also, since global processes do not operate in isolation, how will the UV-B effect on forests affect their ability to cope with anticipated global warming? Most research on the effect of increased UV-B on plants has been done on annual plants, such as crop plants, says tree physiologist John Bassman. But trees are much different in their relationship to increased UV-B. The most obvious difference is their longevity and the resulting increased exposure to UV-B radiation. With conifers, a single needle can stay on the tree--and be exposed to UV radiation--for up to 20 years. Another difference is trees' annual dormancy and their overall exposure to greater environmental extremes. Also, their large size results in considerable physiological complexity, such as the transport of water from its roots to leaves far above the ground. Finally, whereas an annual plant might be able to adapt to climatic change, a tree is slow to adapt because it is so slow to respond genetically. Although public perception of increased UV-B radiation has been diverted lately by global climate change, the problem has not gone away. In fact, even if ozone-depleting emissions were halted immediately, the detrimental gases already in the stratosphere break down slowly. Scientists estimate that their effect on the ozone layer could continue for another 100 years. So what effect, ask Bassman and others, will the resulting enhanced UV-B exposure have not only on individual trees but on forest ecosystems? Studies on agricultural species have shown that about 60 percent are at least moderately sensitive to high levels of UV-B radiation. Among other effects is a lower rate of photosynthesis. One of Bassman and his colleagues' primary interests is what effect UV-B might have on RUBISCO, or "ribulose 1,5-bisphosphate carboxylase oxygenase." Ultraviolet-B radiation affects many important proteins, including DNA and RNA. RUBISCO is not only the most abundant protein on Earth, it is the primary enzyme responsible for capturing carbon dioxide from the atmosphere. Based on work that's been done on crop and herbaceous plants, Bassman and others believe that increased carbon dioxide and global warming will offer a buffer against UV-B damage--to a certain extent. Increased carbon dioxide can enhance plant growth. "But other things associated with that make the problem less than straightforward," says Bassman. From the broadest possible perspective, he continues, carbon dioxide is going to have a positive effect at least on physiology. But combine that with the negative effect of UV-B radiation on photosynthesis and the result is far from certain. One thing Bassman worries about is whether the increased UV-B radiation will change carbon allocations within trees. They may have to put more of their photosynthetic products into protective mechanisms at the expense of growth. There could be more severe direct effects, also, says Bassman. But considering the role of trees in regulating atmospheric carbon, even small effects could in turn have large effects on climate change. One earlier series of studies on loblolly pine showed that enhanced radiation caused a 20 percent decrease in biomass. Another study on sweetgum, however, resulted in no reduction in biomass, even though it did affect the rate of leaf elongation. As with other plants, the effect of increased UV-B seems to vary from species to species. Along with Gerald Edwards and Ron Robberecht, Bassman has begun a project to gather more information on the effect of enhanced UV-B radiation on trees. But doing so is not a simple matter. In fact, one reason so little is known is the difficulty in exposing trees to measurable amounts of UV-B radiation. Ambient UV-B exposure varies constantly. Clouds, the angle of the sun, and the density of the surrounding canopy all affect how much radiation a tree is receiving. Only three or four studies across the country are attempting to mimic the natural environment outside the greenhouse. Bassman has rigged up a system that allows him to measure the UV-B output of the sun. It tracks the output second by second, then supplies multiples of that amount of UV-B to the trees, simulating natural exposure to enhanced levels of radiation. So if a cloud goes over the sun, the lamp levels correspondingly go down. As the cloud passes, the light level goes back up. The trees are subjected to the amount of extra UV-B caused by a 25 percent reduction in stratospheric ozone and a 50 percent reduction. Bassman and his colleagues are examining the effect on four species: poplar, red oak, ponderosa pine, and Douglas-fir. They will consider UV-B's effect on a number of processes: growth and biomass distribution, carbon uptake, carbon allocation and its partitioning into various chemical fractions, and leaf development, anatomy, morphology and aging.
--------
3-> Drug Slows Progression Of Lou Gehrig's Disease
HOUSTON--(Dec. 22, 1997)--Myotrophin, an experimental drug for Lou Gehrig's disease, appears to slow the disease's symptom progression. Results of a nine-month study involving 266 patients at eight North American medical centers were reported in the December issue of the journal Neurology. "Patients taking a high dose of the medication progressed 26 percent slower than patients on the placebo or inactive drug," said Dr. Eugene Lai, a neurologist at Baylor College of Medicine in Houston and lead author of the journal article. "They also experienced a slower decline in quality of life." Lou Gehrig's disease, also called amyotrophic lateral sclerosis or ALS, involves the progressive breakdown of motor neurons, the nerve cells that control muscular activity. It causes severe muscle weakness, difficulty in speaking, swallowing and breathing, and ultimately death. "To ALS patients, slowing progression can mean maintaining arm and leg strength longer, delaying the onset of speech problems and prolonging mobility and independence," said Dr. Stanley Appel, director of the MDA/ALS Clinic at Baylor and The Methodist Hospital and Baylor chairman of neurology. The study drug, Myotrophin or recombinant human insulin-like growth factor-I (rhIGF-I), is a man-made form of the natural protein insulin-like growth factor-I. This protein is important for normal human growth and development. "The growth factor may act in a variety of ways on the motor neuron, nerve and skeletal muscle. It has the ability to induce nerve sprouting and growth and to promote nerve cell survival," Appel said. "These actions are important to ALS patients." The medication was given twice daily as a shallow injection under the skin, and participants received either a low dose, a high dose or a placebo. Patients were evaluated monthly using the Appel ALS rating scale to assess speech and swallowing, respiratory function, arm and leg muscle strength, and arm and leg function. The Sickness Impact Profile measured participants' perceptions of their quality of life, including psychological well-being, daily living and disability. "The drug proved to be well tolerated and simple for patients to administer," Lai said. Treatment-related side effects were relatively mild and included injection-site inflammation, hair change, knee pain and facial swelling. Less than five percent of the patients left the study due to the side effects. Myotrophin currently is under review and pending marketing approval by the Food and Drug Administration.
--------
4-> Mental Exercise May Help Stave Off Parkinson's
LAWRENCE -- People who have Parkinson's disease may someday find themselves undergoing a mental training regimen that helps them respond better to the drugs they take and to avoid surgery. But first, the results of animal studies by Richard E. Tessel and his colleagues must be found to work in humans. "Our studies hint that exercising your brain every day might be just as important as 20 minutes of physical exercise," said Tessel, professor of pharmacology and toxicology at the University of Kansas. Work by Tessel and Stephen R. Schroeder, director of the KU Institute for Life Span Studies, will appear in early 1998 in the journal Brain Research. Most scientists interested in diseases like Alzheimer's and Parkinson's, which stem from massive loss of brain cells, focus on drugs and surgery, Tessel said. But Tessel's work is related to research at other universities suggesting that lifestyle can make a difference in the progression of such diseases. "Several have hinted that the more education you have, the less likely you are to get Alzheimer's or Parkinson's," he said. The root cause of Parkinson's is the lack of a chemical messenger, dopamine, that serves as a relay between certain nerve cells in the brain. The relationship of Parkinson's to dopamine is underscored in the name of the drug commonly used to treat Parkinson's: L-dopa. In their experiments, Tessel and Schroeder used four sets of rats. Two of the sets contained normal rats. The other two sets contained rats that had had almost all of their dopamine-making cells killed, in effect inducing Parkinson's in them. One set of normal rats and one set of Parkinson's rats were put through a training regimen that required them to push various levers different numbers of times to get food. A second set of normal rats and of Parkinson's rats received no training. After the training, Tessel and Schroeder gave all the rats a dopamine-like drug called apomorphine. They wanted to see if the trained Parkinson's rats that received apomorphine would behave better than the untrained Parkinson's rats that also got the drug. The researchers found that the normal rats showed little change in behavior in response to the apomorphine, Tessel said, but the Parkinson's rats differed sharply in their response. "The Parkinson's rats that had NOT been trained were highly excited and ran around in their cages after apomorphine," Tessel said. "The Parkinson's trained rats that received apomorphine acted exactly like the normal rats." In experiments elsewhere, scientists have used rat-brain fetal tissue implants containing lots of dopamine-making cells to achieve a similar calm in rats that had had their dopamine-making cells killed off and then received a dopamine-like drug. Tessel said he theorized that the training regimen helped by making more dopamine available in the brains of rats with induced Parkinson's. If humans follow the same patterns, he speculated, training of some kind might reduce their need for L-dopa -- or the future equivalent of that popular drug -- or surgical therapy or maybe a combination of surgery and L-dopa.
--------
5-> Researchers Discover New Genetic Risk For Alzheimer's Disease
St. Louis -- Investigators at Washington University School of Medicine in St. Louis and the University of Madrid, Spain, have found a genetic variation that appears to increase the risk of developing Alzheimer's disease. This finding provides a link between two substances previously implicated in the disease - APOE, a cholesterol-carrying protein, and beta-amyloid, a protein that forms plaques in the brain. Replicating the results of this preliminary study would raise hopes that drugs in the pipeline may be effective against the disorder, which affects about 4 million Americans. Since 1993, scientists have known of a relationship between the APOE gene and Alzheimer's disease. But no one knew of a mechanism by which APOE might lead to the disorder. In addition, there are several forms of APOE, but only the form known as APOE e4 was closely related to the risk for Alzheimer's disease. The new study, reported in the January 1998 issue of Nature Genetics, shows that other forms of APOE also can increase the risk of Alzheimer's disease and suggests how this might happen. "We've discovered changes in the APOE gene that can alter your risk, and we found those changes in the regulatory part of the gene, which controls how much APOE protein our cells produce," said Alison M. Goate, Ph.D., associate professor of genetics in psychiatry and a lead author of the study. Goate's team at Washington University collaborated with Spanish researchers, led by Fernando Valdivieso, Ph.D., professor and chair of molecular biology at the University of Madrid. The two groups studied individuals with Alzheimer's disease and compared them with individuals of the same age who did not have Alzheimer's disease. In both the American and the Spanish subjects, the investigators found three normal variations, or polymorphisms, in the promoter region of the APOE gene. The promoter is a stretch of DNA that determines how active a gene becomes. One of the genetic variations was linked to a higher frequency of Alzheimer's disease. It caused a higher level of expression of APOE, regardless of whether the APOE gene was the e4 variety. Subjects with this polymorphism were approximately three times more likely to have Alzheimer's disease than those who did not have the variation. When the researchers removed the data from subjects who carried an APOE e4 gene, the risk was four times higher than in people without the polymorphism. After confirming the relationship between the genetic variation and risk of Alzheimer's disease in both a Spanish and an American population, the investigators did test-tube experiments to determine how this polymorphism affected production of the APOE protein. They found that it caused higher levels to be produced. "So we believe that the higher levels of APOE expression are contributing to an increase in the risk for Alzheimer's disease," Goate explained. "And we believe the mechanism involves another protein called amyloid." In animal models of the disease, other researchers have shown that increased APOE levels can raise the amount of amyloid that's deposited in Alzheimer plaques. "So it would seem that a likely explanation for our data is that by increasing the level of APOE expression, this polymorphism might increase the amount of amyloid you deposit in your brain. In turn, that could increase your risk of getting Alzheimer's disease," Goate suggested. Amyloid protein contributes to the development of senile plaques, which dot the brain's cortex in Alzheimer patients. Little is understood about the causes of these deposits. "From our data, we might predict that APOE acts as a chaperon for the amyloid protein. With what we know from in vitro studies, it would make sense that APOE is inducing more of the normally soluble amyloid to deposit in the brain as plaques," Goate explained. "I think this is the first result that has really suggested a connection between APOE expression and amyloid deposition, and it makes me more optimistic that the drugs being developed to inhibit amyloid production or deposition may be effective therapies for Alzheimer's disease." Next, Goate and colleagues will try to determine whether the genetic variation in APOE really does increase amyloid deposition. Studying brains postmortem, Goate hopes to learn whether individuals who had the high-expressing APOE variation also had higher levels of amyloid in the brain. Goate does not believe that this variation in the APOE gene is sufficient to cause Alzheimer's disease on its own. "I think several genes will turn out to be involved in Alzheimer's diseases in the plural," she said. "There may be many different ways of producing the dementia that we associate with the disease, but this could be teaching us about one of them." The Washington University research was funded by the National Institutes of Health and the Metropolitan Life Foundation.
--------
6-> New Molecular Switch Is The Key That Unlocks DNA Repair
When mismatch repair genes go awry, the result may be colon cancer. Such genes are part of the intricate molecular machinery that fixes the cell when for some reason, cell replication doesn’t work correctly. Now, molecular geneticist Richard Fishel, Ph.D., professor of microbiology and immunology, along with colleagues Scott Gradia and Samir Acharya, Ph.D., at the Kimmel Cancer Center and Jefferson Medical College of Thomas Jefferson University in Philadelphia have uncovered a new molecular switch by which mismatch repair is triggered. The work has the potential to enable researchers to specifically target anticancer drugs to these genes. According to Dr. Fishel, who was a co-discoverer of the hMSH2 and hMLH1 colon cancer tumor suppressor genes, only two genes--MSH2 and MLH1--are altered frequently in Hereditary Nonpolyposis Colorectal Cancer, which accounts for some 10 to 15 percent of all colorectal cancers. “We’d like to know why alterations in only two of the five known mismatch repair genes cause cancer,” he says. [The other mismatch repair genes are hMSH3, hMSH6 and hPMS2. They function as protein complexes: hMSH2-hMSH3, hMSH2-hMSH6 and hMLH1-hPMS2] Dr. Fishel and his co-workers have identified the function of two of those key genes in the mismatch repair complex--hMSH2-hMSH6. “Scientists had been trying to understand the real function of these genes since their discovery,” Dr. Fishel says. [Now we know that] “they serve as a regulatory molecular switch. Because we understand the true function, we are provided with a foundation to target the process as a whole.” Dr. Fishel and his colleagues report their results in the December 26 issue of the journal Cell. According to Dr. Fishel, a mismatch of the DNA nucleotides, or building blocks, may occur during cell replication. In replication, precise nucleotide pairing is essential. Researchers have known that in bacteria a protein, MutS, recognizes a replication error and binds to the mismatched nucleotides. In human cells it is the hMSH2-hMSH6 protein complex that attaches to the mismatched nucleotides. Other proteins, such as the bacterial MutL (or in humans, hMLH1-hPMS2), are involved in relaying these mismatch recognition signals. This occurs by assembling the repair machinery which then orchestrates the correction of these errors. “Without hMSH2 or hMLH1 the cellular DNA becomes unstable [genome instability], errors accumulate and the result is cancer,” Dr. Fishel explained. In their experiments, the scientists measured the initial binding of hMSH2-hMSH6 to a mismatch of the nucleotides G (guanine) and T (thymine) in the DNA. Normally, G (guanine) pairs with C (cytosine) and T (thymine) pairs with A (adenine). A G-T pair is a mismatch. Dr. Fishel notes that their results support a new model to explain the triggering of the mismatch repair mechanism. This is based on the association--or disassociation--of the protein complex, hMSH2-hMSH6, from the mismatched nucleotides. The scientists found that the molecular switch is “off” when a molecule of ATP--adenine triphosphate--is attached to the complex. When a phosphate molecule is removed, leaving ADP--adenine diphosphate--the switch is “on” and bound to the mismatch. Dr. Fishel believes that the correct assembly of the repair machinery allows the switch to function properly. “hMSH2-hMSH6 binds [to the mismatched nucleotide pair] and once this whole complex is assembled, it flicks the switch,” he says. According to Dr. Fishel, “these switches and regulators” may be targets for future anticancer drugs. “Any cellular manipulation of its DNA is an inherently risky process since loss or alterations can result in mutations or cell death,” Dr. Fishel says. “To accurately perform such processes, it is likely that the cell assembles all of the necessary components. Then a switch initiates the actual event. What we’ve found is one of those switches, and that’s the novelty". According to Fishel, this is the first identification of such a switch in DNA metabolism. “This a real basic science finding, and it will change the way we think about DNA metabolic events,” he contends. “It has profound implications regarding other DNA processes. From a cancer standpoint, there is clear genomic instability in most tumors,” he says. “Yet we don’t find mutations in the mismatch repair genes in all of these cancers.” Fishel believes that similar regulatory switches may be involved in these other cancers. "Now that we understand one of these switches, we can look for similar switches in other cellular DNA processes and their role in the development of cancer". According to the American Cancer Society, colon and rectal cancer is the third most common cancer in the nation, with some 200,000 new cases diagnosed annually.
--------
7-> “Night Creatures Of The Kalahari” On NOVA
Make a date with a real aardvark. “Night Creatures of the Kalahari” on NOVA Tuesday, January 6, 1998 at 8pm ET on PBS You never know what will emerge after sunset on the parched plains of southern Africa’s Kalahari grasslands—unless, of course, you are a NOVA film team documenting the life, loves, and peculiar habits of some of the world’s most exotic and rarely-seen nocturnal creatures. NOVA viewers get to check in at this remarkable night life, in “Night Creatures of the Kalahari,” airing Tuesday, January 6, 1998 at 8pm ET on PBS (check local listings). By day, zebras, wildebeest, and other grazing animals roam the vast Kalahari grasslands. By night, a new cast of characters takes the stage—critters with discriminating appetites and peculiar ways, such as bush babies, meerkats, striped polecats, spring hares, brown hyenas, and aardvarks. “Night Creatures of the Kalahari” was shot with painstaking patience and stealthy camera technique over a two-year period. For example, the extraordinary underground footage was made using camera blinds that were set in burrows, while the filmmaker simply waited for the animals to move in—which they did. Above ground, NOVA captures an amazing collection of veldt vignettes. There is the aardvark digging furiously into an anthill while vacuuming up the tasty contents, a battle of wills between a bush baby and a giant stick insect, a lion pack calmly relishing a fresh kill, and an exquisite once-a-year mating ritual of a fungal termite colony—attended by a ravenous giant bullfrog. NOVA viewers will also discover the difference between a hedgehog and a porcupine, see how bush babies in love execute gymnastic leaps of up to fifteen feet in a single bound, and learn the true nature of one of the most misunderstood and maligned of nature’s creatures: the hyena. 	Because of its eerie nighttime call and secretive, scavenging nature, the hyena is considered an animal of doom and misfortune among many African people. But NOVA shows its more sympathetic side. Even while scavenging a thoroughly rotten ostrich egg—something of practically no interest to most other creatures—its determination and creativity are quite endearing. “Night Creatures of the Kalahari” is a NOVA production in association with Partridge Films Ltd. The executive producer for Partridge Films Ltd. is Michael Rosenberg, produced and photographed by Ken Oake, written by Alan Miller, narration written by Stephen Sweigart. Now in its 24th season, NOVA is produced for PBS by the WGBH Science Unit. The director of the WGBH Science Unit and executive producer of NOVA is Paula S. Apsell. Major funding is provided by the Park Foundation, Inc., dedicated to education and quality television. Additional funding is provided by the Corporation for Public Broadcasting and public television viewers. Press contact: Paul Marotta, WGBH Boston, 617-492-2777 x4427paul_marotta@wgbh.org Photography contact: Lisa Cerqueira, WGBH Boston, 617-492-2777 x5334lisa_cerqueira@wgbh.org 
--------
8-> New Evaluation Service Helps Institutions Using Animals In Science
Rockville, Md. -- Institutions that use animals in research, teaching or testing can now receive an expert, independent evaluation of their animal care and use programs through AAALAC International (the Association for Assessment and Accreditation of Laboratory Animal Care International).   The new service is called a "Program Status Evaluation," and allows institutions to better assess the quality of all aspects of their animal research programs, including animal husbandry, veterinary care, institutional policies, and the facilities where animals are housed and used. Because good science demands quality animal care, the evaluation will not only promote the well-being of laboratory animals, it will help validate the results of research using animals.  It can also serve as the first step toward achieving AAALAC Accreditation, a distinction earned by more than 620 universities, companies, hospitals and other research facilities in 10 countries that have achieved excellence in animal care and use. A Program Status Evaluation allows institutions to determine where they stand in terms of meeting AAALAC standards, which are based on the principles outlined in the widely-recognized Guide for the Care and Use of Laboratory Animals (National Research Council, 1996).  The evaluation also helps institutions gain a better understanding of the accreditation process before they officially apply. Although entirely separate from AAALAC's traditional accreditation program, a Program Status Evaluation is similar in procedure.  To participate, institutions request an application package from the AAALAC office.  The application process includes developing a comprehensive "Program Description" of the institution's entire animal care and use operation.  This involves conducting an intensive self-assessment which identifies strengths and weaknesses, raises internal awareness of issues surrounding animal well-being, and helps institutions understand exactly what is involved in achieving accreditation. After the application form and Program Description are completed and returned to the AAALAC office, an on-site evaluation is scheduled.  Evaluation teams are led by AAALAC Associate Director, Kathryn A. Bayne, M.S., Ph.D., D.V.M., a Diplomate of the American College of Laboratory Animal Medicine.  Teams also include former members of AAALAC's Council on Accreditation—individuals who are expert in the fields of veterinary medicine, laboratory animal science or animal research, and are committed to humane animal care and use in science.  The on-site evaluation team provides specific guidance on how to improve deficient program areas.  Recommendations are provided in writing after the visit. "Introducing the on-site Program Status Evaluation service is a natural extension of AAALAC's mission.  We have received numerous requests for such a service, particularly from institutions outside of the United States.   These institutions may be less familiar with AAALAC's accreditation program, and are perhaps uncertain about how their program compares with AAALAC standards.  We hope the evaluation service will help more institutions reach accreditable levels, and encourage them to go through the formal process," said John Miller, D.V.M., executive director of AAALAC International. Institutions that complete the Program Status Evaluation process and find they meet AAALAC standards can resubmit an updated Program Description for entry into the accreditation program.  A new team of current Council members and consultants will then conduct the actual accreditation site visit.  The team's evaluation will be reviewed and deliberated by the full Council, which will determine official accreditation status. Fees for Program Status Evaluations are based on the direct cost of conducting the site visit and administrative expenses.  Those that complete the Program Status Evaluation and decide to pursue accreditation will be charged a reduced application fee. To receive more information on AAALAC's Program Status Evaluation service or an application, call 800/926-0066, 301/231-5353 or send e-mail to accredit@aaalac.org. Established in 1965, AAALAC International is a private, nonprofit organization that promotes the humane treatment of animals in science through a voluntary accreditation program and evaluation service.   Institutions seeking accreditation receive independent, expert assessments of their animal care and use programs.   Those that meet or exceed applicable standards are awarded accreditation.   Attaining and maintaining accreditation demonstrates a commitment to the responsible and ethical treatment of animals used in research, teaching and testing.   More information on AAALAC International and its accreditation program and evaluation service can be found on AAALAC's Web site at http://www.aaalac.org, or by calling 800/926-0066 or 301/231-5353.
--------
9-> Lakes And Bogs Reveal Historical Mercury Trends In Maine
Contact: 
--------
10-> Vanderbilt University Engineers Developing Robotic Insects
NASHVILLE, Tenn. - Two Vanderbilt University mechanical engineering professors are developing a tiny insect-like robot, about a third the size of a credit card, which will have applications for military and intelligence-gathering missions. Professors Ephrahim Garcia and Michael Goldfarb were recently granted a three-year contract to produce robotic insect crawlers. The grant was awarded by the Defense Advanced Research Projects Agency (DARPA). Garcia and Goldfarb are also exploring the development of small flying robotic insects (microflyers) for military purposes. The insects could be used to explore a minefield or to support a small infantry unit by seeing over the next hill, an age-old military problem. Knowing where the enemy is and what its strengths are would allow for indirect fire on the enemy. This would allow a small unit of soldiers to project more fire on the enemy than they themselves are carrying. The researchers say the crawlers could also be used to support law enforcement units in urban environments. If terrorists were occupying a building and holding hostages, the crawlers could enter the building and feed back video images and motion-sensing data showing exactly where the terrorists and hostages were located. The two Vanderbilt researchers expect to produce a rudimentary prototype of the crawler in the summer of 1998 and then refine it during the next two years. The crawlers would be equipped with microelctromechanical systems (MEMS) (more) for sensing their surroundings. Garcia and Goldfarb plan to utilize "elasto-dynamic locomotion" to power the insects, using piezoelectric actuators-thin ceramic-coated metal plates that bend when electricity is supplied to them and then snap back to original form when the power is off. The power would come from a small battery similar to those used in watches. The crawler would have a piezoelectric actuator that would make the body's two lengthwise segments oscillate back and forth, Garcia said. One-piece legs attached to the body would carry the insect forward. A space in the center of the body would contain the battery and the payload, which might be a microcamera or sensors that detect sound or heat. Most previous robotic research has involved devices with multiple joints, each with its own motor or actuator. But the Vanderbilt researchers believe their use of piezoelectric actuators is an advance over previous motor technology. Piezoelectric actuators are capable of turning more than 90 percent of electrical power into movement, whereas an electric motor has an efficiency of about 60 percent, Garcia said. For the microflyer, engineers are borrowing from entomological research. Goldfarb and Garcia said scientists have discovered that an insect's wings flap five times faster than its brain can command them to. Scientists have also learned that insects use their muscles to flex their entire exoskeletons, which are in effect resonating to keep the wings in motion, Goldfarb said. The researchers have come up with a metal skeleton they believe will imitate the vibration and magnify the movement of the piezoelectric actuators powering the wings. Garcia and Goldfarb are also working on "swarm dynamics"-the right combination of crawling and flying bugs for conducting a search. The robotic insects will be so small and lightweight (about an ounce) that an individual combat soldier could easily carry large numbers of them in addition to his basic equipment. They will also be cheap and disposable.
--------
11-> Molecule May Help Boost "Good Cholesterol"
Birmingham, Ala. — For the first time ever, cardiovascular disease researchers can now get a good look at human apolipoprotein A-I (apo A-I) — the major protein component of high density lipoprotein (HDL). HDL is known as the "good cholesterol" because it protects against heart disease, the country's leading cause of death.  Scientists caution that while these results may not immediately lead to a new medication to control cholesterol, another very important piece in the puzzle has been revealed in the fight against heart disease. "A lot of science is done ‘under the lamp post,' so to speak," says David W. Borhani, Ph.D., a chemist at Southern Research Institute in Birmingham and leader of the apo A-I crystallography project. "Our new apo A-I structure has made that light a whole lot brighter now — giving researchers a clear picture to focus on." In a paper recently published in the Proceedings of the National Academy of Sciences USA, researchers at Southern Research Institute (SRI) and the University of Alabama at Birmingham (UAB) describe how they determined the three-dimensional structure of  apo A-I using x-ray crystallography — a method widely used to study the structures of biological macromolecules at atomic resolution. X-ray crystallography is also being used increasingly in rational drug design. The new apo A-I structure is the result of a collaboration between Southern Research's Borhani and UAB professors Jeffrey A. Engler, Ph.D. and Christie G. Brouillette, Ph.D., and their graduate student Danise P. Rodgers, Ph.D. Scientists have studied lipoproteins — such as HDL — for decades hoping to advance cardiovascular disease research and drug development. Human clinical trials have shown that the higher the HDL level in a person's blood, the lower the risk of developing atherosclerosis and coronary artery disease. Understanding the structure of apo A-I is key to understanding this protective effect of HDL. The Birmingham apo A-I model is important because it suggests what apo A-I looks like when bound to lipid in the HDL particle. As the researchers began to define this egg-shaped model, they realized its potential impact on the future of cardiovascular studies. 	"We began to call it our ‘Fabergé Egg'," said Engler, the team's molecular biologist, "because it was so rare and valuable." Until now, scientists studying apo A-I have had to rely on educated guesses about the three-dimensional structure of this critical component of HDL. These guesses — or models — focused on two possible alternative structures: the "belt" model and the "picket fence" model. 
--------
12-> Ready, Set, Fight! -- 'Dispatcher' May Help Plants Fend Off Many Different Diseases, Researcher Says
A 'dispatcher' gene--described in the Dec. 12, 1997, issue of Science--seems to juggle assignments for many `sentry' genes in a model plant system and may ultimately help researchers design hardier, more disease-resistant food plants, a University of Delaware scientist says. "This dispatcher, the NDR1 gene, apparently processes a great deal of disparate information from many sources upstream to coordinate the disease-resistance response in this model plant--Arabidopsis thaliana, a common mustard weed," explained Allan D. Shapiro, an assistant professor in UD's Department of Plant and Soil Sciences. "It's possible that other dispatcher genes, similar to NDR1, may mediate disease-resistance in crops, too." (Shapiro coauthored the Science paper, with lead author Karen Century, senior research team member Brian J. Staskawicz of the University of California at Berkeley and others.) Researchers worldwide are scrambling to identify individual genes that protect crops from specific pathogens, Shapiro notes. Already, researchers have described several of these disease-fighting genes in corn, rice and tomatoes. But, he says, resistance genes are often "highly specific," targeting only a particular pathogen. The NDR1 gene, however, seems to dispatch messages from many resistance genes, allowing Arabidopsis to defend itself against a broad range of attackers, Shapiro says. If NDR1 is mutated, he reports, the plant becomes susceptible to numerous strains of the bacterial pathogen, Pseudomonas syringae, and the fungal pathogen, Peronospora parasitica. Exactly how NDR1 translates messages from different pathogens and resistance genes remains a mystery--for now. But ongoing research may point to the exact mechanisms at work. "The ultimate aim," Shapiro says, "is to engineer more disease-resistant plants by understanding how the process works in nature and then souping it up." After identifying NDR1 as a critical dispatcher by isolating mutant plants lacking a functional copy of the gene, the research team then used the mutants to go after the gene itself. The approach, called "positional cloning," involves crossing the mutant plant to a different race of Arabidopsis, Shapiro says. The genetic code of the two races is different in numerous places throughout the Arabidopsis chromosomes. By following both the behavior of these differences and disease resistance in subsequent plant generations, the researchers were able to identify NDR1's location: a small region of Arabidopsis chromosome 3. Next, they identified pieces of DNA corresponding to this region of the chromosome. Finally, they identified a smaller piece of DNA containing NDR1 by introducing the DNA into the mutant plants. This extra DNA made the plants disease-resistant, Shapiro notes. Based on the sequence of this piece of DNA, he says, NDR1 was classified as a novel gene--not yet identified by any other researchers. Although the sequence didn't reveal a precise function for NDR1, Shapiro says it provides valuable tools for use in future research. "This is still basic science," Shapiro cautions. "But this work should help us to further delineate both the function of this particular gene, and the signal transduction pathways by which information flows from resistance genes."
--------
13-> Caver Finds A Brave New World, And Brave New Creatures In It
Between January 2 and 9, 1998, Louise Hose, the country's leading female cave explorer and a geology professor from Westminster College in Missouri, will lead a team of scientists into an almost unknown world--where they will study living creatures so bizarre that for centuries no one realized they were alive. Hose's team will travel to southern Mexico to delve into the Cueva de Villa Luz, or "The Cave of the Lighted House." This unique cave has been used for centuries by the Mayan people and their descendants the Chol, for religious ceremonies. Among the Chol, the story that the cave harbor mythical powers is a long tradition. In a sense, the scientists are about to prove the truth of the ancient myth. Hose, who first visited the cave last year, studied and collected samples of what some cavers have ingloriously but descriptively called "snot-tites" growing there. These slimy white masses, known only to grow in this cave, were thought to be bacteria, living in a highly acidic, and largely unlit environment. They excited her scientific curiosity immediately. The truth, Hose found, was much stranger than the odd name or the old myth. She asked Norman Pace, a microbiologist at the University of California at Berkeley, to help her analyze the material. They found that the ugly masses are in fact microbial veils, colonies of microbial life, and found nowhere else in the world. Unlike most plants which use photosynthesis, these microbes oxidize sulfur as their source of energy and life. The veils can thrive in complete darkness, and produce sulfuric acid-- as strong as battery acid-- a degree of acidity rare, if not unique, in nature. Hose, a cautious scientist, is ecstatic about the possibilities of the Cueva de Villa Luz. "This is potentially the most significant cave discovery in the past ten years or since Lechuguilla," a large but mostly dead cave at Carlsbad Caverns National Park in New Mexico. Space scientists curious about life elsewhere in the solar system have studied Lechuguilla because of the possibility that it may at one time have harbored such creatures as are now living in Cueva de Villa Luz. Hose calls this "the most significant cave discovery as it relates to microbiology and geo-microbiology" because it offers "a different scenario of how life and ecosystems can work in a cave system. It's a world-class natural laboratory." Hose leads an elite team of expert scientists in all aspects of caves from all across the country, including cavers, hydrologists, mineralogists, and biologists, in January. For more information about this incredible journey, contact Louise Hose at Westminster College at 573-592-5303, or try Dan Diedriech in the college news office at 573-592-1311. Norman Pace, the microbiologist at the University of California in Berkeley will not take part in the expedition, but you can contact him at 510-643-2571.
--------
14-> Estrogen Replacement May Help Slow Decline In Memory In Post-Menopausal Women
A new long-term study from the National Institute on Aging (NIA) suggests that use of estrogen replacement therapy (ERT) by post-menopausal women may help slow normal age-related decline in memory. By looking at estrogen use in 288 women enrolled in the NIA's Baltimore Longitudinal Study of Aging (BLSA) between 1978 and 1994, researchers were able to examine the relationship between estrogen therapy and short-term visual memory. The study, in the December 1997 issue of Neurology (Vol. 49), is the first to document the effects of estrogen on age-related changes in memory over a long period of time. The investigators collected information on ERT use during visits to the NIA for memory testing as part of the BLSA and were able to show that women who were on ERT during the memory testing period performed better than women who had never received treatment. Furthermore, some participants who began ERT between their regular visits to the NIA were able to maintain stable memory performance whereas women who never took ERT showed predicted age-associated decreases in memory over a six year period, on average. These findings may be of interest to the 36 million women in this country who have been through menopause, and may be another factor to take into consideration when thinking about starting ERT. Estrogen replacement is not recommended for all post-menopausal women; often, use of estrogen and an additional hormone, progestin, is advised. This study of significant long-term effects of ERT on memory was made possible by use of health data from the BLSA, which, now entering its 40th year, is one of the largest and longest ongoing studies of aging in existence. Using the BLSA database, the researchers looked at 116 women on ERT and 172 who had never used any type of hormone replacement therapy. On each visit to the NIA, the women in the BLSA were given the Benton Visual Retention Test (BVRT) where they were shown a series of figures for 10 seconds and then asked to reproduce each figure from memory. The BVRT uses up to 10 different figures in each testing session. Dr. Susan Resnick, Ph.D, principal investigator of the study, says, "because there is no maximum number of errors that can be scored during the BVRT, one way to evaluate performance on the test is to examine the average difference in the number of errors between follow-up visits to the BLSA. Women who were on ERT showed an average difference of about 2 fewer errors than women who were never treated with ERT, which is a significant difference." Previous studies have indicated that verbal memory may be affected by ERT use, but this study is one of the first documenting an effect on visual memory. The effects of ERT on visual memory decline are smaller than those seen in studies on verbal memory decline and may only be evident in studies like this one that include larger numbers of subjects. These findings, in combination with previous studies of verbal memory, suggest that ERT may influence different types of memory. Age-associated increases in errors in the BVRT have been recorded for some participants in the BLSA since 1960. With the help of 34 years of follow-up, NIA investigators have previously shown that BVRT performance can predict cognitive performance as much as 16 to 22 years into the future, and that declines in BVRT performance can be seen in a six-year interval preceding the onset of symptoms of age-associated disease including Alzheimer's disease. Earlier studies from the BLSA and elsewhere have shown that ERT may reduce the risk for Alzheimer's disease. Dr. Resnick states that "animal studies show that estrogen can directly influence structural characteristics of neurons in the brain, particularly in regions that are important for new learning. These regions are also most vulnerable to neuron loss seen in Alzheimer's disease. Thus, lessening the effects of these changes with ERT holds promise as a drug intervention." Dr. Resnick cautions that before anyone can advocate use of ERT to slow cognitive decline or prevent Alzheimer's disease, results from double-blind, controlled clinical trials are needed. ERT trials supported by the NIA are in the planning stages or currently in progress. E. Jeffery Metter, M.D. and Alan B. Zonderman, Ph.D. are the other authors of this paper. The BLSA will celebrate its 40th anniversary in 1998 and currently has over 1,200 research participants enrolled in its studies. The National Institute on Aging is the major Federal funding agency for Alzheimer's disease research, and leads the Federal effort supporting basic, clinical, epidemiological, and social research on aging and the special needs of older people.
--------
15-> Stanford Scientists Solve Immunologic Enigma, Suggesting Way To Improve Marrow Transplants
STANFORD -- Side-by-side papers featured in the December issue of Immunity resolve a mystery of basic immunology while suggesting a new way to improve the success of bone marrow transplantation. The research -- conducted by postdoctoral fellows Markus Uhrberg and Nick Valiante in the lab of Peter Parham, Stanford professor of structural biology -- focused on enigmatic white blood cells called natural killer cells. Natural killer (NK) cells have been largely ignored by immunologists drawn to T and B cells, the big guns of the adaptive immune system. This obscurity is what inspired the Stanford team to learn more about the function of these large granular cells, thought by some to be an archaic remnant of the primitive mammalian immune system. "The NK cell has always been the ugly stepchild," said Valiante. "It was such a black box you knew there had to be something more there." NK cells are characterized by their ability to spontaneously kill abnormal cells in their vicinity. They recognize and attack tumor cells or those infected by viruses, while sparing cells that are healthy. But how they distinguish between healthy and sick cells has been a mystery. In the newly published papers, Parham's group presents the first systematic, experimental evidence validating a leading explanation for this phenomenon. Missing-self model The explanation, known as the missing-self model, was first proposed in 1986. It holds that a person's NK cells somehow "know" when a nearby cell lacks some essential component that characterizes the rest of the cells in that person's body. Early support for the model came in the late 1980s when scientists discovered that NK cells have surface receptors that recognize target molecules on neighboring cells. These target molecules were the so-called transplantation antigens -- the human leukocyte antigens (HLA) that exist on the surface of almost all cells of the body and that differentiate an individual's cells from those of almost everyone else. Immunologists theorized that when an NK cell encounters "self" HLA antigens, it recognizes the target cell as friend, not foe, and leaves the cell in peace; but if it fails to detect these antigens, it views the cell as diseased or an invader, and kills it. This system for recognizing "self" or "missing self" offered a compelling explanation of how NK cells distinguish healthy cells from sick ones, because many tumor cells and virally infected cells turn off their production of HLA antigens to escape detection by other cells of the immune system. Until now, however, no one had methodically tested these predictions and provided definitive evidence that the model actually works. Detailed analysis "The theory was there, but no one had tested it at the level of the organism," said Valiante. "Others had tried, but they were looking only at a single [NK cell-HLA] interaction in many different individuals. Our approach was to look at only a few individuals but to look at all possible interactions that could occur." Valiante and Uhrberg analyzed more than 100 single NK cells from each of two unrelated people who provided blood for the study and whose "self" HLA antigens were known. Valiante painstakingly isolated and cultured individual NK cell clones and documented their killing response to various "self" antigens. Uhrberg devised a DNA-typing method to define which receptors were expressed on each NK cell. With the new typing system, the researchers were able to correlate receptor expression with the cell's ability to recognize "self" antigens. The results showed that every NK cell could be inhibited by one or more "self" HLA antigens. A set of up to 11 different receptors could be displayed on the NK cell surface in many different combinations. With such an array of receptors to choose from, each cell was assured of being able to recognize the relevant "self" HLA antigens and restrain its natural homicidal urges. If the "self" component was missing, the abnormal cell was killed. Improving marrow matches The immediate implication of this work, said Uhrberg, is that NK cells play an important role in the delicate area of bone marrow transplantation. Clinicians are always careful to match transplant recipients with donors who have the same HLA antigens. It is well accepted that introduction of a foreign HLA molecule from the donor will result in rejection of the grafted tissue. However, even when there seems to be a good HLA match, the grafted tissue is sometimes rejected for no apparent reason. The new research points to the patient's NK cells as a culprit. If the recipient's NK cells detect the absence of a "self" HLA antigen in the transplanted tissue, they will begin killing the donor cells. Therefore, in order to improve outcomes, donors and recipients need to be matched not only for their HLA type but also for their NK cell receptors. Prospective matching for these receptors has never been attempted, but the new research shows that compatible HLA antigens and NK cell receptors may be important for better transplant success -- and Uhrberg's typing method provides the tool to achieve it. "If we can extrapolate from these two [human] subjects, and I think we can, by knowing the [NK cell receptor and HLA] types of donors and recipients we can make pretty accurate predictions about possible bad effects," Valiante said. "Physicians are constantly asking which factors improve transplantation outcome," Uhrberg said. "The new data will encourage people to look for these differences in NK cell receptors because they could have an influence on transplantation outcome." Complementary research skills Uhrberg and Valiante attribute much of the project's success to the melding of complementary research skills: Valiante's long history in cellular immunology, Uhrberg's strength in molecular immunology, and Parham's wealth of experience in HLA structure and function. A productive collaboration with Drs. Lewis Lanier and Joseph Philips of DNAX Research Institute of Molecular and Cellular Biology provided the final necessary ingredient. Funding for the project was provided by grants from the National Institutes of Health and the Leukemia Society of America. Timing was also crucial, the researchers agree. "It was the right time to ask one of the big questions [about NK cells]," said Valiante. "Three years ago it was not possible to do these studies. The receptors hadn't been characterized yet; there were no molecular data." Now they are both excited about the publication of their results in Immunity. Look for the NK cell on the cover.
--------
16-> 1997 -- A Year Of Headlines About Women's Health
ROCHESTER, MINN. -- Women's health issues frequently made headlines in 1997 -- from mammograms and pap smears to diet pills and hormone replacement therapy. According to Mayo Clinic's Dr. Julie Abbott, medical editor of Mayo Clinic Women's HealthSource, a new monthly newsletter for women, "I believe this increased coverage is generally positive because it raises awareness of important issues. However, there are not always concrete answers or definite recommendations for women to follow, which can be frustrating and confusing." Part of the clinic's newsletter is devoted to interpreting headline health news. "Our goal is to offer practical interpretations and reliable advice for women who need to make decisions about these health matters," says Dr. Abbott. Here are six of the year's most prominent women's health issues, which Dr. Abbott and other Mayo Clinic physicians addressed in Mayo Clinic Women's HealthSource throughout 1997. The mammogram muddle -- at what age should I start screening? Mayo Clinic Women's HealthSource: The fog is lifting on this issue following new studies from Sweden showing that women who had annual mammograms in their 40s had a 17 percent reduction in the number of breast cancer deaths. Both the American Cancer Society and the National Cancer Institute now believe that mammograms should begin at age 40. However, the two organizations have different recommendations about frequency of having the exam -- every year or every two years. Mayo Clinic Women's HealthSource recommends following a screening schedule developed by your doctor and based on your personal risks for breast cancer. The pap-smear question -- should I ask for a double-check of the results? Mayo Clinic Women's HealthSource: While the Food and Drug Administration approved two new computerized tests to take a second look at your Pap test, Mayo doctors believe that such computerized re-screening isn't necessary for most women. For now, the new testing procedures don't appear to be any better at detecting missed cells than re-screening manually. And the computerized procedure can double the cost of your Pap test. But the choice is yours and some women choose to have a double-check for peace of mind. Mayo Clinic also offers new advice for women who have had a hysterectomy: Continue to have a regular Pap test only if your cervix wasn't removed; you've had cancers of the uterus, vagina, vulva or ovaries; or if you have HPV, a sexually transmitted disease. The diet pill dilemma -- should I take them? Mayo Clinic Women's HealthSource: There's no magic bullet when it comes to losing weight. That fact was made even clearer when Mayo Clinic physicians discovered that some women who took the appetite suppressant combination of fenfluramine and phentermine (fen-phen) developed serious heart valve problems. The 24 women in the report used fen-phen for an average of one year and appeared to be free of heart disease when they began taking the weight-loss medication. To lose weight, it's best to simply follow a low-fat, low-calorie diet and exercise regularly. HRT heft -- will I gain weight? Mayo Clinic Women's HealthSource: Hormone Replacement Therapy (HRT) may actually help prevent the usual post-menopausal weight gain, rather than contribute to it, according to research reports. It's common to put on 10-15 pounds the first few years after menopause. It's also natural for your waist and hips to broaden. But it is a misconception to think that HRT is responsible. In other HRT-related news, more studies are needed before Mayo recommends taking estrogen to prevent osteoarthritis. If you are using estrogen for menopause-related symptoms, you may be getting more benefit then you expected. If you aren't on estrogen, you can help prevent osteoarthritis by maintaining a healthy weight and avoiding injuries to joints. Headlines also raised concerns about drinking while taking estrogen. Mayo Clinic advises that until more studies are done, it is premature to worry that moderate drinking will increase your risk of breast cancer if you're taking HRT. Cancer quandary -- does the birth control pill increase my risk of breast cancer? Mayo Clinic Women's HealthSource: Some studies suggest "yes," others don't. But the results from the Collaborative Group on Hormonal Factors in Breast Cancer analyzed 54 studies and the results showed no increased risk of breast cancer 10 or more years after women had stopped taking the pill, compared to women who had never taken it. Because breast cancer takes years to develop, researchers believe the pill probably enhances the growth of an existing tumor rather than initiating a new one. Screening question -- are breast self-exams beneficial? Mayo Clinic Women's HealthSource: Mayo doctors and The American Cancer Society say that women should not abandon their monthly breast self-exams even though a 1997 study suggested no difference in the number of cancers detected between women who do and women who don't perform the exam. The reason, according to Mayo Clinic, is that women do find their own breast lumps, which can save precious time and get life-saving treatment started sooner. Mayo Clinic Women's HealthSource is a monthly newsletter published with the purpose of providing reliable, timely and easy-to understand medical and lifestyle information women can use to lead healthier lives. For subscription information, call 1-800-351-8963, ext. 68.
--------
17-> Testing Shows Titanic Steel Was Brittle
Recent tests of steel from the Titanic reveal that the metal was much more brittle than modern steel but the best available at the time, a metallurgical engineering professor at the University of Missouri-Rolla says in a paper to be published in the January 1998 issue of Journal of Metals. The steel used to build the Titanic was not as "impact-resistant" as modern steel, according to Dr. H.P. Leighly, a professor emeritus of metallurgical engineering at UMR. But it was the best steel available at the time, says Leighly, who studied some 200 pounds of steel from the wreckage. Leighly's paper, co-authored by UMR metallurgical engineering student Katie Felkins, will appear in the January 1998 issue of Journal of Metals, the publication of the American Institute of Mining, Metallurgical and Petroleum Engineers. Inferior steel wasn't the only reason the luxury ocean liner Titanic sank in the early morning hours of April 15, 1912. Other factors -- such as flaws in the ship's design, the crew's negligence and the lack of lifeboats -- also contributed to the disaster, Leighly says. "The naval architects can point their fingers and say, 'It was bad steel'" that caused the Titanic to sink, Leighly says. "It's easy to point a finger and say, 'Bad steel.' But it's uncomfortable to point at yourself and say, 'Bad design.'" More than 1,500 of the liner's 2,227 passengers died after the Titanic struck an iceberg in the Atlantic Ocean, some 350 miles off the coast of Newfoundland, Canada. The ship struck the iceberg at 11:40 p.m. April 14 and sank at 2:20 a.m. April 15. In 1996 and early 1997, Leighly, Felkins and one other undergraduate student tested steel from the ship's hull and bulkhead in an attempt to figure out why the steel-hulled ship cracked. The UMR analysis is the second -- and most comprehensive -- ever conducted on steel from the Titanic. The only other test was conducted by the Canadian government and involved a Frisbee- sized piece of steel, in which researchers concluded that the ship's hull fractured when it met the iceberg. At UMR, chemical and stress tests of metal samples from the Titanic's hull and bulkhead show that the steel used to build the ship was very inferior to modern steel. Impact tests conducted by Felkins show that the steel from the Titanic was about 10 times more brittle than modern steel when tested at freezing temperature -- the estimated temperature of the water at the time the Titanic struck the iceberg. Tests of the steel's chemical composition also showed a high content of sulfur, oxygen and phosphorus. High levels of those elements cause steel to be more brittle, Leighly says. The chemical analysis also revealed a low level of manganese -- another symptom of brittle steel. Steel with a higher level of manganese is more ductile and less likely to break.
--------
18-> Farmers Benefit From Satellite Technology Research
STARKVILLE, Miss.--Research based on space technology is helping improve crop management decisions for rural farmers. Alex Thomasson, an assistant professor of agricultural and biological engineering at Mississippi State University, leads a multi-state study focusing on ways satellite remote sensing can provide precise agricultural data. Remote sensing uses high-flying sensors to capture and transmit data about the earth. In agriculture, the data can be used to create field maps showing water, fertilizer and other input needs for specific areas within a field. Treating only precise areas can save farmers money while generating environmental benefits. "The use of satellite data to determine the types of inputs needed for specific locations is in its infancy," said Thomasson, who also is a researcher with the MSU-based Mississippi Agricultural and Forestry Experiment Station. "This study will focus on improving farm management based on site-specific knowledge." The project is funded by a three-year, $372,000 grant from the U.S. Department of Energy's Idaho National Engineering and Environmental Laboratory. It will begin with the 1998 crop year and involve scientists in Mississippi, Kentucky and Idaho. Cotton will be the target in Mississippi; corn in Kentucky and wheat in Idaho. Dean Pennington, executive director of the Yazoo Mississippi Delta Joint Water Management District, is co-investigator for the Mississippi research. He and Thomasson will use the fields of cooperating producers to gather the data. Primarily, they will explore the use of satellite-generated field maps to determine crop yields and water needs, as well as the amount of crop biomass--the residue from earlier seasons. According to Thomasson, some parts of a field can become stressed before others because water loss isn't uniform. "In fact, the variability in water stress increases as a field dries out. We will be looking at ways farmers can use remote sensing data to determine proper irrigation timing." The biomass part of the study will be important for producers using no-tillage systems since biomass builds up on top of the soil. The buildup often will be heavier in some parts of a field, creating the need to increase seeding rates for these locations to ensure an adequate crop stand. "The satellite images will help us identify areas that need heavier seeding rates," Thomasson said. Researchers will compare the satellite data with information collected by researchers on the ground. The comparisons will help them perfect ways to interpret and use the information generated by the satellite observations.
--------
19-> Los Alamos Metallurgists Find Niche In Art World
LOS ALAMOS, N.M., Dec. 22, 1997 -- Metallurgists at the Department of Energy's Los Alamos National Laboratory who honed their craft in the nuclear weapons arena are now sharing their expertise with a Santa Fe sculptor and others in the art world. The Los Alamos researchers, Kendall Hollis and Richard Castro, are adapting industrial technology for spraying molten metals to create corrosive-resistant coatings on nuclear weapons storage containers so they are suitable for long- term storage. Now they are taking their techniques and unique knowledge to the art community to coat sculptures and create corrosion-resistant, highly polished artistic surfaces out of metal combinations not previously possible. Hollis and Castro earlier this year contacted sculptor Tom Bollinger, who was managing a local art foundry and is now based in Arizona. The three have formed a business called Scintilla Artworks to commercialize the sculpture spraying technique and develop metal spray technology specific for the needs of the art community. Using the metal spray technology, the team can coat nearly any surface to any desired thickness. Hollis and Castro used a wire-arc spray process to coat an aluminum casting of Bollinger's sculpture called "New Life." The sculpture represents the bond between a pregnant woman and her unborn child. The technique uses a commercially available device resembling an arc welder that produces a fine metal spray. Two wires, made of the metal that serves as the coating, receive opposite electrical charges, which creates a small electric arc between them and melts the tips of the wires. A pressurized gas blows the melted wire into a fine metal spray that can coat an object from as thin as a few thousandths of an inch to as much as an inch thick. The metal spray technique is more efficient than conventional casting because it requires less energy to melt the tips of the wires than to heat a large pot of material. It also allows artists to cast with more easily worked materials, then finish the form with a sprayed metal coating. Another advantage of metal spraying is that it allows the artist to blend different metals. Part of Bollinger's sculpture is bronze surrounded by nickel. Conventional techniques would have made the combination of nickel and bronze metals extremely difficult. The two metals would have to be separately cast, precisely shaped to fit each other and welded into place. "Metal sprayed coatings offer a new way of combining different metals that could never be done before," Bollinger said. The researchers at Los Alamos spray different metals on cast pieces and can fill in flaws and smooth out the sculpture. Bollinger then uses conventional polishing techniques to buff and shine the finished product. If a mistake occurs, it can be sprayed again and buffed away. There is a trend in the art community for large-scale, cast, stainless steel sculptures for outdoor settings. To achieve these forms, artists and foundry workers must cast the sculpture in small sections and weld the pieces together. Stainless steel welds can distort the sculpture's form, however, requiring extensive finishing to regain the original shape. The spray technology allows artists to use larger cast sections of aluminum, which require fewer welds overall when they are joined; a spray coat of stainless steel finishes the piece. Reducing the distortion makes it easier for the artist to finish the piece or reproduce it. Bollinger believes the metal-spray process, which he calls both a creative and technological resource, could significantly impact the large-scale sculpture community. Metal spraying is not new to the sculpture art community. But, Castro said, "the knowledge and expertise we've gained in developing this technology for national security applications can bring state-of-the-art metallurgy techniques to sculpture production. The application of an outer corrosion-resistant coating to an underlying, easily cast and worked material opens up many new possibilites in fine art production." Hollis and Castro were interested in how their technology could be commercialized and how it could benefit surrounding communities in northern New Mexico, which led to Scintilla Artworks. Los Alamos is operated by the University of California for DOE.
--------
20-> MIT Biologists Identify Aging Mechanism In Yeast Cells
CAMBRIDGE, Mass.--MIT biologists have identified a mechanism of aging in yeast cells that suggests researchers may one day be able to intervene in, and possibly inhibit, the aging process in certain human cells. The mechanism of aging, it turns out, is elegant in its simplicity. During a yeast cell's life, whenever a particular, coiled piece of DNA pinches off from one of its chromosomes, that extrachromosomal ribosomal DNA (ERC) replicates until the cell becomes overwhelmed and dies. Aging in yeast cells is started by the formation of that first ERC. "The best part is, it's obvious it's a clock," said Leonard Guarente, Professor of Biology, referring to the ERCs' role in yeast cell mortality. "Set the clock early and the alarm rings early." An article to be published in the December 26 Cell culminates a year's published work on this topic (articles appeared in Cell, Science and now Cell, again). The piece, co-authored by David A. Sinclair, a postdoctoral fellow in biology at MIT, and Professor Guarente, also communicates the researchers' enthusiasm for the work, with an overtone of wonder at its broad implications and precise beauty. "It is remarkable that this mechanism of aging in mother yeast cells is so simple at a molecular level," the biologists wrote. "It is conceivable that inhibitors of this (aging) process can be found and if so, such strategies might eventually prove useful in forestalling aging in yeast and, perhaps, in higher organisms." The discovery of the simple role of ERCs in cell aging and death has a profound appeal well beyond the laboratory. Indeed, William Shakespeare, a man of powerful intuition and observation, would be pleased to learn how closely Hamlet's phrase denoting mortality -- the "mortal coil" -- portrays an actual molecular drama. A drawing of ERCs in action shows that an aging yeast mother cell is full -- fatally full -- of little mortal coils. PREVIOUS WORK: THE FOUNDATION The MIT biologists' current research builds on two related discoveries published earlier this year in the magazines Cell and Science magazines. The article published in Cell in May measured normal aging in yeast by determining the number of daughter cells a mother cell could produce before dying. Mother and daughter yeast cells are differentiated by their size: mother cells are bigger. That article, by nine authors including Drs. Guarente, Sinclair and Mr. Kevin Mills, a graduate student in biology, also demonstrated that yeast genes SIR2, SIR3, SIR4, and UTH4 determine the life span in yeast. When these genes were deleted from a yeast strain, life span was shortened. When they were overexpressed, the life span of the yeast strain was extended. The research also showed that the gene products encoded by SIR2, SIR3 and SIR4 promote cell longevity by moving from one cell structure to another (from the telomeres to the nucleolus). This action and the fragmentation of the nucleolus would form the basis of more groundbreaking discoveries. A second article, published in Science magazine in August, reported further refinement in the MIT biologists' study of aging. This research, reported by Dr. Sinclair and Professor Guarente, identified the crucial role played by another yeast gene, SGS1, in determining the life span of yeast cells. The gene SGS1 has a DNA code that corresponds structurally to the human gene, WRN. Mutations in WRN result in Werner's Syndrome, a disease whose symptoms resemble a fast-forward aging process. The MIT biologists demonstrated that experimental mutation of SGS1 -- the yeast homolog for WRN -- produced symptoms of aging in yeast cells. Again, the biologists noted how aged SGS1 yeast cells displayed fragmentation of the nucleolus. "Our findings indicate a particular cellular structure, the nucleolus, may be the Achilles' heel as cells get old. We think this fragmentation of the nucleolus is a cause of aging," Professor Guarente commented at the time. The next phase of research would include "answering the question, can we find a way to slow down the fragmentation of the nucleolus as a way to slow down aging?" Professor Guarente said. NEW RESEARCH: THAT MORTAL COIL "Strikingly, the nucleolus of old SGS1 cells is enlarged and fragmented, and the following findings indicate that these changes may represent a cause of aging," wrote the authors in an introduction to the December 26th article in Cell. "We thus sought to identify the molecular events embodied by the enlarged and fragmented nucleoli of old cells." First, the researchers tackled nucleolar enlargement. This, they discovered, was caused by ERCs -- the supercoiled circular form of DNA -- accumulating abundantly in old yeast cells. They named the supercoiled circular molecules "ERCs" -- extrachromosomal rDNA circles -- and showed that accumulation of ERCs is a general phenomenon that occurs as cells age. Next, the researchers noted that the ERCs accumulated in yeast mother cells but not in daughter cells and that mother cells were subject to aging (i.e. sterility) due to this asymmetrical accumulation. Replicating ERCs were also presumed to cause enlargement and fragmentation of the nucleolus in mother cells. But old age is not death, and the researchers still wondered, How do ERCs kill cells? They suggest that the sheer abundance of ERCs could gum up components of the mother cells' replication machinery, leading to an inability to replicate the DNA necessary for life. A WONDROUS PARADOX Armed with data suggesting that the accumulation of ERCs may be the aging clock itself, the researchers wondered, what set the fatal accumulation in motion? What, as Professor Guarente inquired above, could "set the clock early (so) the alarm rings early"? Their experimental results suggest a paradox. The formation of ERCs may be a result of damage to rDNA; that is, ERCs may be the cell's attempt to repair itself. Yet, the very mechanism which saves the cell becomes its "mortal coil" as ERCs "accumulate exponentially in mother cells resulting in fragmented nucleoli, cessation of cell division, and cellular senescence," the authors wrote. Intriguingly, a yeast cell need not itself be damaged to set the mortal clock in motion. ERCs, the researchers note, can be inherited, with the same effect. Near the concluding section of the Cell article, the authors wrote, "Once an ERC is formed or inherited, the period of time until a lethal number of ERCs has accumulated ... may be the clock that determines the life span of the cell." BROADER IMPLICATIONS The implications of the MIT research include possibilities of inhibiting the process of ERC-formation in mother yeast cells and in cells of higher organisms where cell division is asymmetrical. These latter cells -- known as stem or progenitor cells in mammals -- are found in organs such as the skin, kidney, liver and blood. The authors suggest, too, that yeast mother cells may be analogous to mammalian stem or progenitor cells, just as SGS1 was homologous to the human WRN gene. Thus, the next phases of aging research have been defined by the MIT biologists' groundbreaking work. Next, "it will be important to determine whether ERCs or other circular DNAs accumulate in stem cells of aging mice and humans," the authors wrote. David Sinclair is supported by the Helen Hay Whitney Foundation. The Guarente lab is supported by a National Institutes of Health grant.
--------
21-> Lab Works To Make Nuclear 'Gunk' Environmentally Safe
STARKVILLE, Miss.--A "drum-thunker" and a high-temperature electric torch are helping a Mississippi State laboratory develop ways for America and the world to reduce and safely store nuclear wastes. The university's Diagnostic Instrumentation and Analysis Laboratory currently is working with more than $25 million in U.S. Energy Department grants. The research involves new technologies that can reduce environmental threats from both high- and low-level wastes. "DOE has spent well over $1 billion on the development of new technology for nuclear waste cleanup," said lab director John Plodinec. "Very few of the technologies are actually being used because the right link has not been made between developers and the ultimate users." He said DIAL--Mississippi State's longest and largest continuous research project--is focusing on the development of technologies involving an electric arc capable of reaching 15,000 degrees Fahrenheit. Known as the plasma torch, it can turn virtually any material, including nuclear waste, into glass. DIAL researchers also have found new ways to monitor pressure inside drums storing low-level nuclear wastes. Virtually all high-level nuclear waste in the U.S. comes from the production of Cold War nuclear weapons. "The most dangerous portion of the high-level nuclear waste is in the form of aqueous slurries, commonly referred to as 'gunk' because of their appearance," Plodinec said. At present, the gunk is stored in large steel tanks in the states of South Carolina, New York and Washington. Plodinec said DIAL researchers are aiding in the cleanup effort at all three high-level waste sites, as well as at other facilities with low-level radioactive waste. Low-level waste ranges from the spent fuel rods of nuclear reactors to the protective clothing used by nuclear facility workers. Most is stored in sealed 55-gallon drums. Plodinec said tank and drum storage continue to be acceptable methods of dealing with nuclear waste, even though more effective solutions have been developed in recent years. He said DIAL's research is geared to practical applications of new technologies that help storage facilities reduce environmental risks. Projects involving the tremendous heat of a plasma torch are finding effective ways to turn nuclear waste into glass. Then, there are the problems of pressures that build in drums storing low-level wastes. The most immediate danger here is to personnel handling the barrels. "As the sealed material breaks down, pressure builds up and creates the possibility of an explosion if the drum is damaged or opened without care," Plodinec explained. He said researchers Daniel Costley and Mark Henderson have developed a "drum thunker" to test the pressure inside a drum while it is still sealed. The non-intrusive device senses the amount pressure in a drum, which is read with the help of a laptop computer equipped with a soundcard and microphone. The 'thunker' also can be used to test storage containers in non- nuclear facilities. For instance, DIAL scientists recently tested the device at Lockheed Martin Energy Systems in Paducah, Ky., where some 55-gallon drums of waste material were found to be under pressure. "The information provided by the tests will enable Lockheed Martin personnel to plan for safer handling of their storage drums," Plodinec said.
--------
22-> Pittsburgh Researchers Construct Novel Delivery System For Gene Therapy Of Liver Disorders
PITTSBURGH, Dec. 18 -- Like a car that transports its passengers, layers of lipids form a protective barrier for their passenger DNA molecules, safely whisking them past DNA-degrading enzymes and quickly delivering them to their destinations, or target cells. A research team from the University of Pittsburgh has constructed the first prototype of this "car," a delivery mechanism for genes called a reconstituted chylomicron remnant (RCR) that has resulted in the extended production of therapeutic proteins in an animal model, according to a report published in the Dec. 23 Proceedings of the National Academy of Sciences. The research was developed in collaboration with Targeted Genetics Corporation, Seattle, and the RCR Vector is exclusively licensed to Targeted Genetics. In the study, Pitt researchers detailed how they coated twisted strands of DNA encoding for the a1-antitrypsin (hAAT) gene with lipids and added oil to form stable RCR structures with 65 percent of DNA incorporated into the oil core. "We have developed the first non-viral vector that resembles a naturally occurring lipoprotein," stated Leaf Huang, Ph.D., professor of pharmacology at the University of Pittsburgh. Typically, lipoproteins pick up fat and take it to the liver where it is released and processed. "In our studies, we placed genes into the RCR structures instead of fat and found that these genes were released into liver cells and their blueprints were used to build new proteins," added Dr. Huang. "Mimicking the body's own transport system, we have created a model in which we have used a good copy of hAAT to show that RCRs are a great way to get genes into cells and direct the body's cellular machinery to produce therapeutic proteins." A bad copy of the hAAT gene is thought to cause pulmonary emphysema and liver disease. Introducing a good copy into target cells may slow or halt the development of these disorders. Genes can be delivered to cells by a variety of "cars" or delivery mechanisms. Some of these delivery systems only can access cells that are actively dividing and thus are prevented from entering non-dividing cells. Others, like viruses, have structures that are easily recognized by the body as foreign substances and are either rejected or destroyed by the body's immune cells. Non-viral vectors, like the RCRs, can overcome these problems, but in the past, these types of vectors have proven only marginally effective in transferring their cargo of genes to target cells. "The role of RCRs is to transport substances in the body. Because they excel at this task, we successfully used them to deliver the hAAT gene, which was integrated into 10 percent of cells in the liver and led to the production of hAAT proteins. Based on these findings, we feel they are one of the best non-viral vectors," commented Dr. Huang. Once a gene is expressed, the information it contains becomes available and is used to direct the construction of proteins. In these studies, not only was the hAAT gene expressed, but the researchers also found that hAAT proteins were manufactured and released into the bloodstream where they were detected for up to 60 days after the initial injection. By injecting the genetically-altered RCRs directly into the livers of mice (through the portal vein), the researchers reported a 100-fold higher expression of the gene compared with mice who received injections of naked DNA. The more DNA that was incorporated into the RCR complex, the higher the gene expression was -- the optimal dose was 50 mg of DNA. Although the highest expression of the gene was found in the liver, gene activity also was detected in the kidneys and lungs of injected animals. When the researchers injected the mice with a different gene called luciferase contained in the RCR structures, they detected high levels of the gene in the liver for two days, which then rapidly declined, almost disappearing by day seven. A second injection of the luciferase gene incorporated in RCRs restored the high level of gene expression in the liver. Long-term expression of genes is necessary for successful gene therapy. "By administering multiple injections of the RCRs, we might be able to achieve high enough levels of gene to offer a therapeutic effect to patients. It is possible to give this gene therapy to patients through a catheter," remarked Dr. Huang. "By selecting genes specific to a patient's disorder, eventually we may be able to use this delivery system to jump start the body's production of therapeutic proteins and enzymes, which will offer patients with hepatoma, viral hepatitis, cancer and other disorders a viable treatment," stated Dr. Huang. Currently, Dr. Huang and his colleagues are re-engineering their prototype and trying to incorporate surface molecules called ligands which are specific for certain cells. They hope that this will increase the stability of the structure and assist the up-take of the introduced DNA into the target cells.
--------
23-> Regulator Of Fat Thermostat Found
Leptin leapt into the headlines when it was identified in 1995 as a protein that triggers weight loss in mice. But the appetite-taming hormone lost some luster as the ultimate diet drug when scientists found last year that obese people already have high levels of leptin in their blood. This finding suggested that overweight people may become unable to respond to leptin, though little is known about leptin's interactions in the body. Now investigators at Washington University School of Medicine in St. Louis have identified the first factor to significantly boost human leptin concentrations. And surprisingly, this substance also boosted leptin levels in some overweight individuals. In the study conducted by endocrinologist Samuel Dagogo-Jack, M.D., assistant professor of medicine, and by John W. Newcomer, M.D., assistant professor of psychiatry and of psychology, oral administration of a steroid hormone for four days doubled the amount of circulating leptin in 52 patients. Levels of leptin, a product of fat cells, climbed even higher in obese subjects. The results were published in the October 1997 issue of the Journal of Clinical Endocrinology and Metabolism. Dagogo-Jack says the findings suggest that overweight people still have leptin reserves. "Because their supplies are not exhausted," he notes, "future leptin therapy may require the use of high doses of leptin to make a dent in obese people's weight." A similar approach works well in people with adult-onset, or type 2, diabetes, who are resistant to their own insulin. "If we treat these diabetics with insulin to increase their circulating insulin levels, their blood glucose concentrations come down, and their diabetes is controlled." Heavier People Respond Better The study, which was funded by grants from the National Institute of Mental Health, the American Diabetes Association and the U.S. Public Health Service, involved 20 healthy men and 32 healthy women ranging from 19 to 84 years in age. Of the 31 receiving steroid treatment, 11 were considered obese based on their body-mass-index (BMI), which relates weight to height. For instance, a 5-foot-10-inch person who weighs 193 pounds would have a BMI of 28. A BMI of 27.3 or higher for men or 27.8 or higher for women was considered obese in the study. To test leptin levels, Dagogo-Jack, Newcomer and colleagues analyzed the pattern of leptin secretion in volunteers treated with increasing doses of the steroid dexamethasone or a placebo. Dexamethasone, which mimics the hormone cortisol, is commonly used to treat arthritis and other inflammatory conditions. The researchers tested blood samples taken before, during and after a four-day treatment period for concentrations of insulin and other hormones as well as leptin. By the third day of dexamethasone treatment, obese patients' leptin levels had doubled from an average of 24.3 ng/ml to a peak of 47.7 ng/ml. In their lean counterparts, they increased from 11.3 ng/ml to 20.1 ng/ml. A follow-up study by the researchers showed that results were similar when cortisol was used to stimulate leptin release. Although the heavier patients responded to dexamethasone treatment, most were moderately obese. Dagogo-Jack notes that the findings may not apply to people who are morbidly obese, defined as having a BMI of 35 or above. "The ability to keep increasing leptin production may fail at some point of massive obesity," he says. Future studies with dexamethasone and other steroid hormones as stimulants will include this weight group to try and determine if some obese people lose the ability to respond to the stimulants. Men and women responded equally well to dexamethasone treatment, however. This was a surprise because women generally have higher levels of leptin in their blood, possibly because their bodies contain a greater percentage of fat. The different concentrations of sex hormones in men and women also may play a role. Some long-term studies have suggested that insulin elevates leptin levels slightly. Insulin affects energy supplies by triggering cells to take up glucose as an energy source. But no jump in insulin levels coincided with the increases in circulating leptin documented during this four-day study. Weight Loss Link Suggested Besides identifying a leptin regulator, the findings also may help explain how stress can trigger weight loss. Cortisol is called the "stress hormone" because its levels increase during stress and long-term illnesses such as chronic depression and AIDS. But no one has understood how cortisol causes weight loss. "Our study suggests that leptin might be one link between cortisol action and weight loss," Dagogo-Jack says. Dagogo-Jack notes that the dexamethasone finding serves as only one piece in an unfinished jigsaw puzzle depicting the pathways regulating body weight. "This one piece of the puzzle should lead to other areas worthy of examination," he says.
--------
24-> Scientific Research In Russia Struggles To Survive
Scientists are less respected than politicians, journalists and peasants WASHINGTON, Dec. 22 -- An estimated 70,000 to 90,000 scientists emigrate from Russia every year, according to an article published in the Dec. 22 issue of Chemical & Engineering News, the weekly news magazine of the American Chemical Society, the world's largest scientific society. Because they are in the 30- to 45-year-old range, almost an entire generation of scientists has been lost to one of the world's largest countries. This extraordinary brain drain is the result of a bleak situation in the former Soviet Union, due to unusually low salaries, lack of materials and modern equipment, and a decline in funding for research and development. At the Institute of Chemical Physics in Moscow, for example, even basic utilities like electricity are available only half the time, because it is all the Institute can afford. And at the University of Vladivostok, one Russian chemist predicts they won't be doing any chemistry there in two years, because all they will have left is chalk. Some of the other observations made by author Michael Freemantle of C&EN's London Bureau are: During the Soviet period, 75 percent of research was funded by the Defense Ministry, but that has virtually disappeared and the links to applied industry have been broken. Pitiful salary levels that average $100 - $150 a month force many scientists to seek additional employment. One Moscow physicist uses his private car as a taxi whenever possible. At the Institute of Petrochemical Synthesis in Moscow, government funding for fundamental research is eight to 10 times less than it was in the Soviet period. A faltering Russian economy places Russia at the bottom of the industrialized countries in terms of the percent of the gross domestic product spent on research. And in spite of a state law mandating that research receive four percent of the federal budget, in 1998 it will only receive 2.8 percent. In spite of this dismal picture, some positive trends have emerged for Russian research: Institutes and universities have more autonomy than in the past, there are no limitations on international activities; and research has changed direction, with much of the former military effort now replaced by medicine.
--------
25-> Making The Internet 10 Times Faster
Computer scientists at Washington University in St. Louis have patented two major inventions that should make Internet applications like e-mail, the World Wide Web and electronic commerce 10 times faster than they are now. George Varghese, Ph.D., associate professor of computer science in the School of Engineering and Applied Science, has collaborated with three Washington University colleagues in developing processes that enable the "lookup" for an Internet address to be done at the unfathomable speed of 100 nanoseconds, compared with the current average, a none-too-shabby 1.2 microseconds. This 10-fold increase in speed promises to give routers a faster throughput by making it easier to find the destination addresses for their messages. Varghese presented a paper on the techniques at a fall networking conference of the Association for Computing Machinery. The processes are mathematical techniques that sort the 32-bit prefix address possibilities of Internet messages into groups that can be searched far faster than the painstaking bit-by-bit process of the past 20 years. If the difference between nanoseconds and microseconds seems trivial, consider that: the number of computers on the Internet is tripling every two years; the applications are increasingly more complex than e-mail and ASCI text files, now involving multimedia, audio and video as well as print data; and the speed of links (the lines that send data packets) is increasing 12 times over its present rate of 45 megabits (a megabit is one million bits) per second, into the gigabit (1,000 million bits per second) range. While links are faster, routers -- hardware that route Internet messages, much like automated processors in the U.S. Postal Service -- have neither the speed nor the memory to keep up with the data. Today's fastest routers forward messages at a maximum rate of 100,000 to 500,000 messages a second. To keep up with communication link speeds in the gigabit range, a router has to forward five million messages (of an average size of about 1,000 bits) per second. If routers don't get up to speed, bottlenecks, delays and unhappy Internet customers are right around the corner. "There is a shoot-out going on in the Wild West of Internet Country, where established network vendors and a flurry of start-ups are all vying to provide the fastest Internet message forwarding rates," says Varghese. "Washington University is among the Wild Bill Hickoks and Wyatt Earps who've entered the shooting match. There is strong commercial interest in the techniques, but we'll have to wait until the smoke clears to see how we do." Think of a router as a post office that gets your e-mail message with a self-contained Internet (IP) destination address. The post office needs to look up the address in a forwarding table that describes which of its many output links the message must be routed through. Once this is determined, the message is sent on that link. Internet address lookup would be simple if an IP destination address could be found in a table that lists the output link for each Internet address in the world. In this case, the lookup could be done similar to a dictionary search. The only catch is that a router would have to keep millions of entries in its database corresponding to the millions of computers on the Internet. To reduce database size, a router database consists of a smaller set of prefixes. This reduces database size, but at the cost of requiring a more complex lookup, called longest matching prefix. Varghese offers a metaphor to explain how prefixes work. Consider a flight database in London that could list flights to a thousand U.S. cities. Suppose most flights hub through Boston, except those to California, which hub through Los Angeles. The flight database can be reduced from 1,000 entries to just two prefix entries: These are USA* to Boston; USA.CA* to L.A. (the asterisk denotes a wildcard of information that follows). There is a quirk: a destination city such as USA.CA. Fresno now matches both prefixes. In that case it must go to the longest match (USA.CA*). The Internet address lookup problem is similar. To understand it, forget your individual quirky e-mail address of numbers and letters. The Internet works in the binary world where everything is a 1 or zero, a combination of both up to 32 bits, which is the destination address placed in every Internet message. "The Internet address quandary is the problem of finding the longest matching prefix," Varghese says. A destination address whose first six bits are 100100 would match both prefix P1, 10*, and P2, 1001*. But, because P2 is the longer match, messages for this address should be sent to P2, just as USA.CA* was preferred over USA* in Varghese's example. Tackling a 20-year problem Today's routers in the Internet backbone have about 40,000 prefix entries instead of millions of possible Internet addresses. A simple lookup solution would compare the address in each packet to each of these 40,000 prefixes to find the longest match, but that would be much too slow. Presently, there are two ways of finding prefix matches. One breaks up the large data base into sub-data bases of prefixes with the same length. The other, called a trie (tree), is similar to a branching family tree. It is a system of nodes, each one having a table of mathematical pointers that route the addresses to the proper link. Both methods essentially search for a longest match among all possible prefix lengths. Because there are 32 possible prefix lengths, both schemes are too slow to work with the next generation of routers. The Washington University researchers have added two new techniques to tackle this 20-year-old problem. The first method, developed by Varghese and his graduate student, Venkatachary Srinivasan, recognizes that the existing schemes will work faster if they can search through databases that have a smaller number of distinct prefix lengths. Using a technique called controlled prefix expansion, their method takes an existing database with 32 possible prefix lengths and transforms it into a new one with a much smaller number of prefix lengths. The existing schemes then can be run faster on the new database. "The trie, for instance, now can be worked in multiple bits at a time instead of walking through the trie one bit at a time," Varghese says. "For example, if we walk the trie in larger strides of eight bits, we need only four strides to cover 32 bits instead of 32 strides if we go one bit at a time. This translates into a factor of eight improvement in performance. It's basically a simple trick to make routers more successful. We are putting all our eggs in fewer baskets." The second method, developed with Jonathan S. Turner, Ph.D., Henry Edwin Sever Professor of Engineering, and visiting graduate student Marcel Walgvogel, uses a completely different approach. Instead of searching for prefixes one length at a time, 32 different ways, the second method divides the problem in half at different stages in the search and, with the aid of pre-computation and markers, provides a quicker search, especially for longer prefix lengths. On the horizon, Internet routing protocols soon will have to look up 128-bit addresses, as the Internet prepares to retrofit to serve a global community of users and user devices. "In the future, your toaster or air conditioner could have an Internet address, which really exacerbates the problem," Varghese notes, explaining that such household or office items can be controlled and programmed through the Internet. Eight companies have signed nondisclosure agreements with Varghese and Washington University to examine the Washington University techniques. Licensing seems an imminent outcome. "Some vendors like our second technique because it scales well to the next generation 128-bit addresses, using only seven questions to determine an answer," he says. "Other vendors like our multibit trie scheme for the existing Internet because it is simple and fast. Either way, we're glad we can be a factor in speeding up the Internet."
--------
26-> Colon Cancer Linked To Genes, Not Lifestyle
MADISON - Colon cancer and many other geriatric diseases in primates appear to be natural outcomes of aging, rather than being caused by outside factors, a scientist at the University of Wisconsin-Madison has found. The findings, reported recently in Age and The American Journal of Primatology, adds to evidence that how we age may be linked more to our genes than our lifestyle. "The simple lives of captive-born, aged rhesus monkeys result in minimal or no exposure to the varying environmental and lifestyle factors that affect humans," said Hideo Uno, senior scientist at the Wisconsin Regional Primate Research Center and adjunct professor of pathology and laboratory medicine. "Yet the monkeys still get many of the same geriatric diseases people get." From 1980 to 1994, Uno compiled autopsy data from 175 monkeys, all aged 20 to 37 years, roughly the equivalent of people in their 50s to 80s. The animals, which were used for breeding rather than scientific experimentation during their lifetimes, either died spontaneously or were euthanized due to severe illness. Autopsy data revealed that most of the diseases appeared to be brought on by old age and predisposing genetic factors, versus environmental or lifestyle factors. Colon cancer, coronary sclerosis, degenerative joint disorders, and cerebral amyloid plaque (a component of Alzheimer's disease), were among the disorders, Uno said. Despite a simple diet of high-fiber monkey chow and fruit, a relatively nonstressful environment, lack of exposure to known carcinogens, and good veterinary care-old monkeys often get colon cancer, Uno discovered. "As in humans, the incidence of colon cancer dramatically increases with aging," he said. Colon cancer is the third most common cancer in men, following prostate and lung cancer, and the third most common in women, following breast and lung cancer. In captive rhesus monkeys it appears to be the most common. Uno's data did show, however, that certain other geriatric diseases are much less common in monkeys than in humans. "Lung and prostate cancers in elderly people are extremely common, for example, but those two cancers are very rare in our monkeys." Rhesus monkeys share 93 percent of the human genome, which makes them the prime animal model for researchers seeking answers to human diseases like cancer, AIDS and diabetes. "We have only now been able to study colon cancer and other aging-related diseases more closely in monkeys and compare it to that in humans," said Uno. "Few populations of aged monkeys were in captivity up until about 15 years ago." Uno said the data will be valuable to scientists working on preventive or experimental studies related to geriatric diseases in humans. The UW Primate Center is one of seven primate research centers in the U.S. supported by the National Center for Research Resources at the National Institutes of Health. It is a base for local, national and international research in biomedicine and conservation biology and has an annual operating budget of approximately $25 million.
--------
27-> Genetic 'Short Circuit' Leads To Cleft Palate
Scientists have identified not just a single gene but a genetic circuit, that when broken, causes cleft palate in newborn mice. The critical points of the circuit represent genes and gene products that interact with one another to direct palate formation. The "surge" that causes the circuit to break is an environmental assault in the form of steroid hormones given to the female mice during pregnancy. This is the first time that a cause-effect scenario for cleft palate has been worked out at the molecular level. The findings may help define the genetic components of cleft palate in humans, and also explain the link between clefting and risk factors, such as stress, smoking, and certain medications, all of which are known to elevate the level of steroids in the body. The study was carried out by Drs. Michael Melnick, Tina Jaskoll, and colleagues at the University of Southern California through support from the National Institute of Dental Research, and appears in the January issue of Developmental Dynamics. Facial clefting disorders are among the most common human birth defects. Cleft palate occurs in about one in 2,000 live births and can range in severity from a relatively minor split uvula at the rear of the mouth, to a cleft that runs the length of the hard and soft tissues that form the roof of the mouth. The more severe forms require surgery and are often associated with both psychological and physical problems, including difficulties with feeding, breathing, and speech development. Cleft palate is thought to result from a combination of genetic and environmental factors, yet attempts to identify these components in human populations have so far produced inconclusive results. Investigators like Dr. Melnick feel that the mouse model will provide the clues that eventually unravel the mysteries of cleft palate. At present, he thinks that it is still premature to pinpoint the underlying causes of cleft palate from human studies. "It is apparent from studying complex disorders like cleft palate, that simply identifying genetic differences between healthy and affected individuals is not enough to explain the cause of the disorder," said Melnick. "We must know what products are derived from the genes in question and what other genes and molecules are affected in the chain of events that leads to the formation of the palate." The mouse model allows investigators like Melnick and Jaskoll to tackle such questions. Much of their work has revolved around two strains of specially bred mice-one strain sensitive to steroid-induced clefting, the other strain resistant. Using these mice they have now pieced together a molecular explanation for cleft palate. The genetic circuit that they describe is similar to an old-fashioned string of holiday lights that operates only if all the bulbs are functioning properly. The investigators have identified three of the genes and gene products involved in palate formation that are the equivalent of individual bulbs in the string of lights. The clefting-susceptible mice have an overactive gene, comparable to a bulb that burns hot but still is able to complete the circuit and light up the other bulbs in the string. In these mice, the gene alters the normal activity of the other molecules in the circuit, but the palate still forms, although more slowly than in resistant mice that have a less active form of the gene. When steroids are added to the system, the effect of the hyperactive gene is amplified to the point where the circuit is broken. The function of the other molecules is altered so much that palate tissues practically stop growing and a cleft forms in the roof of the mouth. The three key components of the circuit are the growth factor receptor IGF-IIR (hyperactive gene), the growth factor TGF-ß2, and Cdk4, a protein that drives cell division. Equivalent molecules are present in humans, and a similar pathway may be responsible for human cleft palate. However as Dr. Melnick points out, the human situation may also be more complicated. "There are several tissues involved in forming the palate and they are under the direction of dozens of genes," said Melnick. "There are many potential places for things to go wrong, and the places may vary among families and racial groups. We have identified one pathway that accounts for steroid-induced cleft palate in mice, and provides some promising targets to focus on in human population studies." The research team consisted of Drs. Michael Melnick, Haiming Chen, and Tina Jaskoll from the Laboratory for Developmental Genetics, University of Southern California, and Drs. Susan Buckley and David Warburton from the Department of Surgery, Children's Hospital of Los Angeles.
--------
28-> No Sweat! Positive Thoughts Help Exercisers Stick With It
When you haul yourself out of bed to jog around the park, do you curse the dark mornings and think about your aches and pains? Or do you slip into the sunrise and feel good about cranking your body into gear? Although researchers know that half of all folks who take up exercise quit during the first six months, they have failed to ask how people's thoughts and feelings during workouts affect their decision to drop out. Wanting to look at how people interpret the exercise experience itself, Joanne Kraenzle Schneider, Ph.D., R.N., questioned 364 women over 55 after they finished exercising. She found that those who believed in the health benefits of working out tended to exercise more often, more intensely or for longer periods than those with negative beliefs. Those who concentrated on their bodily movements reported exercising less often, less intensely or for shorter periods of time than those who didn't. "It appears that if you can interpret your experience positively, you will want to exercise more," Schneider says. Schneider is a postdoctoral research fellow in medicine at Washington University School of Medicine in St. Louis. Her paper, which appears in a recent issue of the Journal of Gerontology, is based on a doctoral dissertation she wrote at the University of Kansas School of Nursing in Kansas City. An award from the National Institute of Nursing Research (NINR) supported the study. Focus on older women Schneider studies women because most previous exercise maintenance research has focused on men. She works with older people because they're a fast-growing group of health-care consumers in the United States. "Little is known about exercise maintenance in this population, though regular physical exercise may reduce their health-care costs to society," she says. Scouring shopping malls and senior centers in Kansas City and Wichita, Kan., Schneider found 364 women between the ages of 55 and 90 who attended an exercise session of their choice. She gave each woman several questionnaires to complete after the exercise session was over. One set of questionnaires measured exercise behavior -- the number of times the women had exercised during a seven-day period, how hard they had worked and for how long. Another instrument probed the women's beliefs about exercise -- improved well-being, reduced tension or improved disposition, for example. A questionnaire that Schneider designed with input from a previous study asked each woman about her sensations, thoughts and feelings during the actual exercise session. The questions revealed the women's feelings of well-being, how intensely they concentrated on the movements they were making, the intensity of their sweating, their muscle and joint discomfort and the sights and sounds they enjoyed. "This type of episode-specific information was missing from previous studies," Schneider says. When Schneider analyzed the responses, she found that three factors accounted for differences in exercise behavior in this group of women. The first was a well-known factor, age -- the older people get, the less likely they are to stick to a regular exercise routine. Second, those who believed in the physical or psychological benefits of exercise were those who exercised more often, more intensely or for longer periods, the data showed. Most importantly, the responses revealed that women who concentrated on their bodily movements during the exercise session were those who exercised less often, less intensely or for shorter periods. This third factor may be important because women who focus on what they're doing are likely to concentrate on their internal sensations. Or they may become so involved in what they're doing that their exercise intensity drops. Schneider will examine these different explanations in her next study. Attitude change is possible While it isn't feasible to change a person's age, it might be possible to change negative thoughts into positive ones, Schneider suggests. "In contrast to experiences outside the actual exercise episodes, episode-specific interpretations are more immediate than general interpretations and therefore are accessible to change," she concludes. "So they're a prime target for interventions." n a recent pilot study at Washington University, Schneider tried to restructure the thoughts of five volunteers. Each woman picked an aspect of exercising she hated, such as sweating, and was taught to think positive thoughts about it instead. Schneider used the encouraging results in an application for a future grant from the NINR to conduct a larger five-year study. As part of her postdoctoral research, which also is funded by NINR, Schneider is examining episode-specific interpretations over a nine-month period and across different types of exercise in people who are 78 years or older. She also is taking her findings to heart because she has a tough time working out. "I'm telling myself that exercise is healthy and is improving my endurance and physical fitness instead of thinking that it doesn't feel good," she says.
--------
29-> Virologists Track New Influenza Threat
MADISON - University of Wisconsin-Madison influenza experts will conduct a detailed surveillance next month of the dangerous strain of influenza that has infected eight people and killed three in Hong Kong. Yoshihiro Kawaoka, a virology professor in the School of Veterinary Medicine, will travel to Hong Kong in early January to identify the source of the virus, a type found commonly in birds. Finding the virus in animals is important in determining how the virus is being spread. If the spread is person-to-person, rather than extremely rare avian-to-person cases, it poses a more serious public health threat. Kawaoka and UW-Madison post-doctoral fellow Peng Gao will team with Dr. Robert Webster of St. Jude's Childrens Research Hospital in Memphis for the month-long study, sponsored by the National Institutes of Health. This strain of influenza, called H5 influenza, is found in birds worldwide and, in this case, is believed to have originated in chickens. A Hong Kong child who died of H5 influenza in May is the first documented case of a human contracting this type of flu. Since then, seven others have been diagnosed with this potentially lethal strain. "There's no way of knowing at this point whether this virus will take off or die off in people," Kawaoka said, "but the surveillance in poultry will tell us what's out there. We have to work discreetly because at this point there is no need to make people panic." Flu viruses commonly have changes in their surface proteins, called "drift," which makes flu viruses slightly different each year and requires new vaccinations. Of greater concern to virologists is a "shift," which occurs when a radically different strain enters people. A shift is believed to occur when genes from two different strains mix together. Kawaoka said the team will test birds from chicken farms and on the market in Hong Kong. As a precaution, the scientists will take an antiviral drug called rimantadine, which blocks infection from the virus. Kawaoka said identifying the virus in birds and comparing it with the human cases will help determine whether any genetic variation exists between the two. Kawaoka said these influenza cases surprised virologists. In 1983, a massive epidemic of H5 influenza decimated poultry and cost the U.S. Department of Agriculture $61 million to eradicate the virus. But extensive surveillance at the time found no reported cases in humans, leading scientists to believe the H5 virus was not readily transmitted to people. Virologist Virginia Hinshaw, dean of the Graduate School and a UW-Madison influenza expert, said there are 15 different types of influenza distinguished by variations in their surface proteins. People and other mammals commonly get H1, H2 and H3 influenza and have antibodies that can fight off infection for those types. The H5 virus is frightening because people have no antibody protection against this type. Any time a new influenza type is introduced in people, it raises the possibility of a larger epidemic. On top of that, Hinshaw said this H5 strain is lethal in birds, and we don't know of its potentially lethal effects in people. The fact that the virus emerged in a major international trade center such as Hong Kong raises fears about rapid transmission, she said. Scientists also need to learn whether this "all-bird" influenza type is acquiring any genes from influenza viruses common in people. That type of genetic variation could also make widespread transmission more likely, she said. "This could very well die out like the swine flu did in 1976, but I wouldn't bet on it," Hinshaw said. "We certainly hope that it can't be easily transmitted." Major shifts in influenza have caused global flu epidemics in the past. The 1918 flu epidemic, for example, killed 20 million people, and the Asian flu of 1957-58 and the Hong Kong flu of 1968-69 claimed thousands of lives.
--------
30-> Twenty-Eight Day Cycle Found In Solar Neutrinos
Stanford researchers have found evidence for a 28-day cycle in the number of neutrinos reaching Earth from the Sun, and they suggest two controversial mechanisms that might explain their findings. Their preferred hypothesis postulates a region of intense magnetic fields rotating deep within the solar interior. Because neutrinos are created in the nuclear reactions that take place at the Sun's core, such a region might disrupt the flow of neutrinos to Earth. For this hypothesis to hold, however, the basic properties of the neutrino must be redefined in a way that conflicts with the "standard model," the well-tested description of the nature of fundamental particles and forces. Theories that redefine the neutrino in this fashion have been advanced to explain the missing mass in the universe and the unexpectedly low number of neutrinos that have been detected coming from the Sun. An alternate explanation might be regular pulsing in the strength of the nuclear reactions themselves. There is no outward evidence for such a cycle. But light created at the Sun's core takes 100,000 years or more to reach the surface, so any fluctuations in the production of radiation in the core could be completely smoothed out by the time the light reaches the Sun's surface, the researchers propose. The statistical evidence for this cycle is reported in the Dec. 10 issue of the Astrophysical Journal by Peter Sturrock, professor of applied physics; Guenther Walther, assistant professor of statistics; and physics research associate Michael Wheatland. Their analysis is based on data collected at the Homestake neutrino detector in South Dakota over a 24-year period. Using advanced statistical procedures, they found clear evidence for a 28.4-day cycle. "We estimate the probability that the cycle is due to chance to be about three parts in a hundred," Walther said. Nature's shadow particles Neutrinos are nature's shadow particles. In contrast to light, neutrinos take less than nine minutes to travel from the center of the Sun to the Earth. They can make the trip so quickly because they pass through ordinary matter almost as if it does not exist. About one million billion solar neutrinos pass unnoticeably through your body each second. Despite their ghostly nature, neutrinos can be detected because they do interact occasionally with ordinary atoms and molecules. In one such interaction, neutrinos change chlorine atoms into argon. Despite the enormous number of neutrinos passing through the Earth, this interaction is so rare that just to detect it scientists have been forced to build tanks holding tens of thousands of gallons of chlorine-containing liquid and develop methods for picking individual argon atoms out of such large volumes of liquid. It wasn't enough to do this on the Earth's surface, either, because cosmic rays also can convert chlorine into argon. So the tanks had to be buried deep underground. The first successful solar neutrino detector was located in the Homestake Gold Mine. Buried a mile underground, the detector contains 100,000 gallons of carbon tetrachloride. For the last 30 years, the Pennsylvania State University scientists who operate the detector have filtered out and counted the argon atoms that have accumulated every few months. Over this period, the instrument has identified an average of about one neutrino event every two days. That rate is about one-third the number that scientists who study the solar nuclear reactions had predicted. Two other neutrino detectors, the Kamiokande experiment in the Japan Alps and the Gallex experiment in the Gran Sasso Laboratory in Italy, both have verified the shortfall measured at Homestake. One possible explanation for this deficit was that the neutrino-producing nuclear reactions were happening more slowly than the scientists expected, which would be the case if the temperature at the Sun's core were about one million degrees Celsius less than predicted. But observations of sound waves traveling deep into the solar interior have provided a temperature measurement of 15.6 million degrees Celsius, too hot to lower neutrino production. The situation has led some scientists to invoke "new physics" to explain the low observed numbers. According to standard nuclear physics, a neutrino at rest does not have any mass. Now some theoretical physicists are proposing that these particles may have an infinitesimal but non-zero mass. Several major experiments have been built to test this proposal. Sturrock and his colleagues use these new theories to explain the variations in neutrino flow that they have found. If neutrinos have any mass at all, they would help account for the "missing matter" in the universe. Astronomers have found that galaxies act as if they are swirling around a center of mass substantially larger than scientists can account for by summing up the amount of visible matter that they contain. Neutrinos with mass could account for at least some of this "dark matter." Neutrino cycling The proposed neutrino mass is far too small to measure directly. So scientists are trying to detect a predicted side effect. Neutrinos come in three varieties, each associated with a different elementary particle (electron, muon and tau). According to some new theories, if neutrinos have mass, then they may cycle between the three different neutrino types. Directly measuring this effect is the purpose of the Palo Verde Neutrino Oscillation Project, headed by Stanford Associate Physics Professor Giorgio Gratta and Professor Emeritus Felix Boehm from Caltech. They led the design and construction of a neutrino detector a mile from the Palo Verde Generating Station in Arizona to determine if the neutrinos produced by the station's nuclear reactors undergo this cycling effect. This effect could explain the shortfall in solar neutrinos. Only one of the three types of neutrino, the electron neutrino, is detectable. If the electron neutrinos produced by the Sun change into muon and tau neutrinos en route, it would mean that only one-third of the neutrinos reaching Earth would be detectable. To look for regular variations in the number of neutrinos reaching Earth, Sturrock and his colleagues analyzed the data collected at Homestake. Because the data were collected about four times a year, it normally would be impossible to use this information to identify cycles as short as 28 days. But the data were not collected at regular intervals. That allowed the researchers to piece together evidence for a shorter cycle by constructing a detailed computer simulation of the detector, running thousands of simulations, and comparing the outcomes with the detector's actual observations. In an earlier analysis, conducted in 1995 and 1996, the researchers thought they had found evidence for a 21.3-day peak. This was reported in the News and Comment section of Science magazine. When they submitted this analysis to a scientific journal, however, one of the reviewers was unable to duplicate their results. When the researchers reworked the problem from scratch, they discovered an error in their transcription of the Homestake data. When this was corrected the 21.3-day cycle disappeared. The researchers find the 28.4-day cycle particularly intriguing because it corresponds almost exactly to the rotation rate of the Sun's interior, as seen from Earth. The Sun is made up of three parts: the core, where the nuclear fusion reactions that power the Sun take place; the radiative zone where energy is transported outward from the core; and the outer, convective zone. The radiative zone rotates as if it were a solid, rather than a gaseous body, at this same rate. So Sturrock and his collaborators speculate that the source for this cycle in neutrino flux may originate in the radiative zone. A region of extra-intense magnetic fields might modulate the flow of these particles, they suggest. Magnetic moment For magnetic fields to have such an effect, neutrinos must have a physical characteristic called a magnetic moment. According to current particle physics, they don't possess this quality. But the same theories that assign mass to the neutrino also give it a magnetic moment, which would make it respond to magnetic forces. In 1986, a group of scientists from the [then] Soviet Union, made the case that the spin of neutrinos with magnetic moments could be changed by traveling a long distance through a strong magnetic field. Sturrock and his co-authors invoke this effect as their preferred explanation for the cycle that they have found. Neutrinos spin in either a left-handed or right-handed direction. Nuclear reactions produce only left-handed neutrinos, and only left-handed neutrinos take part in nuclear reactions such as converting chlorine into argon. If different parts of the Sun have different strength magnetic fields, the flux of left-handed neutrinos will vary as they travel in different directions from the Sun. That would lead to a detection rate on Earth that varies with the Sun's rotation period. As the Earth orbits the Sun, the neutrinos that are detected on Earth pass through different solar latitudes, due to a tilt in the Sun's axis of rotation. This can produce other, weaker cycles centered on the basic rotation frequency. The period of 28.4 days corresponds to a frequency of 12.9 cycles per year. Sturrock and his collaborators have also found evidence of the expected "sidebands" at 10.9, 11.9, 13.9 and 14.9 cycles per year. At the same time, the new analysis did not find any evidence for neutrino variations that correspond to the 11-year solar cycle and only weak evidence for two other proposed cycles: a 157-day periodicity that Eric Rieger of the Max Planck Institute in Germany found in the intensity of solar flares, and a 780-day "quasi-biennial" periodicity that Kunitomo Sakurai from Kanagawa University reported finding in the Homestake data. "I thought [Sturrock and his colleagues'] analysis was quite convincing," said Jeffrey Scargle, a research astrophysicist at NASA's Ames Research Center, who is an expert in this type of analysis. "The method they used was very good and they made a really good case for the signal being in the data. Of course, what this means for solar and particle physics is quite problematic." 
--------
31-> Scientists Develop Catalytic Antibody With Comparable Efficiency And Of Broader Use Than Natural Enzyme
For the first time, scientists at The Scripps Research Institute (TSRI) have developed a catalytic antibody with an efficiency and mechanism equal to that of a natural enzyme essential to life. According to Richard Lerner, M.D., TSRI President and the study's author, "We have simulated an important enzyme via an antibody, while broadening its specificity. In addition, this will be the first commercially available catalytic antibody." The scientists believe that it will have numerous applications in industrial synthesis, including the synthesis of some of the most important anticancer compounds. The work, "Immune Versus Natural Selection: Antibody Aldolases with Enzymic Rates but Broader Scope" appears in the Dec. 18 issue of Science. Other authors include Carlos F. Barbas, III, Andreas Heine, Guofu Zhong, Torsten Hoffmann, Svetlana Gramatikova, Robert Bjornestedt, Benjamin List, James Anderson, Enrico A. Stura, and Ian A. Wilson. The researchers are members of The Skaggs Institute for Chemical Biology and the Department of Molecular Biology at TSRI. The scientists compared aldolases that use the same chemical mechanism but differ in their origin. One is a naturally-evolved enzyme and the other, a catalytic antibody developed by reactive immunization. The work solves the dilemma of whether the immune system is capable of creating efficient catalysts by altering its selection criteria from simple binding to function. While antibodies generally bind non-covalently with their substrates, the technique of reactive immunization enables catalytic antibodies to react with antigens, allowing the catalysis of chemical reactions previously thought to be impossible. In this case, the antibodies catalyze the aldol reaction, an important carbon-carbon bond-forming reaction and one of the most widely used in making pharmaceuticals, and diagnostic and imaging materials. Because the natural catalysts are too highly restricted in the substrates they use to be of general use to chemists, the scientists also aimed to generate antibodies that are capable of catalyzing reactions with a greater range of substrates than the enzymes that exist in nature. By moving from the creation of antibodies using the principle of transition-state stabilization to reactive immunization, the scientists have created an antibody that behaves in similar manner to the natural enzyme with regard to its reaction chemistry. In so doing, they have programmed a set of binding pockets to interact with substrates in much the same way as the natural catalyst. According to Lerner, this directly addresses the issue of whether proteins can be made with comparable catalytic efficiency as enzymes when each uses a similar mechanism. He commented, "While we would not suggest that catalytic antibodies will ultimately prove to be as efficient as all enzymes, this work demonstrates that we can develop an antibody whose efficiency can approximate that of a natural enzyme whose function is essential to all life." Further, this study provides insights into the evolution of metabolic enzymes that relate to theories of the origins of life. Funding for the study was provided by the National Institutes of Health and The Skaggs Institute for Chemical Biology.
--------
32-> Cattle: Latest Weapon In The War On Cancer?
CSIRO livestock researchers are exploring extracts of cattle cartilage as a possible potent new weapon in the war on cancer, the Chief of CSIRO Tropical Agriculture, Dr Elizabeth Heij, has announced. A team led by Dr Greg Harper of CSIRO's J.M.Rendel Laboratory in Rockhampton is working to identify special factors in cattle cartilage shown by international research to prevent a cancer from developing a blood supply and spreading round the body. In the process they hope to add a valuable new product to Australia's $4 billion cattle and meat industry. "Overseas scientists have demonstrated that certain extracts of shark cartilage, injected into tumours, cause them to regress. They also appear to inhibit the development of blood vessels to the cancer, which allows them to spread round the body," Dr Harper explains. "The shark cartilage extract market is already worth $1 billion a year in the US alone æ but, worldwide, sharks are in short supply. Our marine scientists believe that shark fishing cannot support the predicted growth in demand for this product." However Dr Harper's work has established that similar factors occur in bovine cartilage æ and Australia produces thousands of tonnes of this from the 7 million cattle the beef industry processes each year. "To reach the body's blood supply and spread, a cancer first has to pass through a matrix of extra-cellular material," he says. "Cartilage is a tissue that functions without nerves, blood vessels or a lymphatic system and consists largely of extra-cellular material æ and it is these characteristics which make it useful in trying to stop a cancer from spreading. "Also it contains factors which interfere with the cancer's passage. We believe that by increasing these factors, the cancer is forced to expend more energy in trying to get through the extra-cellular matrix, making it far more difficult for it to spread, or metastatise." The factors go by the family name of glycosaminoglycans æ or GAGs for short. Dr Harper and researcher Xiaoyi Qui from Beijing's Tiantan Hospital in China, are hard at work trying to identify and characterise the particular GAGs in bovine cartilage that do the best job of inhibiting cancer spread. "The reason we believe cattle are such an important source is that, so far, nobody has succeeded in synthesising these compounds. That means the supply will continue to rely on natural sources. "Shark fishing is probably an unsustainable way of obtaining them, but we believe that domestic cattle offer a very promising alternative," he says. The goal of the research is to make GAGs a valuable coproduct of the beef industry. Overseas, shark cartilage extract sells for $250-500 a kilo, but here bovine cartilage mainly goes into blood-and-bone fertiliser. "About one per cent of every cattle carcase consists of cartilage, and nearly a third of that consists of GAGs æ so the value-adding potential for the meat industry is considerable," Dr Harper says. "The real challenge is to identify which of the GAGs are most active against cancers." Down the track, he envisages bovine GAGs not just as a medical treatment, but potentially an additive for therapeutic foods æ just as some special foods are now enriched with substances which protect the consumer against heart disease, osteoporosis and cancer.
--------
33-> UIC Researchers Find Molecular Clue To Genetic Diseases
Scientists at the University of Illinois at Chicago have found an important molecular clue to genetic diseases caused by expansions of repeated DNA segments. They have shown that the lengths of the segments and the status of protein synthesis in a cell affect their replication.  Researchers found that when the number of repeated segments exceeded a threshold, abnormal replication occurred. Their discovery could eventually set the stage for finding possible ways  to block DNA mutations that result in disease. The findings of the UIC research team, led by Sergei Mirkin, associate professor of molecular genetics, were published in the November issue of the  journal Nature Genetics. The research was supported by grants from the National Science Foundation and the Council for Tobacco Research. Individuals affected by disease carry hundreds, sometimes thousands of repeats of certain trinucleotides, while normal individuals carry only about five to 30 repeats. As a result of this expansion, the affected human genes do not function, resulting in disease. More than a dozen human disorders -- including a common form of mental retardation, Huntington's disease, myotonic dystrophy and several hereditary neurological diseases (ataxias) -- are now attributed to the expansion of repeats of certain trinucleotides in different human genes. Mirkin and his colleagues, genetics postdoctoral fellow George Samadashwily and genetics graduate student Gordana Raca, analyzed the effects of various lengths of the trinucleotide repeats (CGG)n/(CCG)n and (CTG)n/(CAG)n on the replication of plasmids (small rings of DNA) in bacterial cells. They cloned long stretches of the trinucleotide repeats and used a sophisticated technique called two-dimensional gel electrophoresis to detect intermediate steps of DNA replication. They found that the replication process of the repeated DNA segments is abnormal. When the number of uninterrupted repeats exceeded a critical threshold -- 30 to 50 repeats -- the replication process is temporarily stalled by the lengthy repeated segments. And, they found the greater the number of repeats above that threshold, the longer the stall, possibly resulting in an abnormal number of repeated segments being produced. "Replication of the repeated segments took as much as ten times longer than it should have," says Mirkin. "We hypothesize that the abnormal expansion of the repeated segments occurs at this stalling point. "It's as if a car hits a large hole in the road, gets stuck and has to spin its wheels extensively to get out." Mirkin adds that the mechanism that causes this replication blockage and subsequent expansion is not known yet. "Once that is understood, we can try to develop ways to bypass that roadblock and make the replication process go smoothly and thus avoid diseases," says Mirkin. Mirkin sees significant future implications for this line of  research. "We would expect to see many more diseases explained by this abnormal DNA replication process. We believe this expansion may occur in many other DNA repeats that are seen in many other diseases such as diabetes and epilepsy. In a sense, genetic diseases are a side product of the complexity of the DNA replication process, where genetic alterations almost inevitably occur."
--------
34-> First Close-Up Mug Shots Of Asteroid 253 Mathilde
 ITHACA, N.Y. -- So many craters, so little asteroid. Cornell University astronomer Joseph Veverka and a team of scientists arereleasing the first close-up images of a little-known C-class asteroid, 253Mathilde, to be published exclusively in the journal "Science" (Dec. 19).Until now, astronomers have been able to do little but gaze throughtelescopes and observe the minor planet, discovered 112 years ago.  On June27 of this year, the Near Earth Asteroid Rendezvous (NEAR) spacecraftpassed within 1,212 kilometers of Mathilde and took images of the asteroid.Scientists didn't expect to find the minor planet so densely pocked withcraters and so porous, as it is made mostly of carbonaceous chondrite. "Mathilde is very porous, and we still don't know if it was formed that wayoriginally," said Veverka. "This is the first time anyone has ever lookedat an asteroid like this and we were surprised at how 'underdense' it is onthe inside." After reviewing 534 frames of images taken with a variety of equipmentduring the close flyby in June, scientists were surprised to find so manylarge craters packed so tightly on the relatively small surface ofMathilde.  This means that large objects have been able to strike theasteroid's surface without destroying it, Veverka said. "Hitting Mathildeis like hitting a Styrofoam cup or packing material," he said. "Even more remarkable than the simple existence of these large craters isthe degree to which their rim crests and basic shapes seem minimallyaffected by subsequent large impacts," scientists write in the articledescribing the images, "NEAR's flyby of Mathilde: Images of a C Asteroid."The article's authors include Veverka and Cornell scientists Peter Thomas,senior research associate; Ann Harch, research support specialist; BethClark, research associate; James F. Bell III, senior research associate;Brian Carcich, systems programmer, and Jonathan Joseph, programmer, all inthe astronomy department. In addition to the Cornell members of the NEARteam, astronomers from the Southwest Research Institute, Boulder, Colo.;Northwestern University; Space Science Systems, San Diego, Calif.; theUniversity of Maryland, College Park; and Johns Hopkins University'sApplied Physics Laboratory participated in the image analysis and thewriting of the paper. Currently, the NEAR spacecraft is on its way to the S-class asteroid 433,named Eros. Enroute to Eros, NEAR flew by Mathilde on June 27 to gatherinformation. At a flyby speed of 9.93 kilometers a second, the spacecraftspent about 25 minutes relatively close to the asteroid. During its closestapproach, the spacecraft took 144 high-resolution images of the minorplanet's irregular shape and heavily cratered surface. The slow-rotating Mathilde resides in the asteroid belt, which containsthousands of minor planets between Mars and Jupiter.  At the time theimages were taken, Mathilde was approximately 203 million miles from Earth.Mathilde rotates once every 17.4 days; only two other known asteroidsrotate more slowly: 288 Glauke and 1220 Crocus. "That's one of the other mysteries of Mathilde," said Veverka . "It is sosluggish and we still don't know why." Launched aboard a Delta II rocket on Feb. 17, 1996, the NEAR spacecraftmission cost NASA about $122 million and is the first of NASA's DiscoveryMissions, which include a series of small-scale spacecraft designed toproceed from development to flight in under three years for a cost of lessthan $150 million each.  In February 1999, the spacecraft will rendezvouswith Eros and orbit that minor planet for about a year.
--------
35-> Dolly Is Tops --
In the 19 December 1997 issue, the editors of Science offer their picks for the year's top ten scientific breakthroughs. Heading the list as "Science's 1997 Breakthrough of the Year" is the cloning of Dolly, the world's first cloned adult mammal. Science, which is published by the American Association for the Advancement of Science (AAAS) in Washington, DC, is one of the world's most often cited peer-reviewed journals. The annual top-ten list honors those advances that break new ground, unite scientific fields, and offer great potential benefits to society. The cloning of Dolly sparked a firestorm of debate: do ethical concerns outweigh the possible social benefits of mammalian cloning? Can human cloning be far behind? Dolly also challenged scientists to revise their ideas about cell growth, development, and aging (Dolly's DNA is older than she is). Many pointed to the potential good that such techniques may offer, from making identical copies of prized livestock to cloning genetically modified animals that can generate human proteins useful in medicine and other areas. (A step in this direction has already been taken, according to a report in the same 19 December issue--building upon their Dolly experiment, Scottish researchers Schnieke et al. managed to produce cloned, transgenic sheep capable of pumping out a human blood coagulant used to treat hemophilia.) * The nine runner-up breakthroughs are as follows: The Breakthrough feature also looks at the leap science made into public consciousness during 1997 and how global warming changed from being merely a theory kicked around by scientists to one of the hottest public policy debates around. As in previous years, the editors of Science propose six areas of scientific research that promise the most exciting results in 1998: genetically altered agricultural crops; "pharmacogenetics"--technologies that can scan a person's genome for disease genes and custom-tailor therapeutic drugs; the complex relationship between biodiversity and the health of ecosystems; improved climate prediction strategies that might allow up to ten-year forecasts; the structure of the ribosome, the cell's protein factory; and supernovae data suggestive of an endlessly expanding universe. And finally, the editors score themselves on how well last year's predictions fared. The ten breakthroughs honored by Science were chosen by the editors, led by Editor-in-Chief Floyd E. Bloom, M.D. of Scripps Research Institute in La Jolla, CA. Bloom writes about the "Breakthrough of the Year" section in the 19 December editorial (available upon request). AAAS is the world's largest general science organization, with programs in science policy, science education, and international scientific cooperation.
--------
36-> Toxic Marine Organism Causes Learning Problems In Animals, Researchers Find
DURHAM, N.C. -- The toxic marine organism Pfiesteria piscicida, which has killed millions of fish and sickened people in North Carolina and Maryland, also interferes with the learning process in rats, according to a series of studies completed at Duke University Medical Center. The findings, which appear in the December issue of the journal Environmental Health Perspectives, are the first published results of scientific experiments showing exposure to Pfiesteria toxin can cause learning deficits. In the laboratory experiments, toxins produced by the one-celled organism appear to interfere with learning new tasks, but don't impair the memory of previously learned tasks, according to Edward Levin, lead investigator of the study. Pfiesteria represents a growing human health concern and hazard to economically important marine estuaries along the Atlantic coastal waters of North Carolina and Maryland, where it caused major fish kills in recent years. Levin and co-investigators Donald Schmechel from Duke, JoAnn Burkholder, Howard Glasgow and Nora Deamer-Melia from North Carolina State University, Virginia Moser from the U.S. Environmental Protection Agency, and G. Jean Harry from the National Institute of Environmental Health Sciences collaborated in the study. The researchers were prompted to begin the animal study after several scientists accidentally exposed to the organism in a research laboratory experienced a range of worrisome symptoms, including dramatic mental impairment, serious disorientation, emotionality, immune problems and skin sores. Since then, doctors at Duke, Johns Hopkins, and the University of Maryland found that some people who had been exposed to Pfiesteria before or during a Pfiesteria-related fish kill showed evidence of neurological problems. Other people have reported burning skin and respiratory irritation, followed by problems with concentration. Funding for the research was provided by grants from the National Oceanic and Atmospheric Administration's Sea Grant College Program, the National Sea Grant Marine Biotechnology Program and the National Science Foundation. Support was also provided by the Duke University department of psychiatry and Integrated Toxicology Program, the N.C. State department of botany, the N.C. Agricultural Research Service, the U.S. Environmental Protection Agency and the National Institute of Environmental Health Sciences. Marine biologist Burkholder, a co-investigator of the current study, discovered Pfiesteria in 1988. After intense study, she and her co-workers at North Carolina State determined the organism is a type of dinoflagellate, which forms plankton, tiny marine organisms that provide food for many small marine animals. Most dinoflagellates are harmless. However, some dinoflagellates are toxic, producing powerful nerve poisons to deter fish from eating them. Pfiesteria, in contrast, uses its toxins to attack and eat fish flesh. For the current study, Burkholder provided water samples from her laboratory that contained active, fish-killing Pfiesteria toxin. The researchers conducted the experiments in two stages, each designed to measure the effects of the toxin on the rats' ability to learn and remember a task. First, scientists injected 26 rats with aquarium water containing Pfiesteria toxin and tested their ability to remember the maze in comparison to 26 rats injected with aquarium water without the toxin. Then they trained the rats for 18 sessions on a wagon-wheel shaped radial maze consisting of a platform with planks radiating from it. At the end of each plank was a food reward. Once eaten, the food was not replaced. The control rats learned quickly that it was not worth their effort to go down the same plank twice, but the Pfiesteria-exposed rats showed significantly slower learning. In the second stage of the project, the researchers pre-trained a different group of rats, then injected the toxin. These rats remembered the maze as well as the control rats. But then the researchers changed the task by baiting only three of the planks, the Pfiesteria-exposed rats showed poor ability to learn the new task. "The rats exposed to Pfiesteria toxin were significantly retarded in their learning," said Levin, associate professor of psychiatry and director of the Integrated Toxicology Program at Duke. "The effect persisted throughout the 10 weeks the animals were retested after the injection." At the same time, researchers tested each rat using a battery of tests in which they observe sensory and motor responses to new sights and sounds. During these tests, the Pfiesteria-exposed animals mainly appeared normal, but they did show a lower ability to get used to new surroundings, a process known as habituation. "The functional battery of tests supports our other results showing that Pfiesteria causes a learning impairment in otherwise healthy animals," Levin said. The animals were then sacrificed under anesthesia and researchers at NIEHS performed a preliminary assessment of a variety of brain structures, but did not identify the source of the Pfiesteria-induced learning impairment.
--------
37-> Human Breast Milk Contains Obesity Hormone, Researchers Find
WEST LAFAYETTE, Ind. -- Leptin, a hormone that appears to play an important role in body metabolism and obesity, has been found for the first time in human breast milk. In a study of 23 lactating women, researchers at Purdue University, the University of Idaho and Washington State University found that the hormone is present in human breast milk in levels that are lower than, but correlate with, levels in the mother's bloodstream. The research also found that the amount of leptin in the breast milk correlates with the amount of body fat of the mother; obese mothers produce large amounts of leptin, thin mothers produce almost no leptin in their breast milk. The study was published in the current issue of the scientific journal Biochemical and Biophysical Research Communications. Leptin is produced by fat cells and the placenta in the body. Since its discovery in the early 1990s, researchers have been racing to learn more about the protein. The reason is simple: Obese mice that are injected with leptin soon lose their excess weight. Scientists are hoping that by learning more about leptin, they can control the problems of obesity and its related maladies, such as diabetes and heart disease. Karen Houseknecht, assistant professor of animal science at Purdue and adjunct assistant professor of endocrinology and metabolism at the Indiana University School of Medicine, is interested in the role of leptin during transitional periods of the body. She decided to investigate whether this newly discovered hormone was in breast milk, because lactation is an obviously important physiological transition for many women. Although the researchers found leptin in the milk, at this point they aren't sure what role the hormone plays for mothers and infants. "Like many hormones in breast milk, it is difficult to determine what it is doing," Houseknecht says. "It may be that leptin is doing nothing; it may be that the leptin is just there." On the other hand, there are reasons to believe that leptin could be important to neonatal development. "We know that breast milk contains many bioactive hormones and peptides. Research by many groups has shown that breast-fed infants have many health advantages over formula-fed infants," Houseknecht says. "Experiments in suckling rats have shown that rat newborns respond to leptin injections by increasing their metabolic rates. "Leptin in breast milk could mean lots of things to the infant's development. There are receptors for leptin throughout the gastrointestinal tract of adults. If leptin is important to the neonate, we know there is a mechanism for it to get from the intestine to the bloodstream." No one knows yet if leptin is present in cow's milk, or if the pasteurization process damages the hormone, Houseknecht adds. Researchers don't know whether leptin offers any advantages or disadvantages for infant development, but they do know that infants whose nursing mothers have significant fat tissue will be exposed to more leptin in the milk. "Leptin levels reflect the mom's leptin levels," Houseknecht says. "Very thin mothers don't produce very much leptin. This adds another interesting twist to this story, because if leptin is important for infant development, these varying levels may mean that some infants are at a disadvantage." Another theory about how leptin could be important is that leptin may play a role in passing obesity from one generation to the next. An obese mother who produces high levels of leptin and passes the hormone on to her infant may influence the child's metabolism into adulthood. "This is a possibility, but we have no data on this," Houseknecht says. "We know from studies of identical twins that have been separately adopted that there is a huge genetic component to obesity. The animal studies cause us to wonder if milk-borne leptin may play a role, too." Another possibility is that leptin is important for the lactating mother and not important for the infant. Research has found that leptin levels in mothers are elevated during the pregnancy, and that it may be involved in milk production. "We also know that obesity plays a role in lactation, because obese mothers don't breast-feed as well as other women. Studies have shown that obese women start breastfeeding later and don't stay with it as long," Houseknecht says. "So it may be that the leptin is in the milk because in some way it is involved in lactation." Houseknecht has discovered previously that leptin circulates in the bloodstream bound to specific proteins, and this binding process is saturated -- or at its upper limit -- in obese people. The next step for the researchers is to see whether breast milk has leptin-binding proteins that may influence the amount of active leptin available for the infant.
--------
38-> Widespread Genus Of Monkeys Gives Up Genealogical Secrets To Columbia Researchers
Genetic detective work at Columbia University has unraveled the complicated lineages of African and Asian macaques, a genus of cocker-spaniel-sized monkeys that is more widespread than any other primate except humans. New information about how, when and where the macaques spread across three continents over the last 5 million years is expected to tell anthropologists more about how other mammals dispersed and adapted to the same conditions. Among the many findings is that the sole African member of the genus and the widespread Asian long-tailed macaques have been inaccurately placed among the other macaques. The study, which appears in the January 1998 issue of the Journal of Human Evolution, clearly separates the Barbary ape of Morocco and Algeria from the Asian macaques and finds no particular genetic affinity of the Asian long-tailed macaques with other members of a species group that bears its name. The researchers advocate abolishing that species group as a classification. The study of all 19 living macaque species confirms that the genus is one of the oldest among Asian monkeys, dating to at least 7 million years ago, and one of the most successful, radiating from its home base in Africa to Europe and across southern Asia, from eastern Afghanistan through Pakistan, India, southern China, Burma, Thailand, Japan, Taiwan and the Indonesian archipelago. The research was reported by Juan Carlos Morales, associate research scientist at the Center for Environmental Research and Conservation at Columbia, who conducted the genetic analysis, and Don J. Melnick, professor of anthropology and biological sciences and director of the Center, who gathered most of the field specimens for genetic analysis over a period of 20 years and worked with Dr. Morales to interpret the results. Because it shows how and where macaques spread most rapidly -- throughout Asia over the past 5 million years -- the new work will serve as a road map to Asian primate evolution, and to the evolution of many other mammalian species in Asia during this time, according to its co-authors. Data on macaque distribution at different periods in history will give researchers clues to what factors influenced that distribution, and will be of most immediate use in helping decipher the movements of two other widespread primate groups, the leaf monkeys and the gibbons, the researchers said. "With each successive genus that is analyzed in this manner, we will get a better and better idea of exactly what was going on in this part of the world and which geological and climatological events were more important than others in shaping the evolutionary history and dispersal paths of a diverse group of organisms, such as primates," Professor Melnick said. Macaques invaded Asia in what appears to be a series of waves, each time spreading and diversifying across the continent over a relatively short period of time, according to the study's authors. Their rapid differentiation into different species indicates that the environment was conducive to both colonization and diversification. The many isolated species of macaques further indicates that periodic lowering of sea levels allowed the spread and subsequent isolation of macaques on what are now offshore islands. Glaciers and river systems probably also contributed to the isolation of populations and creation of new species. Macaques are members of the papionins, a group of old-world primates that includes baboons, mangabeys and mandrills. The macaques have adapted to a wide range of conditions, finding ecological niches at sea level and at 12,000 feet, from semi-desert to cold mountain forest to low-lying tropical habitats. "The macaques have spread to so many environments precisely because they have conserved many of the generalized features of the old-world monkeys," Professor Melnick said. "As good generalists, they have filled many different habitats with only small anatomical alterations of the skull and body. In many ways, macaques are the Darwin's finches of the primate world." In external appearance, the macaque family has no common defining feature, leading to considerable confusion when appearance has been used to classify them. There has even been some debate on whether macaques are a single genus or two genera, and whether some species now classified as macaques, such as the Barbary ape, rightfully belong in the genus. Until Professor Melnick's and Dr. Morales' work, the accepted classification was the one devised in 1976 by Jack Fooden of the Field Museum of Natural History in Chicago, based on genital appearance. Body size, fur length and coloration, face shape and tail length have also been used by others to identify macaque species. The Fooden classification, while generally accurate, has placed Macaca fascicularis, the long-tailed macaque, as the immediate ancestor of a small group of Asian macaques that include the commonly-known rhesus monkey, from which the Rh blood factor was isolated, the Japanese snow monkey and the Taiwan monkey. In fact, the more recent Columbia studies find that the various species thought to be closely related to the long-tailed macaque simply share with it ancestral characteristics, and have no special genetic proximity to the long-tail. The real ancestor of the rhesus, Taiwan and Japanese macaque lineage is the rhesus monkey itself, the researchers believe. They advocate abolishing fascicularis as a classification, and placing the long-tailed macaques as a more distant ancestor to most of the mainland and offshore island Asian macaques. Researchers examined the DNA in cell bodies called mitochondria, because such DNA evolves relatively rapidly and is only transmitted through the maternal line, making it a good indicator of recent genetic changes. They determined the nucleotide composition of a segment of mitochondrial DNA, then compared the results for genetic similarity and shared genetic changes to draw their conclusions. The work was supported by the Center for Environmental Research and Conservation at Columbia University and the National Science Foundation.
--------
39-> Hubble Space Telescope Witnesses The Final Blaze Of Glory Of Sun-Like Stars
 The end of a sun-like star's life was once thought to be simple:  the star gracefully casting off a shell of glowing gas and then settling into a long retirement as a burned-out white dwarf. Now, a dazzling collection of detailed views released today by several teams of astronomers using NASA's Hubble Space Telescope reveals surprisingly intricate glowing patterns spun into space by aging stars:  pinwheels, lawn sprinkler style jets, elegant goblet shapes, and even some that look like a rocket engine's exhaust. "These eerie fireworks offer a preview of the final stage of our own Sun's life," says Bruce Balick of the University of Washington, Seattle.  More than simply a stellar "light-show," these outbursts provide a way for heavier elements --predominantly carbon -- cooked in the star's core, to be ejected into interstellar space as raw material for successive generations of stars, planets and, potentially, life. The astronomers say the incandescent sculptures are forcing a re-thinking of stellar evolution.  In particular, the patterns may be woven by an aging star's interaction with unseen companions:  planets, brown dwarfs, or smaller stars. "The first time we looked at the Hubble's breathtaking pictures, we knew that our older and simpler ideas of how these objects are formed had to be overhauled," said Howard Bond of the Space Telescope Science Institute (STScI), Baltimore MD.  "The basic question is:  How do these nebulae shape themselves?" "Hubble's colorful views are a feast for the eyes," said Mario Livio, also of the STScI.  "Their beauty is matched only by the mystery." Surprising new details revealed by the Hubble pictures include: *  Unexplained disks and "donuts" of dust girdling a star, which pinch outflowing gas.  These may be linked to the presence of invisible companions. *  Remarkably sharp, inner bubbles of glowing gas -- like a balloon inside a balloon -- blown out by the violently outflowing gases called a "fast wind" (1000 miles/sec) ejected during the final stages of a star's death. *  Strange, glowing "red blobs" placed along the edge of some nebulae may be chunks of older gas caught in the stellar gale of hot flowing material from the dying star. *  Jets of high-speed particles that shoot out in opposite directions from a star, and plow through surrounding gas, like a garden hose stream hitting a sand pile. *  Pinwheel patterns formed by symmetrical ejection of material so that intricate structures are mirrored on the opposite  side of a star. "We're still reveling in the quality of the data and the wealth of new details.  In the longer term, we're going to have to confront these strikingly symmetric structures with some fundamentally revised ideas about the final stages of a star's life," said Balick.  "The lovely patterns of gas argue that some highly ordered and powerful process orchestrates the ways stars lose their mass, completely unlike an explosion." A long-standing puzzle is how these nebulae acquire their complex shapes and symmetries.  The red giant stars that preceded their formation should have ejected simple, spherical shells of gas.  "Hubble's ability to see very fine structural details -- usually blurred beyond recognition in ground-based images -- enables us to look for clues to this puzzle," said Balick. Several teams of astronomers will be observing planetary nebulae using new infrared instruments installed on the Hubble Telescope last February.  This way, astronomers can glimpse the ejection of material at a very early stage long before the expelled nebula starts to become visible optically.  Given Hubble's high resolution, astronomers also hope to revisit the same nebula in a few years to actually see how the shell has further expanded into space.  Their observations will be compared to predictions and either refine or dismiss current ideas on the mass ejection mechanisms of dying stars. "These nebulae observed by Hubble give us a preview of our own Sun's fate.  Some five billion years from now, after the Sun has become a red giant and burned the Earth to a cinder, it will eject its own beautiful nebula and then fade away as a white dwarf star," warned Bond. The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc. (AURA) for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency (ESA). Editor's Note: A detailed news release, including photos of other spectacular nebulae photographed recently by the Hubble Space Telescope, can be found at http://oposite.stsci.edu/pubinfo/PR/97/38.html .
--------
40-> Researchers Successfully Regenerate Transplanted Nerve Axons In Adult Animals
Findings, published in Nature, challenge long-held beliefs on adult nerve regeneration CLEVELAND - Neuroscientists from the Case Western Reserve University School of Medicine have shown that transplanted adult nerve cells can regenerate their axons in the adult rat brain's nerve fiber pathways, challenging long-held beliefs that this is impossible. In their study, researchers found that nerve cells regenerated remarkably well and at relatively high rates of speed in 34 of 41 animals. Their paper is published in the December 18-25 issue of the journal Nature. It is widely accepted that the adult mammalian central nervous system will not permit regeneration of nerve cell processes, called axons. In addition to physical or molecular barriers presented by scarring at a lesion site (such as a spinal cord injury), normal adult nerve pathways, which are insulated with white matter called the myelin sheath, are thought to be impenetrable to nerve regeneration. A 10-year old theory holds that the myelin sheath contains a type of cell which prohibits nerve regeneration. Lead author Stephen J. A. Davies, a CWRU research associate, and colleagues removed dorsal root ganglion neurons from adult donor animals and then used a unique microtransplantation system to transplant them into the brain's nerve pathways of other adult animals. They witnessed rapid growth (1 millimeter per day) and saw that 80 percent of the cells were able to extend axon processes all the way into the brain's gray matter where they branched off in new directions, acting like normal nerve cells. "These results were totally unexpected. There is a huge potential for regeneration in the adult white matter tracks of the central nervous system, at least with the nerve cells that we've used so far," said Jerry Silver, Ph.D., professor of neurosciences at CWRU and senior author of the study. "There's not a minimal potential. It's enormous." The scientists believe that their method of transplantation played a key role in their results. Davies, a research associate in Silver's lab, developed the method, which introduces the nerve cells with little or no trauma to them or the host brain. The minimization of scarring may be important because the researchers found scar tissue around the transplanted cells in the study's seven animals that did not regenerate nerve cells. Within the scar tissue, they found a type of inhibitory molecule called chondroitin sulphate proteoglycan. "In the failed transplants," said Davies, "every single regrowing axon had either stopped within the proteoglycan rich boundary or had actively turned away from the boundary and looped back into the transplant interior." Silver said, "It gives great hope that regeneration might be possible, if we can learn how to breach the immediate vicinity of the lesion by building a bridge across that zone or breaking down the inhibitory scar molecules, we may get regeneration beyond what we ever dreamed possible." Other authors on the study are M.T. Fitch, S.P. Memberg, and A.K. Hall of the Department of Neurosciences at CWRU's School of Medicine; and G. Raisman of the Norma and Sadi Lee Research Centre in the National Institute for Medical Research's Division of Neurobiology in London. Davies is also affiliated with this research center. The research is funded by the International Spinal Research Trust, David Heumann Fund, Brumagin Memorial Fund, and the National Institutes of Health.
--------
41-> Symptoms Found That Identify Early-Stage HIV Infection
Researchers from Johns Hopkins and India find that a simple set of symptoms including fever, joint pain, and night sweats can quickly identify people who recently have been infected with the AIDS virus, even before there is evidence from a blood test. Unprotected sex with a prostitute and a fresh genital ulcer also are tip-offs to recent HIV infection. The findings, published in the Dec. 17, 1997 issue of the Journal of the American Medical Association are important because people in the very early, "acute," phase of HIV infection have not yet produced HIV antibodies, which are the proteins that show up in AIDS blood tests. Thus, the tests can be negative, even if the person is infected. In the current Indian study -- the largest of acutely infected people in the world -- the investigators compared antibody test evidence with simple clinical signs to see which signs were present even when the antibody test was negative. The team, which included researchers from the National AIDS Research Institute of India, screened a group of patients in two sexually transmitted disease clinics in Pune, India, for an HIV protein called p24 antigen. Having p24 antigen is proof of HIV infection. "We were able to show that certain symptoms tended to appear in people who had p24 even before they had a positive antibody test," said Robert C. Bollinger, associate professor of medicine. The study was supported by the National Institutes of Health and the National Institute of Allergy and Infectious Diseases. "Those with a recent history of joint pain were more than six times more likely to test positive for p24 antigen," Bollinger says, "and those with a recent history of night sweats had a ninefold increase in the risk of testing positive. Also, patients who did not test positive for antibodies but did report fever within the last three months were five times more likely to test positive for p24 antigen than those without a recent history of fever." The study's results conflict with previous findings that up to 90 percent of people acutely infected with HIV have certain "unique" symptoms, such as swollen lymph glands, sore throat and oral thrush. The present study found only 47 percent of individuals infected with HIV have such symptoms. The researchers conducted the study between May 1993 and June 1996. Among a total of 3,874 patients, 58 (1.5 percent) had p24 antigen on the first visit and most of these individuals (88 percent) were men. Thirty-nine (77 percent) of the 51 men who were p24-positive reported having sex with a prostitute, while 131 (51 percent) of 255 control men did so. Active genital ulcers were found in 46 (79 percent) of the 58 p24-positive men and women, compared with 137 (47 percent) of the 290 control patients. The World Health Organization estimates that India has more than five million HIV-infected persons and may face the largest burden of HIV infection of any country in the world by the end of this decade. Other authors of the study include Sanjay M. Mehendale, Ramesh S. Paranjape and Deepak A. Gadkari (The National AIDS Research Institute, Pune, India); Ronald S. Brookmeyer, and Mary E. Shepherd (Johns Hopkins); and Thomas C. Quinn (Johns Hopkins and The National Institute of Allergy and Infectious Diseases, Bethesda, Md).
--------
42-> Mysterious Brain Disease Killing American Bald Eagles And Coots May Be Spreading
A mysterious disease that has killed bald eagles and American coots in southwest Arkansas may now be present in two other states, according to wildlife disease specialists at the U.S. Geological Survey's National Wildlife Health Center in Madison, Wisconsin. A small number of coot deaths in North Carolina and Georgia have been linked to this disease, which affects the brain and central nervous system by creating holes in the myelin layers that insulate the nerve bundles. According to the Center's veterinary pathologist Dr. Nancy Thomas, "Myelin coats the nerve bundles much like the plastic coating around electrical wire, and when the coating is damaged it can short- circuit the nervous system." In the winters of 1994 and 1996, this disease killed at least 55 bald eagles at three lakes in southwestern Arkansas, along with an unknown number of coots. No other birds or mammals have been found to be affected. Despite the exhaustive efforts of federal, state and private-sector scientists, the cause or source of the disease remains a mystery, said Dr. Kimberli Miller, a wildlife disease specialist at the Center. Other disease agents known to affect birds, including bacteria, viruses or parasites, have been ruled out, and while microscopic evidence suggests that a neurotoxin may be the cause, tests for natural and man-made toxins that can cause this type of disease have so far been negative. Miller said that field investigations led by the USGS Center are under way, and scientists are hoping that clues from the new locations will help to reveal the cause of the disease. Wildlife managers throughout the United States are being asked to observe coot populations for disoriented or uncoordinated behavior such as erratic flying or impaired ability to swim or dive. The public is urged to report observations of sick or dead eagles or coots to Dr. Kimberli Miller at the National Wildlife Health Center at 608-270-2448. As the nation's largest natural resources science and mapping agency, the USGS works in cooperation with nearly 2000 organizations to provide reliable, impartial, scientific information to resource managers, planners and other customers. USGS hydrologists, geologists, biologists and cartographers work in every state to minimize the loss of life and property from natural disasters, contribute to wise economic and physical development of the nation's natural resources, and enhance the quality of life.
--------
43-> Red Wine's Health Benefits May Be Due In Part To "Estrogen" In Grape Skin
CHICAGO --- Researchers at Northwestern University Medical School have found that a chemical in red wine believed to help reduce risk for heart disease is a form of estrogen. The substance, resveratrol, is highly concentrated in the skin of grapes and is abundant in red wine. Moderate consumption of red wine has been widely reported to reduce risk for cardiovascular disease. Some researchers have attributed this cardioprotective quality to the significant amounts of resveratrol naturally present in grape skin. Resveratrol protects grapes and some other plants against fungal infections. It has been shown previously to have a number of potentially beneficial properties, including antioxidant, anticoagulant, anti-inflammatory and anti-cancer effects. Resveratrol has a molecular structure similar to that of diethylstilbestrol, a synthetic estrogen. This prompted Barry D. Gehm, J. Larry Jameson, M.D., and colleagues at Northwestern to investigate whether resveratrol might have pharmacologic properties similar to those of estradiol, the major natural human estrogen. As reported in the Dec. 9 issue of the Proceedings of the National Academy of Sciences, the group's laboratory studies showed that resveratrol is estrogenic. (Specifically, it is a phytoestrogen, from the Greek word for "plant.") At concentrations similar to those required for its other biological effects, resveratrol activated expression of both artificially introduced "reporter" genes and naturally occurring estrogen-regulated genes in cultured human cells. The researchers also found that resveratrol could replace estradiol in supporting the proliferation of certain breast cancer cells that require estrogen for growth. "Estrogen" is not a specific compound but a category of substances defined by their biological effect. Originally named for their ability to induce estrus ("going into heat") in animals, estrogens act on cells by binding to a protein called estrogen receptor, which then causes certain genes to be expressed, or "turned on." In addition to the body's sex hormones, a number of other natural and artificial estrogens are known. In studying gene expression, many laboratories use artificial reporter genes. The reporter gene used in these studies is the gene for the enzyme luciferase, which makes fireflies light up. It was connected to a piece of DNA that the estrogen receptor "recognizes." When this reporter gene was put into cells, luciferase production increased in those treated with estrogen. Then, when mixed with certain chemicals, the enzyme was measured easily by the light it gave off. In some cells, resveratrol caused more expression of the reporter gene than estradiol. This was surprising, Gehm said, since estradiol has always been thought to produce maximal activation of the estrogen receptor. The group found that the most effective dose of resveratrol produced two to four times more light as the most effective dose of estradiol. However, estradiol is effective at much lower doses. "The estrogenic properties of resveratrol may play a role in the beneficial cardiovascular effects of red wine and the so-called 'French paradox,'" Gehm said. Estrogen is known to provide some protection against heart disease, and red wine also appears to. Their specific effects are similar, most notably, increasing high-density lipoprotein (HDL), the "good cholesterol." This effect of red wine may be mediated by resveratrol. But Gehm cautioned that it is not yet known if the body absorbs enough resveratrol from wine to make this plausible. The same can be said of resveratrol's other effects, described earlier. Some researchers have previously suggested that it would be beneficial to supplement people's diets with resveratrol because of its anticarcinogenic and anti-arteriosclerotic properties. "The discovery that resveratrol is estrogenic means that such supplementation might have undesirable side effects," Gehm said. Nevertheless, the observation that reseveratrol produces greater expression of some estrogen-regulated genes than estradiol may ultimately lead to the development of new, more selective estrogenic drugs. Selective estrogens currently available are used in the treatment of breast cancer (tamoxifen) and postmenopausal osteoporosis (raloxifene). Barry D. Gehm is a research assistant professor of medicine; J. Larry Jameson, M.D., is the C. F. Kettering Professor of Medicine and chief of endocrinology at Northwestern University Medical School. Also collaborating on this study were Joanne M. McAndrews and Pei-Yu Chien.
--------
44-> Other Planets Influence Earth's Climate, University Of Toronto Scientist Says
A University of Toronto professor says a better understanding of the Earth's climate requires a better understanding of the interaction between the planet's geophysical processes and the dynamics of the Solar System as a whole. In an article published in Dec. 18 issue of Nature magazine, U of T physicist Jerry Mitrovica and Allessandro Forte of the Institut de Physique du Globe de Paris use numerical simulations to show the connection between Earth's changing shape and the gravitational effects of other bodies in the Solar System, particularly Jupiter and Saturn. "We're showing for the first time that changes in the Earth's shape, when coupled with the gravitational effects from other planets, can produce large changes in the Earth's climate," Mitrovica says. The evolution of the Earth's precession and obliquity are known to have a long-term impact on climate. Precession refers to the slow movement of the rotation axis in a 26,000-year cycle and obliquity, which varies with a 40,000-year cycle, refers to the tilt of the Earth's axis. As the precession and obliquity change, climate is directly affected because the pattern of the sunshine that falls on the Earth has been altered. Mitrovica has used numerical simulations to show that these aspects of the Earth's orbit have been affected by the gravitational attraction of Saturn and Jupiter. His figures show that at some time during the last 20 million years, the Earth passed through a gravitational resonance associated with the orbits of Jupiter and Saturn, which in turn influenced the way the Earth's axial tilt changed during the same period. This gravitational pull would have had a much greater impact on the Earth millions of years ago when the Earth was shaped differently. "To understand climate on Earth it's clear that we need to consider the Earth as this dynamic deforming system," Mitrovica says. "But we also need to understand, more than we thought we did, the Earth's place in the solar system." This work, part of the emerging discipline of Earth systems science, has broad implications for long-term reconstruction of past and future climate, which in turn may have implications on planetary and human evolution. Mitrovica's research is funded by the Natural Sciences and Engineering Research Council (NSERC) and the Canadian Institute for Advanced Research (Earth Systems Evolution).
--------
45-> Remote Cloud Observatory Tracks El Niño Changes
University Park, Pa. -- Perhaps the largest El Niño of the century is currently underway, and a team of scientists is remotely watching the sky, hoping that they can learn from this event. "A year ago we set up a ground-based observing station in the Western Pacific on Manus Island in Papua New Guinea that is intended to last a decade," says Dr. Thomas P. Ackerman, professor of meteorology at Penn State. "The timing was near-perfect, we got measurements before El Niño, now we are getting measurements during El Niño, and I hope we will get measurements after it passes." The observing station is part of the Department of Energy's Atmospheric Radiation Measurement (ARM) program. Another observing station already exists in rural Oklahoma and others are planned. The program will collect continuous cloud observations and measurements for a decade in an effort to evaluate and develop cloud property and radiation algorithms for the global climate models, and to better understand phenomena like El Niño. "We have records of El Niño quite far back, but the largest in recent history occurred in 1982-83," says Ackerman who also is associate director of Penn State's Earth System Science Center. "Right now, the 1997 El Niño is the biggest we have on record, although it is expected to begin to contract in late fall." El Niño is of serious concern because it affects weather patterns across the Pacific and in North and South America. During an El Niño, the western coasts of the Americas become very wet and hurricanes spawn off the Pacific coast of Mexico, track up through Southern California and dump rain on such normally arid states as Arizona and New Mexico. The northern tier of North America becomes warmer and the southern tier becomes colder. The Southwest, Midwest and Southeast become wetter. The Northeast is little affected by El Niño. In the Western Pacific, El Niño causes severe drought, which is especially problematic for islands relying on rain for irrigation and drinking water. "The situation in New Guinea and nearby islands is serious, as are the consequences of West Coast hurricanes," says Ackerman. "While we are pretty good at projecting the effects of El Nino once one begins, we really do not know how to predict the onset." El Niño is a quasi-periodic event, meaning it appears regularly but not necessarily predictably. Hopefully, data collected by the observing station along with sea surface and air/sea atmospheric temperature readings collected from ocean buoys set out by the National Oceanographic and Atmospheric Agency will help meteorologists and climatologists recognize the onset of El Niño. The observing station monitors water vapor and liquid water in the atmosphere and takes a digital picture of the sky through a fish-eye lens every 10 minutes. Measurements of the base of the clouds and their depth, the particulate content of the atmosphere and radiative fluxes through the atmosphere and reflected radiation from the Earth's surface are also collected. Local weather observers collect temperature, humidity, wind speed and direction, and precipitation data. "We have great cooperation from the New Guinean weather service and after a year, the station is extremely successful," says Ackerman. "No one knew if these stations could work on their own and they do." The main focus of the ARM program is cloud cover and the effect of clouds on the surface radiation budget, which is important in understanding El Niño and in refining the output of the global climate models currently used to understand worldwide events. Normally the Pacific trade winds blow from east to west and push warm water across the Pacific Ocean and allow colder water to move in from the north, south and below, along the west coast of North and South America. When El Niño begins, the trade winds slacken and the water stays put. The west coast water becomes 3 to 5 degrees Celsius warmer than usual and the western Pacific becomes about a degree cooler, equalizing the temperatures across the Pacific. The normally cloud-free west coast becomes cloudy and wet, and the Western Pacific, which has frequent cloud cover and rain storms, experiences drought. "We do not know what makes the trade winds slack off, nor why the El Niño system eventually collapses," says Ackerman. "We do know that clouds play a part in El Niño and other system and we hope that the ARM program can provide information on their effects."
--------
46-> Researchers Find Major Green Tea Ingredient Kills Cancer Cells, Spares Healthy Ones
CLEVELAND - In continuing studies of cancer preventing compounds in green tea, researchers at the Case Western Reserve University School of Medicine have found an ingredient that kills cancer cells, while sparing healthy cells. Investigators tested the ingredient, called epigallocatechin-3-gallate, on cancerous human and mouse cells of the skin, lymph system, and prostate, and on normal human skin cells. In the test tube, it led to apoptosis, or programmed cell death, in the cancer cells, but left the healthy cells unharmed. Findings appear in the December 17 issue of the Journal of the National Cancer Institute. Epigallocatechin-3-gallate is a major constituent of the polyphenols found in green tea. This compound has been shown in previous studies from CWRU and elsewhere to prevent cancer in laboratory animals. "We found that this particular compound, which is present in the amount of about 200 mg in one cup of green tea, can kill a variety of cancer cells through apoptosis without affecting the normal cells," said Hasan Mukhtar, a professor of dermatology at CWRU and senior author of the paper. The polyphenol broke the DNA of the cancer cells into fragments, a characteristic of apoptosis. "The killing of cancer cells and the sparing of normal cells is very interesting because apoptosis is a programmed cell death which is a normal process going on in the body all the time. It is a preferential way of elimination of unwanted cells from the body," said Mukhtar. Polyphenols induce the demise of cancer cells, but scientists do not yet know why this happens, said Mukhtar. "It is likely that this compound conveys a message to cancer cells through a highly ordered and well-regulated signal transduction pathway that says, 'You must commit suicide (programmed cell death) or I am going to kill you.' The cells then decide that instead of being murdered, they will commit suicide," said Mukhtar. He feels that this finding leads investigators to a greater understanding of the mechanism involved in the process. If they can decipher the molecular mechanism by which green tea imparts protective effects, the knowledge may provide opportunities to interfere with cancer development through administration of purified polyphenolic derivatives, said Mukhtar. "Green tea appears to be potentially an ideal agent for chemoprevention." The investigators feel that the chemoprevention properties of green tea need to be evaluated in human trials. Tea consumption in the world ranks second only to water consumption. Approximately 20 percent of tea consumed is green; the rest is black tea. Other authors on the paper are Nihal Ahmad, Denise K. Feyes, Anna-Liisa Nieminen, and Rajesh Agarwal, all with the CWRU School of Medicine.
--------
47-> New Bacterium May Aid War On Insect Pests
NASHVILLE - In the world of biological pest control, Bacillus thurengensis, Bt for short, is the king of insecticides. For 30 years Bt, a bacterium with remarkable insecticidal properties, has been a pest-control mainstay for foresters, farmers, gardeners and homeowners in search of a safe, natural way to neutralize the bugs that bug them. As a form of biological pest control, it is the only bacterium from which widespread commercial applications have been possible, giving it, in effect, a microbial monopoly on insect control worth hundreds of millions of dollars. But now a team of scientists from two laboratories at the University of Wisconsin-Madison, working in collaboration with scientists from DowElanco of Indianapolis, hopes to unleash a new bacterium with similar insect-thwarting properties. The bacterium, Photorhabdus luminescens, contains a toxin that has proven effective against a broad array of insect pests - from cockroaches to boll weevils - and promises to become a potent, safe and environmentally benign weapon in the war against insect pests. "It's a voracious pathogen. One bacterial cell can kill an insect," says Jerald Ensign, a UW-Madison professor of bacteriology who, with then-graduate student David Bowen, discovered and characterized the toxic potential of Photorhabdus, a widely-dispersed, multiple strain bacterium that lives inside of and in symbiosis with soil-dwelling roundworms called nematodes. The bacteria live inside the gut of nematodes that invade insects. Once inside an insect host, the bacteria are released from the nematode, kill the insect, and set up rounds of bacterial and nematode reproduction that turns the insect into a "protein soup," food for large numbers of nematodes. "This makes Alien look like a cakewalk," says Richard ffrench-Constant, a UW-Madison professor of toxicology in the department entomology. The Photorhabdus bacteria, in fact, do Alien one better: The corpses left behind by the bacteria glow in the dark as the microbe produces luminescent proteins in addition to potent insecticides. The findings of the Wisconsin group were reported here today (Dec. 17) at the annual meeting of the Entomological Society of America. After establishing that Photorhabdus luminescens was indeed an effective killer of a wide variety of insects, Bowen moved as a post-doctoral fellow to the lab of ffrench-Constant where he continued work on the biochemistry of the toxin and orchestrated a nationwide survey for new toxic strains of the bacterium. So far, that survey has yielded scores of new Photorhabdus strains. The discovery of a diverse new family of insect-killing bacteria has added importance since, in recent years, some insects have already begun to exhibit resistance to the Bt toxin, raising fears that the biological pesticide may be losing its potency. By adding an entire family of lethal bacteria to the biological pest-control arsenal, the Wisconsin and DowElanco scientists have opened a potentially broad new front in the war on insect pests since each of the Photorhabdus strains produces its own variation on the toxin. "What we have is a natural source, almost an infinite variety" of toxic molecules, says ffrench-Constant. "We can't afford to hook ourselves to a single bacterium or a single toxin." The Photorhabdus toxin and the genes that produce it have been patented jointly by the Wisconsin and DowElanco scientists through the Wisconsin Alumni Research Foundation (WARF). The technology has been licensed to DowElanco. In concentrated doses, the toxin can be used as a spray or fed directly to insects. The greatest potential application, however, lies in transferring the toxin-producing genes from the bacteria to crop plants. Already, scientists have transferred the genes that code for Bt's insect-thwarting properties to important crop plants. Next year, an estimated 3 million to 5 million acres of Bt transgenic corn will be planted in the Midwest alone. "This deployment of Bt transgenic crops is perhaps the biggest artificial experiment on natural selection in insect populations since the introduction of synthetic insecticides half a century ago," according to ffrench-Constant. The incentive to confer crop plants with their own insecticides is huge. Farmers now spend more than $575 million annually on chemical pesticides to protect just one crop: corn. Bowen, working with colleagues Thomas Rocheleau and Michael Blackburn in ffrench-Constant's lab, has identified, cloned and sequenced the genes responsible for the Photorhabdus' toxin. Clones were independently derived at DowElanco as well. The next step, already well underway, is to move those genes to any amenable crop plant. Bringing a product to the field, however, may still take anywhere from three to five years, says ffrench-Constant. "The need for Bt replacements is critical before we have many crops in North America expressing a limited range of Bt toxins," says ffrench-Constant. "If we don't have them, it's an open invitation for natural selection to confer resistance on insects and we'll lose that control."
--------
48-> Researchers Improve Treatment Of Industrial Waste
Research being conducted at the University of Toronto's Pulp and Paper Centre promises a cheaper and more energy-efficient method to clean up industrial emissions. Professor Grant Allen of the department of chemical engineering and applied chemistry and a team of researchers have devised a process that treats waste air and water emissions -- while they are still hot -- from pulp and paper mills. Using heat-resistant microbes, the researchers treat waste air and water at temperatures up to 70 degrees Celsius, removing various pollutants. Currently industrial emissions must be cooled before treatment, using methods that require large amounts of energy. Waste gases are cooled to 40 degrees Celsius so they can be treated with bacteria; waste water, to 35 degrees Celsius before secondary biological treatment. "Right now there's a strong interest in treating the air and water effluents at high temperatures because that's how they're emitted," says Allen, associate director of the Pulp and Paper Centre. "Our process will save companies time and money by eliminating the steps that must be followed to cool the waste. There's also an environmental benefit because less energy is used." The ultimate goal of the team's research, he adds, is to treat and reuse the effluent once it has been cleaned. The research on waste air is sponsored by the Natural Sciences and Engineering Research Council and a group of companies known as Environmental Sciences and Technology Alliance Canada; the research on gas emissions is sponsored by an international consortium of 13 pulp and paper companies and by the Ontario's ministry of the environment. CONTACT: Professor Grant Allen, Pulp and Paper Centre, (416) 978-8517, e-mail: allendg@chem-eng.utoronto.ca or Roberta Fulthorpe, department of environmental science at Scarborough, (416) 287-7221, or (416) 287-7223, e-mail: fulthorpe@scar.utoronto.ca or Steven de Sousa, U of T public affairs, (416) 978-6974, e-mail: steven.desousa@utoronto.ca.
--------
49-> Closest Flyby of Jupiter's Moon Europa Marks Start Of Galileo's New Extended Mission
 NASA's Galileo spacecraft yesterday successfully made its closest-ever flyby of Jupiter's icy moon Europa, marking the start of an extended mission that will focus on new and tantalizing scientific questions raised by its just-completed, highly successful two-year primary mission. "Galileo has earned a place in history as the first mission to orbit an outer planet," said Dr. Wesley T. Huntress, Jr., NASA's associate administrator for space science, Washington, DC.  "Galileo already has returned a wealth of new information in its two-year scientific exploration of Jupiter's atmosphere and system of moons.  But the best yet may still be ahead of us as Galileo continues its mission at Jupiter with a focus on the moons Europa and Io in the next two years." Galileo dipped over Europa at an altitude of only 124 miles (200 kilometers), with the signal received on Earth at 7:49 a.m. EST.  This was the first encounter of the Galileo Europa mission, which began formally on Dec. 8, following the end of Galileo's primary mission.  The Galileo Europa mission will study Jupiter's icy satellite in detail in hopes of shedding more light on the intriguing prospect that liquid oceans may lie under Europa's ice crust. New images released today from Galileo's Europa encounter of Nov. 6 show more evidence that the moon has been subjected to intense geological deformation.  The pictures show a mottled region of dark and splotchy terrain that scientists say represents some of the most recent geologic activity on Europa.  It is believed the mottled appearance was created when chaotic areas of the bright, icy crust broke apart and exposed darker material underneath.  The new images also show a smooth, gray band where the Europan crust has been fractured, separated, and filled in with material from the interior.  Numerous isolated mountains or "massifs" are visible. The new images represent a small portion of the 1,800 images obtained during Galileo's primary mission, including hundreds of high-resolution images of Jupiter's moons.  The images and other information gathered by Galileo's science instruments have dramatically revised our knowledge of Jupiter and its moons, according to mission scientists. The Galileo Europa mission is designed to follow up on these discoveries and will include eight consecutive Europa flybys through February 1999, followed by four Callisto flybys and one or two Io encounters in late 1999, provided the spacecraft remains healthy. "The Galileo Europa mission really builds upon the success of the prime mission which has forced us to re-think many of our perceptions of the Jovian system," said Galileo project scientist Dr. Torrence Johnson.  "We've acquired a tremendous pool of knowledge about Jupiter, its magnetosphere and its four largest moons." The key findings of Galileo's primary mission include: *    The existence of a magnetic field on Jupiter's largest moon, Ganymede;*    The discovery of volcanic ice flows and melting or "rafting" of ice on the surface that supports the premise of liquid oceans underneath at some point in Europa's history;*    The observation of water vapor, lightning and aurora on Jupiter;*    The discovery of an atmosphere of hydrogen and carbon dioxide on the moon Callisto;*    The presence of metallic cores in Europa, Io and Ganymede and the lack of evidence of such a core in Callisto;*    Evidence of very hot volcanic activity on Io and observations of dramatic changes compared to previous observations and even during the period of Galileo's observations. "We look forward to providing even more fascinating science results over the next two years," said newly appointed Galileo Europa mission project manager Bob Mitchell of NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA. JPL manages the Galileo mission for NASA's Office of Space Science, Washington, DC.  The new images shown at today's briefing are available on the Galileo Internet home page at the following URL:  http://www.jpl.nasa.gov/galileo/ Members of the Galileo mission will answer questions from the public during a Galileo WebChat on Wednesday, Dec. 17 from 6 to 9 p.m. EST, at URL: http://www.jpl.nasa.gov/galileo/chat/ 
--------
50-> Earth's Interior May Contain Oceans Of Water, Geologist Says
The earth's interior may contain three to five oceans of water locked within billions of crystals that could help regulate the level of water on the surface of the planet, a University of Colorado at Boulder geologist says. Ten years ago, Professor Joseph Smyth discovered that a mineral called wadsleyite, located 250 miles to 350 miles below the earth's surface, could contain water. The wadsleyite does not contain liquid water, but the elements needed to make water bound up in crystals in solid form. As a rule, rocks on earth are quite dry -- much drier than meteorites, for example, which also contain wadsleyite. Earth rocks generally contain only a small fraction of 1 percent of water. Wadsleyite is about 3.3 percent water. That may not seem like much, but given the amount of wadsleyite scientists think is in the earth-- it could be three to five times the amount of all the surface water on the planet, Smyth said. "It's possible the earth has this way of regulating the amount of water on the surface," Smyth said. The part of the earth where wadsleyite is located, the mantle, convects and occasionally breaks through to the surface in the volcanic vents of mid-ocean ridges where the continental plates are spreading. Water may be carried down into the upper mantle through subduction zones where plates converge, and it is possible that wadsleyite could store large amounts of water in this region, he said. With rising convection currents, the wadsleyite may melt and release water vapor into the oceans as the molten rock cools. The wadsleyite in the mantle is at a pressure of about 3 million pounds per square inch and a temperature of about 3,000 degrees Fahrenheit. It is located in the top half of the transition zone between the upper and lower mantle. The amount of wadsleyite in the earth has been calculated. The big question is how much water the wadsleyite contains, and Smyth is conducting laboratory tests to try to find the answer. His tests consist of making wadsleyite in the lab by squeezing it between two diamonds in a vice -- which creates 3 million pounds per square inch of pressure -- and then analyzing the sample with X-rays to determine water content and other physical properties. Determining the amount of water in wadsleyite would allow scientists to know the speed at which wadsleyite transmits seismic waves. If seismic waves sent through the earth matched that speed, scientists would know how much the water is held within the earth. Smyth chaired a panel of 13 scientific presentations on "Water in the Mantle" Dec. 12 at the fall meeting of the American Geophysical Union in San Francisco. The earth's oceans have existed for at least four billion years, and have been fairly constant in volume over the last 500 million years. These "inner oceans" may play a role in regulating that supply, Smyth said. In 1996 Smyth also discovered wadsleyite II, which may store water under even greater pressures at a lower portion of the transition zone. Two undergraduate students and four graduate students are assisting Smyth on his research. More information on wadsleyite structures can be found on the Internet at http://ruby.colorado.edu/~smyth/Home.html .
--------
51-> Programmed Cell Death: Search Accelerates For Mechanism Underlying Cancer, Stroke, Heart Attack
Sometimes cells are supposed to die. The process is called apoptosis or programmed cell death.  Cells die as a part of normal development, as some of them specialize and differentiate into organs and systems.  They die in self-defense when they are infected by intruders such as bacteria and viruses. And sometimes they die because their normal life cycle is disrupted by chemicals or other toxins.  Other times cells don’t die when they are supposed to.  Something interferes with the normal process of apoptosis, and cells continue growing and reproducing out of control. The result of this breakdown of apoptosis is cancer. Pathologists at the University of Maryland School of Medicine now have made a giant stride toward mapping the tortuous biochemical pathway of programmed cell death.  Once the complex interaction of mechanisms along the pathway to programmed cell death is unraveled, it should be possible to devise drugs to cause cell death when it is needed, as in cancer, and to prevent it in conditions such as stroke and heart attack. By micro-injecting cytochrome c–a protein normally found in the mitochondria or energy-generating structures within cells–Benjamin F. Trump, MD, and colleagues have speeded up enormously the process of programmed cell death in normal rat kidney cells.  They will present their findings at the American Society for Cell Biology annual meeting at the Washington Convention Center in Washington, DC, at noon Wednesday, December 17, 1997. Within 30 minutes after cytochrome c was injected directly into the cytoplasm inside the cells, the cells began to show typical changes in structure that indicate that apoptosis was under way.  By five hours after the injection, 50 to 60 percent of the cells had died. Earlier experiments involving injection of P53, another normal cellular protein that causes cell death at appropriate times, showed similar results but took 18 to 48 hours. "This has moved us way down the pathway, close to the end," said Trump, professor and chairman of pathology at the Baltimore-based medical school. "By simply micro-injecting cytochrome c, we can reproduce the other steps in the process and do it incredibly quickly. Now we want to know the role of other proteins along the pathway, such as the proteases and bcl2, and whether an influx of calcium finally causes the mitochondria to swell, the cell membrane to swell, and the cell to die." Trump’s lab has pioneered in cell-death research.  His colleagues on the cytochrome-c research are Seung H. Chang, Patricia C. Phelps, M.L. Ebersberger and Irene K. Berezesky, all in the University of Maryland School of Medicine Department of Pathology.  The work was funded by the National Institutes of Health. 
--------
52-> Studies Shed New Light on HIV Epidemic in India
Two studies supported by the National Institute of Allergy and Infectious Diseases (NIAID) provide important new information about the HIV/AIDS epidemic in India, the country with the single largest number of HIV-infected persons in the world.  One study identifies risk factors and describes clinical symptoms associated with newly acquired HIV infections.  The other sheds light on how the virus is transmitted from high-risk to low-risk populations in India.  Both are published in the Dec. 17 issue of the Journal of the American Medical Association (JAMA). "By advancing our understanding of risk factors, signs and symptoms of acute HIV infection and the dynamics of HIV transmission, these studies should help scientists and physicians in India develop better strategies to prevent HIV infection," says NIAID Director Anthony S. Fauci, M.D.  "This information also should be useful to investigators studying HIV/AIDS in other developing countries, which bear the brunt of the global AIDS pandemic." A recent report by the United Nations and the World Health Organization estimates that 16,000 people worldwide are newly infected with HIV each day, mostly in sub-Saharan Africa and Asia. The report also estimates that between 3 million and 5 million people in India already are infected with HIV, more than in any other country. In one of the JAMA studies, scientists from NIAID, The Johns Hopkins University School of Hygiene and Public Health in Baltimore, Md., and the National AIDS Research Institute (NARI) in Pune, India, identified individuals with newly acquired HIV infections among patients at sexually transmitted disease clinics in Pune.  Patients who tested negative for HIV antibodies were screened for p24 antigen, an HIV core protein.  Because p24 antigen can be detected in HIV-infected blood several weeks before HIV antibodies first appear, its presence serves as an indicator of acute infection. "Patients who test positive for p24 antigen are likely to have been infected with HIV within the last two to three weeks," explains senior author Thomas Quinn, M.D., of NIAID's Laboratory of Immunoregulation.  "Most investigations of acute HIV infection have studied individuals who have been infected with HIV for as long as several months.  With p24 antigen screening we can identify HIV infections much sooner after they occur and thus get a more accurate picture of risk factors and symptoms of acute HIV infection." The researchers found that p24 antigen-positive patients were five times more likely to have had unprotected sex with commercial sex workers and three times more likely to have an active genital ulcer than were p24 antigen-negative controls.  Clinical symptoms that distinguished p24 antigen-positive patients from controls included fever, night sweats and joint pain.  However, symptoms such as enlarged lymph nodes, oral thrush, diarrhea and rash, which previous studies have linked to acute HIV infection, were not clearly associated with the presence of p24 antigen in patients' blood. "Our data suggest that many of the previously described signs and symptoms of acute HIV infection may be relatively nonspecific, particularly in developing country settings where other endemic diseases with similar symptoms are more common," Dr. Quinn and his colleagues conclude. In the second study, Dr. Quinn and scientists from NARI and Johns Hopkins assessed the prevalence of, and risk factors for, infection with HIV in women who were sex workers and women who were not.  The 916 women enrolled in the study were attending sexually transmitted disease clinics in Pune, India. The researchers detected HIV in nearly 50 percent of the sex workers and more than 13 percent of the women who were not sex workers.  Inconsistent condom use and genital ulcer disease or genital warts were factors associated with HIV infection in the sex workers.  The only significant HIV risk factor noted for the other women, however, was sexual contact with a partner having a sexually transmitted disease. "More than 90 percent of these women reported having only one lifetime sex partner," says Dr. Quinn, "and an equal proportion reported that their partners had not used condoms with them within the past three months.  It is therefore likely that the unexpectedly high rate of HIV infection seen among women who are not sex workers is due to transmission of the virus from infected partners.  Many of these women may erroneously believe themselves to be at low risk of infection because of a presumably monogamous relationship." The researchers note that, as in much of the developing world, women in India likely have little ability to discuss or negotiate condom use or reduction of the number of their partners' sexual contacts. This, they conclude, warrants implementation of condom distributionprograms and educational efforts aimed at increasing condom acceptance. Development and availability of effective vaginal microbicides, they add, also would enable women to protect themselves in situations where men refuse to use condoms. Funding for these studies was provided by NIAID, the Fogarty International Center (FIC) and the National Center for Research Resources (NCRR), each of which are components of the National Institutes of Health (NIH).  NIAID supports research on AIDS, malaria, tuberculosis and other infectious diseases, as well as allergies and immunology.  NIH is an agency of the U.S. Department of Health and Human Services.                                                             ###References: Bollinger RC, Brookmeyer RS, Mehendale SM, Paranjape RS, Shepherd ME, Gadkari DA, Quinn TC.  Risk factors and clinical presentation of acute primary HIV infection in India.  JAMA 1997;278(23):2085-2089. Gangakhedkar RR, Bentley ME, Divekar AD, Gadkari DA, Mehendale SM, Shepherd ME, Bollinger RC, Quinn TC.  Spread of HIV infection in married monogamous women in India. JAMA 1997;278(23):2090-92. Press releases, fact sheets and other NIAID-related materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov    advertisement     googletag.cmd.push(function() { 
											deployads.push(function() { deployads.gpt.display("adslot-mobile-middle-rectangle") }); 
										});         advertisement     googletag.cmd.push(function() { 
										deployads.push(function() { deployads.gpt.display("adslot-mobile-bottom-rectangle") }); 
									});     a>.
--------
53-> Skull Of Refrigerator-Size Ancient Armadillo Finds A Home At UF
Writer: Cathy Keen Source: Russ McCarty, (352) 392-1721 GAINESVILLE, Fla. --- At more than 6 feet long and weighing as much as 600 pounds, this is one armadillo that likely wouldn't have ended up as road kill. That's about the size of the armadillo University of Florida researchers say roamed the Sunshine State 10,000 years ago, and now they have a well-preserved skull to prove it. "The skull belonged to one of two species of giant armadillo that lived in Florida during the Pleistocene Epoch, and its unusually good preservation makes it one of only a handful of its kind in the United States," said Russ McCarty, a University of Florida senior biological scientist. Found in a limestone quarry west of Gainesville, the skull now is at the Florida Museum of Natural History on the UF campus, where researchers are preserving and restoring the specimen so it can be stored and displayed in the building's collections. "It's a very important specimen because it is so complete and has all its teeth," McCarty said.  "The wear patterns that we're able to see on the teeth may give us some valuable clues about these creatures' diet. We really don't know exactly what they ate. That information would give us a better understanding of the niche they occupied, their relationship to other animals, as well as the whole ecosystem of the time." Called Holmesina septentrionalis, the beasts, like their smaller modern counterparts, spread to what now is Florida from South America. Ground sloths, tapirs and other exotic creatures followed the same route into the Sunshine State, he said. Unlike today's armadillos that subsist on termites, ants and beetles, the ancient ones, weighing as much as 600 pounds, likely needed more substantial fare to survive, he said. Unfused limb bones indicate the specimen was a juvenile, which may give clues about the armadillo's growth sequence, McCarty said. "We don't know much about juveniles or how they develop into adults," he said. "The few skulls that are found tend to be adult." Scientists also would like to learn more about how the giant armadillos differed in its evolution from the ground sloth and glyptodont, its close relatives, he said. Richard Hulbert, a geology professor at Georgia Southern College who saw the skull at the museum several months ago, said, "It was evident that it was much more complete than any we've previously had of these species. It certainly will be important for studying how these animals lived and trying to figure out why they became extinct." Giant armadillos became extinct in Florida about 9,800 years ago, a period of dramatic climate change, McCarty said. But a smaller variety continued to live in South America, as did llamas, large rodents called capybaras, and tapirs, the pig-size animals closely related to horses and rhinoceroses, all of which once roamed Florida, he said. Because people lived in Florida 11,000 to 12,000 years ago, early humans encountered giant armadillos for a few thousand years before they disappeared, he said. "We haven't found any evidence that people hunted them, but they were probably considered as possible food sources," he said. "Maybe the heavy armored plates on their bodies were a good defense against spear points." The skull at UF was discovered in August. Eric Taylor, a Lake City insurance agent, showed the site to Adam Black, a biological illustrator specializing in painting extinct Pleistocene mammals, who found rabbit bones and armadillo shells sticking out of the vertical limestone cliff face in the Haile quarries. Six months later, when the two men returned, a rock slide had exposed more bones, including the skull. "We were just elated," said Taylor, who also is secretary of the Florida Paleontological Society. "I probably will never see anything like it the rest of the time I'm involved in fossil collecting. We knew right away that it was a significant find because the skulls of these creatures are so rare." The site may have been a wolves' den because of the presence of a "dire wolf" skull and the bones of hundreds of rabbits, which these robust wolves ate, McCarty said. Because armadillos have armored shells, the armadillo skull probably was not prey but just happened to tumble into the sinkhole cavity, ending up in the wolves' den, he said. -30- Editor's Note: Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-9092.
--------
54-> Scientists Confirm Existence Of Atom-Sized Electronic Devices Within Carbon Nanotubes
 BERKELEY, CA. -- Scientists with the Ernest Orlando Lawrence BerkeleyNational Laboratory (Berkeley Lab) have confirmed the existence of atom-sized electronic devices on nanotubes, hollow cylinders of pure carbonabout 50,000 times more narrow than a human hair in diameter. Nanotubedevices have been predicted by theorists but this is the firstdemonstration that such devices actually exist. Alex Zettl, a physicist with Berkeley Lab's Materials SciencesDivision and a professor of physics on the University of California'sBerkeley campus, led a study in which nanotubes of pure carbon wereshown to function as a two-terminal electronic device known as a diode. "What we are seeing is the world's smallest room temperaturerectifier, one that is only a handful of atoms in size," says Zettl. "When we grow nanotubes, electronic devices naturally form on them." Past attempts to identify nanotube devices employed submicron-sizedelectrode contact pads that could only measure small isolated sectionsof the tube.  Evidently, the experimenters were measuring the wrongsections.  Zettl succeeded by measuring nanotubes along their entirelength.  He accomplished this through the use of the ultrafine tip of ascanning tunneling microscope. The research was reported in a recent issue of the magazine Science(10/10/97).  Co-authoring the paper with Zettl were Phil Collins, ofZettl's research group; Hiroshi Bando, from the ElectrotechnicalLaboratory in Japan; and Andreas Thess and Richard Smalley of RiceUniversity. Nanotubes are only a few nanometers (billionths of a meter) indiameter. When made exclusively from carbon molecules, they arechemically inert, about 100 times stronger than steel, and offer a fullrange of electrical and thermal conductivity possibilities. Carbon nanotubes were discovered by the Japanese electronmicroscopist Sumio Iijima.  They are created by heating ordinary carbonuntil it vaporizes, then allowing it to condense in a vacuum or an inertgas.  The carbon condenses in a series of hexagons, like sheets ofgraphite, that curl and connect into hollow tubes. Depending upon its diameter, a pure carbon nanotube can conduct anelectrical current as if it were a metal, or it can act as asemiconductor, meaning it will only conduct a current beyond a criticalvoltage.  According to a theory proposed by Berkeley Lab physicistsMarvin Cohen and Steven Louie, both also with UC Berkeley, an electronicdevice could be created at the interface between two dissimilarnanotubes, one that acts as a metal and one that acts as asemiconductor.  This would create a "Schottky barrier," which means thecurrent will only flow in one direction -- from the semiconductor to themetal.  Under the scheme envisioned by Cohen and Louie, the twodissimilar tubes would be connected by the introduction of pentagon-heptagon pair defects (rings of five and seven carbon atoms) into theinterface region. Zettl and Collins have been able to confirm that Schottky barriers doexist along carbon nanotubes.  The key to their success was the scanningtunneling microscope or STM.  An STM features a metallic tip that is theworld's smallest pyramid: a few layers of atoms descending in numberdown to a single atom at the point.  The Berkeley researchers wouldbring the tip of an STM into contact with a tangle of nanotubes on asubstrate then slowly withdraw it.  Van der Waals forces would induce asingle nanotube to stick to the tip of the STM and the researchers wouldcarefully stretch it out from the other nanotubes on the substrate, muchlike unravelling a single fibre from a nest of thread.  Once a singlenanotube was extracted, the researchers would then slide the STM tipacross its entire surface to measure variations in an electrical currentpassing through. "We measured distinct changes in the conductivity as the activelength of the nanotube was increased, suggesting that different segmentsof the nanotube exhibit different electronic properties," says Zettl. "The changes occurred over very short lengths and were suggestive of on-tube nanodevices." Zettl does not expect nanotubes to replace silicon overnight in theelectronics industry but can see this as a possibility down the road. Silicon must be doped with other atoms to make an electronic device.  Asthe size of a device shrinks, the dopant atoms eventually begin to moveabout, degrading the device's performance.  Heat also becomes a problemdespite silicon's good thermal conductivity.  The use of diamond film,with its exceptionally high thermal conductivity, has been proposed toprotect silicon-based devices but this adds further complications to themanufacturing process.  Size and heat are no issue for nanotubes becausethey are covalently bonded (which means their atoms are locked firmlyinto place) and are predicted to be even better thermal conductors thaneither silicon or diamond at room temperature. "Silicon is eventually going to hit a brick wall where devices can'tbe made any smaller," Zettl says.  "Nanotubes are already smaller anddon't have a problem with heat.  You could not ask for anything betterin a material." Rather than wiring individual devices in nanotubes for specificpurposes, as is done with silicon chips, Zettl suggests a betterapproach might be to make a "tube cube," a block of nanotubes that wouldbe densely packed with billions upon billions of devices.  The tubecould then be wired to form a random network of "nanocomputers."  Thisrandom network would be able to train itself to perform tasks,reconfiguring its input/output architecture to improve its performanceas it learns and develops.  In other words, this random computer wouldnot just get older, it would get better. "The idea is not as far off as you might think," says Zettl, whosegroup has already constructed and wired up a tube cube of sorts.  Thecube cannot yet perform any useful function, but Zettl says it doesyield some "interesting" responses to input signals. "Nanotube technology might be exploited in a conventional manner orwe might have to go off in a completely different direction," saysZettl.  "The technology simply has too much potential to not figure outhow to use it." The Berkeley Lab is a U.S. Department of Energy national laboratorylocated in Berkeley, California.  It conducts unclassified scientificresearch and is managed by the University of California.
--------
55-> Computer Simulations Show That Certain Gasses Could Stimulate Global Cooling
SAN FRANCISCO---Contrary to the conventional wisdom, new computer modeling from the University of Michigan suggests that global warming might not be a product of human activity. Ironically, argues Joyce Penner, professor of atmospheric, oceanic and space sciences, carbon and sulfur emissions can have the reverse effect, serving to cool down the planet. Penner, an expert in computer simulations of climate change, recently found that, whereas greenhouse gases have led to a warming of 2.5 Watts per meter squared, aerosols like soot particles and sulfuric acid reflect nearly twice as much energy under certain conditions. "This effect clouds our understanding of climate change over the last 100 years, but still cannot protect us from the larger increases in greenhouse gases expected in the future," Penner said. "If further research serves to uphold these initial findings, the warming we've seen over the last 100 years may simply be due to natural variability," she said. Penner is presenting the work Friday (Dec. 12) at the fall meeting of the American Geophysical Union in San Francisco. When floating freely in air, carbon aerosols from fossil fuel emissions add between .16 and .20 Wm-2 to the atmosphere, and thus heat it. But, according to the latest simulations by Penner and her colleagues at the Lawrence Livermore National Laboratory, in Livermore, Calif., and the Centre des Faibles Radioactivites, in Gif sur Yvette, France, carbon aerosols trapped in clouds may cool the earth's atmosphere by as much as -4.4 Wm-2---or a net decrease of roughly 0.7 to 2.1 degrees Celsius, provided nothing changed in the future. Penner said that the models are uncertain because they rely on poorly known estimates for natural sources of aerosols, so the actual number for negative forcing could be as low as -2.4 Wm-2. Even so, she said, the results are startling. "I had not expected to get such a large negative forcing from carbon aerosols in clouds. If these results hold up, we are going to have to do a lot more work to understand how climate might change in the future."
--------
56-> Researchers Report Construction Of Genetic Map For Dogs
Ithaca, N.Y. -- Researchers at the Fred Hutchinson Cancer Research Centerin Seattle and the James A. Baker Institute for Animal Health at Cornell'sCollege of Veterinary Medicine are reporting the development of a frameworkreference map of the canine genome. The article appears in today's issue ofGenomics, published by the Academic Press. The ultimate goal of canine genome research is to find all the genes in theDNA sequence of dogs and make this information available to others todevelop tools to better diagnose disease well before the appearance ofsymptoms. It is believed that dog genetics offers the hope of discoveringthe genetic basis of both development and behavior in a variety ofmammalian species including human. "The notion of a canine genetic map had been proposed by the geneticscommunity years ago; over the last three years we developed the markers toserve as the cornerstone of the map," said Elaine Ostrander, PhD, leadinvestigator and molecular biologist, Hutchinson Center." Cornell becamethe catalyst that allowed assembly of the map to begin in earnest two yearsago." "We were able to provide a number of highly informative pedigrees of dogsthat, for several years, had been bred specifically for genetic studiessuch as these," said Gustavo Aguirre, VMD, PhD, professor of ophthalmologyand director of the Center for Canine Genetics and Reproduction at BakerInstitute. The map covers most of the canine genome and represents a major step towardthe completion of a more comprehensive canine genetic map. It wasconstructed from 150 highly informative markers, known as microsatellitemarkers, developed by the Ostrander group and typed on informativepedigrees developed by the Cornell team. The linkage panel used includedinformation from 17 three-generation pedigrees with genetically distinctbackgrounds, a total of 212 individuals. The development of a canine genetic map is of particular importance, notonly in solving questions of inheritance in dogs, but in humans as well.Purebred dogs, though all of one species, in practice represent a multitudeof closed breeding populations. Many of the genetic diseases thatproliferate in inbred dogs also occur in the human population, but aredifficult to trace genetically, according to Aguirre, because the highdegree of genetic diversity and low number of offspring in human familiesmake informative pedigrees a rarity. These diseases include cancer,epilepsy, retinal degeneration, bleeding disorders, skeletal malformations,and a host of others. Dogs represent a unique genetic resource with each ofseveral hundred breeds exhibiting distinct physical and behavioral traitswith remarkable consistency among its members. "In spite of their obvious breed-specific differences, all dogs belong toone species, and can therefore crossbreed successfully. A great deal ofgenetic information can be gained by analyzing crosses between two highlydistinct breeds of dogs," said Aguirre. "This information will potentiallylead to an increased recognition of the role inheritance plays, not only inappearance or in susceptibility to disease, but also in behavior, both inhumans and canines.Ó In a second paper published in the journal, the two groups describe theconstruction of a dog-rodent hybrid cell panel to aid in determining theorder and spacing of genes and traits of interest on the chromosomes of thecanine genome. Both papers are the result of an unusual and highly productivecollaboration between the two major canine genetics groups in Seattle andIthaca, each of which brought a unique set of resources and talents to theventure. The Hutchinson Center is one of 28 comprehensive cancer research centers,as designated by the National Cancer Institute. Using basic and appliedresearch, the Center's mission is to eliminate cancer, and otherpotentially fatal diseases, as a cause of human suffering and death. In 1951 the James A. Baker Institute for Animal Health established thefirst laboratory in the world dedicated solely to addressing the healthneeds of dogs through basic and applied research. The Institute is renownedfor its contributions to the control of canine infectious diseases throughthe development of vaccines against canine distemper, infectious hepatitis,parvovirus, and other diseases. The Institute is part of the College ofVeterinary Medicine at Cornell University, established in 1894; the missionof the College is to advance animal and human health through education,research, and public service. The project was conducted by Dr. Ostrander and her associates at the FredHutchinson Cancer Research Center as a continuation of work that she hadinitiated with Jasper Rine, PhD, professor of genetics, department ofmolecular and cell biology, University of California, Berkeley.Collaborating with Ostrander's team was a team of Cornell researchers ledby Dr. Aguirre. Other members of the Cornell team included Gregory Acland,BVSc, a veterinary ophthalmologist and senior research associate ingenetics; and Kunal Ray, MS, PhD, senior research associate in moleculargenetics. This research was supported by The Canine Health Foundation of the AmericanKennel Club, the Wellcome Trust, the Foundation Fighting Blindness, MorrisAnimal Foundation, the American Cancer Society, and the National Institutesof Health.
--------
57-> New Protein Found In Excessive Quantities In Alzheimer's Disease
A research team based at the Massachusetts General Hospital (MGH) has discovered a new gene that appears to play a role in Alzheimer's disease.  The gene produces a protein in nerve cells, and the researchers found excessive quantities of this protein in brain tissue and cerebrospinal fluid (CSF) of people with Alzheimer's.  They also showed that accumulation in nerve cells of this protein, called AD7c-NTP, causes changes similar to those seen in Alzheimer's, including cell death.  Published in the December issue of the Journal of Clinical Investigation, the study additionally describes a highly sensitive and specific assay for AD7c-NTP, developed by scientists from the Nymox Corporation. "There are many questions about the role this protein may actually play in Alzheimer's, but we're very excited about how closely its effects mimic the damage seen in Alzheimer's and how consistently excessive levels are seen in people with this terrible disease," says Suzanne de la Monte, MD, the MGH neuropathologist who is the paper's first author. Alzheimer's is the most common cause of dementia in the Western hemisphere and currently affects more than 4 million Americans.  In a small proportion of cases — 5 to 10 percent — the disease runs in families.  Three genes have been discovered that cause familial Alzheimer's, and MGH researchers contributed to the discovery of all three genes.  In most instances, however, Alzheimer's appears in people without a family history of the disease.  The current study focuses on this common sporadic form of Alzheimer's. De la Monte isolated the gene for AD7c-NTP and determined its sequence of nucleotides, the genetic building blocks that define a specific protein.  She then showed that the gene's protein was produced in brain tissue but not in tissues from numerous other organs and that significantly higher levels of the protein were seen in tissue samples from people with Alzheimer's compared with samples from elderly people with no neurological disorder.  In addition, elevated AD7c-NTP was seen much earlier in the course of the disease than several other proteins associated with Alzheimer's are known to appear.  When the gene was introduced into cultured nerve cells and its protein was expressed, the cells grew abnormally long branches or processes and died, a phenomenon seen in Alzheimer's. The researchers from Nymox, led by Hossein Ghanbari, PhD, developed a very sensitive test to measure levels of the protein in cerebrospinal fluid.  They then examined samples from people who had died with Alzheimer's (confirmed by postmortem examination), who had early Alzheimer's, who had other neurologic diseases (multiple sclerosis or Parkinson's disease), or who had no neurologic disorders.  The Nymox researchers, who did not know beforehand which diagnostic categories individual samples represented, found elevated AD7c-NTP levels in 84 percent of the confirmed Alzheimer's cases.  Levels that could be considered elevated also were seen in 89 percent of the early Alzheimer's cases, compared with 11 percent of elderly individuals with no neurologic disease.  In those with other neurologic disorders, levels were slightly higher than those seen in healthy controls. "AD7c-NTP levels were uniquely elevated in patients with Alzheimer's," Ghanbari says.  "We were particularly surprised to see this protein was present in very early Alzheimer's cases and that its level generally increased as patients got worse." The researchers stress that they do not yet know whether the gene itself is abnormal or whether it is a normal gene that is overactivated by some other factor.  However, nerve cells stimulated to produce AD7c-NTP can be used to screen possible Alzheimer's drugs for effectiveness.  The protein assay could be helpful in determining whether an individual with dementia has Alzheimer's or another condition as well as for tracking the success of clinical Alzheimer's therapies. Additional coauthors of the study are senior author Jack R. Wands, MD, of the MGH; Kasra Ghanbari, Iraj Beheshti, PhD, and Paul Averback, MD, of Nymox; William Frey, PhD, of the Ramsey Alzheimer's Treatment and Research Center in St. Paul, Minn.; and Stephen Hauser, MD, of the University of California Medical Center in San Francisco.  The research was supported by grants from the National Institutes of Health, the American Cancer Society, Nymox Corporation and the Tan Yan Lee Foundation.
--------
58-> Strong Response To Mental Stress Could Indicate Heart Disease
It's all in your head -- and heart An exaggerated response to mental stress could be a marker for future heart disease among people under age 60 with a strong family history of premature heart disease, according to a study by Johns Hopkins researchers. This study was the first to link an exaggerated response to mental stress with signs of early heart disease in an apparently healthy group of people with brothers and sisters who had premature heart disease.  Study participants who responded strongly to mental stress tests were likely to have silent coronary ischemia during exercise, indicating a lack of adequate blood flow to the heart. Results of the study, supported by the National Institutes of Health, were published in the Dec. 16 issue of Circulation. "People have long believed that stress is a leading cause of heart disease, but until now we've had very little direct evidence that this was true," says Brian G. Kral, the study's lead author and a graduate student at Hopkins.  "This study is one of the first to show actual blood flow decreases in the hearts of people who are  hot responders' to stressful events." Researchers studied 152 siblings, ages 30 to 59, of people with premature heart disease.  While these people showed no apparent signs of heart disease, they had a high prevalence of coronary risk factors.  Forty-six percent had high blood pressure, 33 percent were smokers and 53 percent were obese. All study participants had their heart rate and blood pressure measured during mental stress tests.  They also completed a treadmill and thallium exercise test to measure blood flow to the heart during exertion. The siblings who developed ischemia during exercise (15 of the 152) had significantly greater increases in blood pressure compared with siblings who had normal exercise tests. Further analysis showed that the siblings who developed ischemia during exercise tests were 21 times more likely to be "hot responders" to mental stress. The study's other authors were Lewis C. Becker, M.D.; Roger S. Blumenthal, M.D.; Thomas Aversano, M.D.; Lee A. Fleisher, M.D.; Raphael M. Yook, M.S.P.H.; and principal investigator Diane M. Becker, Sc.D., M.P.H.  The study was supported by the National Heart, Lung and Blood Institute and the National Institute of Nursing Research. 
--------
59-> Austrian Scientists Experimentally Demonstrate "Quantum Teleportation"
Quantum teleportation has been experimentally demonstrated by physicists at the University of Innsbruck. First proposed in 1993 by Charles Bennett of IBM and his colleagues, quantum teleportation allows physicists to take a photon (or any other quantum-scale particle, such as an atom), and transfer its properties (such as its polarization) to another photon -- even if the two photons are on opposite sides of the galaxy. Note that this scheme transports the particle's properties to the remote location and not the particle itself. And as with Star Trek's Captain Kirk, whose body is destroyed at the teleporter and reconstructed at his destination, the state of the original photon must be destroyed to create an exact reconstruction at the other end. In the Innsbruck experiment, the researchers create a pair of photons A and B that are quantum mechanically "entangled": the polarization of each photon is in a fuzzy, undetermined state, yet the two photons have a precisely defined interrelationship. If one photon is later measured to have, say, a horizontal polarization, then the other photon must "collapse" into the complementary state of vertical polarization. In the experiment, one of the entangled photons A arrives at an optical device at the exact time as a "message" photon M whose polarization state is to be teleported. These two photons enter a device where they become indistinguishable, thus effacing our knowledge of M's polarization (the equivalent of destroying Kirk). What the researchers have verified is that by ensuring that M's polarization is complementary to A's, then B's polarization would now have to assume the same value as M's. In other words, although M and B have never been in contact, B has been imprinted with M's polarization value, across the whole galaxy, instantaneously. This does not mean that faster-than-light information transfer has occurred. The people at the sending station must still convey the fact that teleportation had been successful by making a phone call or using some other light-speed or sub-light-speed means of communication. While physicists don't foresee the possibility of teleporting large-scale objects like humans, this scheme will have uses in quantum computing and cryptography. 
--------
60-> Monkey Business In China Pays Off In Apples For USDA And Cornell
GENEVA, NY -- Phil Forsline and Herb Aldwinckle have won some hard-fought victories in their wars against apple pests, but they met their match recently when confronted by rogue monkeys. The two were on a trip to China to collect wild apple germplasm when a band of primates attacked their party. "One of them ripped my wife’s poncho and grabbed her collecting bag," said Aldwinckle, a mild-mannered Brit who is the chairman of the U.S. Apple Germplasm Committee. "I yelled at him as loudly as I could, but when he stood up on his hind legs, screamed back at me with a blood-curdling screech and showed his fangs, we dropped our bags and got out of there as fast as we could walk." The scientists ventured back about an hour later. They found their cloth bags ripped open and the small, bitter apples they had been collecting strewn about the forest floor. The party of four Americans and four Chinese was on a two-week expedition to expand the apple collection at the USDA-ARS Plant Genetic Resources Unit (PGRU) at Geneva that is used for breeding and species preservation. At the time of the attack, they were 11,000 feet high in the mountains of Sichuan in central China on the Tibetan plateau, one of the most botanically diverse regions of the world. Sichuan and neighboring provinces of China are considered the center of diversity for many wild species of apples that are important for the PGRU collection. The U.S. team, in cooperation with scientists from other countries, completed four expeditions between 1989 and 1996 to the former U.S.S.R. in Central Asia to collect other wild apples more closely related to the commercial apple. Forsline is curator of the PGRU apple collection at Geneva, the world’s largest "living library" of apples, with some 5,000 apple trees representing 2,500 different accessions, among which are wild species, landraces, current cultivars and obsolete cultivars. Over 1,000 new additions including seed populations as well as selected elite clones from the wild habitats have been added to the collection from the five collecting trips. Aldwinckle, a plant pathologist at Cornell, uses genetic material from these trips and the apple collection in the rootstock development program at the New York State Agricultural Experiment Station in Geneva that he runs jointly with a plant breeder, and has successfully developed rootstocks that are resistant to fire blight and phytophthora. Other researchers at the Station and worldwide also use the material. The new collections are being evaluated at 25 different laboratories worldwide. On this trip to China, Aldwinckle and Forsline were accompanied by Laura Benson, a graduate student in plant breeding, Herb’s wife Bernadine, and from four to eight Chinese cooperators, depending on the site. Collecting wild germplasm is not easy. In addition to fighting monkeys, malaria, and mosquitoes, scientists have to adhere to strict governmental protocols, systematically keep track of the material they collect, and protect it during the long trip. To arrange the China trip, for instance, permitting procedures had to be filed with the Chinese Ministry of Agriculture, the forestry department, the provincial governments of the provinces, and local administrative district’s foreign affairs office. Researchers from New York were not allowed to pick the fruit from the trees. That privilege was granted to their Chinese colleagues, especially professor Li Yunong, of the Southwest Agricultural University in Bei Bei, Chonqing, and his associate, Zhou Zhiqin, who were authorized to collect seven of the 15 species the party requested. "Li and Zhou were very helpful," said Aldwinckle. The party collected apples in five different ecosystems throughout Sichuan. The trip was funded by a grant from the USDA, which funds germplasm collection trips around the world. Members of the group hope to return to other areas of China to collect samples in the fall of 1999. To preserve the diversity of the apple gene pool, scientists and plant explorers from the Experiment Station and the U.S.D.A. have trekked the world in search of primitive varieties and wild relatives. Prospecting for apple germplasm is like prospecting for green gold. Germplasm contains important genetic traits that have the potential to boost disease and insect resistance, increase yield, and improve quality. Apple germplasm is the product of millions of years of evolution, thousands of years of selection by humans, and scarcely 100 years of scientific plant breeding. With it, researchers can help fight epidemics of pests and pathogens that threaten the security of the world’s apple supply. "Wild germplasm is critical in maintaining diversity in the gene pool," Forsline explains. If a new strain of disease or insect comes along that decimates current commercial varieties like McIntosh or Gala, for instance, germplasm which has evolved desirable traits through natural selection might provide genes for resistance that could be bred into future varieties. Apple explorations have taken Aldwinckle and Forsline and other U.S. and international researchers to Kazakhstan and neighboring former U.S.S.R. states in search of Malus sieversii, which is a wild relative of the cultivated apple (Malus x domestica).  Since the first trip in 1989, Aldwinckle and Forsline have been collaborating to evaluate M. sieversii  for resistance to apple scab, cedar apple rust, and fire blight. Researchers now think that apples originated in Central Asia and then migrated along trade, silk, and spice routes into the Middle East and then Western Europe, making adaptations all along the way. Wild apples in Central Asia range up to a full pound in weight; in color from white to yellow, green and red; in taste from sweet to bitter; and in tree form from single to multi-trunked, to bush-like. Apples from China were mostly very small and bitter with diverse leaf forms but have other valuable genetic traits. Aldwinckle, Forsline, and Benson are just beginning to evaluate the material they systematically collected in China and—despite the monkey business—consider the trip a great success. "We are very encouraged by our initial sampling of the Chinese germplasm," said Forsline. "There appears to be many traits that will be especially useful in developing new rootstocks particularly." PGRU and the Cornell department of horticultural sciences are in the process of hiring a new rootstock breeder who will be located at Geneva within the next few months. That person will cooperate very closely with Aldwinckle and Forsline’s programs in utilizing these newly collected genetic treasures.
--------
61-> University Of Florida Researchers Investigate Phenomenon Of Seizure-Alert Dogs
By Sarah Carey GAINESVILLE, Fla.---Determined to separate fact from fiction, University of Florida researchers are attempting to document the existence of seizure-alert dogs -- animals that purportedly can detect seizures about to strike their owners and warn them of the coming trouble. Even a few minutes' advance notice could allow the stricken person to find a safe environment prior to the seizure's onset, take seizure-blocking medication or contact a caregiver or emergency medical help. "A number of reports in the popular press, electronic media and dog-related publications assert that some dogs have this ability," said Roger Reep, associate professor of physiological sciences at UF's College of Veterinary Medicine. "If these phenomena are real and occur reliably, this offers great hope to people who experience seizures. "Furthermore, similar to guide dogs who serve as constant companions to visually impaired people, early-alert dogs could allow people who are presently homebound the potential to expand their ability to care for themselves, and in some cases, to obtain employment," Reep said. Working with a $31,000 grant from the Able Trust, a private, Tallahassee-based foundation that helps people with disabilities find employment, Reep and his colleagues, Paul Davenport, canine information specialist/trainer Deb Dalziel and neurologist Basim Uthman will study not just anecdotal evidence from people who say they have such dogs, but also the groups that claim to be able to train them. About 25 million, or one in 10, Americans have had, or will have, a seizure at some point in their lives. In the project's first phase, researchers will give 300 questionnaires to patients and former patients of the Epilepsy Clinic at Shands hospital at UF and at the Veterans Affairs Medical Center. "We are trying to determine if these people have companion animals, and specifically if they have dogs that seem to be alerting them to an oncoming seizure," Reep said. "Our preliminary findings suggest that dogs respond in a variety of ways -- barking, nudging, vocalizing, licking, etc. -- before, during and after a seizure." Previous VA research has shown that certain events occur in the brain prior to a seizure, Uthman said. "These events are demonstrated by complex mathematical analyses, but are not readily apparent to the patient, a neurologist or the patient's family," he said. "It's possible, however, that these changes in the brain might be sensed by a dog." It has also been suggested that epileptic patients may emit certain odors just before a seizure, Uthman added. "A dog has a sense of smell much more powerful than humans," Uthman said. "You and I might not smell a change, but a dog could." In the study's second phase, the focus shifts to organizations that work with seizure-alert/seizure-response dogs. "Some of these places make more aggressive claims than others," Reep said. "Different organizations have varying degrees of success." Researchers want to know what dog trainers have to say about the reliability of training dogs to "detect and alert." Among the questions team members hope to answer are whether the ability to detect seizures, if some dogs do have it, is a spontaneous reaction or a trainable behavior. Eventually, the team hopes to bring dogs into the clinical setting where patients can be physiologically monitored, to determine the cues to which dogs may be alerting. "This study represents UF's first scientific approach to determining if these dogs do exist, and if so, whether it would be possible to selectively breed for these traits," said Charles Courtney, associate dean for research and graduate studies at the UF veterinary college. "After we reviewed (Reep's) proposal, we felt this was a great opportunity to study in more detail how these dogs act with patients who have epileptic seizures," said Kristen Encizo, the Able Trust's spokeswoman, who added that the trust's primary goal is finding jobs for disabled peoples. "If you are able to alert people to when seizures are going to occur, you have more control in the workplace," Encizo said. "Lots of times, there's that stigma, 'I can't hire this person, because what if they have a seizure?' But if they have a dog that can alert them, that would put that fear to rest." For more information about the project, point your browser to http://www.vetmed.ufl.edu/ufmrg/dog/ --------------------------------------------------------------------------------	Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html 
--------
62-> Use Of Novel Antipsychotic Shows Decreased Rehospitalization Rates, Lower Cost
Long-term outcomes for patients with schizophrenia have been disappointing. Treatment using conventional antipsychotics show high rates of recidivism which, in turn, is costly for the system. However, new findings by researchers from the University of Maryland show that patients treated with the novel antipsychotic risperidone (brand name Risperdal®) experienced a lower readmission rate than patients who received conventional antipsychotic treatment. The study team, lead by Dr. Robert Conley, assistant professor of psychiatry at the University of Maryland School of Medicine, along with Dr. Raymond Love, director of the Mental Health Program at the University of Maryland School of Pharmacy, and Dr. Deanna Kelly, instructor at the School of Medicine, found that after one year, the rehospitalization rate for patients treated with risperidone for schizophrenia or schizoaffective disorder was 17 percent, which compares favorably to previously published rates of as high as 50 percent using conventional antipsychotics. "This study shows that in a real-world setting, the benefits of novel antipsychotics include improvements in the patients’ quality of life and potential monetary savings," said Conley. "This evidence suggests that the higher cost of these novel agents can be made up for in terms of dollar savings from fewer readmissions." In a separate but related study, Dr. Conley’s team analyzed risperidone dosing trends in schizophrenia patients within the Maryland Mental Health System between 1994 and 1996, the first such study in a large population. They determined that patients successfully discharged on risperidone were treated with significantly lower doses than those who remained hospitalized. "The importance of establishing effective dosing regimens cannot be overstated," said Conley. "Patients who are under dosed or who receive excessive doses may fail to respond or could experience negative side-effects, which, in turn, could lead to drug discontinuation by clinicians or noncompliance by patients. Higher doses also may mean higher costs." Love pointed out that another benefit of using lower doses of risperidone may be a decrease in costs per patient treated. In 1996, the cost for a patient receiving the average discharge dose of risperidone was approximately $1,900 compared to $2,450 for a patient receiving the average dose reported for those who remained hospitalized. Recent reports from Maryland’s Statewide Pharmacy and Therapeutics Committee show that the average daily dose of the antipsychotic olanzapine (brand name Zyprexa®) was $3,350 for discharged patients and $4,000 for those who remained hospitalized. "Although the availability of a newer generation of antipsychotics has resulted in savings by reducing hospitalization, the higher costs of these medications may offset some of those savings," said Love. "This study shows that at least for risperidone, use of lower doses may produce better outcomes as well as reduce costs."
--------
63-> The Next Big Speed Boost: Parallel Computing With High-Speed Networks
Writer: Kristen Vecellio, vecellio@ufl.edu Source: Alan George, (352) 392-5225, george@hcs.ufl.edu GAINESVILLE, Fla. --- An accountant for XYZ Widget Co. has stepped out for lunch and left his computer running with the Dilbert screen saver doing its job. In his absence and without his knowledge, a co-worker downstairs in engineering has silently tapped into the very brain of the accountant's computer, borrowing powerful processor cycles and using them for her own purposes. A hacker at work? Not at all. It's parallel computing with high-performance networks, a concept University of Florida researchers are developing, and it's perfectly legal. Alan George, director of UF's High-performance Computing and Simulation Research Lab, says parallel computing could make computers thousands of times faster than today's models and sidestep the physical limitations of ever-shrinking microprocessors. However, to achieve effective parallel computing, computer communication networks must undergo major advances. That's what the lab is after. "The lack of virtually instant access and immediate problem solving are keeping us from reaching the full potential of the computer revolution," said George. With parallel computing, multiple processors are linked together in a network so computers can talk to each other -- across the hallway or across the globe -- as easily and quickly as possible by replacing existing network wires with fiber-optic cables. With advancements under way for next-generation networks, George said, a user working on a large and difficult problem could borrow unused power from the processors of other computers in a network to boost their own machine's power. George said only a fraction of conventional computer networks' full potential currently is attainable from conventional computers because of network bottlenecks. He said the computer revolution has been dependent largely upon advancements in microprocessors, which are nearing their peak because of limits on chip density. Existing technologies such as the World Wide Web, teleconferencing and e-mail allow people to interact, but limits on computing and communication speed pose barriers. When it comes to computers communicating more quickly for parallel computing or Web browsing, computers never were designed to exploit its potential. The future, he said, will depend on high-performance networks to support parallel and other forms of computing. "The performance we can achieve is inevitably driven by the weakest link in that chain," George said. So what are the potential benefits? Operating rooms could be equipped with video conferencing so the best surgeons from other medical facilities could consult on an operation in real-time with no delays. Another for-instance: Meteorologists could build a complex hurricane tracking model and simulate it in minutes or hours, well before a hurricane makes landfall. Existing computers may take a week to build and simulate such a model; by that time, the storm has reached land and done its damage. This form of parallel computing also plays a large role in cartoon animation. "Toy Story," the first full-length feature film done entirely by computer, used multiple workstations to refine the picture. Each frame of the film was broken into sections, and  each section was perfected by separate computers and pieced back together. 	Bill Phipps, an electrical and computer engineering graduate student who has been working at the UF lab for more than two years, said linking multiple computers with high-speed communication may be the next big step in carrying computers into the 21st century. "This is going to be the thing that saves the day," Phipps said. Parallel computing with high-performance networks likely will reach the commercial market early in the next decade, though George said several problems still must be solved before it reaches the home, such as how to connect to the home inexpensively with fiber-optic cabling in place of telephone and cable wires. -30- Editor's Note: Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-9092.
--------
64-> Oxygen Discovered At Callisto's Surface, Sulfur Dioxide Sources At Io
New data from a University of Colorado at Boulder instrument on board the Galileo spacecraft now at Jupiter indicates one of its four large moons, Callisto, has oxygen on its surface and another, Io, continues to emit hot volcanic gases. Charles Barth, a senior researcher at the Laboratory for Atmospheric and Space Physics and a member of the CU science team that designed and built the ultraviolet spectrometer flying on Galileo, said hydrogen atoms escaping from Callisto implies the Mercury-sized moon has oxygen locked up in its ice and rocks. In 1996 the CU Galileo team detected evidence of oxygen on the surface of Callisto's neighboring moon, Ganymede. On Ganymede, the UV spectrometer data from Galileo indicated hydrogen atoms were being knocked off the icy surface by charged particles emanating from Jupiter's plasma torus, a massive, doughnut-shaped ring surrounding the planet, said Barth. Because hydrogen atoms are lighter than oxygen atoms, the hydrogen floated out of the atmosphere and into space, leaving the oxygen behind. But on Callisto, the furthest of the four large moons from Jupiter, it appears that sunlight striking its rock-hard ice is the primary mechanism for separating the hydrogen and oxygen atoms, he said. Callisto, roughly 3,000 miles in diameter, is the most heavily cratered moon in the solar system. Callisto is the third largest moon in the solar system behind Ganymede and Titan, the dominant moon of Saturn. "Because it is further away from Jupiter, Callisto does not interact as strongly as Ganymede with the charged particles in the planet's atmosphere," said Barth. "Instead, we believe it is the ultraviolet solar radiation that is knocking the hydrogen atoms out of the ice on Callisto." The surface of Ganymede is thought to contain about 50 percent ice, while the ice on the surface of Callisto is thought to comprise less than 20 percent of the planet's surface, said Barth, a professor in the astrophysical and planetary sciences department and former director of LASP. The CU team, which also has been monitoring sulfur dioxide emissions from Io during recent Galileo fly-bys, discovered that the gases are the result of both active volcanoes and the sublimination of frost on Io's surface. The analysis of the Io data, led by LASP Research Associate Amanda Hendrix, indicates the volcanic activity on Io is extremely variable. The researchers, who made 10 observations of Io volcanoes with the UV spectrometer, found that the thickness of Io's sulfur dioxide atmosphere varied with both time and location over the past year, said Hendrix. Any water present on Io probably disappeared billions of years ago when the volcanic activity commenced. Launched in 1989 aboard the space shuttle Atlantis, the Galileo spacecraft arrived at Jupiter orbit in December 1995. The Galileo spacecraft is managed for NASA by the Jet Propulsion Laboratory of the California Institute of Technology. Barth and Hendrix presented the CU-Boulder Galileo results at the fall meeting of the American Geophysical Union in San Francisco Dec. 8 to Dec. 12. Other LASP researchers on the Galileo UV spectrometer science team led by principal investigator Charles Hord include Ian Stewart, Wayne Pryor, Bill McClintock and Karen Simmons. The team also includes scientists from JPL and the University of Arizona. Data is being sent from the spacecraft to Deep Space Network antennas located in Goldstone, Calif., Madrid, Spain, and Canberra, Australia. Information from the CU spectrometers is sent on to JPL, then forwarded over data lines to LASP's Space Technology Building in the CU Research Park. The incoming information will be analyzed by faculty and students. While the original mission goals of Galileo have been accomplished, the instruments will continue to gather data, said Barth. Two primary targets in the next two years will be the continuing search for a possible ocean under the icy surface of the moon, Europa, and additional observations of Io's violent volcanoes.
--------
65-> Recent Abrupt Cold Event Could Shed Light On Future
San Francisco, Calif. -- About 8,200 years ago, the world climate suddenly got colder and stayed that way for a few hundred years before temperatures returned to normal, according to a team of paleoclimatologists. "This event, which we are calling the 8k event, was short compared to other, more distant events, lasting only about 200 years" says Anna Maria Agustsdottir, graduate student in geosciences, Penn State. "We see it in the Greenland ice cores as one of the biggest dips during the Holocene." The Holocene is the geologic period beginning about 10,000 years ago at the end of the last glaciation and continuing up to today. Unlike other events, the 8K takes place in what for geologists is the very recent past. "Temperatures abruptly decreased about 11 degrees Fahrenheit during the 8K event," Agustsdottir said today (Dec. 10) at the fall meeting of the American Geophysical Union in San Francisco. The change in climate during this period can be seen not only in the temperature record from the Greenland ice cores, but also in ice accumulation, in the indicators of forest fires and in the amounts of methane found in the atmosphere. "Methane is not just an indicator of local climate change," says Agustsdottir, "But it indicates a global change in climate." The researchers, who include Agustsdottir; Richard Alley, professor of geosciences, Penn State; and Peter J. Fawcett of the University of New Mexico, note that during the 8K, Greenland became cold, dry and windy, Canada became cold and the North Atlantic Basin cold and fresh. Asia and Africa also showed colder, dryer climate while South America and North America were wetter. "This event appears to be very similar to, if some what shorter than, the Younger Dryas event that occurred about 12,000 years ago," says Agustsdottir. "We are trying to find the underlying cause for these sudden temperature drops." The researchers believe that these events occur when the ocean conveyor system shuts down. This system is a series of currents that normally move warm water from the equatorial zone to the north. This water cools as it moves northward and the colder, saltier water sinks and flows back toward the equator to replace water moving north. Temperature, water density and salinity control ocean currents. When the ocean conveyor shuts down, deep, cold water formation stops in the north and the cyclical flow of water halts, cooling Europe and its surroundings. "We do not know what shuts down the conveyor, but one possibility is an increase in fresh water in the North Atlantic that would decrease salinity and prevent the water from sinking," says Agustsdottir. Using a climate simulation model called GENESIS, the researchers are trying to model events leading up to the 8K event to simulate an ocean conveyor shut down and temperature decline. The Penn State researchers have used this method on the Younger Dryas event with some success. "Using conditions similar to today's oceans, the model response to a conveyor shutdown does not match data from the 8K event," says Agustsdottir. "However, shutdown from an ocean with a more vigorous conveyor does match observations. This indicates that things were different in the early Holocene." She considers the mechanism behind these sudden cold spells important because the climate changes are so rapid. While we cannot predict the future, we can learn from events in the past and see how they occurred. "If change is gradual, animals, plants and humans can adapt to the new environment," Agustsdottir says. "If change is abrupt, crops fail, rains do not come or come too frequently and people do not have time to adjust."
--------
66-> PET Technology Finds Cancer, Infections Quicker, More Accurately
ANN ARBOR---Two new studies at the University of Michigan Medical Center demonstrate that a technology, previously considered experimental in the United States, is significantly more accurate than other imaging methods used to detect cancer and can also find areas of infection in the body far quicker than conventional means. PET, or positron emission tomography, is widely used clinically in Europe, but has seen relatively limited clinical use in the United States. To produce a PET image, patients are injected with a glucose that contains a radioactive tracer. Cells that are the site of higher metabolic activity, which is usually the case with cancer and infection, take up more glucose. Radioactivity emitted by the glucose is recorded on the PET camera and reconstructed by a computer to form an image similar to a CT (computed tomography) scan. Unlike CT, which shows anatomy, a PET scan highlights tissue metabolism. These areas show up as bright color on the computer-generated image. The U-M studies were presented Dec. 3 at the 83rd Scientific Assembly and Annual Meeting of the Radiological Society of North America. They come in the wake of an announcement by the U.S. Health and Human Services Department that it will accelerate its review of PET technology. In the two U-M studies, researchers found: Dedicated PET scanners outperformed newer imaging devices that were created as a lower-cost alternative to PET. Researchers found that the newer devices, called dual-head coincidence cameras, missed from 10 percent to 77 percent of the cancers successfully detected by standard PET cameras. Researchers at U-M performed both PET and dual-head camera imaging on 35 patients with known or suspected cancers. PET detected 121 cancer sites, compared with 70 sites found by dual-head imaging. Compared with cancer types detected by PET imaging, dual-head cameras only found the following percentage of sites: neck---90 percent; lung---86 percent; metastatic cancers in the rib or spine---77 percent; lymph nodes in the chest---58 percent; axillary lymph nodes---50 percent; abdomen---23 percent. "This study demonstrates that current dual-head coincidence camera technology is considerably less sensitive than PET in detection of small cancers," says lead author, Paul Shreve, M.D., assistant professor of radiology and internal medicine. "The newer technique may compare to PET in detecting some lung cancers." Shreve adds there are significant improvements to the dual-head imaging devices now under development. The dual-head cameras were created as a low-cost alternative to PET, but according to Shreve, the price of PET scanners has fallen dramatically. They now compare favorably to the cost of some CT scanners. A new study shows PET can quickly diagnose infections. U-M researchers studied 11 patients who were believed to be harboring various bacterial infections. PET successfully identified infection in eight of nine patients and correctly ruled out infection in the other two---and did so much faster than other conventional diagnostic methods. Current tests can take anywhere from 24 hours to a few days to diagnose infections, while PET can do so in an hour or less. "The speed with which the site of an infection can be pinpointed and appropriate treatment started can have a significant effect on outcomes and cost of care," says Richard Wahl, M.D., professor of radiology and internal medicine, and director of general nuclear imaging at U-M. Wahl cautions that the study results are preliminary, but says they indicate PET shows great promise in rapidly identifying sites of infection. "More extensive clinical evaluation is warranted to determine the accuracy of this method," Wahl says, "including its application for imaging viral and fungal infections." Previous studies have shown that in up to 30 percent of patients with cancers, PET can detect cancer spread not found by other imaging methods. PET has been shown in other studies to change treatment decisions in 25 to 40 percent of cases. Wahl's co-authors are Y. Sugawara, M.D., who presented the study at RSNA; S. Fisher, B.S.; P. Kison, B.S.; and K. Zasadny, Ph.D. Co-authors on the paper presented by Shreve at RSNA are R. Steventon, C.N.M.T; E. Deters, C.N.M.T.; M. Gross, M.D.; and R. Wahl, M.D.
--------
67-> Nature's yearly gift to humanity: $2.9 trillion in economic and environmental benefits of biodiversity, biologists estimate
If the planet's biota -- all the plants and animals and microorganisms -- sent a bill for their 1997 services, the total would be $2.9 trillion, according to an analysis by biologists at Cornell University. For the United States alone, the tab for economic and environmental benefits of biodiversity would be $319 billion, the biologists report in the December issue of the journal BioScience . (Vol. 47 pp. 747-757). "When you compare our spending (to preserve biodiversity) to the benefits we reap, we're really getting a bargain," said David Pimentel, the professor of ecology who led eight graduate students in Cornell's College of Agriculture and Life Sciences through a rigorous analysis to arrive at what he terms a conservative estimate. A previous study had valued the world's ecosystem services and natural capital at $33 trillion a year. The Cornell study counted natural services of a diverse biota, such as organic waste disposal, soil formation, biological nitrogen fixation, genetic resources to increase food crop and livestock yields, biological control of pests, plant pollination, pharmaceuticals and other nature-based products, ecotourism, and sequestration of carbon dioxide that otherwise would contribute to global warming (see "Biotic Invoice," attached). The biotic beneficence would be even greater, the Cornell biologists observed, if human society took full advantage of nature's genetic offerings. For example, cultivating perennial cereal grains that can be harvested continuously for 4 to 5 years without tilling and replanting -- in place of annual grains whose energy-intensive spring and fall tilling exposes soil to wind and water erosion -- could reduce erosion as much as 50 percent, saving $20 billion worth of soil and $9 billion in tractor fuel every year in the U.S., according to the analysis. Genes for perennial cereal grains already exist in wild plant species, they said, estimating the worldwide value of a perennial grain system at $170 billion a year. "We hope assessments such as this," Pimentel said, "can serve as a foundation to develop strategies and policies to preserve biological diversity and maintain ecosystem integrity. All these services to humanity are possible only because our planet is such a diverse place. Every species that's lost diminishes that vast resource and makes us all poorer for the loss."
--------
68-> More Studies Needed To Determine Genetic Controls Of Il-4 Receptors In Allergies and Asthma, According To National Jewish Medical And Research Center Physician
DENVER-A National Jewish Medical and Research Center researcher who earlier reported genetic variations of interleukin-4 in people predisposed to asthma and allergies writes in today’s edition of the New England Journal of Medicine that new research increasing understanding of the role of IL-4 receptors in genetic predisposition to these diseases deserves continued exploration. "Research on genetic variations of  IL-4 and IL-4 receptors will have value as markers for susceptibility and as models that may lead to innovative treatments for allergic disease and asthma," said Lanny Rosenwasser, M.D., head, Division of Allergy and Clinical Immunolgy at National Jewish. The new research expands scientists’ understanding of IL-4 receptors.  IL-4, a type of protein, or cytokine, released by cells when they come in contact with an allergen, causes the body’s immune system to release substances that cause inflammation in diseases such as asthma.  IL-4 is also instrumental in causing the immune sytem to produce the allergic antibody IgE.  When activated by an allergen entering the body, IL-4 binds to IL-4 receptors causing a series of immune responses by cells.  These responses can cause inflammation of the airways. In clinical trials at National Jewish, researchers are using a soluble form of IL-4 receptors to treat people with asthma who have a particularly high number of the IL-4 receptors.  Researchers hope to "turn off" IL-4’s immune response to allergens. For more information about National Jewish, call (800) 222-LUNG or visit http://www.nationaljewish.org/pa . 
--------
69-> Sandia National Labs Scientists Use Digital Paleontology To Produce Voice Of Parasaurolophus Dinosaur
Scientists at Sandia National Laboratories and the New Mexico Museum of Natural History and Science have collaborated to recreate the sound a dinosaur made 75 million years ago.The low-frequency sound was produced by computer scientists and paleontologists using computed tomography (CT scans) and powerful computers. Sandia is a Department of Energy multiprogram science and engineering laboratory whose primary mission is to ensure the nuclear weapon stockpile is safe, secure, and reliable. The study of dinosaur vocalization began after the discovery in August 1995 of a rare Parasaurolophus skull fossil measuring about 4.5 feet long. The dinosaur had a bony tubular crest that extended back from the top of its head. Many scientists have believed the crest, containing a labyrinth of air cavities and shaped something like a trombone, might have been used to produce distinctive sounds. As expected, based on the structure of the crest, the dinosaur apparently emitted a resonating low-frequency rumbling sound that can change in pitch. Each Parasaurolophus probably had a voice that was distinctive enough to not only distinguish it from other dinosaurs, but from other Parasaurolophuses. The sound is an approximation of the possible tones that the dinosaur crest was capable of producing. Paleontologist Tom Williamson and computer scientist Carl Diegert had to use common sense and some imagination to reconstruct not only missing parts such as the beak and nostrils of the dinosaur, but also the soft tissues of the head and throat that were not fossilized. Since it's uncertain whether the Parasaurolophus had vocal cords, a variation of sounds with and without vocal cords was simulated. "The sound may have been somewhat birdlike, and it's probably not unreasonable to think they did songs of some sort to call one another," Diegert said. "Fossil records of the large bones in the dinosaur's ears compared to corresponding bones in human ears suggests they were able to hear lower frequencies than humans." Williamson, curator of paleontology for the New Mexico Museum of Natural History and Science in Albuquerque, speculates the dinosaur's ability to make distinctive sounds probably enhanced its tendency to socialize with other Parasaurolophuses. The computer-modeling techniques used to create the dinosaur sound are the same ones Sandia uses to create complex, three-dimensional models for conducting computer simulations of problems that cannot be subjected to real-world tests. Sandia uses X-ray tomography similar to the CT scans taken on the dinosaur to develop advanced-imaging techniques for manufacturing design and testing. The dinosaur imaging allowed Sandia scientists to expand their own computing skills in developing and applying those complicated codes. The basic-science work is funded by the Department of Energy Office of Computer Technology and Research under the auspices of the Mathematics, Information, and Computer Science (MICS) program. "The most important thing about Carl's work is that it opens an entirely new field for the application of computing, which is critical to our mission and to real-world engineering in general," said George Davidson, manager of Sandia's Computer Architectures Department. Davidson said the same 3D imaging techniques can be used to analyze and predict the structural integrity of mounting brackets on aging airplanes, the internal structures of aging weapons, and the accurate reconstruction of the forces and mechanical failures associated with the crash of an airplane carrying nuclear weapons. "The general capability that Carl's research is developing offers an early look at a new engineering use of computers, which will one day be a broadly applied engineering tool," Davidson said. An added benefit of the project, Diegert noted, is the widespread visibility it gives to high-performance computing and its growing importance as an engineering tool. "So much of our work at Sandia is classified and we therefore can't talk about it." Diegert said. "This is a project that's appealing and we can talk about it, and therefore, it can serve as a recruiting tool for getting more young people interested in thinking about a career in computing." Parasaurolophus, one of the dinosaurs that appeared in the films Jurassic Park and The Lost World, lived during the Late Cretaceous Period, about 75 million years ago. The crest of the Parasaurolophus was unearthed near Farmington in northwest New Mexico on public land administered by the Bureau of Land Management. The well-preserved skull includes a nearly complete crest, lacking only the segment below the eyes, making it the second-most complete skull of a Parasaurolophus known. A three-dimensional computer model of the crest was created by first performing a CT scan of it at St. Joseph Medial Center in Albuquerque. A series of about 350 cross sections were taken of the skull and crest at 3mm intervals. The results showed a much more complicated internal structure than had been known previously. "Not only are there more tubes than the simple, trombone-like loops described in previous studies, but there are new chambers within the crest," Williamson said. The use of digital paleontology, Williamson said, permitted a thorough analysis of the inside of the crest without having to physically cut through it, and thereby damaging it. The cross sections were loaded in numerical form into a computer in order to reconstruct an undistorted crest. Diegert and Williamson studied the images and instructed the computer how to read the density in order to sort out which was bone and which was the sandstone and clay that fills and encases the fossil. Once the size and shape of the air passages were determined with the aid of powerful computers and unique software, it was possible to determine the natural frequency of the sound waves the dinosaur pumped out, much the same as the size and shape of a musical instrument governs its pitch and tone. High-performance computers were used to do the initial image processing, analysis and actual sound creation, including a Compaq Computer professional workstation, an Intergraph Corporation TDZ workstation, and a Silicon Graphics infinite reality workstation. "A very complex shape such as the dinosaur crest takes lots and lots of numbers to describe the shape in the computer," Diegert said. "It's only recently computers have become powerful enough to allow that to happen." Once the 3D model was completed, the computer was able to simulate blowing air through it to amplify the tones it was capable of making. Sandia National Laboratories is operated by a subsidiary of Lockheed Martin Corporation for the Department of Energy. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has broad-based research and development programs contributing to national defense, energy and environmental technologies, and economic competitiveness. Editor's Note: To hear the recreated sound of Parasaurolophus, download the digital sound clips at http://www.sandia.gov/media/dinosaur.htm .
--------
70-> NASA Payload To Fly Around The World On Solo Spirit Balloon
A NASA instrument package that may one day study the atmospheres of Mars or Venus will fly aboard adventurer/businessman Steve Fossett's Solo Spirit balloon as he makes his second attempt to be the first person to fly around the world solo. The prototype instrumentation is being provided by NASA's Jet Propulsion Laboratory to measure latitude, longitude and elevation, temperature, atmospheric pressure, humidity and vertical wind velocity.  Washington University in St. Louis, MO, which is mission control for Fossett's attempt, invited JPL to fly the scientific payload. "NASA's Jet Propulsion Laboratory is actively developing a program to fly balloons in the atmospheres of other planets.  We are very excited with this opportunity to test this payload in Earth's atmosphere and are looking forward to the data that could be applied to our future missions," said Dr. Jonathan M. Cameron, payload team leader at JPL. Other JPL members of the team are Aaron D. Bachelder, Robert V. Ivlev and David P. McGee. Eventually, a version of the NASA prototype may fly in the atmosphere of Mars or Venus on a robotic balloon called an aerobot. Like Fossett's balloon, the aerobot would vary its altitude to steer through the atmosphere. NASA/JPL will receive raw data from the payload telemetry system through a commercial satellite system. Data will be converted into scientific measurements and relayed to Washington University, where the information will be made available to the public via a web site. The science payload will gather information from the troposphere, the lowest layer of Earth's atmosphere, during a continuous, two-week period as the balloon flies through the mid-northern latitudes.  Fossett's balloon is expected to fly at an average altitude of about 7,000 meters (24,000 feet). "This experiment will simulate a planetary mission with an aerobot payload mounted on the balloon," said Dr. Raymond E. Arvidson, professor and chair of Earth and Planetary Sciences at Washington University and science coordinator for the payload.  "The observations to be made during Solo Spirit's flight offer an outstanding opportunity to educate the public on the characteristics and dynamics of the lower atmosphere." A low fuel supply and other problems ended Fossett's earlier solo flight attempt on Jan. 20, 1997. Nonetheless, he set a new balloon distance record at 16,673.81 kilometers (10,360.61 miles). Fossett will again launch from St. Louis' Busch Stadium when flying conditions are optimal.  This winter's flight is expected to last 15 days. The launch window opens in mid-December and closes at the end of January 1998. "This circumnavigation of the Earth by Solo Spirit will provide valuable experience to JPL in carrying out planetary aerobot missions," said Dr. James A. Cutts, manager of the JPL's Special Projects Office. "We will soon have the technological capability to carry out aerobot missions to circumnavigate both Mars and Venus that will collect unique scientific observations to complement the information obtained by orbiting spacecraft and surface vehicles." After Fossett's flight, Washington University will publish all of the science data on NASA's Planetary Data System Geosciences Node, housed at the university and accessible through the Internet. To follow Fossett's flight, the public can visit http://www.wustl.edu/solo . Information about JPL's aerobot program is also available at http://robotics.jpl.nasa.gov/aerobot . The scientific payload is managed by the Jet Propulsion Laboratory, a division of the California Institute of Technology, Pasadena, CA, for NASA's Office of Mission to Planet Earth, Washington, DC.
--------
71-> Leaf Diversity Discovery Important For Global Climate Change Studies
DIVERSITY "LEAVES" OFF WHERE SIMILARITY BEGINS UPTON, NY -  A new study of leaves from 280 diverse plant species from allover North America shows striking similarities in structure and function,despite different evolutionary origins. Far from just a curiosity, the finding could make it easier to usecomputers to model the Earth's vegetation and the effects of climate.  Suchmodels attempt to predict the effects of global climate change on theplants and trees that produce much of the world's oxygen, food and shelter,and absorb much of its airborne carbon dioxide. The result is published in today's issue of the Proceedings of theNational Academy of Sciences by scientists from the University of Minnesotaand the U.S. Department of Energy's Brookhaven National Laboratory, led byMinnesota's Peter Reich. "This research addresses an important question that has doggedecologists and evolutionary biologists for two centuries: 'Do plant speciesaround the world produce leaves with similar forms in differentclimates?'," said David Ellsworth, BNL tree physiologist.  "We have foundthat the lifespan of leaves and their form and function show repeatedpatterns in ecosystems spanning nearly the entire range of climatesworldwide." "Of course, this doesn't mean that a tropical poinsettia is thesame as an alpine fir tree," Ellsworth continued, "but our results offergreat promise for global-scale modelers who desperately seek measuringtools that they can use when facing the difficult challenge of assessinghow global climate change might affect plant function." The authors' article describes their research on plants found inclimate regions, or biomes, ranging from tropical and temperate forests toalpine tundra and desert. Such biomes feature vastly different temperature ranges,precipitation levels, soils and species evolutionary histories.  But theplants found in every one of the regions seem to share certainrelationships between different factors like their nutrients and the amountof photosynthesis they performed, and the carbon dioxide they releasethrough a process called respiration. The relationships we describe will help scientists makequantum-leap simplifications in models and measurements without having tofully measure or understand every one of the thousands of plant species onearth," Ellsworth said.
--------
72-> Glass Containers May Be The Answer For Nuclear Waste Disposal, Researcher Says
ROLLA, MO. -- Glass may be the answer to safely dispose of nuclear waste,says a University of Missouri-Rolla who recently received a patent for hisresearch efforts to encapsulate plutonium in a special type of glass. Dr. Delbert E. Day, Curators' Professor of ceramic engineering at UMR,received the patent from the United States Patent Office for his researchinto ways to dispose of excess plutonium from dismantled nuclear weapons. Day's method involves the use of a special iron phosphate glass tochemically dissolve the nuclear waste. Day, also a senior research investigator in UMR's Graduate Center forMaterials Research, says it will take several decades and billions ofdollars to dispose of all the radioactive waste that was created from theproduction of nuclear weapons and electricity in the United States duringthe past 50 years. But a special family of glasses hold promise as the means to safely disposeof much of the waste. The U.S. Department of Energy awarded UMR athree-year grant to research the unique iron phosphate glasses developed atUMR. According to DOE, "If geologic disposal is the option selected fordisposition of plutonium, this research may result in a less expensive andsafer disposal."  . "The permanent disposal of the radioactive wastes generated over the past50 years is a major problem that will be with us well into the 21stcentury," Day says. It will be expensive, he adds, "but we must find amethod to safely dispose of these radioactive wastes, which will bepotentially dangerous for hundreds of years." At UMR, Day is directing research to develop glasses to encapsulate this nuclear waste. "We prepare simulated nuclear waste and determine how much of that wastecan be dissolved in the iron phosphate glasses," Day says. Through aprocess called vitrification, Day and his colleagues melt a mixture ofsimulated radioactive waste with a non-radioactive base material to form aglass that immobilizes the waste. The glass must have an exceptionally good chemical durability and notrelease any of the radioactive waste to the biosphere, Day says. "Iron phosphate glasses have the potential to be used with certain types ofnuclear waste," Day says. "The glass can then be stored in a repositorydeep in the Earth for thousands of years, with little or no chance of theradioactive materials escaping into the environment." Day hopes to develop iron phosphate glasses which are well suited forcontaining nuclear wastes. Iron phosphate glasses have an exceptionallygood chemical durability and can dissolve certain types of nuclear wastewhich are not well suited for the borosilicate glasses that have beendeveloped for nuclear waste disposal. Even though Day cautions that one type of glass may not work with everytype of nuclear waste, he adds, "Our ultimate goal is to develop glassesthat can contain large amounts of specialized nuclear wastes, areenvironmentally safe to use, and lower the cost of disposal." The research project to develop iron phosphate glasses at UMR is beingconducted in collaboration with the Westinghouse Savannah River Co. inSavannah, S.C., and Battelle Pacific Northwest National Laboratories inRichland, Wash. "Nuclear waste is presently stored in large steel tanks at both sites. Someof those tanks are leaking, so a better method of permanently disposing ofthat waste is needed," Day says.
--------
73-> Holiday ‘Blues’ Can Be Lessened With A Few Easy Tips
By Michael Moran, M.D. During the holidays happiness should abound.  At least that’s what we’ve been told since we were children. But it’s common for the healthiest people to get a little "blue" during the holiday season. For many people with chronic illnesses, such as asthma, emphysema, cancer, diabetes and other serious diseases, the holidays can make this the most difficult and stressful time of the year. For all of us, the holidays are an annual reminder of the past. For people with chronic illnesses, the holidays take on an even more significant meaning. The holidays are a reminder of the times before illness set in—of what has or could have been. Because holidays are anniversaries steeped in ritual and nostalgia, casting a backward glance to family get-togethers forces an inevitable comparison of the past and present. People with emphysema may recollect the years of their lives before they needed oxygen; people using wheelchairs likely remember the days when they needed less help from others. The result is that current events almost never measure up. At a time when spirits are supposed to be high, people with chronic illness may find themselves at an emotional low. When many negative emotions hit at once, serious problems can occur. If you or a loved one experience excessive periods of sadness, daily crying spells, loss of appetite, feelings of being a burden on others and/or no desire to sleep during this holiday season, it’s time to seek help. Keeping a stiff upper lip and avoiding working through these difficult times will only make you miserable much longer than you need to be. The good news is that depression may be much more treatable than chronic diseases, such as asthma or emphysema, which affect emotions. For people who just feel "blue," here a few ways to take control and increase the number of good memories the holidays could provide this year. If doing last-minute shopping, go at a comfortable pace; stay out of malls if they seem overstimulating; sit down to dinner rather than grabbing fast food; and try moderate exercise like stretching or walking to enhance well-being. Perhaps the best weapon in the arsenal against the "blues" is turning off the television and talking with family and friends. This is one of the best ways to increase enjoyment and combat the "blues" during the holidays. Take the opportunity to talk over any events that have or might make you uncomfortable, and to listen to others’ versions of previous holidays. When engaging family and friends in conversation, and telling stories of holidays past, you may be surprised to learn that another person has a different, and a more positive impression of the same events. This new perspective on the past may help you find pleasure in what has been and what could be in the coming weeks—even with a chronic illness. If you or a loved one have a chronic illness and additional help is needed this holiday season, please call LUNG LINE, (800) 222-LUNG. Michael Moran, M.D., is director of Adult Psychosocial Medicine at National Jewish Medical and Research Center. 
--------
74-> Lucent Technologies Announces The Next Generation In Internet Security
MURRAY HILL, N.J. -- Lucent Technologies today announced a new Internet firewall that it said was designed to be the industry’s most secure, expandable and easy-to-use hardware and software platform for protecting  customers’  data networks.  Called the Lucent Managed Firewall, it is backed by five patent-pending security technologies developed by Bell Labs, and can be expanded readily as the data networks of service providers and businesses grow. "Network security is one of the biggest issues businesses face in using the Internet.  With the Lucent Managed Firewall in their networks, customers can flexibly deploy security throughout their network without affecting network speed," said Howie Gittleson, director, Lucent Internet Security Products Group.  "Businesses can place sensitive data on their intranet or extranet and access the information securely in a way not possible before.  With today’s announcement, Lucent has re-invented the firewall." The company said the Lucent Managed Firewall is the latest product in the company’s rapidly expanding Internet and data networking portfolio, which is designed to bring the reliability and manageability of voice networks to data networks.  By separating the fundamental security function, performed on its firewall hardware, from the centralized management function, performed by its Security Management software, Lucent provides a scaleable approach to firewalls.  It is this distributed network approach which enables users to easily administer security throughout their entire network.  Users of the Lucent Managed Firewall can cost-effectively provide distributed security for Internet, intranet, and business-to-business communications such as Virtual Private Networks. The Lucent Managed Firewall can replace or complement any Internet firewall now in use, and it can support a variety of applications without requiring any network reconfiguration.  The company also said since a single Security Management Server can support multiple firewall appliances, corporate intranets can be segmented, and branch offices can be secured cost effectively. Planet Access, an Internet service provider (ISP) with 3,000 regional users, recently completed testing of Lucent’s new firewall, and plans to integrate the first release into its network by the end of 1997. "We've been searching for a firewall that could give us the highest level of security protection for our customers that at the same time could grow with our needs and was easy to manage, " said Jeff Cartwright, director of Communications Technology, Planet Access.  "Lucent has done it.  Now our engineers can spend more time developing new service opportunities and less time managing the system." The market for firewalls is growing rapidly.  According to International Data Corporation market research, the market is expected to be $328 million in 1998 and grow to $729 million by the year 2001.  Hewlett-Packard (HP) and Lucent plan to integrate Lucent’s firewall technology with HP’s OpenView network management system. Merisel and MicroAge already have agreed to distribute the product. At the heart of Lucent’s new firewall hardware is the Infernoä operating system, a networking software innovation from Bell Labs.   The company said it has more than 60 Original Equipment Manufacturers (OEM) and Independent Software Vendors (ISV) customers for Inferno.  The small size, high speed, robust capabilities and embedded security make Inferno the ideal platform for the firewall hardware, according to Lucent. The Security Management Server will run on NT or UNIX operating systems. The Bell Labs scientists who developed the new Lucent Managed Firewall have more than a decade of experience in computer network security. Noted security pioneer  Bill Cheswick served as an advisor to the Lucent project.  He is co-author of the authoritative reference book -- Firewalls and Internet Security: Repelling the Wily Hacker. Pricing for the Lucent Managed Firewall begins at $15,995. General availability  is planned for late December with new releases and international rollouts throughout 1998. For more information about the Lucent Managed Firewall, customers may contact Lucent at 1-888-4-LUCENT. Lucent Technologies, headquartered in Murray Hill, N.J., designs, builds and delivers a wide range of public and private networks, communications systems and software, data networking systems, business telephone systems and microelectronic components.  Bell Labs is the research and development arm for the company.  For more information on Lucent Technologies, visit our Web site at http://www.lucent.com. ### Inferno is a trademark of Lucent Technologies. 
--------
75-> New Venture From Lucent Technologies Offers Businesses Better Decision Making Through Data Analysis
MURRAY HILL, N.J. –  Lucent Technologies today announced a new business venture that will offer a unique software product that uncovers and displays trends and patterns often buried in large amounts of data.  Called Visual Insights, the venture will use Bell Labs software to help businesses make faster, better decisions, the company said. One early customer of Visual Insights,  AT&T, is using the software to detect unusual calling patterns in masses of telephone call data, which helps it prevent long distance toll  fraud.  Another customer, IBM, will incorporate Visual Insights™ software into its business intelligence solutions products for data management. “For analyzing very large corporate data bases, one picture is worth a thousand inquiries,” said James Weichel, president of Visual Insights.   “By helping managers see, in a glance, relationships and trends hidden in their corporate data, Visual Insights software is revolutionizing how data can be used to gain competitive advantage.” Visual Insights software displays large volumes of data in an interactive, graphical format, allowing users to quickly analyze complex and expanding networked databases.  In another application, for example, a consulting company has used the product to analyze and assess the impact of the year 2000 date change on its client companies’ operations. The patented software product improves on such traditional tools as static graphs, tables, and business charts by presenting complex data in an intuitive form, using color, shape, size, motion and other visual elements to represent the data.  It can significantly enhance the use of standard data analysis tools, such as spreadsheets. 				 Visual Insights applications are also currently helping large software development groups to manage software system changes. “Visual Insights software complements existing data-mining products in use today,” Weichel said.  “Our software product makes it easier to explore and discover connections in  data by supplying an interactive interface for data-mining systems.” IBM has licensed and is exploring uses of Visual Insights software in its businessintelligence solutions.  “Visual Insights software has the potential for raising our award-winning Intelligent Miner software to a new plateau, enabling customers to more quickly realize the values inherent in data mining,” said Tom Kendra, VP, data management marketing, IBM Software Solutions.  “Powered by our DB2 data management software, IBM’s business intelligence solutions help companies make competitive business decisions.“ AT&T is using the product to enhance fraud detection in international long distance services.   “After integrating Visual Insights software into our existing fraud detection and analysis system, we have improved our ability to find and quantify new types of fraud,” said Laura Monahan, director of Long Distance Fraud Control for AT&T. Complete Business Solutions, Inc., an information technology services provider, has also licensed Visual Insights software.  “Visual Insights has proven most useful for us to help clients quickly grasp the size and scope of the year 2000 problem at their organizations,” said Dan Rankin, VP of  Technology for CBSI. Visual Insights software combines Bell Labs work in computer graphics, statistics, human factors and computer science and allows the corporate manager to apply the resulting technology to key business problems. “Having a visual interface to complex networks of data will help our customers make better, more informed business decisions,” said Stephen Eick, chief technical officer of the venture.  “Visual Insights software will help companies solve large-scale problems involving millions of pieces of data, without the need to wade through reams of paper.”Visual Insights software for year 2000 analysis is available now.  The product for enhancing systems/network efficiency will be commercially available in the first quarter of 1998.  Ordering information is available at 1-800-295-3067. Additional Information Additional information about Visual Insights software is available on the web site,  www.visualinsights.com Visual Insights is the fifth announced Lucent Technologies business venture group.  The Inferno and elemedia businesses were launched in 1996.   Veridicom Inc. and Electroplating Chemicals and Services were launched in 1997. The Inferno group markets Lucent’s new distributed network-operating system software.  The elemedia (elements for multimedia) venture provides Media Plus™ software for high-quality voice, music and video over the Internet and intranets.  Veridicom offers Bell Labs patented fingerprint-authentication technology in advanced software and hardware components for identification verification.  Electroplating Chemicals and Services provides electroplating products and services to industrial companies worldwide. Lucent Technologies, headquartered at Murray Hill, N.J., designs, builds, and delivers a wide range of public and private networks, communications systems and software, data networking systems, business telephone systems and microelectronic components.  Bell Laboratories is its research and development arm.  For further information on Lucent Technologies, visit the web site at  http://www.lucent.com 
--------
76-> One Star's Loss Is Another's Gain:  Hubble Space Telescope Captures Brief Moment In Life Of Lively Duo
Some stars in double-star systems have found a quick way to lose weight by dumping their extra pounds onto their companions.  Astronomers using NASA's Hubble Space Telescope have discovered such a case in the double-star system Phi Persei.  A "rapid diet" program has trimmed an aging, once massive star to a lean one-solar mass, while the once mild-mannered, moderate-sized companion has bulked up to a hefty nine-solar masses and is spinning so violently that it's flinging gas from its surface.  This observation has allowed astronomers to catch a glimpse of an unusual, fleeting moment in the life of a massive star in a double-star system. "We have seen massive star binaries at the end of their lives, when one star has collapsed to become a neutron star," says Douglas Gies of the Center for High Angular Resolution Astronomy at Georgia State University, Atlanta.  "There are about six dozen of those known in our galaxy.  But what we hadn't seen before is the phase just prior to the collapse of the aging star.  The Hubble observations dramatically show how severely a star's material can be removed through the gravitational influence of a nearby companion." What Gies and his team have seen is an opportunistic star that has taken advantage of an aging, ailing partner.  After consuming most of its hydrogen -- the fuel that keeps its thermonuclear furnace running -- the aging star swelled up and began jettisoning its mass until only its bare core was left.  The companion star cannibalized the discarded material, thereby increasing in size.  Gies calls the stripped-down star a subdwarf, a type of aging star that has passed the expansion phase -- by swelling and puffing away its outer layers -- and is on its way to becoming a fading white dwarf.  Yet this aging, stripped-down star, which has the same mass as the Sun, is nine times hotter than the Sun at 95,000 degrees Fahrenheit and is very bright. The subdwarf would be the brightest object of its class in the sky (a sixth-magnitude star) if it could be seen alone.  If placed at the Sun's distance, it would appear 200 times brighter than the Sun.  However, the beefed-up companion is ten times brighter in visible light than the subdwarf, which is lost in its glare and eluded detection for many years. The subdwarf was detected by the Hubble telescope's Goddard High Resolution Spectrograph (which was removed from Hubble last February during the second servicing mission), allowing scientists to identify its spectral signature.  Gies' analysis of these observations will appear in the Jan. 20, 1998, issue of the Astrophysical Journal.  With the Hubble data, he pieced together a better picture of life in this double-star system, especially how the beefed-up companion gained its extra mass. By puffing away most of its mass, the aging, stripped-down star has given new life and a new identity to its companion.  The roughly 10-million-year-old companion has potentially doubled its lifetime because it has gained a vast amount of hydrogen fuel, which is needed to maintain its thermonuclear furnace.  By beefing up, the companion also has changed its identity from a normal, moderately massive star to a "Be" star, a type of hot star with a broad, flattened disk of hydrogen gas swirling around it, much like the rings of Saturn.  Based on measurements taken by astronomers at the U.S. Naval Observatory, the disk is eight times wider than the star. The disk formed from gas spun off the rapidly rotating "Be" star.  What causes the fast spin of "Be" stars has been a mystery to astronomers.  Now the Hubble telescope observations of Phi Persei offer at least a partial explanation:  The gas discarded from a nearby swelling star strikes the companion off-center, causing it to spin faster. "The companion is now rotating so fast (one million mph or 450 kilometers per second at its equator) that the star is distorted into a flattened oblate figure in which gravity can barely maintain its hold on the star's outer layers," Gies explains. This new information about the stripped-down star and its companion leads scientists to speculate about their past.  Before the exchange of material, the stripped-down subdwarf was the more massive of the two, about six times more massive than the Sun.  Its companion was slightly less bulky, about five solar masses. Such massive stars usually race through life at a faster pace than most stellar objects, ending their lives in one big supernova explosion.  However, stars in binary systems live differently.  When the once massive subdwarf entered its twilight years about one million years ago, it swelled in size as it began using up its hydrogen fuel.  A single massive star would have eventually exploded, but the presence of the companion prevented the once-massive star from suffering such a violent fate.  Instead, the once-massive star dumped most of its outer layers onto its companion, and now may be heading to a quiet demise. A curious destiny may await this pair.  As long as the "Be" star doesn't break apart, it will live for another 10 million years because of the hydrogen fuel it acquired from its companion.  Then it will swell during the expansion phase and possibly dump some of its mass back onto the subdwarf, which will have evolved into a white dwarf.  The subdwarf then might grow in mass and eventually explode as a supernova.  Or, the companion might swell up so much that it would engulf the white dwarf, eventually tossing out its material in mix-master action. "The beefed-up 'Be' star has won a new lease on life, but its ultimate fate will be determined by the corpse of its former companion, which remains in orbit uncomfortably nearby," Gies concludes.  Phi Persei is 720 light-years away in the constellation Perseus, visible in the autumn evening sky in the northern hemisphere, just north of the Andromeda Galaxy, M31.  The double-star system is visible as a fourth-magnitude star. The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc. (AURA) for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency (ESA).
--------
77-> New Method Simulates Sonic Boom Ocean Penetration
University Park, Pa. --- Penn State engineers have developed new methods for simulating sonic boom penetration into the ocean and estimating how loud a noise the boom makes underwater where it could potentially annoy whales, fish and other marine life. Dr. Victor W. Sparrow, associate professor of acoustics, and Judy Rochat, a doctoral candidate in the Graduate Program in Acoustics, developed the technique and described improvements to it today (Dec. 4) at the annual meeting of the Acoustical Society of America in San Diego, Calif., in the session on Noise and Engineering Acoustics: Noise Modeling and Outdoor Sound Propagation. Sparrow and Rochat's new simulation technique, called a finite difference method, can compute the penetrating sonic boom noise for both simple and complex ocean surfaces, corresponding to calm and rough seas. Using the new technique, the Penn State researchers found that a somewhat complex wavy ocean surface only slightly augments the underwater noise from a sonic boom. Recently, through a stroke of luck, Sparrow was able to confirm that simulations developed through the new computational technique closely match actual ocean observations. In a case of discovery favoring the prepared mind, Sparrow heard a report, in summer 1997, from a Canadian research team that was measuring ambient ocean noise as part of a project unrelated to his. A supersonic aircraft just happened to pass overhead as they were taking underwater measurements. The booms produced by the aircraft were an annoyance to the Canadians but a gift to Sparrow since the observations confirmed the reliability of the Sparrow/Rochat approach. Sparrow says, "One would have had to spend millions of research dollars to arrange an expedition to make the underwater sonic boom recordings that the Canadians researchers got by chance." Rochat adds that it is currently illegal to fly supersonically over land. So, supersonic planes use sea routes. She says that we can expect a new breed of supersonic passenger aircraft to be operating early in the next century, making the need for ways to gauge the possible underwater disturbances newly imperative. Sparrow notes that all whales are mammals and some species hear over much of the same range of frequencies that humans do. However, he is quick to point out that he and his research group will not be looking into the effects of the sound levels the new fleet of supersonic planes will have on marine life. They are leaving that to the biologists. Sparrow says that by using the new simulation method and other techniques, engineers will be able to tell aircraft designers what the whales and fish will hear before the new planes are built. As a result, the aircraft designers and manufacturers should be able to minimize effects in the range that the biologists indicate may be problematic for marine life. At the meeting Sparrow also presented a paper in the session on Noise, Musical Acoustics and Underwater Acoustics: Session in Honor of Robert W. Young. That paper described the application of another complementary tool, the boundary element method (BEM), to simulate the sonic boom noise reaching the whales. The Sparrow and Rochat research was supported, in part, by grants from the National Aeronautics and Space Administration.
--------
78-> Hopkins Researchers Closing In On Manic-Depressive Gene
GENE LIKELY TO BE "ONE OF MANY" THAT CONTRIBUTE TO INHERITED FORMS OF DISORDER Johns Hopkins researchers have confirmed that a gene related to bipolar disorder in families is located in the "long arm" of human chromosome 18.	The new results strengthened an earlier Hopkins study, making the linkage among the first genetic connections to a psychiatric illness to be reinforced by a second study. "If you think of all the human chromosomes as a city, we've clearly found the block where a gene that helps cause some forms of bipolar disorder resides," says Francis McMahon, M.D., associate professor of psychiatry and lead author of a report in the December issue of the American Journal of Human Genetics. The exact gene and the nature of the protein it makes is not known, but there are some potential suspects in this area.  Finding the gene should help scientists make sense of bipolar disorder's physical effects on the brain and develop tests and better treatments, according to McMahon. "We know that many of the message-sending and mood-regulating chemical systems of the brain are disrupted in bipolar patients," says McMahon.  "But it's very difficult to determine the chain of events for all these changes.  Finding genes can help us organize symptoms and work the problem from the bottom up: system A disrupts system B, which unsettles system C and so on." McMahon and his Hopkins colleagues interviewed and took blood samples from 259 individuals from 30 different families in which at least one family member had demonstrated, medically evaluated bipolar disorder, which is marked by extreme emotional swings from explosive elation to suicidal depression.  In the general population, one in every 100 persons has the disorder. Scientists selected sets of markers on chromosome 18 -- patterns of genetic code that allowed them to follow the chromosome's passage from parent to child. They compared patterns of inheritance of these markers with the psychiatric evaluation of study patients.  They found that children who developed bipolar disorder were significantly more likely to receive their copy of chromosome 18 from fathers, even if the fathers didn't have the disorder. One potential explanation is genetic imprinting, McMahon notes, a phenomenon in which genes are differently "tagged" and differently expressed depending on whether they came from the mother or the father. Like finding the call numbers for a book in a library, mapping a gene tells scientists where to look for the gene so they can try to "pull it from the shelves," or isolate it, and "read" its contents. Relatively little is known about the genes on chromosome 18, whose asymmetric shape gives it a "long arm" and a "short arm." The new study indicates the "long arm" probably contains a bipolar disorder gene.  One potential suspect in this area is a gene for a melanocortin receptor, a protein that binds to an important hormonal regulator of the brain. "Theoretically, changes in this receptor could have a whole-brain effect on mood," says McMahon.  "It's a shot in the dark, but it's worth following up."   	Scientists also will try to tighten their search.  "It's nice to have the search narrowed down to this  city block', but there are still probably several hundred genes in this region," he says.  "We'd like to narrow that down to a smaller area where we might have 25 to 50 genes to investigate." Hopkins researchers have sent their blood samples to the Center for Inherited Disease Research (CIDR), a new facility at Johns Hopkins Bayview Medical Center that helps scientists rapidly search DNA for disease-linked genes. Created through a contract between the Hopkins School of Medicine and the National Institutes of Health, CIDR will apply the latest technology and new analytical methods to search beyond chromosome 18 for signs of other genes involved in manic depression. Funding for this study was provided by the Dana Foundation for Brain Research, the National Institutes of Health, and the National Alliance for Research on Schizophrenia and Depression. Other authors were P.J. Hopkins, J. Xu, M.G. McInnis, S. Shaw, L. Cardon, S.G. Simpson, D.F. MacKinnon, O.C. Stine, R. Sherrington, D.A. Meyers, and J. Raymond DePau 
--------
79-> Shape Changes In Ceramic Particles: A Paradox Explained
BERKELEY, CA -- A long-standing paradox in the theory of sintering ceramics has been resolved by Alan W. Searcy of the Materials Sciences Division at the Ernest Orlando Lawrence Berkeley National Laboratory. Searcy's work, done in collaboration with Jeffrey Bullard of the University of Illinois and W. Craig Carter of the National Institute of Standards and Technology, promises to shed light on the properties of many ceramics, including layered semiconductors and heat-resistant silicon nitrides.  In sintering, one of the most important processes in ceramics manufacture, fine-powder compacts are heated to temperatures only a little lower than their melting points; atoms and molecules are set in rapid motion, and the particles coalesce, reducing porosity and increasing the strength of the finished product. The "classical" approach to sintering assumes that the initial particles in the compact are spheres and that movements of atoms or molecules are driven by differences in curvature. In order to reduce surface free energy (the work required to form a surface), atoms supposedly move from particles of smaller radius to particles of larger radius; the concave regions formed by contact between particles are filled by atoms from convex surfaces. In fact, the molecules of crystalline particles sometimes move in directions the theory forbids -- "Which is not surprising," Searcy remarks, "because the classical theory fails what I think of as the 'single-particle sintering test.' It predicts that an isolated particle of arbitrary shape will evolve into a sphere. On the contrary, most single crystals, if grown slowly enough, are faceted." Unlike an idealized sphere, the surface energies of a crystal depend on the different orientation of the surfaces to the underlying crystal-lattice structure. "So here's a theory that says you can't get sintering with particles that have planar surfaces and edges," Searcy says, "while in fact many solids, such as magnesium oxide, cobalt oxide, sodium chloride, and lithium fluoride, keep their faceted shapes -- or even grow into faceted shapes -- while they are being sintered." A clue to the puzzle came when Searcy read a footnote in the work of Josiah Willard Gibbs, the nineteenth-century founder of chemical thermodynamics. Gibbs pointed out that molecules at the edges between crystalline facets would leave and return to their crystal sites more often than molecules in the facet surfaces, because the edge molecules are less strongly bonded. Inspired by what he calls Gibbs's "qualitative description of dynamic equilibrium," Searcy worked with Bullard and Carter, both former students at LBNL, to develop equations that explain shape changes during sintering in terms of energy differences among differently oriented surfaces and edges -- "rate equations" founded on Searcy's "statistical thermodynamic description of the unstable internal equilibrium" in crystals of any shape. The new equations are based on two governing principles: first, any change in shape is possible if it reduces total energy -- the change need not minimize energy, merely reduce it. Second, among all possible shape changes, the one that actually occurs is the one in which the exchange of atoms or molecules and vacant crystal lattice sites is easiest -- the one most favored kinetically. The new equations make it plain that particles don't grow faster because they are curved; instead the apparent curves are produced by the growth of new crystal layers. "Rounded" edges which appear during sintering are actually small additional facets -- kinetically favored to grow because it is easier to move atoms or molecules to those sites. As these small, fast-growing facets multiply, particles begin to appear classically rounded, but become faceted again in the final stages of sintering. For example, if two cubic crystals of magnesium oxide are in contact with each other, the smaller rapidly transforms into a nearly spherical particle. A rounded neck forms between it and the larger particle, which is still nearly cubic -- producing a sort of lopsided dumbbell. Given enough time, a single large cube with slightly rounded edges will form. At every step the changes serve to balance the demands of minimum surface energy; only changes which reduce energy are allowed. Recently Searcy, Bullard, and Carter used Searcy's model to solve a puzzle reported by Oak Ridge researchers. Observed in a transmission electron microscope (TEM), box-like particles of magnesium oxide slowly grew connecting necks during over two hours of sintering -- then in 20 minutes the necks collapsed and disappeared. Three thermodynamic pathways were suggested by the new equations, one of which matched the observations exactly by taking into account the chemical reaction of the magnesium oxide particles with the supposedly unreactive carbon substrate on which they were mounted. In the vacuum chamber of the TEM, carbon and magnesium oxide react to release carbon monoxide and magnesium vapor, reducing the overall energy of the magnesium-oxygen-carbon system. Searcy is now extending his model to study the thermodynamics of films on and between solid surfaces, work which promises to illuminate production methods and properties of such ceramics as layered semiconductors and strong, tough, high-temperature engine parts made with silicon nitride particles separated by glass films only a billionth of a meter thick. Searcy and Bullard report confirmation of a prediction of the new model in the Journal of the American Ceramic Society, September 1997: cubic particles of lithium fluoride sinter as readily as spherical particles of other ceramics. The Berkeley Lab is a U.S. Department of Energy national laboratory located in Berkeley, California. It conducts unclassified scientific research and is managed by the University of California. 
--------
80-> National Trial Begins For Controversial Lung Surgery For Emphysema
DURHAM, N.C. -- Medical researchers hope that an unusual clinical trial will prove whether or not removing portions of lungs can provide long-term benefit to patients severely disabled by emphysema, a progressive lung disease for which there is no other cure. The trial's findings are both medically and economically important, researchers say, because it is estimated that there are currently more than 10 million Americans with emphysema and the procedure costs $50,000 to $60,000. Most of these patients are usually elderly and disabled and are covered by Medicare, the federal insurance program. Medicare had paid for thousands of the procedures in the early 1990s, when many hospitals began offering it to enthusiastic patients. Although short-term benefits were observed in many patients, important unanswered questions included the duration of benefit, which patients were most suitable, and what were the potential short- and long-term complications, researchers said. The National Emphysema Treatment Trial, which is now enrolling the first of a planned 4,700 patients, is being carried out in 18 centers across the country. Patients will be enrolled for three to five years, and will be followed for at least five years. Duke University Medical Center is the only hospital in the Southeast participating in the trial. Funded jointly by the National Heart, Lung, and Blood Institute (NHLBI) and the Health Care Financing Administration (HCFA), the agency that handles Medicare claims, this is the largest clinical trial the two federal agencies have combined to sponsor. "This can be the model of how Medicare and other third-party payers can work together with researchers to evaluate new procedures," said pulmonologist Dr. Neil MacIntyre, Duke's principal investigator in the trial. "Instead of just deciding arbitrarily whether or not a specific procedure or therapy is effective and should be covered, the government is funding a trial to actually find out the answer. "Because of the large numbers of patients and way the trial has been designed, we should get definitive answers on the role of this procedure." In the procedure, known as lung volume reduction surgery (LVRS), surgeons remove portions of the lung that have become overinflated from the disease. This allows undiseased portions of lung -- which had been compressed by diseased lung tissue -- to expand and function properly. The removal of the inflexible portions of lung also improves the ability of the diaphragm to function in a more normal manner, MacIntyre said. The first surgeries were performed in the early 1950s and although some patients regained a degree of lung function, one in six patients died. Because surgeons had difficulty controlling air leaks after surgery, the procedure fell out of favor. However, with the advent of improved surgical techniques, surgeons revisited the procedure in the early 1990s. "Studies involving small numbers of patients in the surgical literature showed significant improvements in lung function tests and exercise tolerance, with early mortality rates between 2 percent and 7 percent," MacIntyre said. When success stories began appearing in the popular press about the benefits of the procedure, many emphysema patients demanded it. By 1995, many hospitals jumped on the bandwagon and offered the new surgical approach to their emphysema patients. As the popularity of LVRS grew, so did the number of claims submitted to Medicare for reimbursement. In 1992, between 200-300 claims were submitted for the procedure; by 1995, the number had jumped to more than 2,000. "For obvious reasons, HCFA began tracking claims," MacIntyre said. "After studying 711 consecutive claims, they found that 26 percent of the patients were dead after one year, there was a 40 percent rehospitalization rate, and 16 percent needed long-term care. "Clearly, there was quite a difference between what was being reported in the literature and what HCFA found." So in January 1996, HCFA halted reimbursements for LVRS, and called for a large-scale trial to determine the effectiveness of the procedure and to determine which patients would benefit the most from surgery. In December of last year, HCFA and the NHLBI announced the trial and the 18 participating centers, who have worked for the past year designing the trial. "It is obvious to us that while many patients may benefit from the procedure, patients could also be harmed," MacIntyre continued. "It is important to sort these things out before making a blanket statement about the benefits of LVRS." To be eligible for the trial, patients must have moderate to severe emphysema, have no other complicating medical problems, and must have quit smoking for at least four months. The vast majority of these emphysema cases are the result of smoking, MacIntyre said. "In general, these patients get short of breath at mild exertion, some are on oxygen, and most are unable to carry out the routine activities of everyday life," MacIntyre said. "It is truly a debilitating disease for which little can be done." Patients must be Medicare-eligible to participate in the trial. Many hospitals, including Duke, continue to offer the surgery, but patients may have to pay for it out of their own pocket, because many insurers do not cover the operation. Like the federal government, they are awaiting the outcome of the trial, MacIntyre said. All participants in the trial will receive intensive medical therapy and rehabilitation and half will be selected by random for LVRS. Those picked for surgery will be further separated randomly into two different surgical approaches -- either by median sternotomy (open chest) or by video assisted thoracic surgery (VATS). At Duke, Dr. Duane Davis will perform the open surgery, while Dr. David Harpole will use the VATS approach. Duke pulmonologist Dr. Victor Tapson and study coordinator Abby Krichman will evaluate potential patients and will be in charge of the medical care of study participants, while MacIntyre serves as director of the Duke pulmonary rehabilitation program. Study participants will be evaluated for exercise ability, lung function, quality of life, illness and survival. Although it has been estimated that it will take seven years to complete the trial, treatment recommendations may be made sooner if the data, which will be reviewed at regular intervals by an independent panel of experts, show clear-cut benefits or risks. "If it is determined that the surgery is clearly beneficial, those patients who had been randomized to maximum medical care alone will be offered the surgery immediately," MacIntyre said. "Likewise, if the surgery is doing more harm than good, the trial will be stopped." Current treatment for patients in the final stages of emphysema is largely supportive, including nutritional supplementation and exercise rehabilitation. Lung transplantation may be an option for some patients under age 60, but donor lungs are scarce, and the procedure is expensive.
--------
81-> Pathfinder Photographs Provide Geological Support For The Important Role That Liquid Water Has Played On Mars
ITHACA, N.Y. -- After studying more than 9,500 images taken during the acclaimed Mars Pathfinder mission, scientists report in the latest issue of the journal Science (Dec. 5) that surface photographs provide strong geological and geochemical evidence that fluid water was once present on the red planet. "We now have geological evidence from the Martian surface supportingtheories based on previous pictures of Mars from orbit that water played animportant part in Martian geological history," said James F. Bell, Cornellsenior research associate in astronomy and a member of the Mars Pathfinderimaging team. Bell, along with lead author P. H. Smith of the University of Arizona;Robert J. Sullivan Jr., Cornell research associate in planetary science;and 23 other scientists authored the paper, "Results from the MarsPathfinder Camera."  The report is part of a complete Mars Pathfindermission report published in Science . During the first 30 days of the Mars Pathfinder mission, the Imager forMars Pathfinder (IMP) returned 9,669 pictures of the surface.  Thesepictures appear to confirm that a giant flood left stones, cobbles androcks throughout Ares Vallis, the Pathfinder landing site.  In addition tofinding evidence of water, the scientists confirmed that the soils are richin iron, and that suspended iron-rich dust particles permeate the Martianatmosphere. Bolstering their evidence for once-present water, the imaging team foundevidence for a mineral known as maghemite -- a very magnetic iron oxide.Bell explained that maghemite forms in water-rich environments on Earth andcould likely be formed the same way on Mars.  Bell explained that reddishrocks like Barnacle Bill, Yogi and Whale rock show evidence of extensiveoxidation on their surfaces. He said the oxidation -- or the rusting of theiron -- is possible only if  water existed on the surface at some time andplayed an important role in the geology and geochemistry of the planet. But, where did all the water go? "That's the golden question.  No one knows," said Bell, explaining thatseveral theories about the disappearing water exist, such as evaporationinto space, or seepage into sub-surface ice deposits or liquid aquifers, orstorage at the Martian poles.  Bell said that robotic missions to Marsearly in the next century, including a Cornell-led rover mission to belaunched in 2001, will attempt to determine the water's whereabouts, aswell as to determine whether the Martian environment may once have beenmore conducive to life. Mars Pathfinder's camera also revealed that Mars' atmosphere is more dustyand dynamic than expected, Bell explained.  Surprisingly, the scientistsfound wispy, blue clouds, possibly composed of carbon dioxide (dry ice),traveling through Mars' salmon-colored sky.  White cirrus-like clouds, madeof icy water vapor, also circulate throughout the thin Martian atmosphere. "We were surprised to see such variations in the clouds, particularly sinceMars has such a thin atmosphere," Bell said.  "We figured the atmospherewould be the same everyday, but there is a lot of real weather occurringthere.  It's a small atmosphere, but a vigorous one." Looking at Martian rocks like Yogi, Barnacle Bill and Scooby Doo revealsthat the rocks have been sitting on the planet's surface for billions ofyears, enduring a slow-motion sandblasting from a usually weak, dustyMartian wind.  To carve rock with such a weak wind force requires a vastamount of time, Bell explained. "The slow, persistent weathering and erosion of the rocks is like watertorture to the max," he said.  "Mars really is an ancient world.  We'restill trying to sort it all out."
--------
82-> It'll Move You: New Research Shows That Sensory Experience Alters The Development Of Brain Areas That Control Movement
WASHINGTON, D.C. December 3 -- New animal research shows that sensory deprivation not only influences the sensory brain areas, but surprisingly also stifles the development and organization of areas involved in the control of voluntary movement. And the effects are particularly drastic in early life. "The research suggests that sensory feedback to the brain's motor cortex system is one of the major driving forces that shapes motor function during development," says the study's author, George Huntley of The Mount Sinai School of Medicine in New York. "The discovery also suggests that early in development there is a restricted time period where the motor system is most susceptible to modification and refinement by incoming sensory signals." "The human implications could be that visual defects early in life may affect not only the sensory brain areas that process vision, but also the motor cortex areas that mediate visually-guided motor coordination," he says. Huntley's study, primarily funded by the National Institutes of Health, is published in the December 1 issue of The Journal of Neuroscience. "The study reinforces the view that our children require sensory and motor experiences during development," says Jon Kaas, a sensory systems expert at Vanderbilt University in Nashville. "While deprivation is harmful, supernormal sensory and motor conditions may lead to supernormal individuals." In the study, Huntley tested the effects of a form of sensory deprivation by trimming the whiskers on rats. This made the animals experience abnormal sensory inputs to sensory and motor areas of the cerebral cortex. Rats use the whiskers on their snouts like humans use their fingertips to explore and discriminate surface features such as texture. Whiskers function through motor areas of the brain including the motor cortex, which sweep them back and forth and the somatosensory cortex, which processes the retrieved information. Huntley examined a group of adult rats that had the whiskers on one side of their snout trimmed starting at birth and another group that had their whiskers trimmed starting in adulthood. A stimulating electrode implanted in the animals' motor cortex revealed representations of motor activity. "Study results show significantly smaller representations of motor activity and some abnormal motor activity patterns in the rats that were trimmed at birth," says Huntley. "The adult-trimmed group had no significant changes in the size of their representations of motor activity maps, but they did show some slight changes in the form of motor activity elicited." In future studies, the researchers plan to investigate the mechanisms that underlie the changes in the motor cortex. Huntley is a member of the Society for Neuroscience, an organization of more than 27,000 basic scientists and clinicians who study the brain and nervous system. The Society publishes The Journal of Neuroscience.
--------
83-> UF Researcher Designs "Diet Pill" To Control Mosquitoes
VERO BEACH---Dov Borovsky wants to put mosquitoes on a diet. Under the Borovsky three-day diet plan, legions of anorexic little buzzers would just starve to death. And that's exactly the idea. The University of Florida scientist says a mosquito "diet pill" he has perfected alters mosquito digestion, making it impossible for them to feed, lay eggs or survive. As a mosquito control breakthrough, the diet pill could save lives. "We hope this can stop the advance of malaria and other mosquito-borne diseases," said Borovsky, an insect biochemical and molecular biologist at the Florida Medical Entomology Laboratory, a part of UF's Institute of Food and Agricultural Sciences. "It works on all mosquitoes, all over the world." In the mosquito control war, mosquitoes are winning. There are more than 3,000 species of mosquitoes. Worldwide, mosquito-borne diseases infect about 700 million people each year and kill 3 million, according to the Centers for Disease Control. But the diet pill, which could be on the market within a year, is a promising new weapon, not only because it is wickedly efficient but because it also is safe for the environment. And this diet plan is no secret. Borovsky is quite willing to share his recipe for mosquito death. First, take 100,000 mosquito ovaries, dried and crushed into a powder that contains their digestive control hormone. From the nearest pool or pond, scrape off the green scum, also known as chlorella, an algae. Insert the hormone into the chlorella, make it into a pill, then place the pill into any water body where mosquitoes are known to breed. Then watch the larvae feast on the chlorella. Famine follows. Borovsky said when he first pulled out mosquito ovaries, homogenized them and inserted them back into mosquitoes, he found that the mosquitoes produced no more eggs. "So at first we thought we had a birth control pill," Borovsky said. "But then we found that the reason they were not producing eggs was because they were not digesting, so then we knew we had a diet pill, not a birth control pill. "Fortunately, now we can synthesize the hormone, so we don't have to use 100,000 ovaries for each batch anymore," Borovsky said. The synthesized hormone is inexpensive, as is chlorella, which is found and produced worldwide. Chlorella, in fact, turns out to be the perfect ride for the mosquito hormone, because it can be freeze-dried and stored for long periods and then brought back to life as the deadly diet pill. The mosquito fen-phen is benign environmentally. Unlike DDT and some other pesticides, it does not alter the environment in any way, except for poisoning the larval lunch. Mosquitoes that feed on the hormone-laced chlorella starve to death within 72 hours. "This is a natural bullet that we can use in the environment because the hormone doesn't stay in the environment," Borovsky said. "The chlorella stops producing the hormone within three weeks." That's by design, Borovsky said. If the hormone were incorporated into the chlorella genome and chlorella continued to produce the hormone, making it omnipresent in the environment, mosquitoes could become resistant to it. But the hormone sits outside the genome, and after the third division of the chlorella it no longer can be detected. Of course, Borovsky points out, if mosquitoes become resistant to their own reproductive hormone that could have unknown adverse consequences for them as well. "We have to stay a step ahead of them or outsmart them all over again," Borovsky said. In the decade since he began work on the pill, Borovsky has made believers out of even the most ardent doubters. "Ten years ago, everybody was laughing at us, but now they are taking us seriously," Borovsky said. "Eight years ago, at a Vancouver meeting, a colleague harshly criticized this work. He just did not believe it." The next step, Borovsky says, is to develop diet pills for infamous agricultural pests. Current methods to keep agricultural pests from molting fall short of protecting crops, Borovsky said. "A pest that doesn't molt but still feeds is still a problem," Borovsky said. "By putting the diet pill into the crop or into the plant, the insect feeds and then dies before it takes its next meal."
--------
84-> Eating Lake Ontario Fish Linked To Shorter Menstrual Cycles; Consumption May Delay Pregnancy, UB Researchers Find
BUFFALO, N.Y. -- Eating contaminated sport fish from Lake Ontario is associated with shortened menstrual cycles, epidemiologists from the University at Buffalo have found. They also reported that the fish consumption was associated with a small, but statistically insignificant, delay in the time it took women to become pregnant. The results are from two separate studies that are among the first to assess the dietary effect of low-level environmental exposure to organochlorines, heavy metals and pesticides, all recognized reproductive toxicants, on the reproductive process in humans. The studies are published in the Dec. 2 issue of the American Journal of Epidemiology, which is dedicated to research by faculty members and graduates of the UB Department of Social and Preventive Medicine. Women enrolled in New York State Angler Cohort provided the data for the studies. The cohort, composed of 10,518 male anglers, 918 female anglers and 6,651 spouses or partners of male anglers, was formed in 1991 to provide a representative sample of fishing-license-holders between the ages of 18 and 40 from the 16 counties near Lake Ontario. The sample provides a population base for a variety of studies on the implications of Great Lakes contamination. Eating Great Lakes sport fish delivers a mixture of toxic chemicals, including PCBs at a level estimated to be 4,300 times greater than through exposure in the air or via drinking water. Many of these chemicals accumulate in the body. Lake Ontario fish are reported to have more than twice the amount of dioxin, mirex and PCBs than fish from the other Great Lakes, a finding that has resulted in the New York State Department of Health recommending that women of childbearing age eat no Lake Ontario fish. An earlier UB study showed that most anglers are aware of the advisory, but many don't know the specific recommendations for women and didn't change habits because of the advisory. For the two studies of fecundity and Lake Ontario fish consumption, researchers from UB's Department of Social and Preventive Medicine assessed both time-to-pregnancy, a measure that can reveal conception delays, and length and regularity of menstrual cycle, aspects that affect a woman's fecundity. The time-to-pregnancy study, headed by Germaine Buck, Ph.D., UB associate professor of social and preventive medicine, involved 874 women who were trying to become pregnant between 1991 and 1993. Trained telephone interviewers collected information on time to pregnancy. Information on duration and frequency of sport-fish consumption was collected when participants enrolled in the cohort in 1991. Time-to-pregnancy data were based on women's answers to questions asking if they stopped using birth control to become pregnant; if they were attempting to prevent pregnancy in any way, and during which cycle they became pregnant after deciding to try to conceive. Consumption data showed that 42 percent of the women of child-bearing age ate Lake Ontario fish, and 10 percent reported eating fish for at least seven years, dating back to a time when lake contamination was higher than in recent years. Researchers found a small conception delay for women who ate fish, but the effect was not statistically significant. The study on the association of fish consumption and length of menstrual cycle, headed by Pauline Mendola, Ph.D., involved data from 2,223 women from the same cohort who reported menstrual-cycle length when they were re-interviewed in 1993. Results showed that eating sport fish from Lake Ontario more than once a month was associated with a menstrual cycle 1.1 days shorter than the cycles of women who did not eat sport fish. Among women who experience regular menstrual cycles, the reduction was half a day. Women in the group with moderate- to high-PCB exposure due to consumption of Lake Ontario fish showed a 1.3-day average reduction in menstrual cycle compared to women who did not eat fish. The average reduction for women who experience regular cycles was half a day. Mendola said that while these small decreases in menstrual-cycle length are not currently a major public-health concern, the findings may indicate that these environmental contaminants have an effect on hormone production, notably estrogen production, which could have larger implications. A former member of the UB Department of Social and Preventive Medicine, Mendola now works for the EPA. Additional researchers on the two studies were Maria Zielezny, Ph.D., and John Vena, Ph.D., of the UB Department of Social and Preventive Medicine, and Lowell E. Sever of the Battelle Centers for Public Health Research and Evaluation. Both studies were supported in part by grants from the Great Lakes Protection Fund and the Agency for Toxic Substance and Disease Registry.
--------
85-> Vitamin C Shown To Cross The Blood Brain Barrier
Findings May Be Useful To Slow Progression of Some Brain Disorders New York, November 30, 1997 -- The blood brain barrier has long been regarded as the body's most formidable gatekeeper. It is a virtual fortress of blood vessels that forms a protective barrier between the blood and brain, screening any chemical that attempts to access the brain's inner sanctum. But the blood brain barrier's protective role can be a drawback, as it also blocks access to substances that would be good for the brain. One such substance is vitamin C, an antioxidant that is essential to keep the central nervous system functioning properly. Now, researchers at Memorial Sloan-Kettering Cancer Center have discovered how to get large amounts of vitamin C past the blood brain barrier so that it is transported and retained in the brains of laboratory mice. This finding may prove useful in efforts to slow the progression of certain neurodegenerative diseases, such as Alzheimer's. The investigators report their findings in the December 1st issue of the Journal of Clinical Investigation. "We now know how to get large amounts of an antioxidant into the brain," said Dr. David Agus, an oncologist at Memorial Sloan-Kettering Cancer Center and lead author of the study. The researchers studied vitamin C absorption in the brain to determine why it was present in this organ's tissue at higher concentrations than any other area of the body. Earlier research by Dr. David Golde, Physician-in-Chief of Memorial Hospital, and his colleagues had established that specific glucose transporter molecules were responsible for transporting vitamin C into cells. This process occurs when vitamin C, which is used by cells in the form of ascorbic acid, is converted into the form of dehydroascorbic acid and transported into the cell. Once inside, the vitamin is converted back to ascorbic acid. Building on this research, Drs. Agus, Golde and their colleagues reasoned that vitamin C would cross the blood brain barrier as dehydroascorbic acid via the same glucose transport mechanism and be retained as ascorbic acid in the brain. To find out, mice were injected with either ascorbic acid, dehydroascorbic acid, or sucrose (as a measure of blood volume) and their brains were subsequently analyzed at varying time intervals for vitamin C content. The researchers found that ascorbic acid was not able to cross the blood brain barrier, while dehydroascorbic acid readily entered the brain and was retained in the tissue as ascorbic acid. Although scientists do not know the exact role that vitamin C plays in the brain, recent studies have shown that various vitamin compounds with antioxidant-like properties can slow the progression of moderately severe Alzheimer's disease. In addition, vitamin C is also known to act as a scavenger of free radicals - substances that play a role in causing diseases. "Our findings from this study have therapeutic implications because we can potentially increase vitamin C concentrations in the brain by increasing the blood level of dehydroascorbic acid," said Dr. Golde. He added that this was not possible by taking vitamin C as an oral supplement because most of it would be excreted in the urine. Now, the researchers are conducting on-going laboratory experiments in mice to test the clinical effectiveness of large amounts of dehydroascorbic acid. They hope to increase the antioxidant potential in the brain. Memorial Sloan-Kettering Cancer Center is the world's oldest and largest private institution devoted to prevention, patient care, research, and education in cancer. Throughout its long, distinguished history, the Center has played a leadership role in defining the standard of care for patients with cancer. In 1997, Memorial Sloan-Kettering was named the nation's best cancer center for the fifth consecutive year by U.S. News & World Report.
--------
86-> Martian Meteorite Contains No Biological Life, Research Team Says
December 4 Nature article offers point-counterpoint approach to controversy The famous Martian meteorite, ALH84001, contains no biological life forms, according to a Case Western Reserve University researcher and colleagues. The team issues this report in the December 4 issue of Nature, duplicating the methods of a team of scientists from the Johnson Space Center and Stanford University. In rare counterpoint writings in the "Scientific Correspondence" section, Nature allowed the Johnson Space Center team to respond to the group's findings. This paper also appears in the December 4 issue. CWRU's Ralph Harvey, senior research associate in the Department of Geological Sciences, was on the research team. The lead researcher on the paper was John Bradley from MVA Inc. and the School of Material Science and Engineering at Georgia Institute of Technology. The third researcher is Hap McSween from the University of Tennessee. The trio reports that most of the purported nanofossils or "worm-like images" are nothing more than lamellae, or fractured surfaces of pyroxene and carbonate crystals. Last year, the Johnson-Stanford team announced it found evidence of nanofossils in the meteorite. Reports of life on Mars spurred the July 4 mission to Mars to look for further evidence of life. Allan Hills 84001 -- a meteorite the size of a potato -- remains in the center of a spirited controversy about the possibility of life on Mars. The meteorite was found in the 1980s in Antarctica by the National Science Foundation's Antarctic Search for Meteorite Program (ANSMET), headed by Harvey with headquarters at CWRU. A Web page offers details on ANSMET, including a link to more information on the meteorite. To view these resources, visit http://www.cwru.edu/artsci/geol/ansmet/index.html . Harvey, who is currently on his annual expedition to Antarctica to collect meteorites, commented before leaving November 21 that the Johnson-Stanford team has always argued that they had used different techniques to study the meteorite. Bradley, Harvey, and McSween published a paper last year in Geochimica et Cosmochimica Acta (GCA), announcing that what the other researchers observed was formed geologically, not biologically. The Johnson-Stanford group also announced that these nanofossils were lying on the surface of the meteorite. In the first GCA study, which used transmission electron microscope imagining (TEM), the researchers found non-biological magnetite whiskers on or near the surfaces of the carbonates. Superficially the whiskers look like worms, but in fact they have nothing to do with biological processes, according to Harvey and colleagues. The latest study took place over the past six months as the researchers re-examined the meteorite using the new techniques. This time they found yet another population of worm-like forms that are actually mineral lamellae formed by non-biological, geological processes. The lamellae look like worms or nanofossils, but when the specimen is tilted and viewed from another angle, it clearly shows that the lamellae are attached and part of the mineral surfaces. "The surface topography is highly irregular on a nanometre scale, with emergent lamellae following the major cleavage direction of the substrate," Bradley writes in the paper. The researchers have published pictures of the TEM images to support their findings. "Peculiar surface structures or segmentation on the worm-like forms are artifacts from conductive metal coatings applied to the samples for imaging in the electron microscope. This is not the first time metal coating artifacts have lead to misidentification of nanofossils in rocks," Bradley said. "We have now found two different types of mineral forms in ALH84001 that look just like nanofossils, but they are strictly non-biological origins. Sometimes even nature has a perverse sense of humor," he added. Harvey stressed that during this latest study, the team was careful to use exactly the same methods as the Johnson-Stanford group to lay to rest any arguments that the research methods had affected the findings. The worm-like mineral lamellae are commonly found at the fractured surfaces of planar crystals. Harvey noted that lunar rocks -- in which there has been no evidence of life found -- contain these same formations. Does this put an end to the life on Mars debate? "We haven't driven the final nail in the coffin yet about organisms in this Martian rock, but our latest article offers a lot of insight that shows these fractures zones in the rock are incredibly complex," Harvey said, "and that it is very dangerous to try to draw any hypothesis from a few pictures from here or there."
--------
87-> Researchers Suggest Using Shock Waves As Inexpensive Method To Detect Plastic
BUFFALO, N.Y. -- Plastic land mines are a guerrilla fighter's dream: they cost as little as a dollar, they're easy to make, they're often lethal and they cannot be detected by current technology. However, an accurate and inexpensive detection method effective for land mines in either plastic or metal casings may be on the horizon as the result of computer simulations conducted by Surajit Sen, Ph.D., assistant professor of physics at the University at Buffalo. The research, to be published in the February 1998 issue of Physical Review E, indicates that weak shock waves sent into granular beds, like soil, will cause acoustic signals containing critical information to be reflected off buried objects, such as land mines. The findings build on previously published work (in Physical Review Letters, vol. 74, pp. 2686-2689, 1995 and in Physical Review E , vol. 54, pp. 6857-6865, 1996) in which Sen found that in model systems, shock waves travel through granular media as solitons, tight bundles of energy that travel without dispersing. Only after the publication in 1995 of the initial findings and after watching a television news report about land mines did Sen begin to think his research might be applicable to land- mine detection. The earlier work showed that solitons, which are encountered in only a handful of known physical systems, are very stable; they travel compactly, interacting very weakly with the systems through which they travel. Sen said the weak shock waves used in the more recent UB studies are soliton-like signals. "These signals are softer bundles of energy, which allowed us to strike a middle ground, generating signals that, like solitons, travel well in granular systems, but which also have some interaction with these systems. "For typical sound waves traveling through any granular system, you would see some reflection of sound waves from a buried object, but it would not reveal many details about the size and shape of that object," said Sen. "What our computer simulations have demonstrated is that when a weak shock wave penetrates into granular media and hits an object, the reflected pulse carries a lot of information about what it hit." That information includes the size and shape of the object, critical features in determining whether or not a land mine has been detected. According to Sen, the weak shock waves are detecting differences in density. For example, sand grains have typical densities of 2700 kilograms per meter cubed, while a piece of plastic has a density of only 1100 kilograms per meter cubed. "So a plastic object buried in a solid would be detected as a light object lying in a heavier medium," he said. In their computer simulations, the researchers showed the reflected soliton-like pulses split in a particular way, depending on whether they collided with a light or heavy object. "Our models tracked the motion of individual grains as the pulse traveled along," he said. "After it hit a buried light or heavy object, relative to the soil, the pulse split up and the reflected pulse had distinctly different properties, depending on whether it was reflected by a light or heavy object. We want to take that knowledge and see if it can be used to detect land mines." The system envisioned by Sen and his collaborators would consist of a special microelectromechanical device that would send weak acoustic shock waves deep into soil and detect the pulses that are returned after hitting an object. The pulses would provide information about the weight and shape of the object, which would reveal whether or not it likely is a land mine. "Ideally, you would envision flying over a suspected mine field and dropping onto it many of these devices," Sen said. "The pulse or pulses would be sent down by each detector and any reflected signal would be received and interpreted to locate the precise position of a land mine." Sen added that a key selling point for the proposed technology would be its low cost, a critical factor in developing detectors for countries where plastic land mines are common, such as Cambodia, Afghanistan and Bosnia. He cautioned that so far, the distinguishing characteristics of the reflected pulse only have been seen in simulated systems. The next step will be to try to observe the phenomena experimentally with high reliability by sending weak shock waves through a box filled with sand or soil. Sen's co-authors on the project are Michael J. Naughton, Ph.D., UB associate professor of physics and chemistry; Marian Manciu, a doctoral candidate in the UB Department of Physics, and James D. Wright, a master's candidate in the Department of Physics at the University of Kent in Canterbury. The work is being funded by the U.S. Army Corps of Engineers.
--------
88-> Gamma Knife May Replace Surgery For Parkinson’s Disease
Researchers at Jefferson Medical College of Thomas Jefferson University and Wills Eye Hospital, Philadelphia, are sidestepping surgery and using a device to deliver high doses of tissue-destroying radiation to tiny targets deep within the brain in the hopes of alleviating the symptoms of Parkinson’s disease. Doctors hope that the noninvasive gamma knife will offer both reduced recovery time and shorter hospital stays for patients with Parkinson’s and other movement disorders whose symptoms cannot be controlled with medication. At the 83rd Scientific Assembly and Annual Meeting of the Radiological Society of North America in Chicago, David P. Friedman, M.D., associate professor of radiology, Jefferson Medical College, reports results on December 3 of the first 12 Parkinson’s disease patients to undergo gamma knife treatment. Of those treated, seven showed marked improvement in their symptoms, three had moderate improvement and two showed mild improvement with a three-month follow-up. Dr. Friedman notes that such results are comparable to those of surgery. The patients in the study all were unable for various reasons to undergo conventional surgery. The gamma knife uses magnetic resonance imaging to identify the radiosurgical target. The radiation destroys certain areas of the brain’s thalamus or globus pallidus, hoping to control tremors, rigidity or other involuntary movements. According to H. Warren Goldman, M.D., Ph.D., professor and vice-chair, neurosurgery, Jefferson Medical College, and at Wills Eye Hospital, Philadelphia, as many as 50,000 patients a year could benefit from the treatment. Dr. Goldman, who notes "this is a relatively new use of the gamma knife," says that doctors are so pleased with the technique’s results to date that they have begun offering the treatment as an alternative to other patients as well. Nearly all patients with Parkinson’s eventually, within five to eight years, become refractory to treatment by medicine. When medication fails, doctors may treat Parkinson’s by two types of brain surgery. In a thalidotomy, surgeons remove or destroy tissue in thalamus, which controls tremors. In a pallidotomy, tissue in the globus pallidus is destroyed in an attempt to control rigidity and some involuntary movements. The gamma knife has several advantages over surgery, according to Drs. Goldman and Friedman. The treatment is noninvasive, without the risks of bleeding or infection. Patients remain hospitalized for only 24 hours compared to three or more days with surgery. Recovery time from gamma knife treatment is minimal; recovery from surgery typically takes at least two weeks. The treatment has some downsides, however. Whereas surgery results are almost immediate, gamma knife treatment results take time, and may not be known for perhaps as long as six or eight weeks. The gamma knife is primarily used to treat brain tumors and various vascular malformations. "This expands its uses," Dr. Friedman says. "Though some 90 centers worldwide, including 32 centers in the United States, have the gamma knife, only perhaps a handful use them this way." Jefferson and Wills began using the gamma knife to treat Parkinson’s in July 1996. Dr. Goldman believes that it is the only such device in the Philadelphia area.
--------
89-> Banning Chemicals To Protect Ozone May Aggravate Global Warming, Atmospheric Scientist Says
CHAMPAIGN, Ill. -- Some of the chemicals being phased out to protect the ozone layer offer offsetting benefits, such as reducing global warming, a University of Illinois researcher says. "By independently addressing the issues of ozone depletion and global warming, we are jeopardizing desirable options for one effect based on lesser -- or even inconsequential -- impacts on the other," said Don Wuebbles, director of the Environmental Council at the U. of I. and a professor of atmospheric sciences. "We need to stop looking at these issues as though they are separate from one another, and start considering them together when we determine environmental policy." In the Nov. 7 issue of the journal Science, Wuebbles and colleague James Calm, an engineering consultant in Great Falls, Va., write that the regulatory actions on certain chemicals -- imposed by both the Montreal Protocol and the U.S. Clean Air Act to protect the ozone layer -- will have little impact on stratospheric ozone while contributing unnecessarily to global warming. "Most of the chemicals responsible for ozone depletion are also greenhouse gases," Wuebbles said. "Chlorofluorocarbons [CFCs], for example, tend to be severe offenders for both the depletion of ozone and for global warming. The need for their regulation is unambiguous." But there are other industrially important chemicals that fall into the gray area. "Some hydrochlorofluorocarbons [HCFCs], for example, have very short atmospheric lifetimes and mostly decompose before reaching the upper atmosphere," Wuebbles said. "Effects on ozone depletion from some of these compounds are likely to be negligible. Nevertheless, they are still being tightly regulated and eventually the intention of the rulings is that they be banned entirely." One such chemical, HCFC-123, is a high-performance refrigerant commonly used in the cooling systems of large buildings. Some of the intended replacements for HCFC-123 not only have much longer atmospheric lifetimes that could contribute to global warming, but they also are far less energy efficient. "High efficiency translates into reduced emissions of carbon dioxide and other greenhouse gases from associated energy use, which, in net impact, dwarf those from incidental releases of the refrigerant itself," Wuebbles said. "High efficiency also reduces fuel and other resource requirements. "It is probable that HCFC-123 and several other CFC replacements would have survived the ban if the global warming regulations had been implemented before the ones for ozone," Wuebbles said. "With keener awareness of the more limited options to reduce global warming, the framers of the Montreal Protocol and the U.S. Clean Air Act might have been more cautious in rejecting chemicals with minimal impacts and offsetting benefits. "There are many other chemicals that also have special uses, small impacts, and where the replacements for them would cause other problems or issues," Wuebbles said. "In such cases, it might make more sense to reconsider current policy and allow the continued use of some chemicals."
--------
90-> UF Researcher: Families Not Necessarily Best Suited To Care For Elderly
Writer: Cathy Keen Source: Karen Pyke -- (352) 392-0265, ext. 251 GAINESVILLE, Fla. --- Many aging parents would rather take the risks of personal freedom than kowtow to their grown children for help with daily living, a  University of Florida study finds. "Older people whose families care for them often feel they must repay their children by deferring to their wishes," said Karen Pyke, a UF sociology professor who did the research. "Many elderly resent this loss of power and would rather do without care -- even if they badly need it -- than pay the price of having to be deferential and obedient toward their children." Pyke's findings were based on 67 in-depth interviews with aging parents, adult children and adult grandchildren in 20 families in the Los Angeles area. Unlike most caregiving studies, which focus on the children -- usually daughters -- her study relies on the perspectives of both parent and child, she said. The study was funded by a grant from the National Institute on Aging. Conflict with parents and children could escalate, Pyke said, if cost-conscious politicians shift elder care from institutions such as subsidized nursing homes to unpaid family members. She said lawmakers already are concerned about the future costs of caring for millions of aging baby boomers. "Politicians often call up a nostalgic image of the family of an earlier day, which was often mythical anyway, to invoke this notion of family values, where people care for their elderly parents," she said. "But values alone do not assure that the nation's elderly are taken care of, and politicians ignore the costs parents pay when their children take on this burden." Elderly parents who get help with yard work, shopping and transportation often feel pressure to comply with their grown children's wishes, Pyke said. For example, one elderly couple in the study reluctantly sold their house and moved into a mobile home after the wife's stroke because their adult children insisted it was too much to care for anymore. "The smoothest, most harmonious parent-child caregiving relations occurred when parents acquiesced to their children's decisions, something staunch individualistic elders are simply unwilling to do," she said. When parents refused to obey, children became resentful and often reduced or set firm limits on how much they would help, Pyke said. Loneliness and not receiving needed care were the price parents paid for not subordinating themselves, she said. Pyke found elderly parents in families that emphasize self-sufficiency and independence over family obligation are especially unhappy at having to be compliant when their children step in. However, even in families where parents normally received more day-to-day help from their children, failure to defer to their children's wishes or express gratitude strained relations between generations, she said. "We need policies that don't rely on just one model of family life," Pyke said. "Politicians need to recognize that families organize themselves in different ways instead of simply viewing family-based care as a panacea for the problem of elder care in this country." Actually, suggesting that families don't do enough is something of a myth because most elder care already occurs in families and not in nursing homes, she said. Feeling overburdened by parental responsibilities and fears about their own future, some children feel increasingly resentful about their role, Pyke said. For instance, she said, one 85-year-old woman's refusal to put her bed-ridden husband in a nursing home led her son, in his 60s, and his wife to wonder if they would ever have time to enjoy their boat, which had remained docked the entire year. "For the children," Pyke said, "it was a case of wondering, ‘When do we get a turn to enjoy some leisure before we get old and frail if all we're doing is helping our mother take care of our father?'" "So much research on intergenerational helping patterns are bookkeeping efforts to say who gets what from whom," said Judith Treas, a sociology professor at the University of California at Irvine. "Karen Pyke's work has shown how people feel about family care, particularly the emotional downside of feeling put-upon or coerced into doing what you really don't want to do."
--------
91-> New Delivery System May Improve Gene Therapy
REHOVOT, ISRAEL, December 3, 1997...In the genes of an organism, as in real estate, location is key. The functioning of any gene is significantly affected by its exact placement on the chromosome. However, scientists currently have no means of delivering a new gene to a predetermined location in a cell's chromosomes during genetic manipulation, such as gene therapy. A method that may make it possible to control where new genes go has been developed by Prof. Ernest Winocour of the Molecular Genetics Department at the Weizmann Institute of Science together with post-doctoral fellow Dr. Joe Corsini and Prof. Jacov Tal of Ben-Gurion University of the Negev's School of Medicine. The approach, described in the December issue of the Journal of Virology, may significantly improve all types of genetic manipulation in which new genes are introduced into an organism. "The ultimate goal is to target a gene to a position where it brings the most good and causes no harm," says Winocour. Long-lasting benefits To carry new genes to the cells of an organism, scientists often use viruses that serve as "delivery vehicles." Before such a "vehicle," called a vector, is dispatched, researchers equip it with the gene they want it to deliver - for example, a healthy "replacement" copy for a faulty, disease-causing gene. The vector inserts itself into the chromosomes and the newly delivered gene begins to replicate every time the cell divides. However, all existing vectors insert themselves into chromosomes at random positions. As a result, scientists have poor control over the function of the new genes. When these genes make their home in certain positions, they will function poorly or not at all; in other positions they may be evicted from the cell altogether. Moreover, there is the risk that, in some positions, the new genes will negatively affect the neighboring DNA. "Knowing where the genes go on the chromosomes may make it possible to develop improved gene therapy with a long-lasting effect," says Prof. Winocour. 'Single-minded' vectors To attain this goal, Winocour and colleagues propose to use a family of viruses called parvoviruses. The striking feature of parvoviruses is their "single-mindedness": they are the only animal viruses that integrate themselves into the cell's chromosomes at unique sites. Knowing in advance where the virus is headed gives scientists greater control over what it will do once it has inserted itself into the organism's genome. In the new study, Winocour and colleagues studied one type of parvovirus called minute virus of mice, or MVM. The scientists revealed the mechanism that allows MVM to zero in on a particular target site. They were then able to replicate this mechanism - which consists of signals exchanged by the virus and the chromosomes - in a model system. "Further research needs to be done to see if our method works in laboratory animals, " says Winocour. If successful, it can have far-reaching applications in medicine and animal breeding. Winocour notes further that this research may be extended to other parvoviruses. There are about 50 known parvoviruses, each of which might be capable of inserting itself at a specific location. If the entire parvovirus family is harnessed, it may provide scientists with an extremely useful and versatile array of gene vectors. A patent application for the new method has been filed by Yeda Research and Development Co., the Weizmann Institute's technology transfer arm, together with Ben-Gurion University of the Negev. This research was supported by the German-Israeli Foundation for Scientific Research and Development (GIF). Dr. Corsini is the recipient of a postdoctoral fellowship from the Planning and Budgeting Committee of the Israel Council for Higher Education. The Weizmann Institute of Science, in Rehovot, Israel, is one of the world's foremost centers of scientific research and graduate study. Its 2,500 scientists, students, technicians, and engineers pursue basic research in the quest for knowledge and the enhancement of the human condition. New ways of fighting disease and hunger, protecting the environment, and harnessing alternative sources of energy are high priorities.
--------
92-> Strange South American Fossil Mammals Found In Madagascar And India
A strange group of fossil mammals, heretofore only known in South America, has been discovered on the island of Madagascar and in India. The unexpected discoveries were announced in this week's issue of the journal Nature by an international team of researchers. The team was funded by the National Science Foundation (NSF) and led by paleontologist David Krause of the State University of New York at Stony Brook. The 65-70 million year old mammals, dating from the Late Cretaceous period, were unrelated to any groups living today and are known as gondwanatheres. The discovery of their highly distinctive teeth in such disparate places as South America, Madagascar and India has fundamental implications for plate tectonics, the theory that landmasses move slowly over the face of the earth and were in different places in the past than they are today. Ironically, though the group of mammals was previously known only to be from Argentina, it was named Gondwanatheria after the supercontinent of Gondwana, which once included all of the landmasses of the southern hemisphere. "These are major discoveries that go far beyond their obvious significance to paleontologists," says Chris Maples, program director in NSF's division of earth sciences, which funded Krause's work. "Krause and his large-scale, multi-investigator team have provided an excellent example of the contributions that paleontology can make to many areas of geoscience, including tectonic plate positions in Earth's past." Krause says, "Finding representatives of gondwanatheres on these three now widely separated landmasses suggests to us that they were connected in the Late Cretaceous. A recently proposed geophysical model shows that India and Madagascar were attached to eastern Antarctica well into the Cretaceous while South America was attached to the western end of Antarctica. This discovery supports that hypothesis with totally independent evidence derived from the fossil record." Significantly, gondwanatheres have not been found in Africa, which lends credence to the research team's conclusion that Africa was relatively isolated during the 35 million years of the Late Cretaceous. "It's not just the mammal evidence that suggests that Africa was off doing its own thing; the dinosaur evidence also indicates a high degree of African endemism during this interval," adds Krause. Krause has led large-scale NSF-funded paleontological expeditions to Madagascar for three years. Krause's team has discovered a spectacular array of well-preserved and extraordinarily complete skeletal material of crocodiles, birds, dinosaurs and other backboned animals in Madagascar. Despite finding only fragmentary remains of mammals, Krause notes that the mammal specimens "may not be all that spectacular visually, but they're extremely important. Scientific significance, just like beauty, is in the eye of the beholder." NSF is an independent federal agency responsible for fundamental research in all fields of science and engineering, with an annual budget of about $3.3 billion. NSF funds reach all 50 states, through grants to more than 2,000 universities and institutions nationwide. NSF receives more than 50,000 requests for funding annually, including at least 30,000 new proposals.
--------
93-> Astrophysicists Solve Mystery Of Gas Flow From Sunspots
One of the classic problems of solar physics has been solved, and the solution turns out to be a model of solar gas flow first proposed by a University of Rochester astrophysicist in 1988. In a paper to appear in the December 4 issue of Nature, John H. Thomas and collaborator Benjamin Montesinos of Madrid's Laboratory for Space Astrophysics and Fundamental Physics present a more realistic version of the siphon-flow model, which predicts how gas flows from sunspots into the solar atmosphere. The results of their model match in considerable detail the observations reported by another research group in the September 4 issue of Nature. Thomas calls this recent observational evidence "the clincher" in support of the siphon-flow model. The work could also offer insights into other astrophysical processes that involve strong magnetic fields and jets of gas, such as when stars form or die -- an area that's the focus of much research. "Unlike most gas or plasma flows in space, sunspots can be observed in great detail," says Thomas, former chairman of the Solar Physics Division of the American Astronomical Society and a scientific editor of the Astrophysical Journal. "They can serve as a test bed for our understanding of similar flows throughout the universe." Indeed, some astrophysicists think that siphon flows analogous to those in sunspots may occur on a galactic scale. Sunspots have mystified humans ever since Galileo's first telescopic observations in 1611. Sunspots mark areas on the Sun's surface where the star's magnetic field becomes so intense that a buoyant tube of magnetism literally pops through the Sun's surface. The magnetic field disrupts the outward convection of heat, resulting in dark Earth-sized splotches that are some 2,500 degrees Celsius cooler than the rest of the solar surface. As many as 30 sunspots may be visible on the Sun's surface at any given time; they last anywhere from one hour to three months. Sunspot activity exhibits an 11-year cycle, with the number of sunspots next expected to peak in 2000 or 2001. Periods of high sunspot activity also usher in an increase in the number of solar flares -- intense bursts of magnetic energy hurling energetic particles out from the Sun. When these flares reach the Earth's magnetic field, they can wreak havoc with electrical lines, communications satellites, and even automatic garage door openers. The solar puzzle that has absorbed Thomas is the Evershed flow, a flow of gas emanating from sunspots that has perplexed astrophysicists for nearly 90 years. The September observations, published by researchers from the Canary Islands Institute of Astrophysics and the High Altitude Observatory in Boulder, Colorado, demonstrate -- as Thomas first hypothesized in 1988 -- that the flow follows along arched magnetic field lines that emerge from within the sunspot and then dive back down below the solar surface near its outer edge. "An ionized gas like that in the Sun's atmosphere flows strictly along lines of magnetism," says Thomas, a professor of mechanical engineering and of astronomy. "The magnetic field in a sunspot is shaped roughly like a sheaf of wheat -- with the base rooted beneath the Sun's surface and each stalk representing a discrete tube of magnetic flux. The original siphon-flow model held that gas would flow outward along field lines extending well beyond the sunspot, but little of this outward flow was ever detected outside the sunspot. Now we know that most of the flow returns into the Sun at the outer edge of the sunspot, along low-lying, arched magnetic field lines." The original siphon-flow model was first proposed in 1968 by Friedrich Meyer and Hermann Schmidt of the Max Planck Institute for Astrophysics. But Thomas, who spent a year in the early 1970s working with Meyer and Schmidt in Munich, realized in the mid-1980s that the early siphon-flow model had some shortcomings. "The original theory did not accurately describe the flow of gas in the photosphere, the region of the solar atmosphere closest to the sun's surface," Thomas says. "It assumed that the flowing gas had no effect on the configuration of the magnetic field, but this is not true in the photosphere, where most of the flow occurs." Since Thomas' 1988 modifications to Meyer and Schmidt's theory, he has become the siphon-flow model's main proponent, penning a half-dozen scientific papers -- most of them with Montesinos -- that have steadily filled in the model's details. Thomas' sunspot research is funded by NASA. 
--------
94-> Single Genetic Locus Linked To Top Cancer-Targeted Biochemical Pathways
MEMPHIS, Tenn., November 28, 1997 -- While identifying a new cancer-fighting tumor suppressor gene called ARF, scientists at St. Jude Children's Research Hospital have made another, potentially more far-reaching discovery, that a single genetic locus called INK4a encodes protein products that regulate the most frequently targeted biochemical pathways in human cancers, regardless of patient age, tumor site or type. The findings, likely to have major implications for the development of anti-cancer therapies, appear in today's issue of Cell. Pivotal in one of the pathways is the newly identified tumor suppressor ARF. The St. Jude researchers found that ARF interacts with one of the most frequently mutated tumor suppressor genes in human cancer, p53. Tumor suppression by ARF in mice could not occur if p53, which causes cells with defective DNA to arrest their growth and to self-destruct, is itself defective, missing, or otherwise nonfunctional. The interdepartmental St. Jude research team led by Charles J. Sherr, M.D., Ph.D., an investigator of the Howard Hughes Medical Institute, had earlier found ARF embedded in INK4a. "This economical, overlapping organization of both the ARF and INK4a genes in the same chromosomal location, observed in both mice and humans, is not seen anywhere else in mammals," explained Sherr. The other cancer-related biochemical pathway, previously discovered, involves a protein separately encoded by INK4a that affects the activity of another tumor suppressor, the retinoblastoma protein, RB. "What is most surprising," said Sherr, "is that a single genetic locus, INK4a/ARF, encodes two different products that regulate the two biochemical pathways involving p53 and RB." Mutations and deletions that adversely affect the INK4a/ARF locus are very common in different forms of human cancer. Sherr and his team confirmed ARF as a tumor suppressor by finding that, when ARF is eliminated or knocked-out in mice, the mice develop cancers. At two months of age, mice deprived of ARF began to develop cancer spontaneously and, by six months, a third exhibited malignant tumors. Treating the mice with a known carcinogen or with X-rays hastened the onset of tumors. Conversely, mouse cell lines missing the protein encoded by ARF promptly stopped proliferating when the ARF protein was reintroduced in the cells via a retroviral vector. Although the exact mechanism by which ARF exerts its antiproliferative effects on cells is unknown, ARF may operate, like p53, through another cell growth inhibitor called p21Cip1 , which is found at increased levels in the presence of ARF. St. Jude Children's Research Hospital, in Memphis, Tenn, was founded by the late entertainer Danny Thomas. The hospital is an internationally recognized biomedical research center dedicated to finding cures for catastrophic diseases of childhood. The hospital's work is primarily supported through funds raised by the American Lebanese Syrian Associated Charities (ALSAC). All St. Jude patients are treated regardless of their ability to pay. ALSAC covers all costs of treatment beyond those reimbursed by third party insurers, and total costs for families who have no insurance.
--------
95-> Preventing Sudden Death: New Sodium Channel Raises Hope For Control Of Cardiac Arrhythmias
Like a car, the heart depends on a complex and tightly timed series of electrical and mechanical events to do its job.  If its precisely synchronized system malfunctions, the car may stall–and the heart may suffer cardiac arrhythmias, life-threatening disruptions in the coordination of contractions in different regions of the heart muscle needed to keep blood pumping through the body.  Arrhythmias kill nearly half a million Americans a year, and there is no effective drug therapy. Just as the electrical system of a car triggers movement of the pistons, electrical events in the heart trigger its contraction. Now researchers at the University of Maryland School of Medicine have identified a previously unrecognized step in the electrical process of stimulating the heart to beat, a new sodium channel that could pave the way for effective drug treatments for cardiac arrhythmias. C. William Balke, MD, associate professor of medicine and physiology;  Lawrence Goldman, PhD, professor of physiology;  Stephen R. Shorofsky, MD/PhD, assistant professor of medicine; and Rajesh Aggarwal, PhD, research associate in medicine, report their findings in the December 1, 1997 issue of the Journal of Physiology (London). Balke describes the new sodium channel as "a seminal finding with broad implications, not just in the heart, but in many kinds of excitable cells." A sodium channel is a minute pathway through the membrane or outer surface of cells.  Made up of protein molecules embedded in the cell membrane of heart muscle cells, sodium channels open and close in response to electrochemical changes, allowing positively charged ions to pass into the cell and trigger the rhythmic contractions that pump blood through the body’s circulatory system. Electrophysiologists have known about sodium channels in heart muscle for some time.  It had long been believed that the rhythmic electrical activity of the heart caused contraction by directly opening these "classical" sodium channels in heart muscle cells. Balke and Goldman found instead that the heart’s rhythmic electrical activity opens a new type of sodium channel, which in turn opens the classical sodium channels that trigger contraction of ventricular cells. The new sodium channel appears to be a previously unknown and vital step in the normal sequence of electrical activity that causes the heart to pump. Balke calls it a "gatekeeper" between the electrical signal and contraction of heart muscle. "This may give us a tool for preventing and correcting arrhythmias," he said. "It is a trigger we didn’t know existed, and it gives us a whole new target for pharmacological therapy for arrhythmias." Added Goldman: "Even if it isn’t the source of the defect, if you can modulate it properly, you should be able to control the arrhythmia," The Maryland investigators’ research was funded in part by the National Institutes of Health. 
--------
96-> Sandia Scientists Are Developing A Portable Evidence Finder That Makes Organic Substances Appear To Blink In Fluorescent Colors
 ALBUQUERQUE, N.M. -- Some evidence is hard to find, particularly the kinds of evidence that can help police place the perpetrator at the scene of the crime -- fingerprints, semen, urine, and other organic substances that carry clues to a criminal's identity. Now researchers at Sandia National Laboratories are developing an evidence-detection system that would -- with the aid of a flashing lamp and a pair of modified 3-D video game goggles -- make organic substances appear to blink, allowing investigators to locate potential evidence more quickly and in a lighted room if necessary. The National Institute of Justice, the research arm of the Department of Justice, has provided $393,000 for the project. The researchers hope to begin testing a prototype of the system in 12 months and have it available for licensing and manufacture in 18 months. The Albuquerque Police Department's crime lab has agreed to test a prototype system at actual crime scenes. "If it works, this system would give us the ability to see things we haven't been able to see more quickly and in ambient light," says APD Criminalistics Director Ann Talbot. An important feature of the system is its affordability, says Dave Sandison, lead researcher for the project. "We don't want to develop something the FBI would have two of and nobody else could afford," he says. "It would be accessible to police departments everywhere." The approach originates from a Department of Energy-sponsored weapons security project. Less thinking when it's blinking To locate certain organic evidence, fingerprints for example, police typically rely on optical aids such as powders, lamps giving off various wavelengths of light, and yellow-tinted goggles that increase the evidence's visibility. Even with these aids, investigators typically must conduct their investigations at night or in a darkened room. It can take hours to scour every inch of a crime scene. Most fingerprints that are discovered are lifted from smooth surfaces such as glass windows or polished furniture, says Talbot. Latent fingerprints on walls and other textured surfaces are more difficult to find, and some kinds of organic evidence, such as semen or urine, don't show themselves even with optical aids. Sometimes fluorescent dyes are used in situations where they won't contaminate other evidence, but rarely and as a last resort. "If you use chemicals, you typically have to spray down the entire room," Talbot says. "That can get expensive." A lot of potential evidence can go unnoticed, she says. Sandia's proposed evidence-detection technique relies on the fact that all types of organic substances give off weak fluorescent emissions, normally invisible to the naked eye because other, much brighter sources of light interfere. The proposed system takes advantage of the periodic dissonance between two signals at slightly different frequencies -- an effect called heterodyning -- as well as the human eye's natural affinity to anything that moves or blinks. "We like to say, 'There's less thinking when it's blinking,' " says Sandison. On, off, on, off, on, off In a nutshell, the system's lamp is modulated at a specific frequency, say 100 times per second, which is to say it flashes at a rate too fast for the human eye to detect. The glasses, modified from a 3-D video game, shutter open and closed at a slightly different frequency, say 102 times per second, which essentially turns the user's eyes on and off at a rate also too fast to be detected by the human eye. To the wearer, the lenses appear transparent. Every so often, about twice a second, the glasses shutter open at the exact moment the lamp is "on," which for a split second drowns out most background light whose wavelengths are different than that of the lamp. With the background light masked, the net effect is that the fluorescing materials appear to flash brightly at a rate that is distinctly noticeable to the human eye. From behind the shuttered glasses, the crime-scene investigator would see the room lighted normally, but any organic substances would flash a few times per second when illuminated by the system's lamp. It's like the combined sound two jetliner engines make, every once in a while humming in harmony and alternatingly reverberating in discord. The engines hum when the acoustic wavelengths match up. They clash when they don't. The researchers may also test the system using a low-light video camcorder that is more sensitive to the fluorescence than the human eye. Law enforcement practicality The APD crime lab tests are intended to help work out any bugs in the technique, define what kinds of evidence it can help find, and determine whether the system will be practical as a law enforcement tool. "Who knows, we may turn the system on and see thousands of fingerprints," Talbot says. "If we see too much, we won't be able to sort out the real evidence. "But if it works with some discretion and it's portable, it would be useful to us on a fairly frequent basis. The beauty of this approach is that it doesn't contaminate other evidence." It may be particularly useful at sexual assault crime scenes for identifying semen, which fluoresces much more brightly than the oils from fingertips. The researchers also hope to determine whether fresh fingerprints fluoresce more brightly than organic substances that have been there for awhile. If so, the system might be good at screening out evidence that isn't pertinent to an investigation. A related system is being used by a private company for detecting cancerous lesions in tissue samples. And Molecular Technologies Inc. (run by Ned Godshall, a Sandia researcher on entrepreneurial leave-of-absence) has applied fluorescence to the problem of DNA sequencing. The heterodyning technique originates from an early 1990s Sandia weapons security project. Sandia is a multiprogram Department of Energy laboratory operated by Lockheed Martin Corp. With main facilities in Albuquerque and Livermore, Calif., Sandia has research and development programs contributing to national security, energy and environmental technologies, and economic competitiveness.
--------
97-> Global Climate Change Recorded In Antarctic Marine Fossils
An ancient type of marine community typical of 450 million years ago has resurfaced in Antarctic fossils of near-modern age. A National Science Foundation-sponsored expedition to Seymour Island off the Antarctic Peninsula unearthed an ecological anomaly: fossil communities only 40-million-years-old dominated by brittle stars and sea lilies (marine invertebrates like starfish). The authors of the paper detailing the findings, published in the October, 1997 issue of the journal Geology, believe that as Antarctica entered its current deep freeze, cooling ocean temperatures suppressed predation and spurred a dramatic increase in nutrients upwelling in the Southern Ocean surrounding the continent. "This discovery is a good example of how global climate change can have severe impacts on marine life," said Richard Aronson, senior marine scientist at Dauphin Island Sea Lab and lead author of the paper. The community structure reflected in the Seymour Island fossils -- that is, the comparative numbers of different organisms occupying particular ecological niches -- was much more typical of the shallow seas of 150-to-450 million years ago. After that, predation by newly evolved fish and other creatures confined brittle stars and sea lilies to habitats in the depths of the sea. The paper's authors believe that when Antarctic temperatures began to plummet, however, predation was disrupted -- some predator populations shrank and others went extinct -- and the archaic community structure reappeared. In fact, the brittle stars and sea lilies clustered in dense beds of fossils show few arm injuries, an indication that predation was light. Bottom dwellers such as brittle stars and sea lilies also require abundant nutrients. "Global cooling accelerated about 40 million years ago in the late Eocene, and this longterm trend was accompanied by increased upwelling in the Southern Ocean, including around the Antarctic Peninsula," the authors said, which made more nutrients available. The authors also point out that today, living bottom-dwelling communities in Antarctic waters also show archaic characteristics. Perhaps conditions in the Antarctic or in the Southern Ocean generally work in some way to maintain these old-fashioned community structures, they suggest.
--------
98-> Mental Stress Response Linked To Blood Vessel Blockages
DALLAS, Dec. 2 -- For the first time, in a large study, researchers have linked an exaggerated response to mental stress to blood vessel blockages that can trigger heart attacks and strokes. The findings appear in today's American Heart Association journal Circulation. The study of 901 Finnish men found that those with the most extreme blood pressure responses on a mental stress test had the thickest blockages from atherosclerosis in their carotid arteries, the vessels that feed blood to the brain. The association was strongest among men younger than 55. In the study, mental stress responses were associated with the same degree of atherosclerosis risk as smoking and elevated cholesterol in the younger men, suggesting that cardiovascular reactivity to stress may turn out to be a new risk factor for heart disease and stroke, says the study's lead author, Thomas Kamarck, Ph.D., associate professor of psychology, University of Pittsburgh. Since all of the measures were taken at one time, the researchers cannot yet conclude that the responses to mental stress cause the atherosclerosis. Further research is needed to determine if mental stress response predicts future development of plaque. Just like elevated cholesterol, mental stress over time may injure blood vessels and promote atherosclerosis in susceptible individuals, Kamarck says. "Frequent and prolonged periods of elevated blood pressure during mental stress may promote mechanical injury to the endothelial lining or cause release of stress hormones that can promote the build up of plaque," say the researchers. They note that further research is needed to determine the cause of the association observed in this study. The new study builds on existing evidence that individuals who show exaggerated responses to stress ("Type A", or hostile individuals) may be at higher risk for heart disease and stroke than more relaxed individuals. The latest study seeks to further pinpoint the "unhealthy" characteristics of "stress-prone" individuals who have been previously identified by questionnaires or interviews. The test used in this study requires a person to perform a series of mental tasks that require a range of cognitive and memory skills. Each task is designed to stimulate a state of mild mental stress. The difficulty level was adjusted to maintain performance of less than 60 percent accuracy rate so that the person remained challenged throughout. "Cardiovascular reactivity" was measured by examining the acute changes in blood pressure and heart rate produced by the tasks. The participants in the study -- who were enrolled in a heart disease investigation called the Kuopio Ischemic Heart Disease Study -- all had carotid ultrasound testing. This non-invasive test provides an X-ray image of the thickness of the carotid artery wall, a measurement called mean intimal thickness which is thought to be a reflection of atherosclerosis in the vessel. The carotid ultrasound is a widely accepted tool used to estimate atherosclerosis in other blood vessels in the body. Men who were in the highest quintile for cardiovascular reactivity had a mean intimal thickness of .89 mm, compared to .85 mm in the lowest fifth. An increase of .1 mm of intimal medial thickness has been associated with an 11 percent increased risk for heart attack in previous studies. Future research is needed to determine whether cardiovascular reactivity predicts heart attacks or other results of atherosclerosis, says Kamarck. Researchers don't know why the association was not found in individuals older than 55. Since this sample of Finnish men was particularly prone to heart disease, some of the most susceptible individuals may not have survived into their 60s. The survivors may have been less prone to develop diseases regardless of their stress reactivity. Researchers don't know why people differ in their cardiovascular reactivity to acute stress. Evidence suggests that about 50 percent of the differences may be due to genetics, but chronic stress exposure may contribute in some cases as well. Co-authors are Susan Everson, Ph.D., M.P.H.; George Kaplan, Ph.D.; Stephen Manuck, Ph.D.; J. Richard Jennings, Ph.D.; Riitta Salonen, M.D., Ph.D.; and Jukka Salonen, M.D.; Ph.D., M.Sc.P.H.
--------
99-> Compressed Sulfur Found To Be A Superconductor
A group of scientists from the Carnegie Institution and Russian Academy of Sciences report in this week's Nature magazine the surprising observation that sulfur becomes a superconductor at 93 GPa (9.3 million atmospheres). At this pressure, pure sulfur transforms to a superconductor with a Tc (critical temperature) of 10 K, or -263°C. As pressure increases, so does the superconducting temperature, at a rate of .06 K per GPa (up to 14K). At a pressure of 160 GPa (the highest measured in the current experiments), Tc again increases--to 17 K. In a related study, appearing in this week's Physical Review Letters, the same authors report the first measurements on a known superconductor, the metal niobium, above one million atmospheres (or one megabar)--to 132 GPa. A material is said to be a superconductor when it loses resistance to electrical current flow. The phenomenon, one of the most non-intuitive in physics, has been recognized since 1911. Within the last decade, superconducting materials have been found at temperatures high enough to hold promise for energy-related applications, especially in the computer and electric energy fields. Most studies have focused on oxide-based ceramics. The mechanisms of superconductivity in materials are of great theoretical interest but are, in many cases, in dispute. Studies of simple materials such as the pure elements that might superconduct, including an examination of the effects of pressure on Tc, are essential for understanding the underlying physics. Such studies in turn are crucial for designing new, technologically useful superconductors. The authors of both papers are Viktor Struzhkin, Russell Hemley, Ho-kwang Mao, all of Carnegie's Geophysical Laboratory and NSF Center for High Pressure Research, and Yuri Timofeev, of the Institute of High-Pressure Physics, Russian Academy of Sciences. The group used the Geophysical Laboratory's megabar high-pressure diamond-anvil cell in conjunction with a magnetic susceptibility technique they have perfected over the past few years. The technique allowed them to determine the superconducting transition temperature without the need for placing electrical leads on the sample. Thus, they could perform their measurements on very small samples (down to 0.04 of a millimeter in diameter and a few thousandths of a millimeter in thickness). Tests of the method in the megabar pressure range (above 100 GPa) were done on niobium, which has a Tc of 9.5 K at atmospheric pressure but decreases to 4.5 K at 132 GPa (rather than increases). Sulfur's transition from insulator to superconductor at 93 GPa was unexpected. Several years ago, scientists elsewhere had observed changes in optical properties of sulfur that suggested that the material transforms to a metal at about 90 GPa (at room temperature), with a corresponding change in crystal structure, and that it transformed to another structure at about 160 GPa. Recent theoretical calculations had predicted that sulfur would become a superconductor only at much higher pressures (above 550 GPa). The new results show that the material transforms directly from an insulator to a superconductor at the first transition (at 90 GPa). The results provide an important example of the large-scale changes in physical properties that can be induced by pressure. The authors write in their Nature paper that their results are particularly notable because the metallic phases of sulfur have the highest Tc's of any elemental solid measured to date. Sulfur now joins the heavier members of its family in the Periodic Table of the Elements (the chalcogenide family, including selenium and tellurium), as a superconductor. This fact should provide critical tests for theories of superconductivity. In closing their paper, the authors write: "Given the comparative simplicity of elemental sulfur for electronic structure calculations and knowledge of its high-pressure crystal structures, this element should provide important tests of possible new mechanisms." The work is part of a much larger effort at the Geophysical Laboratory devoted to studying the behavior of materials at ultrahigh pressures, including those that prevail deep within the planets. The research was supported partially by the National Science Foundation (Division of Materials Science and Center for High-Pressure Research).
--------
100-> Jefferson Researcher Finds New Digital X-Ray Technology May Cut Costs And Improve Patient Care
A new digital X-ray technology being studied at Thomas Jefferson University Hospital, and to be unveiled next week, has the potential to replace the current film X-ray technology, while reducing health care costs and improving patient care, says Gary S. Shaber, M.D., research professor of Radiology, Jefferson Medical College, Philadelphia, and director, Division of General Diagnostic Radiology, Thomas Jefferson University Hospital, Philadelphia. Dr. Shaber has spent more than a year extensively studying the DirectRay digital radiography technology designed by Sterling Diagnostic Imaging of Newark, Del. DirectRay, which is currently being reviewed by the U.S. Food and Drug Administration, will be formally unveiled Sunday, Nov. 30, at the 83rd Scientific Assembly and Annual meeting of the Radiological Society of North America meeting (RSNA) in Chicago. Dr. Shaber will also be presenting two major papers on the technology at the meeting on Sunday, Nov. 30 and Monday, Dec. 1. Dr. Shaber, who has been the primary investigator of the technology, said the images produced by digital radiography are equivalent to those produced by film-based radiography. The technology has also been studied at the Cleveland Clinic Foundation in Cleveland, Ohio. “I think digital radiography has tremendous potential,” said Dr. Shaber. “In my opinion, it is the wave of the future.” Currently, an estimated 70 percent of all diagnostic exams are performed using conventional film-based radiography because of its functionality and high image quality. Film-based systems, however, can be indirect because fluorescent materials must first absorb the X-ray energy and convert it into light during the exposure process, Dr. Shaber explained. Then the light must be converted to electronic signals. During this second step, the emitted light scatters and can reduce the sharpness of the image. With digital radiography technology, X-ray energy is captured and converted into electronic signals that form a precise digital image on a video screen, said Dr. Shaber. These images can be duplicated and transmitted electronically with no loss of quality, he said. Furthermore, there is software available that would allow a radiologist to focus on or enhance a specific area of interest on the digital X-ray. This new technology can result in reducing the cost of processing, storing and transporting images, so radiologists will be able to process and review more X-rays, Dr. Shaber said. The X-rays can also be stored in the computer for easy and quick access by physicians. Digital X-ray technology would also allow hospital radiology departments to see more patients and cut down on repeat examinations. In time, hospitals could have totally filmless radiology departments, Dr. Shaber noted. “This should improve output and increase productivity, and this is one of the issues that radiologists will have to face in the future, as well as efficiency,” he said. “And the only way they’re going to become more efficient, I feel, is through digital radiography. “I’ve been working on this technology myself for 25 years,” he added. “It had to come at some point.” Patients can also greatly benefit from this technology, he noted. With digital radiography, a patient will spend less time waiting for X-rays to be developed and read, and the results can quickly be communicated to their primary care physician, often while the patient is in the doctor’s office, Dr. Shaber said. “If this technology offers us improved diagnostic capability, the patient is going to gain a significant amount of care,” he said. Digital technology also offers a significantly lower dose of radiation than conventional imaging.
--------
101-> NASA/Marshall Lightning Imaging Sensor On Japan's Tropical Rainfall Measuring Mission Satellite To Illuminate Link To Weather And Climate
 Folklore has it that rain follows lightning. Scientists think there might be more than a little truth to that saying. Soon, a new spaceborne instrument - the Lightning Imaging Sensor (LIS) - will help us understand more about the role of lightning in weather and climate. LIS, developed by NASA's Marshall Space Flight Center, is one of five instruments aboard the Tropical Rainfall Measuring Mission (TRMM, pronounced "trim," depicted at right) launched today by Japan's National Space Development Agency. Other sensors aboard the craft include the first radar designed to map rain from space, and sensors to look at clouds and moisture in visible and infrared light and microwaves (short-wavelength radio). When operations start in a few days, TRMM's instruments will gives us new insight into how clouds work, including the role played by lightning. LIS images and data will be used in at least five areas: Global lightning and rain, Tropical convection and sea surface temperatures, Rainfall estimates from geostationary orbit, Global electric circuit and lightning, and Atmospheric chemistry. Lightning research is one of the first sciences developed in America. Ben Franklin became famous for his experiment in which he flew a kite in a thunderstorm to test his theory that lightning was the same as the exciting, new phenomenon called electricity. (Franklin was lucky; another scientist was electrocuted a few months later repeating the experiment, so don't try it. Lightning kills.) NASA/Marshall has a long background in observing lightning from space since the second Space Shuttle mission (STS-2) in 1981. Marshall scientists modified a 16mm movie camera so the crew could record lightning from above the clouds rather than from below. A version also flew aboard a high-altitude U-2 research plane. In the Mesoscale Lightning Experiment, the shuttle's payload bay cameras recorded hundreds of nighttime lightning flashes (left). Many were spectacular events that lit up entire storm systems. Others sometimes seem to talk to each other as flashes in one region were echoed by flashes in another. Most recently, the Optical Transient Detector (OTD) has been operating aboard the Microlab 1 satellite, launched in 1995. OTD and LIS are almost identical (some minor improvements were made for LIS). OTD, though, operates at a higher altitude and has a wider field of view. These experiments proved not only that lightning could be observed from above the clouds (like the map of a storm over Oklahoma, right), but that most of the electrical activity in clouds is not seen nor is it detected by electrical sensors on the ground. (Many people will be familiar with these from TV stations that map lightning strikes during severe weather. Because these use the Earth as part of the detection network, they only show cloud-to-ground strikes.) Even El Nino is a factor in global lightning studies. In Central Florida, the most widespread severe weather outbreak in its history occurred the during the first week of February, 1983. Increased cyclogenesis in the Gulf, and jet stream winds 30-40 knots above normal, produced conditions favorable for an outbreak of 21 tornadoes (4 killed, 200 homeless). Goodman and Christian an Steve Goodman, also of NASA/Marshall, examined the warm, cold, and neutral El Nino/Southern Oscillation periods from 1986-1989 in the southeast United States. They found a direct relationship among rainfall, lightning, Gulf moisture transport and the upper level winds. Editor's Note: The original release can be viewed at http://science.msfc.nasa.gov/newhome/headlines/essd28nov97_1.htm 
--------
102-> Strongest El Niño In History Dampers '97 Hurricane Season; Colorado State's Gray Says Still Most Active Three-Year Period
FORT COLLINS -- Despite the strongest summer El Niño event on record, 1997 hurricane activity in the Atlantic Basin was 54 percent of the long-term average but was less than predicted by Colorado State University's noted team of hurricane forecasters. The team, lead by Professor William Gray, issued a report Nov. 26 that outlined why the El Niño of 1997 flattened the team's August prediction of 11 named storms, six hurricanes and two intense hurricanes for the season. Instead, the Atlantic Basin saw seven named storms, three hurricanes and one intense hurricane during the season, which ends Nov. 30. On average, 9.3 tropical storms, 5.8 hurricanes and 2.2 intense hurricanes form annually. Although the hurricane season was below average, Gray's statistics show that the period between 1995-1997 was still the busiest three-year period for hurricane activity on record. The three-year span generated 39 named storms, 23 hurricanes (13 of which were intense) and 116 hurricane days. "We knew going into the hurricane season that this would be an extremely difficult year to forecast," Gray said. "The El Niño proved to be twice as strong as any other previous record El Niño event in history for this time of year. No one guessed that it would grow to be so intense. And yet, despite this very extreme weather event, we still saw hurricane activity--more than was to be expected." El Niño is a weather phenomenon marked by warmer-than-normal water temperatures in the eastern Pacific Ocean off the coast of Peru and along the equator. This rise in ocean temperatures causes strong upper tropospheric winds to blow in a westerly direction from the Pacific Ocean to the tropical Atlantic Ocean. These winds typically act to shear off developing hurricanes. Gray said that in other years with strong El Niño events, such as 1957, 1972 and 1982, waters warmed only 2 or 3 degrees centigrade above normal. But the El Niño of 1997 actually warmed waters 4 or 5 degrees centigrade above normal--nearly twice as much as the previous record El Niño of 1982-83. This rare and extreme rise in ocean temperatures helped produce even more intense westerly upper tropospheric winds in the Atlantic Basin, which caused strong wind shear and prevented most easterly waves from Africa from forming. Gray and his team of researchers are investigating the possibility that the extreme El Niño this year may have been the result of a long period of warm water accumulating in the western Pacific, possibly left over from smaller El Niño events in 1991-1993. The team contends this kind of warm water build-up could only have produced the type of El Niño that emerged this year. Despite El Niño's extreme influence over the Colorado State team's 1997 hurricane forecast, Gray points out that factors in the Atlantic favorable for hurricane activity were still enough to produce seven named storms this year. These factors included warmer sea surface temperatures in the north and tropical Atlantic and colder sea surface temperatures in the South Atlantic, as well as colder than normal air temperatures 54,000 feet above Singapore. Also present was the Quasi-Biennial Oscillation, equatorial stratospheric winds at 68,000-75,000 feet than tend to promote hurricane formation when they blow from the west--as they did this year. And, as predicted in the team's August forecast, El Niño pushed many of the storms that did form in 1997 to higher latitudes--some of them closer to the United States. Of the seven named storms that formed in the Atlantic, six originated above 25 degrees north latitude, higher latitudes than hurricanes typically form. Gray attributes this to the fact that while El Niño produces strong upper-level westerly winds at lower latitudes that block African-origin storms, it also creates weaker upper-level westerly winds at higher latitudes that are less able to thwart hurricane development. Using atmospheric models, Gray and his colleagues have shown that if the El Niño of 1997 had only been as intense as previous record El Niño events in 1957, 1972 and 1982, those positive factors for hurricane formation would have generated 10 named storms, six hurricanes and three intense hurricanes--virtually on target with the team's prediction. "The 1997 El Niño was truly in a class by itself," Gray said. "But I don't think it will be around to influence the 1998 hurricane season to any significant degree." The Colorado State team's historical data shows that nine out of the past 30 years have actually produced less hurricane activity than in 1997. Of the nine years that were less active, seven occurred during El Niño events. When Gray's team issues the first forecast for the 1998 season on Dec. 5, the statistical model will now include the extreme 1997 El Niño conditions. The team's hurricane forecasts--issued in early December, April, June and August--do not predict landfall and apply only to the Atlantic Basin, which encompasses the Atlantic Ocean, Caribbean Sea and Gulf of Mexico. In addition to Gray, the hurricane research team includes John Knaff, Paul Mielke and Kenneth Berry from Colorado State; and Chris Landsea, a Colorado State graduate and a researcher at NOAA's Hurricane Research Laboratory in Miami, Fla.
--------
103-> OHSU Scientists Shed Light On The Role Of Leptin In Body Weight Regulation
Leptin, a hormone produced by fat cells, has been the subject of extensive research since its discovery in 1994 when it was implicated in the regulation of body weight and appetite. Now scientists at Oregon Health Sciences University have discovered evidence indicating that certain obese mice develop a tolerance for leptin. Their findings appear in the Nov. 28, 1997 issue of Science and shed light on the role of leptin. "It has been known that high levels of leptin correlate with increased body fat in both humans and mice," explains Bruce Boston, M.D., lead author of the paper and assistant professor and scientist in the pediatrics department at OHSU. "Whereas low levels of leptin are associated with low body fat, extremely low levels of leptin are associated with starvation and compel an animal to eat voraciously when food becomes available." Boston further explains that fat cells produce the protein leptin which enters the blood stream and travels to the brain where it binds with receptors on nerve cells in the hypothalamus of the brain. "The leptin pathway creates a feedback loop for body weight regulation," says Boston. High levels of leptin signal that enough food has been consumed, whereas very low levels initiate the starvation response. Since low levels of leptin are thought to turn up an animal's appetite, it was hypothesized that increasing an animals leptin level would have the opposite effect and turn down the appetite. However, Jeffrey Friedman, Ph.D., of the Rockefeller University has recently demonstrated that several types of obese mice, including a strain called yellow agouti mice, do not lose weight when they are given increased levels of leptin. The obese agouti mice thus appeared resistant to the leptin hormone. Friedman's work suggested that animals may become obese because they are unable to respond to leptin. This paper by Boston and senior author Roger Cone, Ph.D., of OHSU's Vollum Institute, argues for a very different conclusion. Their data implies that obese animals have already responded to the high leptin level in their system and simply cannot respond to any additional leptin. This raises questions about the potential therapeutic value of leptin for the treatment of obesity. Boston further explains that decreasing the levels of leptin may have evolved to help the body respond to starvation, but high levels of leptin may not play an important role in preventing animals from becoming obese. Further Details from Science's Press Digest Leptin and obesity: Not long ago, researchers discovered that giving the hormone leptin to obese, leptin-deficient (lepob/lepob) mice caused dramatic weight loss. But leptin has little effect on normal mice or in other mouse models of obesity. Here, Boston et al. disprove one theory some scientists had posed to explain this leptin-resistance, which is a hall mark of obesity in so many species. Obesity in the so-called lethal yellow (Ay/a) mouse is caused by a defect which interrupts the flow of brain signals that would otherwise curb the animals' eating. Specifically, there is a disruption in the signal from a region of the brain called the arcuate nucleus proopiomelanocortin (POMC). Administration of leptin to these mice has no impact on their eating behavior, leading researchers to speculate that their signaling defect acts as a direct block to leptin action. If true, this hypothesis would link the POMC and leptin pathways, and shed light on the mechanism by which leptin is used or resisted in the body. But the authors disproved this theory. They showed that leptin-deficient (lepob/lepob) mice which also carry the Ay/a mutation are fully sensitive to injections of leptin÷they lose weight. Thus, leptin resistance in the Ay/a mouse is more likely caused by classic desensitization÷because the animals have a normal response to leptin, they are desensitized to higher leptin levels.
--------
104-> Monoclonal Antibodies -- The Gentle Cure For Cancer?
When the immune system responds to disease it produces many different antibodies against different viral or bacterial proteins (antigens). One of the most exciting discoveries for medical science was how to produce, in the lab, many antibodies responding to a single antigen. These so-called monoclonal antibodies have found many uses in modern medicine, including the diagnosis of cancer. At the British Society for Immunology Annual Congress in Brighton this week Dr Martin Glennie, from the Tenovus Research Laboratory, Southampton, UK, will explain how he thinks monoclonal antibodies (mAbs) could be used in the treatment of cancer too. There has been some interest in using antibodies with drugs or irradiation attached to target therapy at the site of a tumour. However, Dr Glennie and colleagues are using unmodified antibodies alone - these are often referred to as "naked mAbs". What interests the Southampton researchers is why some naked mAbs are highly effective in killing cancer cells whilst others are not. The traditional thinking on how mAbs exert their effect is that they alert the body to danger and recruit immune cells to the site of the tumour. However, Dr Glennie now has evidence which suggests that the successful mAbs are the ones which can trigger a change in the cancer cells themselves. These mAbs tell the cancer cells to stop growing or even to commit suicide (a process known as programmed cell death). Thus the mAbs are restoring the very control mechanism thought to have gone wrong in cancer. Dr Glennie and Professor George Stevenson (also at Southampton) have developed a mAb which recognises a molecule (CD20) found on the surface of B cells. They are using this in trials with patients with a type of cancer called transplant lymphoma. This cancer affects approximately 3% of patients who have had an organ transplant as a side-effect of the immunosuppressive drugs they need to take. So far the mAb has been given to nine patients and Dr Glennie describes the results as "very impressive". The antibodies destroy all the patient's B cells, both cancerous and healthy. However healthy B cells return when all the mAb has gone from the patient's body, approximately 6 months after treatment. Surprisingly the patients seem to manage very well without their normal B cells! Advances in antibody engineering and production means that the cost of making mAbs is falling rapidly, so that large-scale application is now economically viable. The prospects look good for a therapy that should be without the unpleasant side-effects of current cancer treatments.
--------
105-> SFU Researcher Fools Forest Pest Into 'Barking Up The Wrong Tree'
Who says you can't fool Mother Nature? It certainly isn't Dezene Huber, a PhD student in Simon Fraser University's department of biological sciences. He's part of a research team investigating the secret scent life of two of British Columbia's most destructive forest insect pests. His goal? To fool the insects into bypassing vulnerable trees. For the past two years, Huber has been studying how two species of bark beetle - the Douglas fir beetle and the mountain pine beetle - find the trees they need to survive in a mixed forest environment. The answer is in the air - in natural scents given off by the beetles, and, surprisingly, by the trees themselves. These two species of bark beetle are tiny, about half a centimetre long, and attack their preferred host trees - Douglas firs and lodgepole pines - by tunnelling under the bark and laying eggs. They eventually girdle and kill the trees, destroying billions of dollars worth of commercial timber in B.C. every year. It's long been known that bark beetles use chemical signals, or pheromones, to attract others of their kind to a suitable host tree. It's also known that they can detect the scent of host trees. But Huber's work reveals that the beetles are doing much more. They're smelling other trees in the forest, too. Every type of tree, says Huber, releases signature compounds, or 'volatiles,' into the air. And just as we can smell the fragrance of a nearby pine or fir, a bark beetle can sort through the scent bouquet of a mixed forest to find the tree that it wants. The beetles can't afford to make a mistake. Burrowing into the wrong tree not only wastes time, but the strong defences of non-host trees, such as toxic resin, can kill adult beetles and their young. "We think that, as a beetle flies through the forest, it smells a non-host tree before it even gets to it, and the message is to keep on going," says Huber, who has hacked down trees such as birch, aspen and maple to extract key volatiles. "We now know that there are perhaps 20 different compounds that the beetles can detect from non-host trees," he says. "There must be a reason for this, and we think it's because it improves their search efficiency." Ironically, the bark beetle's superb sense of smell may soon be used against it. Researchers plan to use the non-host scents to disguise trees that the beetles would normally attack. "In an area where we know bark beetles are present, we'd, say, make a Douglas fir smell like a cottonwood," says Huber. "Instead of attacking the tree, the beetles would fly on by." Huber is now analysing and testing various non-host compounds to see which, if any, are better beetle deterrents than others. He divides his time between an SFU lab, and the woods near Princeton and Lytton, where there are current bark beetle outbreaks. "We challenge them to find traps baited with various combinations of scents, so there are a lot of confused little beetles out there," he grins. The results are promising. This past summer, he found that single trees can be protected "quite well" using non-host volatiles, along with other compounds that the beetles avoid. Huber believes the method has huge potential as a control agent. "I don't think it'll be the only method used, because there are so many other aspects of bark beetle biology that we can tweak for our own purposes," he says. "But if we can get this developed, I think it's going to be a very important part of a pest manager's portfolio of weapons."
--------
106-> Columbia Scientist Warns That Global Warming Could Trigger Collapse Of Ocean Currents
Halt to Gulf Stream and Other Currents Could Freeze Europe; Dublin Would Share Spitsbergen's Icy Climate On the eve of the international meeting on global warming that opens Dec. 1 in Kyoto, Japan, one of the world's leading climate experts warned of an underestimated threat posed by the buildup of greenhouse gases ' an abrupt collapse of the ocean's prevailing circulation system that could send temperatures across Europe plummeting in a span of 10 years. If that system shut down today, winter temperatures in the North Atlantic region would fall by 20 or more degrees Fahrenheit within 10 years. Dublin would acquire the climate of Spitsbergen, 600 miles north of the Arctic Circle. "The consequences could be devastating," said Wallace S. Broecker, Newberry Professor of Earth and Environmental Sciences at Columbia University's Lamont-Doherty Earth Observatory, and author of the new research, which appears in the Nov. 28 issue of the magazine Science. A complex of globally interconnected ocean currents, collectively known as the Conveyor, governs our climate by transporting heat and moisture around the planet. But the Conveyor is delicately balanced and vulnerable, and it has shut down or changed direction many times in Earth's history, Professor Broecker reports. Each time the Conveyor has shifted gears, it has caused significant global temperature changes within decades, as well as large-scale wind shifts, dramatic fluctuations in atmospheric dust levels, glacial advances or retreats and other drastic changes over many regions of the Earth, he said. The Conveyor "is the Achilles heel of the climate system," Professor Broecker wrote in Science. "The record . . . indicates that this current has not run steadily, but jumped from one mode of operation to another. The changes in climate associated with these jumps have now been shown to be large, abrupt and global." The ongoing accumulation of heat-trapping industrial gases blanketing the Earth threatens to raise global temperatures, he said, but such a rise would occur gradually. Far more worrisome is the buildup's potential to stress the climate system past a crucial threshold that would disrupt the Conveyor and set off a rapid reconfiguration of Earth's climate, predicted by existing computer models. Professor Broecker also offered a new theory: Scientists generally agree that periodic changes in Earth's orbit and the amount of solar radiation it receives have paced fundamental climate changes on the planet over millions of years. But the global climatic flip-flops may have been set in motion by sudden switches in the operation of the Conveyor, he said. Today, the driving force of the Conveyor is the cold, salty water of the North Atlantic Ocean. Such water is more dense than warm, fresh water and hence sinks to the ocean bottom, pushing water through the world's oceans like a great plunger. The volume of this deep undersea current is 16 times greater than the flow of all the world's rivers combined, Professor Broecker said, and it runs southward all the way to the southern tip of Africa, where it joins a watery raceway that circles Antarctica. Here the Conveyor is recharged by cold, salty water created by the formation of sea ice, which leaves salt behind when it freezes. This renewed sinking shoves water back northward, where it gradually warms again and rises to the surface in the Pacific and Indian oceans. In the equatorial Indian Ocean, surface waters are too warm to sink. Northern Pacific waters are cold, but not salty enough to sink into the deep. This is primarily because prevailing winds that whip around the planet hit the great mountains of the western United States and Canada and drop their moisture. The resulting snow and rain runs into the Pacific, adding a dose of fresh water that dilutes the Pacific's saltiness, said Professor Broecker, a geochemist at Lamont-Doherty, Columbia's earth science research institute in Palisades, N.Y. Northern Atlantic surface waters have only about 7 percent more salt than their counterparts in the northern Pacific, but that is just enough to reach the threshold that allows them to sink. But if the North Atlantic waters warmed by only a few degrees, or if they were diluted by just a bit more fresh water from melting glaciers and sea ice or more rainfall, for example, the threshold would not be achieved, and the waters would not sink. Computer models that simulate the Earth's climate system show that the ocean's so-called thermohaline circulation (from the Latin for 'heat' and 'salt') is sensitive to such small changes, Professor Broecker said. The entire Conveyor might shut down or rearrange in a different pattern, with serious effects on global climate, he said. Today, the Conveyor comes full circle, eventually propelling warm surface waters, including the Gulf Stream, back into the North Atlantic. In winter months, this warm water transfers its heat to the frigid overlying air masses that come off ice-covered Canada, Greenland and Iceland. Thus tempered, the eastward-moving air masses make northern Europe noticeably warmer in winter than comparable latitudes in North America. Without the Gulf Stream, nothing would temper the Arctic air, and Europe would enter a deep freeze. In recent years, evidence has mounted that the Earth frequently has experienced rapid, large-scale climate changes. Greenland ice cores have shown that during the last ice age Earth's climate switched back and forth every few thousand years between periods of intense and moderate cold, with the transitions occurring on a timescale of a few decades to as little as a few years. Each interval of intense cold was matched by the launching of great armadas of icebergs in the North Atlantic, seen in ocean sediment cores, and a great influx of dust into Earth's atmosphere, indicating a pronounced change in wind and storm patterns. Wetlands in tropical areas and mountain glaciers in Chile and New Zealand expanded and shrank in synchrony with the North Atlantic changes. There is also strong evidence, from tropical latitude glaciers, that the water vapor content of Earth's atmosphere can shift, too. Water vapor is the most abundant greenhouse gas in Earth's atmosphere and a marked reduction would lower air and ocean temperatures significantly. "Although the exact linkages that promote such climate changes have yet to be discovered, a case can be made that their roots must lie in the ocean's large- scale thermohaline circulation," Professor Broecker said. The most telling clue is that the boundaries that mark climate changes in continuous sediment or ice core records are sharp, not gradual. That is true even in climate change records spanning millions of years, whose rhythms are governed by Earth's orbit. Professor Broecker suggests that sudden switches in thermohaline circulation may act as a trigger that sets off ice ages and other large-scale climate cycles. Professor Broecker noted that abrupt climate changes have occurred not only during ice ages but during warmer eras such as today's. The Eemian Period - the last major warm period before the last ice age began about 115,000 years ago - ended with a brief but intense cold period. A brief, intense cold spell also occurred about 8,000 years ago -- about 2,500 years after the last ice age ended -- when conditions were similar or warmer than they are now. "Through the record kept in Greenland ice, a disturbing characteristic of the Earth's climate system has been revealed, that is, its capability to undergo abrupt switches to very different states of operation. I say 'disturbing' because there is surely a possibility that the ongoing buildup of greenhouse gases might trigger yet another of those ocean reorganizations and thereby the associated large atmospheric changes," Professor Broecker said. "Were this to happen a century from now, at a time when we struggle to produce enough food to nourish the projected population of 12 to 18 billion, the consequences could be devastating." Professor Broecker is one of the world's leading authorities on global climate change. He has won nearly every major geological award, including the Vetlesen Prize, considered by many to be the equivalent of the Nobel Prize in earth sciences. Last year he was awarded the National Medal of Science and the Blue Planet Prize, for achievements in global environmental research. Lamont-Doherty Earth Observatory is part of the Columbia Earth Institute, a new enterprise at Columbia University dedicated to creating innovations for wise stewardship of our planet.
--------
107-> Recombinant Protein Immunizes Mice, Promises New Strategy Against Infection And Cancer
Solving a long-standing problem in vaccine development, scientists have crafted a new way to deliver foreign proteins into the body such that the immune system is primed to attack virus-infected cells and cancer cells. Because this kind of an immune response is key to vaccine development, the findings have profound implications for developing safe vaccines to immunize against AIDS and other infectious diseases, and for creating new cancer therapies. Results from the study, led by Dr. Richard Young, Member of the Whitehead Institute for Biomedical Research, will be published in the November 25 issue of the Proceedings of the National Academy of Sciences. In the study, scientists created a new, recombinant protein by fusing together a special type of protein called a 'heat shock protein,' isolated from the tuberculosis bacterium, and a protein called ovalbumin, long used by immunologists to study immune function. When scientists injected the recombinant protein into mice, the animals mounted an immune response against ovalbumin and developed immunity against cancer cells that make ovalbumin. These ovalbumin-producing cancer cells normally kill unimmunized mice. "These results have led us to use the same heat shock fusion technology to develop vaccine candidates against AIDS and other infectious diseases," says Dr. Young, who now leads a consortium of scientists from Harvard University and the Massachusetts Institute of Technology to develop a vaccine against AIDS. Dr. Young and his colleagues are creating a recombinant monkey vaccine consisting of the heat shock protein fused to a protein from the Simian Immunodeficiency Virus (SIV). Researchers plan to test the efficacy of this vaccine in macaques. When germs enter the body, the immune system responds in two ways. One arm of the immune system, led by immune cells called B cells, works mainly by secreting antibodies into the body's fluids. These antibodies seek and destroy the germs circulating in the bloodstream. However, antibodies are useless when it comes to penetrating cells. The task of attacking cells infected by viruses or deformed by cancer falls to the second arm of the immune system, led by immune cells called T cells. T cells orchestrate a multi-pronged attack, and if appropriate, turn into 'killer cells,' called cytotoxic T cells or CTLs, that home in on infected cells and destroy them. The goal of vaccine development is to produce a full-blown immune response without causing full-blown disease. However, when vaccines containing soluble proteins from the microorganisms are used to produce an immune response, the CTLs are rarely activated. For decades, vaccine development experts have sought to find a simple and practical way to activate the killer cells or CTLs using soluble proteins, but finding a method that works has been a challenge. "We were able to solve this problem by taking advantage of the observation that a class of proteins, called heat-shock proteins, are exceptions to the rule that soluble proteins are unable to stimulate CTL responses. In fact, heat-shock proteins are extremely potent in stimulating a CTL immune response," says Dr. Young. Heat shock proteins, or stress proteins, are a family of proteins that cells produce in response to stress from heat, injury, germs, or toxins. Normally, these proteins act as molecular chaperones, binding to other proteins and ferrying them to and from various compartments of the cell. A few years ago, immunologists noticed that heat shock proteins are present on the surface of bacteria and are responsible for flagging the T cells and triggering the CTLs to attack. Dr. Young and his colleagues found one particular protein from the tuberculosis bacterium, called hsp70, that could elicit powerful immune responses and could be used as an immune system booster. The special properties of hsp70 prompted the researchers to investigate whether soluble hsp70 proteins could be fused with bacterial or viral proteins of interest to elicit the desired type of immune response. "This study shows that the heat shock proteins can function as vehicles to deliver viral proteins to the right immune system pathway and elicit a CTL response. The fusion technology can also be used against cancer cells. Microbial stress proteins could be introduced into tumor cells to act as red flags that attract a CTL immune response," says Dr. Young. The work reported in the PNAS paper was supported by the National Institutes of Health.
--------
108-> Biological Clocks No Longer Found Only In The Brain
A recent discovery by a team of scientists, working in part through the National Science Foundation (NSF)'s Center for Biological Timing, challenges the strongly-held belief that 24-hour rhythms (biological clocks) are centrally controlled by the brain. Using the fruit fly as a model system to study circadian rhythms, the researchers -- led by cell biologist Steve Kay of the Scripps Research Institute in San Diego, California -- sought to determine whether individual body parts would respond to changes in the light/dark cycle. In each appendage, clock genes turned on and off in unison, according to rhythms set by environmental light manipulations. The scientists hope that understanding the location of the clock tissues and cells, as well as identifying which genes and proteins make up the biological cogs, will lead to new strategies for the treatment of disorders associated with jet lag, shift work and seasonal depression. "These results are fundamental to understanding how the timing of cellular functions is integrated in complex organisms," says Christopher Platt, program director in NSF's neuroscience program. "This advance shows how basic research with a model system has a broad impact on fields from agriculture to human biology." According to Kay, "Our findings confirm that body clocks run independently in many tissues outside the brain, and are reset by light, implying that cells harbor novel photoreceptors that aren't involved in vision." The researchers borrowed some tricks from the world of bioluminescent organisms, to measure the genes that control clocks in animals. They fused the fruit flies' clock DNA to "glow" genes either from jellyfish or fireflies, to make glow-in-the-dark fruit flies. Kay commented, "We found that all tissues we cultured from the whole animal were glowing on and off, demonstrating that lots of clocks are running throughout the fly, independently of the brain." Under normal light/dark conditions, the clock genes rhythmically luminesced in each of the segments -- head, thorax and abdomen. The clock genes were especially conspicuous in chemosensory cells at the base of hairs on the legs and wings and on the antennae and proboscis. These clocks also ebbed and flowed autonomously in response to light, suggesting that circadian rhythms likely regulate a fruit fly's sense of smell, much as they influence light and pain sensitivity in mammals. While the authors raise the possibility that this evidence challenges the current notions about the role of the brain as the seat that coordinates rhythms throughout the organism, they acknowledge that the brain still retains a certain distinction, even in a fruit fly. In the prolonged absence of light, the brain was the only organ in which the clock genes remained in sync. A mammalian variant of the clock gene recently was identified, and another similar gene also has been found throughout the body of mice. According to Kay, the discovery of many non-brain clocks in fruit flies could well be true for humans. "In this case it might mean that our skin, liver or other peripheral tissues have their own clocks to control these local functions," he suggests. Participating in the research were scientists Jeffrey Plautz of the Scripps Research Institute and Maki Kaneko and Jeffrey C. Hall of Brandeis University. The study was also funded in part by the National Institute of Mental Health of the National Institutes of Health.
--------
109-> 10,000-Year-Old Clues Suggest Future Forest Changes
Some idyllic, alpine meadows and giant, red cedars in coastal rain forests may only be fond memories in B.C.'s not-too-distant future, according to Simon Fraser University biology professor Dr. Rolf Mathewes. By studying the past in the form of pollen and other plant remains, Mathewes has gained valuable insights into what the future might hold. "We know that the climate was warmer in the past and how it affected forest cover, and we can use this information as an analog to predict the future," he explains. Mathewes studied pollen to reconstruct vegetation - as old as 10,000 years - found in lake bottoms and wetlands. He has found that from 9,000 to 7,000 years ago in B.C. there was a warming trend similar to what is currently being predicted for the next century. His findings, confirmed by a serendipitous discovery on Castle Peak in the South Chilcotins near Lillooet, have serious implications for the province and its economy. During the ancient warming period, forests on the south coast had more abundant Douglas fir, alder and bracken ferns than today. "All three species grow after a severe disturbance such as fire. We have found a large amount of charcoal in the lake bottoms dating to that period (7,000-9,000 years ago) indicating forest fires," Mathewes explains. He attributes the fires to a drier, warmer climate with prolonged droughts and possibly to an increase in the number of storms. A chance discovery on Castle Peak helped confirm what Mathewes discovered in his lab. A surveyor from the Geological Survey of Canada, encamped on Castle Peak, went to collect water for his tea in a nearby stream. When he looked in the stream he found a log, even though he was 100 metres above the treeline. Eventually Mathewes was called in and visited the site. "This serendipitous discovery helps confirm that the climate was warmer many years ago and helps confirm our theories of what happened in the past," he says. "The discovery was truly independent evidence that the climate was warmer than today. The treeline is determined largely by temperature and it was at least 100 metres higher at that time." Mathewes also found fossil seeds and cones that indicate a thriving forest of whitebark pine and sub-alpine fir, radiocarbon dated at 9,000-8,000 years ago. From this and other evidence, he can predict that, if our West Coast climate does warm, it will eliminate some current alpine and sub-alpine meadows as trees move up the mountains. "This has already been observed in some regions in the Pacific Northwest such as the Olympic Peninsula," he notes. He says that a prolonged warming trend will have other implications for the forest industry and landscape as more drought-resistant Douglas fir trees begin to replace western red cedar and hemlock. "We are likely to have more forest fires of increased severity. Cedar is especially susceptible to fire and drought. In fact there is evidence to show cedar is not regenerating well in some areas now," Mathewes says. He says the forest industry has already taken note of his findings in deciding what kind of seedlings to use in replanting clearcuts. He also predicted that as a result of a warmer, drier climate, many small lakes and wetlands will dry up, threatening the survival of some species of birds, fish and other wildlife in B.C. In the future, for those searching for flowering alpine meadows, it looks like their hikes will be higher and farther.
--------
110-> Crystal Growth Research On Space Shuttle Helps Industry And Paves Way For Future Experiments
 A series of space shuttle crystal growth experiments led by a team from Rensselaer Polytechnic Institute is helping increase productivity in the iron and steel industry. At the same time, Rensselaer's latest Isothermal Dendritic Growth Experiment, which is aboard the space shuttle Columbia flight this week, is serving as a testbed for the type of remote telescience that will be needed when scientists begin placing experiments on the International Space Station. And the presence of a high-tech NASA control room on the Rensselaer campus is giving students in about 25 elementary, middle-school, and high-school classrooms a firsthand view of shuttle science. Pure Science That Is Making a Difference The IDGE team, led by Rensselaer professors Martin E. Glicksman and Matthew B. Koss, is studying the formation of dendrites, needle-like crystals shaped something like Christmas trees, which are formed when metals solidify. Understanding how conditions such as temperature affect growth rate and shape would help engineers design better foundry and casting processes. But convective processes on Earth complicate dendrite formation, making it very difficult to isolate various parameters to understand how they affect the crystals. In the microgravity environment of a space shuttle, it is possible to study crystal formation without the complications caused by gravity. On the second and third United States Microgravity Payload (USMP) shuttle flights in 1994 and 1996, the IDGE team repeatedly solidified samples of succinonitrile under carefully controlled conditions. This material forms crystals much like many common metals such as sodium, calcium, and iron, known as "body-centered" because of the shape of their crystal lattice. At a Nov. 12 briefing, held to describe the science planned for the upcoming shuttle flight, NASA officials were asked how five years of microgravity research has changed our lives. They referred the question to Glicksman, saying the IDGE is a good example of the impact microgravity research can have. The data gathered on the first two flights was used to derive and verify scaling laws that tie process rate, temperature, and other parameters to the size and shape of the dendritic structure in materials such as iron and steel, Glicksman said. Information published after the first flight is already being used by engineers to build foundry and casting models, which translate directly into improved metals, he added. Doru Stefanescu, a professor at the University of Alabama who has worked with industry, said such models have created quantitative leaps in productivity in the metal cast industry. Before computer models, casts were designed by trial and error, often requiring a week or two to test each variation. With models derived with information such as that generated by the IDGE, the industry now can cast a product on computer screens, making changes until the desired results are achieved. This cuts design-to-pouring time from weeks to less than a day. Such productivity advances help industry keep jobs in the United States rather than moving them to areas where labor costs less, Stefanescu said. On the current USMP-4 flight, the IDGE team will work with pivalic acid, which forms crystals with a "face-centered" structure like aluminum, gold, or silver. In addition, the variation of surface energy with respect to crystal structure is much stronger for pivalic acid than for succinonitrile. The surface energy is a critical property affecting how dendritic crystals form. These pivalic acid tests are expected to help extend and verify the scaling laws and models, making it possible to build data bases for additional metals. Testbed for Telescience USMP-4 may carry the last microgravity shuttle experiments, with future research scheduled for the International Space Station. On the space shuttles, most experiments have been autonomous or have been controlled by astronauts. Improved equipment for sending images and data to Earth and commands to the experiments aboard the shuttle has made it possible to monitor and control experiments from the ground. To do this, scientists generally travel to the Marshall Space Flight Center in Huntsville, Ala., for the duration of the flight. On the Space Station, however, experiments will frequently operate for six months or longer. Science teams clearly will not be able to leave university or industry labs and work at a NASA center for that long. To solve that problem, NASA has been using the IDGE experiments to pioneer remote operation of telescience. In 1996, NASA established a control room on the Rensselaer campus and trained students to operate it. For the last few days of the experiment, the Rensselaer team took control of the experiment. As a result of the success of that test, the science aboard the current flight will be controlled from Rensselaer for the entire 16 days of the flight. Thirty-six Rensselaer undergraduate and graduate students have been trained by NASA to assist in the control room, giving them an experience that would be impossible if the experiment were controlled from the Marshall Space Flight Center. The Rensselaer experience has shown that when the Space Station is in operation, researchers will be able to participate in space experiments from their home campuses, Glicksman said. The dramatic improvements in NASA's ability to conduct telescience can be seen by looking at the three IDGE flights. The 1994 experiment was one of the earliest to include downlinked television and extensive teleoperation. During that mission, the IDGE gathered data with two 35 mm cameras. The data from these cameras could not be evaluated until the mission was over and the film was recovered and developed. But images also were sent to Earth during the mission by telescience, enabling the science team to make real-time adjustments in the experiment. This relatively unsophisticated system greatly reduced wasted photos and enabled the team to gather data from twice as many crystallization cycles, Glicksman said.  On the second IDGE flight, an improved system sent back images that provided velocity data almost as good as the data from the 35 mm films. On USMP-4, video equipment has been added, which will provide additional information on dendrite dynamics. Outreach to Local Schools The presence of a functioning NASA control room on the Troy, N.Y., campus has also inspired a substantial outreach program to local schools. "When I asked my students what were the words Neil Armstrong first spoke on the moon, one fellow answered "Yippee!" "But that kind of summarizes the enthusiasm these kids have for this microgravity project," says Bob Lawrence, a middle-school teacher in Guilderland, N.Y. His students are learning what it's like to become an astronaut and live and work in outer space. Lawrence was one of 25 teachers who spent two weeks at Rensselaer this summer learning the secrets from engineers, scientists, and NASA experts. These teachers are now using the wonders of microgravity to fire the imagination and improve the math and science skills of school children in five New York counties. The children are building rockets, simulating microgravity with a Rensselaer-designed "drop tower," and performing mock interviews for the NASA space program. The program will last most of the year, and they'll visit the campus during Rensselaer's participation in the 16-day shuttle flight. There, they will get a firsthand view of real microgravity science. In a special discovery room, the students will view shuttle telemetry and download experiment data. They'll see what's happening at NASA ground control, watch NASA feeds from space, and eavesdrop on Rensselaer's own operations center. In addition, they will be briefed by members of the IDGE team. "This partnership with one of the nations best universities is helping our schools meet New York's rigorous new standards for math, science, and technology education," says Ellen Sullivan, of the Greater Capital Region Teacher's Center. Sullivan helped develop the project in cooperation with the Rensselaer Center for Initiatives in Pre-College Education (CIPCE) and the IDGE team. NASA provided $30,000 in program support.
--------
111-> Research Finds Insulin Ineffective For Many Diabetics
ANN ARBOR---People with type 2 diabetes are routinely encouraged to strictly control their blood sugar at near-normal levels, but a new study indicates this is extremely difficult to do through conventional use of insulin. "Insulin therapy was found to be largely ineffective in achieving tight blood sugar control, even when combined with substantial increases in a patient's visits to the doctor's office and home blood sugar monitoring," said Rodney Hayward, M.D., leader of the study and an investigator at Veterans Affairs and the University of Michigan Health System. The study's findings are published in the Nov. 26 issue of the Journal of the American Medical Association. About nine out of 10 diabetics have type 2 diabetes, which means their pancreases produce some insulin, but not enough to meet their needs. In the U.S. alone, more than nine million people are diagnosed with type 2 diabetes---a leading cause of blindness, renal failure, and amputation in industrialized nations. Thirty to 40 percent of type 2 diabetics are on insulin in an effort to improve blood sugar control and thereby reduce their risk of the disease's devastating complications. Previous research has demonstrated that carefully selected patients under close supervision can achieve strict blood sugar control with insulin, but this is the first study to evaluate how effective, safe and costly insulin treatment is in a more typical setting---when patient care is less intensive and managed by primary care doctors. Here is a summary of the study's key findings and their ramifications: ---For type 2 diabetics with poor blood sugar control, starting insulin treatments significantly improved blood sugar control---but rarely approached the commonly recommended goal of near-normal control. "Much more aggressive treatment is needed for the 10 to 15 percent of patients who currently have poor glycemic control," Hayward said, "because, otherwise, they are at high risk of blindness, kidney failure and nerve damage." The study suggests insulin can help many of these patients reach a far safer moderate blood sugar level. ---For patients using pills to control their diabetes and maintaining moderate blood sugar control, administering insulin was only minimally effective, and did not move most patients into the near-normal range for blood sugar. That contradicts previous studies that indicated insulin can achieve tight blood sugar control---but those studies used volunteer subjects who likely were highly motivated to follow their medical regimen and received closer medical supervision and support than occurs in a typical clinical setting. These new findings suggest it would be difficult, troublesome and costly for most type 2 diabetics to achieve the tight control of blood sugar typically recommended. ---Most type 2 diabetics develop the disease later in life and maintain moderate control of their blood sugar, two factors which put them at relatively low risk of developing severe complications such as blindness and renal failure later in life. That risk often is less than one chance in 100. Given the difficulty diabetics will have achieving the recommended tight control of blood sugar and the fact that most are at relatively low risk of developing serious complications, Hayward suggests the medical profession needs to reconsider whether the standard of tight glycemic control for virtually all diabetics is appropriate or necessary. "Achieving optimal blood sugar control with insulin requires either highly motivated patients, such as those likely to participate in experimental trials, or greater education and monitoring than can be accomplished in a patient's typical two to four annual visits to the doctor's office," Hayward said. ---In a study published earlier this month in the Annals of Internal Medicine, Hayward and colleagues at U-M demonstrated that people who develop type 2 diabetes at a relatively early age---before age 50, for example---are at far greater risk of ultimately losing their vision and kidney function than those whom the disease strikes later. For those high-risk patients, the new research suggests insulin therapy will not be adequate to achieve the near-normal blood sugar levels needed to help lower their risk. "For this group, tight blood sugar control is a reasonable goal," Hayward said, "but more effective treatment approaches are likely to be needed." One such treatment that is showing promise, he said, is a combination of insulin given at bedtime and oral medicine administered during the day. "High-risk patients, those who require tight blood sugar control to reduce future health complications, will need closer monitoring and more medical attention than most diabetics typically receive." For this project, the investigators analyzed insulin use over a three- to four-year period among 1,738 patients treated by generalist physicians participating in a large health maintenance organization. "Although it is disappointing that blood sugars did not return to near-normal levels on insulin, the results fit well with reports of many doctors with whom we have spoken over the last few years," said Sheldon Greenfield, a co-author of the study and director of the Primary Care Outcomes Research Institute at New England Medical Center and director of the Diabetes Patient Outcomes Research Team National Study, from which this analysis was drawn. "Physicians often feel guilty, frustrated or even inadequate after major efforts that include switching to insulin from an oral medication. They are also worried that national quality of care standards soon to be proposed will call for normalization of sugar in all patients." The study was funded by the Agency for Health Care Policy and Research.
--------
112-> World Fisheries At Maximum Capacity, Scientists Warn
New Management Schemes Needed To Conserve Remaining Stocks After four decades in which landings increased by over 300 percent, most of the world's fisheries are now considered fully or heavily exploited, with many needing new management schemes to prevent collapse, warns a team of top fisheries scientists. In a compendium of more than 25 peer-reviewed papers published this month by the American Fisheries Society, biologists and managers paint a picture of increasing demand of fish products and participation in fishing -- particularly in the developing world where more than 60 percent of the world's fish are now caught. Meanwhile, current fisheries operate at huge deficits and waste nearly a third of their catch. Called Global Trends: Fisheries Management, the compendium documents how the overcapacity seen in fisheries today stems from a history of open access bolstered by active development and subsidization. This has lead to an increase in wasteful and destructive fishing practices, ranging from the Alaska groundfish fishery in which large industrial vessels compete in a massive "race for fish," to small-scale, tropical, artisanal fisheries where the use of poisons and dynamite is spreading. Other trends noted include the growing use of individual transferable quotas (ITQs) which give property rights to fishers providing the incentive to sustain rather than over-exploit fisheries. ITQs, however, are not without controversy and are currently under a five-year moratorium in the U.S. The compendium also discusses the rise in aquaculture, which now accounts for 30 percent of the value of fishery production, and also looks at the influence of climate shifts on fish stocks. "These changes are all associated with an evolution from the era when oceans and fisheries resources were considered so vast that they could not be damaged by mankind, to a future of sustainable use, we hope. The challenge is to successfully manage the transition to more rational fisheries. The status quo is not an option.," said Dr. Ellen Pikitch, director of fisheries programs at the Wildlife Conservation Society, headquartered at the Bronx Zoo, and lead editor of the compendium.
--------
113-> Vietnam Combat Linked To Many Diseases 20 Years Later
Veterans of heavy combat in Vietnam who were diagnosed with post-traumatic stress disorder (PTSD) are significantly more likely to have a host of both chronic and infectious diseases as long as 20 years later, a medical researcher has found. After studying the medical histories of 1,399 Vietnam veterans, Joseph A. Boscarino, PhD, MPH, vice president for outcomes research with the Sisters of Charity of Nazareth Health System (SCNHS), found that, compared to non-PTSD veterans who saw little combat, those with PTSD who saw heavy combat were 50- 150 percent more likely to have circulatory, digestive, musculoskeletal, respiratory, infectious, and other serious disease 20 years after military service. The national study, one of the first to confirm a direct link between exposure to traumatic stress and the occurrence of a broad spectrum of diseases many years later, is published in the current issue of Psychosomatic Medicine. "This research suggests the need to better understand the results of exposure to severe stress in the human disease process," said Boscarino, who noted that the findings may have particular relevance for veterans now suffering from "Gulf War Syndrome." Boscarino urged more research attention on the long-term health status of those in other dangerous occupations, such as firefighters and police officers. The Vietnam veterans were located by the Centers for Disease Control and Prevention in a random follow-up study of men selected from all U.S. Army veterans of the Vietnam War. The researchers controlled for both pre-service and post-service risk factors for disease, including socioeconomic status, alcohol abuse, cigarette smoking, and other factors. According to Boscarino, of the 1,399 Vietnam veterans studied, 24 percent (332) were diagnosed with PTSD sometime after military service, and nearly all cases of PTSD in the study resulted from exposure to heavy or very heavy combat in Vietnam. He said his research and others' suggest that those with PTSD often have altered neuroendocrine and sympathetic nervous systems. Disturbances in these key body systems are the main reason for increases in a broad spectrum of diseases among combat veterans, he said. His research also uncovered abnormal immune functioning and clear medical evidence of coronary artery disease among the veterans studied. The study was funded by the National Institute of Mental Health and the Sisters of Charity of Nazareth Health System (SCNHS), a health network with facilities and programs in Kentucky, Tennessee and Arkansas. On September 1, SCNHS joined Catholic Health Initiatives, a national health care organization based in Denver, Colorado, as its new Southeast Region.
--------
114-> Duke Engineers Seeking To Make 'Smarter' Land Mine Detectors
DURHAM, N.C. -- New techniques for analyzing signals from the kinds of land mine detectors now in use could for the first time enable mine removal teams to discriminate real mines from other buried clutter, according to Duke University electrical engineers developing the techniques. The mathematical methods for analyzing signals from electromagnetic land mine detectors could be programmed into microchips to create "smarter" systems, the researchers said. These innovative signal-processing techniques could be programmed into microchips to tap signal information disregarded by designers of currently used detectors. "The current detectors are the only ones soldiers now have, so if we can improve them we can really make an impact," said Lawrence Carin, a Duke associate professor of electrical and computer engineering, who is leading a $6 million U.S. Army funded multi-university research initiative (MURI) to spearhead new approaches to electronic land mine detection. More effective detection technology would reduce the high cost of finding and neutralizing real land mines among a much larger array of buried false "targets." That per mine neutralization cost is currently estimated to be as high as $400 for devices Iraqis implanted in Kuwait during the Persian Gulf War. "It would take about 1,100 years, at current clearance rates, to remove all the land mines in the world," said research colleague Leslie Collins, an assistant professor of electrical and computer engineering at Duke. "That's assuming no more are laid," she added. "But they are laying more mines than you can remove in a year." Several Duke land mine detection investigators described their ongoing work in this area at a Department of Defense "clutter conference" held Oct. 29-30 at the Institute for Defense Analyses Science and Technology Division in Alexandria, Va. Other presentations are scheduled next year at meetings in Orlando, Fla., Greece, France and Israel. The project also involves researchers at California Institute of Technology, Georgia Institute of Technology, Ohio State University and Stanford University as well as Oak Ridge National Laboratory and three industrial partners, EG&G of Albuquerque, N.M.; Hughes Aircraft Co. of Malibu, Calif.; and Northrop Grumman Corp. of Baltimore, Md. In an interview, Carin said the "electromagnetic induction" (EMI) devices now widely employed to locate mines are essentially the same as the metal detectors used to find lost coins in beach sand or buried artifacts on Civil War battlefields. EMI technology "has been around since the 19th century," he added. In fact, doctors unsuccessfully tried to use an early version to pinpoint the assassin's bullet that felled President James Garfield. That attempt failed only because of interference by metal springs in Garfield's bed, Carin wrote in one of several related research papers recently submitted to Institute of Electrical and Electronic Engineers (IEEE) publications. In EMI, electrified metal coils in the detector's tip create a magnetic field that can penetrate the ground to reach a buried object. Objects that respond to magnetic fields -- especially metals -- then perturb the induced field. That field disruption, which varies according to the nature of the target object, is then sensed by the detector as a returning signal. Operators can adjust an EMI detector's sensitivity so it sends them a tone through a headset. When properly adjusted, the detector produces an audible tone only when the return signal reaches an optimal strength that indicates the presence of an object of interest. Researchers around the world -- including those at Duke -- are now investigating futuristic new land mine detection approaches, but EMI-based devices "are now the only working sensors in the field today," Carin said. The major problem with current EMI detectors is that they cannot discriminate metal mines from other metal objects that may emit signals of similar intensity. So, the devices may wrongly identify an array of other debris as possible mines. Such sham signals mean that mine deactivation and removal teams must endure many false alarms as they go through the harrowing and dangerous ordeal of probing and digging the ground around a potential target. "Nobody has really ever cared about discrimination before," Carin added. "It's only relatively recently that people even knew why EMI worked." So Carin decided to go back to the basics in his research. Exploring the "underlying physical principles" behind electromagnetic induction, he investigated in detail how a target's shape, size and composition affect the resulting signal. He realized, for example, that buried objects with a certain "rotational symmetry" are more likely to be land mines. More significantly, Carin discovered that the magnetic energy from objects being stimulated by the sensor contains a rich array of previously untapped information. In one set of studies, the engineers analyzed how the signal decayed with time, like the decay of the sound of a pinged bell. "In this case, we ping the object with a short pulse of electromagnetic induction," he said. "Then we 'listen,' in an electromagnetic sense, to how the energy decays as a function of time." Carin is also exploring how other useful information can be extracted by pinging mines with different frequencies. He uses a "wideband" EMI land mine detector under development by Geophex Ltd, a Raleigh, N.C., firm. This wideband technique transmits the initial pulse in several different frequencies instead of just one. Collins is working closely with Carin to develop mathematical rules, called algorithms, that can analyze the complex incoming data from both "time and frequency domains" with the help of "Bayesian" statistical methods. The Bayesian approach, which can be incorporated into a data processor, inputs the available information from detectors and then calculates the probability that a buried object is, say, a land mine as opposed to a collection of nails. Carin and Collins have tested their algorithms using EMI sensor data recorded at an Army land mine sensor testing site, where mines and other objects are buried at precisely known locations. "We've been able to show, whichever route you go, you can do a better job of rejecting things like nails and identifying buried mines," Collins said. In fact, they've found their approach produces "a "five-fold decrease in the false alarm rate," she added. "Normally, for every mine you average finding 100 pieces of clutter. So, effectively, what this decrease means is instead of finding 100 pieces of clutter you'd only find 20 or 25." Their results are "really starting to make some ripples within the U.S. Army, because it's so much better than what is currently being done in the field," Carin said. Collins said an advanced detector incorporating their algorithms on a digital processing chip would no longer beep every time a detector senses the presence of buried metal; only when the sensed object is a likely land mine. Carin is also investigating the use of EMI detectors to sense the presence of plastic mines, which are unresponsive to magnetic fields. In such experiments, researchers would throughly soak the ground with water to boost the conductive properties of the underlying soil. Then the Duke engineers could use their analytical techniques to look for simulated plastic mines in "conduction voids," where an EMI signal is absent. "A plastic mine is a very poor conductor," Carin said. Meanwhile, Erol Gelenbe, a professor who chairs Duke's electrical and computer engineering department, has invented another algorithm to help EMI sensor operators weed out false from real targets. Called the "delta technique," Gelenbe's mathematical method searches for characteristic cone-shaped patterns in graphical representations of the reflected energy of EMI signals. His analyses show these cones tend to be present near mines. The technique can mean 150 percent fewer false alarms, he said. It could be programmed into a portable computer for use in the field, he added. "It's a way of cleaning out clutter and identifying those points which are significant candidates for being the locations of mines," Gelenbe said. "But this technique, like any other, does not guarantee that what remain are actually mines; it simply reduces drastically the cost of de-mining or of finding unexploded ordinance." Other MURI studies are exploring the use of synthetic aperture radar, ground penetrating radar and ground vibrations, and infrared sensing. Another would use a combination of ultrasound, microelectromechanical (MEMS) analyzers, and an odor-sensing microchip to detect explosives within buried mines.
--------
115-> UIC Program Allows Patients To Test Blood At Home, Send Results To Hospital Electronically
The National Council on the Aging and the Ameritech Foundation have awarded a $25,000 grant to the University of Illinois at Chicago Medical Center to support a program that allows older patients to test their own blood at home and transmit results to the hospital electronically. "During the cold Chicago winters and the hot Chicago summers, it is very difficult for many of our older patients to come to the lab every three to four days to have their blood drawn," says Mary Bondmass, coordinator of the program and a doctoral candidate at UIC's College of Nursing. In response to this problem, Bondmass has adapted a system that will allow patients to monitor their blood at home and transmit the information via a modem to the hospital. Bondmass will train patients to take a blood sample and use a machine called a coagulation monitor to analyze the blood.  With the press of a button, the patient will then transmit the blood analysis information over a telephone line directly to the UIC Medical Center. The results will be monitored by a doctor at the hospital.  If there is a problem, the patient's physician will be alerted and the physician will contact the patient about treatment.  The response time for such a situation is under five minutes. The blood-information transmission program at UIC will target patients with atrial fibrillation who are susceptible to blood clotting, which can lead to strokes.  Atrial fibrillation is an abnormal heart rhythm that occurs when the heart's upper chambers (atria) contract extremely rapidly. Atrial fibrillation affects about two million people in the United States and occurs in 7 to 14 percent of the older adult population. The grant to UIC is part of the Innovations in Communications Technology program -- sponsored by the National Council on the Aging and the Ameritech Foundation -- which fosters innovative uses of technology that help older people and people with disabilities. "Ameritech is awarding these grants to recognize how organizations are beginning to use advanced communications to enhance the quality of lives of people of all ages and capabilities," says Douglas L. Whitley, president of Ameritech Illinois. "Many people have the false assumption that older Americans cannot or do not want to benefit from new communications technology. "The fact of the matter is that such technology helps foster independent living among older Americans and people with disabilities. Many of these individuals are now learning how computers can help better manage their fiances and give them access to a greater variety of health services and medical information. It also allows them to stay active and independent in today's society and enables them to stay in touch with family and friends." The National Council on the Aging is a center of leadership and expertise on the issues of aging. The council's 7,000 members include individuals and organizations that serve or work on behalf of older persons. Founded in 1950, the council is headquartered in Washington, DC. Ameritech services millions of customers in 50 states and 40 countries by providing a full range of communications services, including local and long distance telephone, cellular, paging, security monitoring, cable TV, electronic commerce, on-line services and more. Ameritech has a strong tradition of giving back to the communities it serves. Last year, the company contributed more than $25 million to 2,000 nonprofit organizations, and Ameritech Pioneers -- 25,000 employees and retirees throughout the Midwest -- volunteered 332,500 hours of community service by supporting health and human services, civic and community projects, and educational and arts programs.
--------
116-> New Microtransmission Developed at Sandia National Laboratories Vastly Increases Power Of Microengine
 ALBUQUERQUE, N.M. -- First, there were micromachines -- actually, microengines -- each about the size of a grain of sand. Now there are microtransmissions. Fabricated for the first time by researchers at Sandia National Laboratories, these remarkably augment the power of the tiny engines. A visitor interested in scale looked through a microscope to see a spindly, one-millimeter-thick Allen wrench passed over a microtransmission. The sight resembled the huge alien space ship darkening and then covering New York in the movie "Independence Day." Despite its tiny size -- like a microengine, about that of a grain of sand -- a microtransmission can increase the power of its microengine by a factor of 3 million, theoretically generating enough force to move a one-pound object, say researchers Steve Rodgers and Jeff Sniegowski. "We believe this is by far the most force ever generated by a polysilicon micromechanical device," says Rodgers. "We're showing that you can move significant loads and get the function you want." Microtransmissions operate on the same principle that allows a multigear bicycle to be pedaled up a steep hill more easily than a single-speed bike: No more input force is used, but the force is applied over a shorter portion of the wheel's turn. The new distribution of energy slows the bike but magnifies the force because it is concentrated over a shorter distance. The robust micromachines may be effective in satellites, where minimizing payload weight is important. Other possibilities include sensors that can communicate with each other aboard an aircraft, and in optical telescopes and optical switching for telephone lines. Microsurgical applications, which require relatively large forces on very small areas, are another possible area of application. While Sandia, a laboratory of the U.S. Department of Energy (DOE), is interested in the tiny machines as near-invisible locks for nuclear weapons, companies and universities who wish to utilize the modular technology for fabrication purposes will be able to download basic units of the transmission "as easy as clip art," says Rodgers. Having downloaded the blueprint for the gears, a company can design as few or as many intermeshing transmission systems as needed merely by duplicating and moving the basic gear arrangement. This can be done cheaply and easily on commonly available computer automated design programs. "In general, people needing this technology would use much lower gear ratios than 3 million:1, since the power and precision that this demonstration assembly offers would be required only in very special cases," says Rodgers. "But since the assembly is modular, they can easily do as little or as much as they'd like." Sandia in the recent past has licensed micromachine technology to private industry to build cheaper, more effective air bag sensors in cars, as well as to create newer anti-skid technologies than those currently being developed in the auto industry. Why the microtranny? Micromachines need power in larger amounts than first thought necessary because of the adhesion and static friction -- together termed Ôstiction' -- that a stationary gear must overcome in order to begin movement. One reason for stiction is that after a gear is etched out of silicon, the surface of the silicon oxidizes Ñ in a sense, rusts Ñ into glass, which binds microaxles or microgears to stationary surfaces surrounding them. "Even minute amounts of water vapor and outgassing from epoxies can be significant in blocking the startup action of a microgear," says Sniegowski. "Power is needed to overcome that resistance." The new device also should benefit basic engineering research, says Sniegowski. "Micromachine science does not yet understand how to deal with the effect of friction on machines that are so small," he says. "To study how these effects and others operate, you've got to be able to apply a significant level of force. Now we can apply these forces in fundamental tests to determine qualities such as a micromaterial's fracture strength." Another peculiarity of the microrealm is the difficulty of developing a clutch to change gears. In automobile transmissions, gears keep turning through inertia when a clutch disengages, and so synchronization with a replacement gear is possible. But to have inertia, an object must have mass, and for practical purposes, microgears -- each approximately the diameter of a human hair -- have no mass. For this reason, they can be accelerated very quickly, reaching velocities of several hundred thousand revolutions per minute in a few tenths of a second, but as soon as power is removed, stop dead. "Automobiles," says Paul McWhorter, one of the leaders of the Sandia micromachine effort, "have a much lower range of operating speeds." Other problems involve building an interface with the macrorealm when the amount of power transmitted may vary over several orders of magnitude. A positive possibility is that the microtransmission may one day provide accurate displacements on the atomic scale. One revolution of the demonstration drive gear generates a calculated displacement of the output gear of only 0.8 angstroms Ñ the same unit of measurement normally used to determine spaces between atoms. One can see, in Sandia videos, the odd sight of a drive gear spinning at tens of thousands of revolutions per minute, with succeeding gears each turning more slowly and presumably more powerfully until, at the end, almost no motion is observed. Layout and fabrication The 3 million:1 Sandia microtransmission comprises six identical transmission systems, each with two dual-level gears. The two gears, crafted one atop the other, operate at ratios of 3:1 and 4:1, which together form a 12:1 gear reduction ratio. A coupling gear allows more gear sets to be added modularly. In less than one square millimeter of area, through use of 29 intermeshing gears, the transmission achieves a 3 million:1 gear reduction ratio . The gearing is reversible, and so can increase speed as well as decrease it. The gearing is driven by a five-level micromachine, believed (like the transmission) to be the most advanced motor of its kind in the world. Like its earlier siblings, it is powered by comb drives, but these new drives are thicker and stronger. According to Roger Howe, director of the University of California at Berkeley's Sensor and Actuator Center, "Sandia's five-level polysilicon technology enables lots of new devices, including the transmission. The most powerful thing is that they can do five levels." The Berkeley lab is one of the original founts of micromachining. Micromachine "levels" refer to the tiny elevations that separate a gear or row of comb "teeth" in order that they may move freely. This is achieved by etching away so-called "sacrificial" oxide layers. The creation of additional levels permits thicker and therefore stronger comb drives. It also allows more gears to overlap each other, compressing the amount of horizontal space needed. While other laboratories have built three-level machines, there is no known competitor to the Sandia five-level machines, which require sophisticated design and processing knowledge. Each drive consists of two tiny comb-like structures, with teeth of one lying between the teeth of the other. By alternating tiny electric signals to the combs, they attract each other to one side and then the other. The motion is transmitted to a tiny piston-like linkage moved by one of the combs. A second comb drive provides power at right angles to the first. The piston it drives, when timed with the force of the first piston, is sufficient to turn a drive wheel on the microengine. The fabrication method has been used to create previous generations of four-level Sandia micromachines that spin at hundreds of thousands of revolutions per minute.
--------
117-> Genetic Variation For Enzyme In Lung May Point To Cancer Susceptibility Gene, Mechanisms That May Cause Cancer
A preliminary study by scientists at the National Institute of Environmental Health Sciences indicates that a human gene variation that reduces production of an enzyme in the lungs also makes people less susceptible to lung cancer. The scientists said about 8 percent of the population -- 9.4 percent of African Americans and 7.8 percent of Caucasians--have the "protective" gene form, or polymorphism, which reduces by about 54 percent the risk of a smoker getting lung cancer. Called the myeloperoxidase gene, the protective form of it is designated A/A. Most people have the A/G or G/G forms of the gene which confer no protection against lung cancer. Only about 5%, or 16 out of 339, of people in the study with lung cancer had the protective gene, but about 8%, 59 out of 703, of controls had it. NIEHS' Stephanie J. London, M.D., Dr.P.H., and Jack A. Taylor, M.D., and BioServe Biotechnologies' Terri A. Lehman, reported Nov. 19 in Cancer Research that they collected blood samples from lung cancer patients and randomly collected non-patient controls from Los Angeles County, Calif., which were then compared for the presence of genotype A/A. The significance of the presence or absence of genotype A/A, and its consequences for a person's chances of developing lung cancer, is related to the enzyme which is produced by everyone but reduced in people with genotype A/A. "The enzyme, myeloperoxidase, activates the potent carcinogen benzo(a)pyrene, which is a product of tobacco smoke, the burning of most fuels and most other kinds of combustion," Dr. London said. She said the enzyme may also lead to lung cancer by generating free radicals which are molecules that disrupt the copying of genes and cause genetic errors that can lead to cancer. "This is a preliminary study; it requires confirmation in other data. If confirmed these potential mechanisms will have to be studied more fully," Dr. London said. "Myeloperoxidase is of interest -- there is a lot of it in the lungs of smokers and it is good at activating tobacco carcinogens into their more dangerous forms."
--------
118-> Researchers Propose New Fusion Reactor That Would Be Highly Efficient, Environmentally Safe
Irvine, Calif. -- As scientists debate building the world's first fusion reactor, the International Thermonuclear Experimental Reactor (ITER), as a key future source of energy, researchers at UC Irvine and the University of Florida contend the long-planned, $10 billion project is an important research facility, but will not lead to a viable reactor. They instead have proposed an alternative fusion reactor that would produce electricity from cheap available fuel and produce no more radioactivity than a coal-fired plant. Writing in the Nov. 21 issue of Science, UCI physics professor Norman Rostoker, UCI research physicist Michl Binderbauer, and University of Florida physics professor Hendrik Monkhorst, say the fusion-powered ITER is beset by daunting design and engineering obstacles. These include its mammoth size, maintenance challenges and the need to protect itself and the surroundings from the high-energy neutrons it would produce. For three decades, the world's scientific community has looked to the Tokamak, an experimental fusion reactor that would be fueled by a mix of deuterium and tritium, as a possible solution to long-term global energy needs. ITER would produce energy using the Tokamak design. In the research and design stages since the late 1960s, ITER represents an unprecedented collaboration among fusion scientists from the United States, Europe, Japan and Russia forged to develop the next generation of nuclear energy. Plans call for the design phase to end in 1998 and for construction to begin at an undetermined time and location. "The research that led to plans for ITER has yielded a lot of important information, and most of our work is based on that research," Rostoker said. "But we don't think it has any hope of creating a reactor that anyone will want." Rostoker, Monkhorst and Binderbauer instead propose a colliding beam fusion reactor that would be fueled by protons and boron, rather than the deuterium-tritium mix that would power ITER. The reactor they have designed, on paper, would produce a very small fraction of the radioactivity of ITER, in turn allowing the facility to be much smaller, easier to maintain and environmentally safe, Rostoker said. "These reactors could replace all gas, coal and oil-fired power stations in the world," Monkhorst said. "They would be very safe and environmentally benign." The team plans to develop a commercial reactor over the next 10 years with money from private investors. The product of five years of investigation, their work differs from other fusion research through the years because it is devoted mainly to reactor design questions, instead of focusing on fusion experiments and theory that eventually might lead to reactors, Rostoker explained. Rostoker, Monkhorst and Binderbauer belong to a growing international chorus of scientists voicing doubts about ITER, the first experimental reactor that would attempt to harness fusion, the same power that fuels the sun and other stars. But the project has become so mired in controversy -- from its anticipated engineering problems to political division over its monumental costs -- that its chances of ever being built are in serious doubt, Rostoker said. One of ITER's main shortcomings, the researchers write, is its fuel source: deuterium and tritium, which produce high energy neutrons. "Since most of the energy produced is in the neutrons, protecting the device from itself presents a difficult engineering problem," said Rostoker, who has studied fusion science since 1958. ITER's neutrons would require elaborate shielding, which in turn would require the plant itself to be huge -- roughly five times the size of today's nuclear fission power plants, according to Rostoker. ITER's radioactivity, combined with its size, would mandate a remote construction site, in turn making it necessary to transmit power over long distances, inevitably leading to power loss. Also, ITER's proposed reactor design, the Tokamak, poses significant challenges to accessing and maintaining its coils, vacuum system and other internal components because they would be radioactive. Rostoker, Monkhorst and Binderbauer propose a reactor design known as a field-reversed configuration, which would enable reactor components to be mounted on rails, providing much easier, and less expensive, maintenance than ITER. It could be placed in cities to avoid significant transmission losses. Monkhorst said their reactor would work like this: Beams of boron and hydrogen would be sent into a reactor where magnets would cause the beams to bend, causing the nuclei to collide and fuse. The fusion would create energetic-charged particles that could then be converted directly into electrical power. The conversion process of the proposed reactor would be twice as efficient as heat conversion, in which coal is burned to heat water and produce steam, which runs turbines that produce electricity. Rostoker and his colleagues said their reactor would convert nearly 90 percent of the particle energy it generates into electricity, compared with, at most, 40 percent for a traditional coal-burning power plant or a deuterium-tritium Tokamak. What's more, the reactor would cost half as much to run annually as coal- burning fossil plants, the researchers said, mainly because the fuel is accessible and inexpensive, and because safety measures are minimal due to the greatly reduced radioactivity the reactor would produce. Monkhorst said it would require about 200 grams of boron to run a 100-megawatt reactor per day at a cost of only a few dollars. The reactor would not produce so-called greenhouse gases that contribute to global warming, the researchers said. Energy in the form of electricity and helium gas would be the reactor's only products. If complications arose during operation, the reactor would quickly shut itself down, they said. Developing safe and cost-efficient new sources of energy is imperative, the researchers said, because existing nuclear fission power plants built in the 1950s and '60s must be closed down within the next decade as their operation licenses expire. A license typically is valid from 40 to 50 years; the plants must be closed due to radiation damage, and many components must be buried due to high levels of radioactivity. But Rostoker, Monkhorst and Binderbaeur said these problems would be absent in their colliding-beam fusion reactor with proton-boron-11 fuel.
--------
119-> How Little Gray Cells Process Sound: They're Really A Series Of Computers
Hearing is a far more complicated process than once imagined. But neuro- scientists are beginning to unravel the ways individual brain cells continually perform complex computational tasks to help creatures as diverse as humans, gerbils, bats and birds distinguish what a sound is and where it is coming from. Individual neurons, or brain cells, do not just relay information from one point to another, according to a group of researchers from across the United States who discussed new insights into the process of hearing at a symposium held last month at the Society for Neuroscience's annual meeting in New Orleans. Instead, they said, each neuron could be compared to a tiny computer that compiles information from many sources and makes a decision based on that information "In hearing, the brain does not function as one big computer, but rather as a series of small computers working in series and in parallel. Now, for the first time, we are getting a good idea of how individual neurons work as computers," said Ellen Covey, an assistant professor of psychology at the University of Washington and organizer of the symposium. Other members of the panel were Dan Sanes, associate professor of neural science and biology at New York University; George Pollak, professor of zoology at the University of Texas, and William Spain, associate professor of neurology at the University of Washington. In New Orleans, the researchers reported on new techniques that for the first time permit them to record and monitor low-level electrical activity in single neurons of awake animals. They also discussed a number of findings showing how neurons analyze and integrate information from different sources Understanding the mechanisms of sound recognition in the brain and in single neurons is basic neuroscience that Covey said may permit researchers to design better processors used in hearing aids for the hearing impaired and the totally deaf. The research also has implications for improving sonar devices and creating speech recognition systems for computers. Here are highlights of what each panelist discussed: While the bat's awake: Covey works with the widely distributed North American big brown bat (Eptesicus fuscus) and reported on the first successful use of a technique utilizing tiny glass electrodes one micron in diameter to record very low-level, sound-evoked electrical activity in single neurons in awake bats. The auditory system in mammals and birds initially is divided into parallel pathways so different types of information can be extracted from a complex signal, Covey explained. To fully analyze a signal or set of simultaneous signals, the results of the calculations in the different pathways must be integrated. An important center for this activity is a portion of the midbrain called the inferior colliculus, where many auditory pathways converge. The outputs from some pathways excite the cells on which they terminate, making the cells more likely to respond to a signal. Other signals inhibit cells, making them less likely to respond to a signal. Covey said it is computations that result from the interaction between the excitatory and inhibitory inputs that ultimately tells an animal not only where a sound is coming from but also what the sound is. Big brown bats echolocate by emitting calls and listening to the echoes reflected from objects in their environment. Echolocation calls, while higher in frequency, possess many of the characteristics of human speech. The bats' auditory pathways are similar to those of humans. Because of these similarities, it is possible that some of the same mechanisms used by bats to process echolocation sounds also are used by humans to process speech signals, she added. Tracking moving sound: Sanes research lab developed a method for understanding how neurons respond to a sound moving into an animal's field of hearing by measuring the excitatory and inhibitory responses of individual brain cells of gerbils (Meriones unguiculatus). Sanes unexpectedly found that when sound is moved neurons can become unusually sensitive to the new location of a sound through a process called release from inhibition. Inhibition initially decreases the responsiveness of the cell, but subsequently raises its level of excitability. Release from inhibition can last for several seconds, which by auditory standards is a long time. Sanes said that the process not only occurs under conditions of natural sound stimulation, but also can be created artificially by applying the inhibitory neurotransmitters glycine and GABA. The suppression of sound: Pollak's research team has been studying how animals locate a sound source by initially processing information in the brain stem, a lower region of the brain, and then sending the processed information to a series of higher regions. He found a response similar to the so-called precedence-effect which enables humans sitting in an auditorium at a concert to hear the primary sound originating from an instrument or singer and ignore the echoes bouncing off walls and the ceiling. Without this effect, the primary sound and the echoes would be perceived as originating from different locations. Working with Jamaican mustached bats (Pteronotus parnelli), Pollak discovered that neurons in one brain stem nucleus create a precedence-like effect or long-lasting inhibition that suppresses sounds that occur during the period of the inhibition. Thus he said, this nucleus is inhibited by the initial sound from sending any information to higher regions of the brain. Telling the time of sound: Spain's research involves using chicken embryo cells to study how cells in the brain stem can calculate the spatial location of a sound source based on signals from an animal's two ears that are received microseconds apart. In order to detect the very small delay in the time of arrival of a sound at both ears, neurons must be able to sense differences in arrival times within 1/2000th of a second, Spain said. Sound detected independently by each ear is turned into an electrical signal and the timing of the electrical signals are checked for coincidence. Spain and his colleagues have begun to investigate how coincidence detection is accomplished inside individual cells.
--------
120-> Researchers Studying Deformed Frogs Found In Southeastern Ohio
 ATHENS, Ohio -- Researchers at Ohio University are studying deformed frogs found at a pond in Southeastern Ohio, trying to determine if the deformities are caused by a naturally occurring parasite, chemicals used in a nearby cornfield or some other phenomenon. Researchers studying the pond in Lancaster, about 30 miles from Columbus, have found that about 5 percent of the frogs have some sort of deformity, said James Barron, an assistant professor of biological sciences at Ohio University's Lancaster campus. Scientists at the National Institute of Environmental Health Sciences say it's normal to find a small number of deformed frogs -- 1 percent -- at any given site. "The incidence of these deformities in Ohio appears to be low, but the numbers are sufficient enough to warrant investigation," said Barron, who is coordinating all Ohio reports of amphibian malformations for the North American Reporting Center for Amphibian Malformations, a project of the Biological Resources Division of the U.S. Geological Survey. While the frogs collected from Lancaster are the only ones currently under study by Ohio University researchers, Barron also plans to investigate reports of amphibian malformations he's received this fall from Hamilton, Franklin, Madison and Coshocton counties. "I've been aware of the problem in other states, but this gives us a unique opportunity to examine the problem in Ohio," Barron said. National reports of deformed frogs date back to the 1700s, but the number of reports have increased dramatically since 1995. The largest deformed frog populations have been found in Wisconsin, Minnesota and parts of Canada. In these areas, reports suggest that anywhere between 10 and 75 percent of specific species of frogs have deformities. Researchers at Ohio University first heard of the frogs in Lancaster from a local family that discovered a frog with five extra legs growing from its sternum. After documenting the case, Barron sent the bullfrog, nicknamed Lefty, to researchers at the National Wildlife Center in Madison, Wisc., for further study. Working with biological sciences graduate students Shala Hankison and Wade Winterhalter, Barron collected deformed bullfrogs and green frogs from the pond in Lancaster. Hankison, who has done earlier research on frogs, will spend the next several months studying the frogs and water and soil samples collected from the site. "There are several hypotheses about the causes of frog deformities, and I'll examine each to see what may have caused the problems here," Hankison said. One hypothesis is that amphibian deformities are caused by a naturally occurring parasite, called a trematode, which alters limb development by burrowing into the limb buds of tadpoles. While this may hold true for some of the frogs the researchers collected, it most likely isn't the cause of all the deformities, Hankison said. "Lefty's deformity is an extra leg growing from its sternum, and there's no way a trematode could cause a limb to grow there. That is more of a developmental deformity," she said. Some scientists believe pesticides are to blame for the growing number of amphibian malformations, and Hankison says that is a possibility in this case. The frogs were found in a pond bordering a cornfield that was subjected to a new tilling technology using a lot of herbicides. "When we study the water and soil samples, we should have some answers about herbicides," she said. Still another hypothesis is that deformities are caused by exposure to ultraviolet radiation caused by holes in the Earth's ozone layer, but Barron says recent research casts doubt on that possibility. It's likely there is no one cause of the frog deformities the researchers here will be studying, since the deformities range from extra limbs to too few limbs to facial deformities. And, Barron added, investigations of deformed frogs in other counties may reveal an even broader range of malformations.
--------
121-> Study Finds Striking Environmental Change In Arctic
Natural causes, not just human-induced forces, played a significant role in an unprecedented warming trend in the Arctic in the last 150 years, according to a study published in the November 14 issue of Science. The study found that the Arctic experienced its highest temperatures in 400 years between the mid-19th and mid-20th centuries. Contrary to previous assumptions, the evidence indicates that the Arctic is characterized by significant climatic change even without the influence of environmental effects caused by humans. "Some of the warming that we observed after the time of the Industrial Revolution may be attributed to atmospheric greenhouse gases, but our observation of dramatic environmental change pre-dates this period," said investigator Dr. Marianne Douglas, an assistant professor in the University of Toronto's department of geology. The lead author of the study was Jonathan Overpeck of the National Oceanic and Atmospheric Administration's Paleoclimatology Program in Colorado. The multi-centred project capitalized on the expertise of 18 North American researchers who studied complementary climate indicators in all parts of the Arctic. The final compilation of paleoenvironmental data included information from glaciers, tree rings and marine, lake and pond sediments. Douglas's work focused on diatoms, a type of algae known to respond in a measurable way to environmental change, in Arctic ponds. "I reconstructed past environmental conditions using the diatom assemblages that are preserved in lake and pond sediments," she said. Until recently the record of Arctic climate change was geographically and historically limited, but this study contributes to an improved understanding of the area's environmental variability. The findings suggest the Arctic is especially susceptible to global climate change caused by both natural and human sources, and in turn it can influence changes at lower latitudes through mechanisms such as river runoff into the Arctic Ocean and subsequent changes in thermohaline (ocean currents distributing heat) circulation. The period of warming that began in the 1840s ended the Little Ice Age, caused melting of permafrost and sea ice and alterations in land and lake ecosystems. Douglas's funding came from the Natural Sciences and Engineering Research Council and the Canadian government's Polar Continental Shelf Project. In the United States, the National Science Foundation provided financial support. The other institutions involved in producing this paper were the University of Colorado, the University of Massachusetts, the University of California, the University of Alaska, Bates College, the University of Ottawa, the University of Alberta, the University of New Hampshire and Columbia University.
--------
122-> New Search Engine, Language Simplifies Web Surfing
NEW YORK, N.Y. and HAIFA, ISRAEL, November 14, 1997 -- After years of struggling with often frustrating and time-consuming searches on the World Wide Web, users will soon be able to get much more accurate results using a new search engine developed in Israel. Called W3QS, the search engine actually looks for structures or relationships within the content of documents, rather than just searching for key words. That means that instead of generating a multitude of irrelevant sites, as often happens in conventional search engines like Infoseek, Lycos and Excite!, a W3QS query can yield very specific results. "The current search engines are limited because the structural information, namely the organization of the document into parts pointing to each other, is usually lost," explains Dr. Oded Shmueli from the Computer Science Faculty of the Technion-Israel Institute of Technology, who developed the new search engine with David Konopnicki, a graduate student. Most search services today use "robots," or programs that scan the network periodically and form text-based indices, but "those searches are limited by the kind of textual analysis provided by the search service, and the depth of site exploration," Dr. Shmueli says. "In particular, robots do not fill forms themselves, as the number of possibilities is enormous, so they miss interesting avenues that humans might follow." W3QS, by contrast, can look for complex content relationships, rather than just looking for words or groups of words. That can make for more accurate searches and less time wasted chasing down irrelevant leads. W3QS also searches a designated portion of the Web, in its most current configuration, rather than relying on text-indices that may be out-of-date. Unlike the current search services, W3QS is capable of filling forms that are encountered as it navigates the WWW. Consider the following example: You're looking for the actual texts of scientific papers written by Drs. Smith and Jones, who work in the Computer Science Department at West University. With conventional searches, you might type in the key words "Smith," "Jones," "West" and "University." A basic Infoseek or Alta Vista search could bring up hundreds of sites that contain those words. But the results could very likely include a document that discusses the Smith building at Jones University, on West Street, or Michael Jones's analysis of Jay Smith's university architecture in the West in the 1800s. And even if you could find authors Smith and Jones at West University, you might have trouble linking to their home pages, and there's no guarantee that all their papers are listed in their home pages. If you were to use W3QS to look for those same papers, you could ask the search engine to first go to the Computer Science Department at West University, and then follow hypertext links, all the while looking for documents that contain "Smith "and "Jones" in some specified proximity, together with a link to a file containing the text of a scientific paper. W3QS would then fetch that actual file and store it on the server that runs W3QS, rather than making the user go to the specified Web page and extract the needed document. All the fetched documents can then be e-mailed to you. To limit what could be searches ad infinitum, you can tell W3QS to follow links through only four documents, or six, or ten. Most search engines available today do not search a site to any depth. And because W3QS uses its own language -- W3QL -- users can create very rich queries and be sure that W3QS will do the querying precisely as specified. Current search services mostly offer ad-hoc ways of stating the conditions of a search, which leaves the results somewhat up to chance. W3QS includes a number of other conveniences, including: The Technion-Israel Institute of Technology is the country's premier scientific and technological center for applied research and education. It commands a worldwide reputation for its pioneering work in communications, electronics, coater-resource management, materials engineering, aerospace and medicine, among others. The majority of Israel's engineers are Technion graduates, as are most of the founders and managers of its high-tech industries. The university's 11,000 students and 700 faculty study and work in the Technion's 19 faculties and 30 research centers and institutes in Haifa. The American Technion Society (ATS) is the university's support organization in the United States. Based in New York City, it is the leading American organization supporting higher education in Israel. The ATS has raised $632 million since its inception in 1940, half of that during the last six years. Technion societies are located in 24 countries around the world.
--------
123-> Scientists Discover Substances That Make Grapefruit Juice Squeeze More Out Of Some Medications
ANN ARBOR---Researchers, led by a team from the University of Michigan Medical Center, have isolated a pair of substances in grapefruit juice that cause greater absorption of certain drugs in the human body. The new findings are published in the November issue of the journal Drug Metabolism and Disposition. Earlier studies found that patients who took certain medications with grapefruit juice absorbed more of the medicine. The key to how grapefruit juice enhances drug absorption lies in the interaction between the grapefruit juice and an enzyme found in the small intestine. Now, Paul B. Watkins, M.D., director of the U-M General Clinical Research Center, and his colleagues have isolated two substances in grapefruit, called furanocoumarins (few-ran-oh-COO-muh-rinns), that are responsible for the so-called grapefruit effect. Watkins says the two components act like suicide bombers, attaching themselves to the enzyme and destroying its ability to interfere with drug absorption. The enzyme, known as CYP3A4, normally acts as a sort of gatekeeper against certain types of medication, including those prescribed for high blood pressure, heart disease, allergies, AIDS and organ transplantation. These types of drugs, unlike most medications, are not absorbed efficiently in the intestines because they are largely broken down by CYP3A4 in the intestinal wall. Watkins says people typically have varying levels of the enzyme in their intestines---which appears to explain why some individuals absorb greater amounts of a given medication than others. Watkins says the two furanocoumarins have different properties. The major active substance in grapefruit juice is called 6',7'-dihydroxybergamottin (DHB) and the researchers named the other ingredient they discovered FC726. Where the two differ is that DHB appears to have multiple effects, while FC726 seems to work specifically on the CYP3A4 enzyme. Watkins says these findings could have important ramifications for the future of drug-making. Researchers now believe that by adding one of the furanocoumarinscontained in grapefruit to certain oral medications, the reliability and safety of the drugs can be noticeably improved. "This discovery allows for the development of improved oral medications, not just for existing drugs, but more importantly, drugs that would not have made useful oral medications without this prior understanding," Watkins says. "By placing DHB or FC726 directly into a pill, much more of the drug will be absorbed in a reliable manner." Another interesting finding in the study was that the concentration of the active ingredients varies dramatically among grapefruits and grapefruit juices, even within the same product line. This is most likely because of growing conditions in different regions and because manufacturers typically buy their grapefruits from many areas. "For this reason," Watkins says, "it would be preferable to add the active ingredient to pills, rather than just taking medication with grapefruit products." Watkins believes there are probably additional substances in grapefruit that control drug absorption. "The direction of the research now," he says, "is to continue to search for these furanocoumarins to find the magic bullet, the one that just does what we want it to without interfering with anything else. We believe the grapefruit harbors all kinds of compounds that will be useful in formulating different kinds of drugs."
--------
124-> As Africa's Human Population Grows, Wild Dogs Plummet
A combination of a natural wanderlust and bad image among humans has driven African wild dogs from nearly two thirds of their original range. Their population in parks has plummeted to around 3,000 -- making them as endangered as black rhinos -- according to a recently released report by IUCN Species Survival Commission. Authors Joshua Ginsberg of the Wildlife Conservation Society, headquartered at the Bronx Zoo, Rosie Wodroffe of Cambridge University and David Macdonald of Oxford University, found that even the largest parks can support only small numbers of wild dogs, which are distant relatives to wolves and jackals. Each pack uses up to 400 square miles, probably to avoid lions, which prey on both adults and pups, and can compete for the same prey species. In Kruger National Park in South Africa for example, just 400 wild dogs live within its 9,000- square-mile expanse. According to the report, this tendency for the dogs to wander often puts them in contact with humans who have persecuted them since colonial days. Half the wild dogs found dead in reserves have been shot, snared, poisoned, or killed by road traffic. Wild dogs roaming outside of reserves meet up with domestic dogs where they fall victim to rabies and other diseases. Rabies has already caused the extinction of at least one wild dog population. The researchers have proposed a series of conservation measures to ensure protection of the remaining population of African wild dogs. These include working with local landowners to minimize persecution and contact with domestic dogs. Inside protected areas and along their borders, the use of snares must be controlled, and new high-speed roads should be routed away from reserves. "Wild dogs, more than any other species in Africa, show the difficulty of doing conservation in fragmented landscapes. Unless we are able to insure the integrity of Africa's protected areas, wild dogs will disappear from the continent. With the growing human needs of many African countries, balancing conservation of African wild dogs -- and other wildlife -- with development will be a real challenge," said Joshua Ginsberg.
--------
125-> MGH Team Identifies New Immune Activity That May Control HIV Levels
Researchers from the Massachusetts General Hospital (MGH) and other Boston institutions have identified, for the first time, an activity by the human immune system that seems to suppress replication of the human immunodeficiency virus (HIV), the virus that causes AIDS. The discovery may explain why a tiny group of those infected with HIV have remained healthy for many years and indicates the possibility of duplicating that protective response in other individuals.  The report, which appears in the November 21 issue of Science, shows that the immune systems of these long-term nonprogressors produce large numbers of helper T cells specifically targeted to HIV.  Previous studies of individuals infected with HIV have found very few or none of these virus-specific helper cells, which animal studies have suggested are important in controlling many types of viral infections. "One of the biggest mysteries in our understanding of AIDS and HIV has been why the immune responses that usually control viral infections don't work," says Bruce Walker, MD, director of the Partners AIDS Research Center based at the MGH and senior author of the report.  "Our work now suggests a simple explanation for how HIV escapes the normal immune response, why the immune system slowly but inexorably breaks down, and why a very small group of people have been able to avoid getting sick from this virus." Helper T cells are the central orchestrators of the entire immune system.  Individual helper cells are targeted to specific antigens, the protein signatures of viruses, bacteria, tumors or other disease-causing entities.  All helper cells are vulnerable to infection by HIV, and AIDS develops when so many helper cells have been infected and destroyed that the entire immune system breaks down. Usually when a virus invades the body, helper T cells that recognize that virus's antigens become activated — reproducing in great quantity.  Not only does this proliferation of helper cells direct the immune response to suppress the original infection, but the immune system keeps making virus-specific cells to deal with any recurrence of the same infection.  Since proliferation of HIV-specific helper T cells had never been previously observed, some scientists thought the virus somehow avoided all recognition by helper cells.  The MGH-led study, however, shows that, in rare instances, HIV-specific helper cells are generated and may be able to keep viral levels under control. The initial clues came from studies of a long-term nonprogressor who has been infected with HIV for more than 18 years with no evidence of illness.  Although the presence of HIV antibodies proves he is infected with the virus, the amount of virus in his blood has remained so low as to be undetectable, even though he has never been treated with antiviral drugs.  When the researchers exposed samples of his blood to several HIV-specific antigens, they observed something totally new.  "Not only did this individual have HIV-specific helper cells, but he had a huge helper-cell response, the first such response we had ever seen to HIV," Walker says. The researchers then looked for helper-cell responses in samples from ten chronically infected people, some with high levels of virus and some with low viral loads, whose infections had been recently diagnosed.  The tests, done before the patients started antiviral therapy, showed a strong correlation between levels of virus and helper-cell response:  those with the strongest HIV-specific T-cell response had the lowest viral loads, while those with higher viral levels showed weaker T-cell responses.  "We began to develop a theory about why these virus-specific cells usually don't appear in HIV-infected people," says Eric Rosenberg, MD, the paper's first author.  "Perhaps the very helper cells capable of recognizing HIV were being destroyed in the earliest stage of infection.  We wondered if antiviral treatment at that time might keep these helper cells from being eliminated." The research team soon had an opportunity to test this hypothesis when Rosenberg met a patient with symptoms of acute HIV infection — fever, severe sore throat, rash and swollen lymph nodes.  Discovering that this individual had a possible HIV exposure only two weeks previously, Rosenberg ran blood tests that revealed high levels of virus but no antibody in the patient's blood, indicating a very recent infection.  The patient was started on powerful antiviral drugs, and his viral loads dropped dramatically to virtually undetectable levels while his immune system began to generate a strong HIV-specific helper T-cell response.  Similar treatment in two other recently-infected individuals produced the same responses.  In people infected for longer periods — six months or more — treatment did reduce viral levels but did not produce the helper T-cell response seen in those treated immediately after infection. "This suggests that there is a window of time  — and we don't know yet how large it is — during which we might be able to salvage the helper T-cell response through vigorous antiviral treatment," Walker says.  "So it could be critically important for physicians to be alert for the symptoms of acute HIV infection and, in those patients who appear at risk, to test for the presence of virus." Walker stresses that preservation of the helper T-cell response probably requires beginning treatment immediately after infection, and he emphasizes that his team has not yet proven that this response is solely responsible for controlling virus levels.  Except for the known long-term nonprogressors, all of the indivi duals participating in this study continue to receive antiviral therapy.  It also will be important, he adds, to determine whether induction of this helper cell response in persons who lack it would lead to more effective immune control of the virus.  Recent studies have shown that the virus persists in the body in spite of potent antiviral therapy.  Whether the immune response to the virus can be augmented to provide additional benefit remains an open question. Along with Walker and Rosenberg, the study's coauthors are James Billingsley, Angela Caliendo, MD, PhD, and Spyros Kalams, MD, of the MGH; Steven Boswell, MD, of the Fenway Community Health Center; and Paul Sax, MD, of Brigham and Women's Hospital.  The research was supported by grants from the National Institutes of Health and by private donations.
--------
126-> New Simulator Technology To Give Surgeons 'Feel' Of Really Operating
Surgical students soon will be able hone their skills with simulators that for the first time present a realistic feel of performing surgery, thanks to a research project under way at the University of Washington. The project also could improve patient care by leading to the development of instruments that enhance surgeons' sense of touch. A team of engineers and surgeons at the UW has developed technology for precisely measuring the forces and torques involved in performing various surgical procedures. These measurements will be programmed into training simulators with force-feedback technology so that surgeons and medical students can learn exactly how it feels to execute a procedure correctly before they perform it on live patients. "These enhanced surgical simulators have the potential to drastically reduce the time and cost involved in training surgeons and to improve performance," says Dr. Mika Sinanan, associate professor of surgery, who is co-directing the project along with Blake Hannaford, associate professor of electrical engineering. The research is funded by a $500,000 grant from the Defense Advance Research Projects Agency. More than 90 percent of surgical skills training currently is done in the operating room. Resident surgeons learn procedures by assisting in hundreds of operations under the supervision of teaching doctors. This form of training is expensive (costing up to $24 per minute), time-consuming and creates inefficiencies in the provision of surgical care. It would be beneficial, Sinanan says, if resident surgeons could hone their skills before they set foot in the operating room much like pilots learn to fly in simulators before taking to the air. But unlike flight simulators, existing surgical simulators don't come close to replicating the feel of performing an operation and consequently are of limited value. One of the problems, according to Hannaford, is that nobody has accurately measured the forces involved in doing surgery. As a result, simulators have relied on subjective impressions from surgeons rather than objective data in attempting to recreate forces such as the amount of pressure that should be applied to surgical instruments for a given procedure or the different levels of resistance offered by healthy and diseased tissue. "Practicing surgeons know from experience what these forces feel like, but they have never been quantified," Hannaford says. To get those measurements, post-doctoral fellows Mark MacFarlane and Jacob Rosen have attached specialized sensors to surgical instruments such as scalpels, graspers and cauterizing tools. In laboratory experiments, the sensors will measure the pressure and torque applied by surgeons to the handles of the instruments as well as the forces acting on the working end of the tools. The experiments also will quantify the force tolerance levels of various tissues in order to establish performance standards. These measurements eventually will be used to program small motors and sensors to recreate the prescribed forces and performance parameters in surgical simulators. The measurements also could be programmed into 'smart' surgical instruments to enhance surgeons' sense of touch or prevent them from causing injury by exceeding normal tissue tolerances. The demand for more sophisticated training simulators and 'smart' instruments has grown over the past decade with the rise of videoendoscopic surgery. This minimally invasive technique allows surgeons to perform procedures such as gall bladder surgeries and hernia repairs using specialized instruments fitted with tiny cameras that are inserted through small incisions in the body. Videoendoscopic procedures result in smaller scars and faster healing, according to Sinanan, but they require a new set of surgical skills. "Surgeons used to reach in and feel the tissue or organs with their own hands, but now they're wearing two pairs of latex gloves and using endoscopic tools that really distort their sense of touch," Hannaford says. "What we're trying to do is give that force-feedback information back to the surgeon."
--------
127-> Africanized Honey Bees Head West For Food, Says UC Davis Researcher
Africanized honeybees in southeastern California's ImperialValley region are once again moving west, according to a UCDavis bee expert. Because winter is approaching and the bees don't store a lotof food, they are currently swarming in a westerly directionlooking for food sources, according to Eric Mussen, a UCCooperative Extension specialist in the UC Davis entomologydepartment. Many of the Africanized honeybees won't find food by the endof November and will die of starvation, he notes.  But, whilethe bees are swarming in search of food, they pose apotential threat to folks using public parks, golf coursesand other places where there are a lot of plants and flowers. Members of the public should not try to deal with any type ofswarming bees, rather they should call a local countyagricultural authority or a pest control expert, Mussenstresses.
--------
128-> Global Land Precipitation Increases In 20th Century, NASA Scientists Find
Global land precipitation has increased during the 20th century, especially at the mid and high latitudes, according to a paper published in the November 1997 issue of the Journal of Climate. The paper, written by scientists Drs. Inez Fung, Anthony Del Genio, and Aiguo Dai, is based on a recalibrated compilation and analysis of data from 1900-1988 and confirms previous speculation that land precipitation is increasing.  The new research shows a global land trend of a 2.4 mm per decade increase in annual precipitation amounts.  Multiplied by almost nine decades, this means that there is about 22 mm more rain falling now each year than there was at the turn of the century -- rainfall as a global mean has risen by slightly more than two percent. "Though much speculation remains as to the cause of this increase, further long-term study is needed to help ascertain the reasons for this change.  The research does show, however, that both the spatial pattern and rate of precipitation increase are reminiscent of global climate model predictions of the atmosphere's response to an increase in greenhouse gas concentrations," said Dr. Anthony Del Genio, research scientist at NASA's Goddard Institute for Space Studies (GISS), New York City. NASA scientists learned of this rise in precipitation from a new data set constructed at GISS.  Scientists analyzed the data at face value but, in the process, used mathematical techniques to detect patterns of historical errors.  Researchers developed new ways to objectively determine variations and remove ones that are not accurate.  Finally, they performed a statistical test to determine the numerical confidence and came up with the revised database, which they believe shows the long term changes more precisely than previous analyses of the data. "This database represents a potentially valuable resource for understanding the nature of land precipitation variations and their role in climate processes," said Dai, a researcher at GISS, a branch of NASA's Goddard Space Flight Center, Greenbelt, MD. For example, the research analysis confirms the global patterns of the presence of an El Nino and also depicts the well-known Sahelian drought of the past few decades that has been a major influence over parts of Africa. Through the construction of this historical database, researchers confirmed the occurrences of 24 droughts and five floods world-wide in the 20th century, though most took place in the tropics rather than middle latitudes. Scientists have long held that precipitation is one of the most important aspects in Earth's climate system because of its impact on the global biosphere.  In addition, precipitation limits the amount of water vapor in the atmosphere.  Water vapor is the most important greenhouse gas and thus helps to determine Earth's surface temperature.  The amount of water vapor in the atmosphere determines when and where clouds form. "The latent heat released when water precipitates out of the atmosphere is the primary way in which the tropical ocean 'communicates' with the atmosphere and drives the tropical atmospheric circulation," said Del Genio. Tracking precipitation and its relationship to global climate, however, has been difficult because the data have not been recorded into coordinated databases until recently.  In addition, precipitation measurements vary widely across small geographic areas making it difficult to measure accurately.  Through further study, NASA and researchers at GISS hope to create more accurate models from which conclusions about global rainfall can be drawn. NASA also is due to launch this month the Tropical Rainfall Measuring Mission (TRMM), the first mission dedicated to measuring tropical and subtropical rainfall through microwave and visible infrared sensors.  The TRMM mission includes the first spaceborne rain radar.  Tropical rainfall comprises more than two-thirds of global rainfall.  Data from the TRMM mission should greatly enhance researchers' understanding and prediction abilities of global climate change. The ongoing research at GISS is funded through NASA's Mission to Planet Earth Enterprise, a long-term coordinated research effort to study the total Earth system and the effects of natural and human-induced changes on the global environment. -end- More information is available on the Internet at the following URL:  http://www.giss.nasa.gov/data/adai/ 
--------
129-> Smoking, Drinking, Drugs: The Younger They Start, The Harder It Is To Quit
Young people who experiment with tobacco, alcohol or illicit drugs at an early age are less likely to quit their habit than those who start later. David J. DeWit, PhD, of the Addiction Research Foundation in London Ontario, and colleagues at McMaster University came to that conclusion after studying the drug use histories of 4,364 youngsters in Ontario, Canada who were surveyed in 1990-91. Their results, published in the December 1997 issue of Health Education & Behavior, revealed that starting to smoke and to use drugs and alcohol begins earlier than previously reported, with some children taking their first drink as early as at 10 and 11, their first illicit use of prescribed drugs at 11, their first use of hallucinogens at age 12, and their first use of cocaine and crack at 15 and 16. Overall, they report, the major risk period for beginning tobacco, alcohol or illegal drug use begins around age 12, peaks between 15 and 19, and is mostly over by age 22. For crack cocaine use, the risk begins at about age 15 and fluctuates to age 29. The research team concluded that "knowing the exact ages when young people are at greatest risk of engaging in substance use and abuse is crucial for health and education experts to introduce prevention programs in a more timely fashion." They urged that abuse-prevention programs for alcohol, prescribed drugs and hallucinogens begin as early as middle and late elementary school years. "Programs must ... be introduced in a more timely fashion, well in advance of periods in which the incidence of abusive consumption begins to escalate," they write. "Our data revealed that age at onset of drug use was a strong correlate of young people's propensity to quit their drug habit," they write, noting that this was particularly true for marijuana users: nearly 60 percent of those who said they started using marijuana before age 15 were still doing so after eight years, but among those who started at 19 or older, only 20 percent were still users after 8 years. Among other findings:
--------
130-> Researchers Find Drug May Help Cystic Fibrosis Patients
Researchers at the Johns Hopkins Children’s Center have found that a drug used to normalize blood ammonia levels also holds promise for cystic fibrosis. People with cystic fibrosis have mutations in the cystic fibrosis transmembrane conductance regulator (CFTR) gene, which normally codes for a protein that transports chloride across the cell membrane. Approximately 70% of cystic fibrosis patients have the same mutation (called the deltaF508 mutation) in this gene, which results in a protein that is partly functional but that rarely gets transported to the surface of the cell. Instead, this protein become “stuck” on the way to the surface and is degraded. Consequently, little or no chloride can be transported across the cell membrane. In cystic fibrosis, this chloride imbalance results in a thick mucus that causes recurrent airway and intestinal obstructions, as well as chronic respiratory infections. The addition of sodium 4-phenylbutyrate (4PBA) to cells with the deltaF508 mutation allows more CFTR proteins to reach cell surfaces, where they can transport chloride, according to Ronald C. Rubenstein, M.D., Ph.D., an instructor in pediatrics at Hopkins and lead author of the study. This phenomenon occurs at concentrations of 4PBA normally seen in patients who already take the drug for urea cycle disorders, which are genetic diseases characterized by high levels of ammonia in the bloodstream. The study appears in the November 15 issue of the Journal of Clinical Investigation. “A therapy directed at correcting the abnormal intracellular transport of the deltaF508 mutation is potentially beneficial to the majority of CF patients,” says Rubenstein.  “We are very encouraged by 4PBA’s apparent action to repair this mutation’s function in the lab.” Cystic fibrosis occurs in about one in every 2,500 births in the Caucasian population, one in every 16,000 births in the African American population, and about one in every 90,000 births in the Asian American population. “There are currently an estimated 23,000 patients diagnosed with CF in the United States, with an average survival age of 31 years,” says Pamela Zeitlin, M.D., Ph.D., associate  professor of pediatrics at Johns Hopkins and a co-author of the study.  “4PBA has the potential to benefit more than two-thirds of these patients.” However, say Rubenstein and Zeitlin, it is not clear if this therapy alone would lead to significant improvement in patients.  Even if the mutant proteins reach cell surfaces, they still cannot transport as much chloride as normal proteins do. Rubenstein and Zeitlin are currently conducting clinical trials of 4PBA in CF patients who have the deltaF508 mutation. Marie E. Egan, M.D., of Yale University, is also an author of the study. The Johns Hopkins Children’s Center is the children’s hospital of the Johns Hopkins medical institutions.  Maryland’s most comprehensive acute-care hospital for children, the center, with its 177-bed hospital and more than 40 divisions and services, treats some 8,000 inpatients and more than 64,000 outpatients annually.
--------
131-> World's "Smartest" House Created By University of Colorado Team
 What may be the world's "smartest" house, a dwelling whose environment is controlled by a computer system that learns the occupant's daily habits and preferences, is unknown to most residents of Boulder, Colo. A former schoolhouse more than 90 years old, the structure was purchased in 1991 by Associate Professor Michael Mozer of the University of Colorado at Boulder's computer science department. It was then renovated and retrofitted with high-technology hardware. Using data gleaned by sensors installed by Mozer and his students, the computer system essentially "programs itself" by observing his lifestyle and habits over time, eventually learning to anticipate and accommodate his needs. Mozer and more than a dozen graduate and undergraduate students have installed 75 sensors and nearly five miles of conductor in the home, as well as actuators to control lighting, ventilation and air and water heating. The sensors continually monitor temperature, ambient light, sound and motion in each room, the opening of doors and windows, outdoor environmental conditions, boiler temperature and hot water usage. Many homes can be programmed to perform tasks like watering lawns or turning on televisions, but programming a home is a complex and difficult task that few homeowners are interested in doing, he said. "The twist is that this house programs itself by observing inhabitants as they live their lives," he said. "The system is based on neural networks, which are learning devices inspired by the working of the human brain." The human brain relies on billions of neurons constantly communicating with each other as they acquire knowledge and form memories. In Mozer's house, artificial neural networks consisting of hundreds of simple, neuron-like processing units interact to predict and control the environment. The system predicts Mozer's behavior and movements, including which rooms will be occupied at what times, when he will leave the house and return, and when hot water will be needed in the boiler. "The system infers rules of operation and adapts to the lifestyle of the inhabitant," maximizing comfort by setting appropriate temperatures and light levels while minimizing energy consumption," he said. In Mozer's house, anticipating and carrying out the wishes of the inhabitant and conserving energy sometimes conflict. So Mozer and his colleagues at CU's Institute of Cognitive Science devised mathematical techniques for translating discomfort to a cost in dollars that can be weighed against energy costs. One technique, based on an economic analysis, depends on the loss in productivity that occurs when the system ignores the inhabitants' desires. Another technique adjusts the relative importance of the inhabitants' desires based on how much they are willing to pay for gas and electricity. Even if the inhabitants do not have a particularly regular schedule, there are statistical regularities in their behavior that the system can exploit. For example, if Mozer is not home by 3 a.m., he likely will not be home by 4 a.m. and therefore the house does not need to be warmed up. Mozer demonstrated the bathroom light, which turned on to a low intensity as he entered. "The system picks the lowest level of the light or heat it thinks it can get away with in order to conserve energy, and I need to complain if I am not satisfied with its decision," he said. To express his discomfort, he hit a wall switch, causing the system to brighten the light and to "punish itself" so that the next time he enters the room, a higher intensity will be selected. "The house has been the source of a dozen student research projects and two masters theses," he said. "This is a good testing ground for undergraduates who have never actually built something in the real world. And we are in a domain that I believe may have great practical potential." Much of Mozer's neural network research has been funded by the National Science Foundation. In 1990, Mozer received a prestigious Presidential Young Investigator Award from NSF worth $100,000 annually for five years. The NSF also funded some of Mozer's undergraduates through its Research Experience for Undergraduates program.
--------
132-> Duke Primate Center Lemurs Are Released Into Wilds Of Madagascar
DURHAM, N.C. -- The leader of an unprecedented effort to return endangered lemurs to their homeland of Madagascar has emerged from the depths of the forest preserve to report that the five captive-born animals from Duke's Primate Center now roam free for the first time in their lives. Project leader Charles Welch reported that the black-and-white ruffed lemurs were released on Monday and immediately dispersed to begin their new lives in the 5,000-acre Betampona Natural Reserve, where they will enhance the dwindling lemur population. The lemurs are part of a project by the international Madagascar Fauna Group (MFG) to systematically repatriate as many as 20 of the adaptable animals to their ancestral island nation over the next three years. Black-and-white ruffed lemurs, known for the fur that frames their faces and the lush coats of black and white fur, are among Madagascar's most endangered. They are regularly hunted for food on the island. After their arrival in Madagascar three weeks ago, the animals -- Janus, Letitia, Praesepe, Sarph and Zuben'ubi - had spent time in an outdoor cage in the reserve, under the care of San Francisco Zoo veterinarian Graham Crawford. During that time, all began eating fruits harvested from the forest, supplemented with commercial monkey chow. Since all were in good health, the release was set for Monday morning, Nov. 10, Madagascar time. The release process began with a trimming of the animals' tail hair into distinctive patterns, so they could be better identified as they were tracked through the forest. "Two of the project's conservation agents then led a traditional ceremony in which they explained the lemur release project to the ancestors and asked the ancestors for their blessing," wrote Welch in an e-mailed report. "Short speeches were made and everyone took a sip of the local home-made rum, held in a folded leaf. Three leaves were left full of rum in a pile of stones at the base of the release cage. "The ceremony complete, the doors were opened in front of an anxious audience of the project's personnel and the representatives of the Malagasy government's Department of Water and Forests and National Association for the Management of Protected Areas." The lemurs at first emerged cautiously from their cage, wrote Welch, but it proved to be the last peaceful moment the researchers would enjoy. "We had expected the lemurs to remain close to the release cage for the first days, where they could be sure of an easy meal of monkey chow. Completely contrary to our predictions, within five minutes all of the lemurs had moved away from the release site, some in their own direction. The chaos of the day had begun." Three animals immediately headed for the project's base camp and had to be recaught and released to ensure they would stay away from the familiar comforts of manmade structure. Another moved too close to the territory of a wild group of ruffed lemurs, a contact which the researchers wanted to discourage early in the animal's adjustment to the wild. So, he had to be recaught and freed near the release site, Welch wrote. The researchers spent several days in exhausting treks through the dense, hilly forest, coping with malfunctioning radio-tracking equipment, tracking the animals. "We feel it critical to observe each animal daily during this initial period and to continue to supplement their diets with monkey chow till they are observed to feed substantially on wild leaves and fruit," Welch wrote. All the animals have been reported in good condition so far, he wrote, "probably in better shape than the project personnel who are exhausted with efforts to keep up with them." "The lemurs are dispersing and coming back together irregularly, perhaps exploring potential territories," he wrote. "Time will tell." Welch said the Duke lemurs were visited in their outdoor cage by wild lemurs, but the researchers said they had as yet observed no post-release contacts. "Yesterday for the first time, Zuben'ubi, Letitia and Sarph vocalized loud and long, so perhaps it won't be long till their first meeting with their wild neighbors," he wrote. Primary collaborators in the Betampona restocking project include some of the MFG's keymember organizations: the Duke Primate Center, Philadelphia Zoo and Roger Williams Park Zoo in the United States; and the Jersey Wildlife Preservation Trust, Marwell Preservation Trust and Zoological Society of London in Great Britain. The American Zoo and Aquarium Association also support the project. Madagascar collaborators include the National Association for the Management of Protected Areas, the Malagasy Department of Water and Forests, the University of Madagascar and Parc Ivoloina. The total budget for the first three-year phase will be $300,000. Almost half that money is already in hand due to fund-raising efforts -- principally by the Jersey-London-Marwell group, which has raised $120,000. In one notable example, actor-producer John Cleese donated the proceeds from the London premier of his comedy film Fierce Creatures, which featured captive lemurs in addition to its human cast. Other MFG members include: Aktiengesellschaft Zoologischer in Koln, Germany; Baltimore Zoo; Brookfield (Ill.) Zoo; Cincinnati Zoo; Colchester Zoo in Essex, England; Columbus (Ohio) Zoo; Denver Zoo; Fort Worth (Texas) Zoo; Institut d'Embryologie, Strasbourg, France; Institute for the Conservation of Tropical Environments in Stony Brook, N.Y.; Knoxville (Tenn.) Zoo; Los Angeles Zoo; Micke Grove Zoo in Lodi, Calif.; Oklahoma City Zoo; Orgrod Zoologiczny Poznon in Poland; Parc Zoologique et Botanique Mulhouse in France; Point Defiance Zoo in Tacoma, Wash.; San Antonio Zoo; San Francisco Zoo; St. Louis Zoo; Transvaal Snake Park in South Africa; Wildlife Conservation Society in Bronx, N.Y.; Zoo Atlanta; Zoological Garden Zurich in Switzerland; and Zoologischer Garten der Landes in Saarbrucken, Germany. The Duke Primate Center, located in an isolated off-campus forest, is now home to 16 different endangered lemur species, as well as six other "prosimian" (pre-monkey) species such as lorises and bushbabies. The center is supported by the National Science Foundation, Duke University and private donations.
--------
133-> 'Computational Grid' Supercomputing Demonstration Will Link 3,000 Processors In Europe And The U.S.
A prototype for future "computational grids," which will provide supercomputing power on demand, just as a power grid provides electricity, will be demonstrated in San Jose this coming week by researchers from the University of Southern California's Information Sciences Institute (ISI) and the Argonne National Laboratory. The testbed grid at the SC97 conference in San Jose's McEnery Convention Center Nov. 15-21 will harness approximately 3,000 data processors in the U.S. and Europe. GUSTO (Globus Ubiquitous Supercomputing Testbed) is the latest development of the Globus system, an integrated set of software components for next-generation high-performance Internet computing. "By providing pervasive access to supercomputing capabilities, computational grids will change the way we think about and use high-end computing," said Ian Foster of Argonne, who co-leads the Globus project with Carl Kesselman of ISI. "We're excited to take this step toward establishing a permanent computational grid facility." "From previous experiments, we know that both the technical and organizational obstacles to creating such integrated grids are tremendous," Dr. Kesselman said. "However, the cooperation that we have received from all participants has been amazing. People are clearly ready for this next step towards widespread collaborative supercomputing." Drs. Foster and Kesselman believe that future computational grids will place the most advanced supercomputers, data archives, virtual-reality displays, and scientific instruments at the fingertips of the nation's scientists and engineers -- regardless of where tools or people are located -- and hence enable new problem solving techniques, such as distributed supercomputing, remote visualization, and tele- immersion. At SC97, 10 groups will use Globus software and GUSTO resources for a range of distributed supercomputing applications, including:
--------
134-> Brain Scans Prove Dopamine's Involvement In Cocaine Abuse
Scientists at Johns Hopkins have used brain scans to show that intravenous doses of cocaine increase the availability of dopamine, the brain's "feel-good" chemical.	Dopamine's activity appeared to increase two to three times over baseline levels in the brain area studied, the putamen, compared to a control area, the cerebellum. Although the increase cannot yet be directly linked to a cocaine user's "high," investigators report that this is the first time anyone has directly demonstrated that cocaine makes more dopamine available in the human brain. Improvements in scanning technology eventually may track cocaine's effects on the dopamine-generating nucleus accumbens, a smaller area nearby in the brain that is known to play a role in addictive behavior in animals, adds Godfrey Pearlson, M.D., professor of psychiatry and a lead author on the paper. "The new finding should advance efforts to understand addiction and treat it by blocking the euphoric effects of drugs," says Pearlson.		Brain cells use dopamine by binding the chemical to specific openings on their surfaces.  Pearlson used these openings to measure dopamine activity.  First, he injected cocaine users with the compound raclopride, which binds to these same receptors.  The raclopride was equipped with a mildly radioactive "tag" visible on positron emission tomography (PET) brain scans.	Soon after, scientists gave the subjects an injection of a placebo and scanned their brains.  Several hours later, the same subjects received a second dose of raclopride followed by a "street-equivalent" dose of cocaine.  Then they scanned the patients again.	"Because the raclopride and dopamine compete for the right to bind to the same receptors, we could compare the two sets of scans and be virtually certain that the differences in the second group were caused by extra dopamine produced by cocaine exposure," says Thomas Schlaepfer, M.D., now at the University of Bern in Switzerland.	"It's likely cocaine affects other neurotransmitters besides dopamine, and these may also be helping create the immediate  rush' or feeling of euphoria caused by cocaine," Pearlson explains.  "But dopamine is still obviously a very important part of drug addiction.  Marijuana, alcohol and  heroin all initially act on different brain systems, but the common bond between them is that they all also increase dopamine availability." The study, published with an accompanying commentary, in the September issue of the American Journal of Psychiatry, was funded by the National Institutes of Health, the Swiss National Science Foundation, the Roche Research Foundation, the CIBA Research Foundation, and other government and private sources. Other authors were Dean Wong, M.D.; Stefano Marenco, M.D.; and Robert Dannals, Ph.D.
--------
135-> Surviving AIDS Appears To Require Permanent Triple-Drug Therapy
Researchers from Johns Hopkins, the Aaron Diamond AIDS Research Center (New York, N.Y.) and the University of California, San Diego, have shown that drug "cocktail" therapy for AIDS does not completely clear the body of HIV. Rather, small amounts of the virus remain "hidden" in immune system cells, unable to cause disease or develop resistance to anti-AIDS drugs. The findings give hope for long-term survival with HIV infection. But the results also suggest these individuals must continue multiple-drug therapy to prevent reactivation of the infection and active disease. The "cocktail" comprises the relatively new protease inhibitors, plus such long-used drugs as AZT and ddI. "The bad news is we can't yet get rid of the virus entirely," says Robert F. Siliciano, M.D., associate professor of medicine. "The number of immune system cells that remain infected with HIV declines only very slowly. But the good news is that as long as people infected with HIV keep taking the triple-drug cocktail, they have an excellent chance of surviving the infection for a long time, without developing symptoms of the disease."  Siliciano is senior author of an article reporting these results in the Nov. 14 issue of Science. The study was funded by the National Institutes of Health (Center for AIDS Research) and by the Research Center for AIDS and HIV Infection of the San Diego Veterans Affairs Medical Center. The new results follow reports by Aaron Diamond researcher David Ho, M.D. that drug cocktail therapy reduced HIV to such low levels it was no longer detectable. Ho suggested that treatment might stop active replication of the virus completely. The present study was undertaken to find and measure HIV "reservoirs" if they existed. "Ho's idea of measuring the decline in the level of HIV in various reservoirs of the virus was a revolutionary way of looking at the disease," says Siliciano. "Our study identified a specific reservoir that may persist for a long time." The Hopkins-led researchers studied 22 patients treated with triple-drug therapy for up to 30 months. The patients, who were treated at the Johns Hopkins AIDS Service, received close supervision to ensure they remained on their demanding treatment schedule. This prevented patients from suffering rebounds in their HIV levels and provided the team with a group of  individuals with no detectable levels of HIV measurable by standard laboratory methods. CD4+ lymphocytes are immune system cells targeted by HIV. Most CD4+ lymphocytes infected with HIV produce many copies of the virus before dying. But some of these infected cells survive, become inactive, and enter a resting phase. During the resting phase, these infected cells do not produce new copies of HIV, but remain a reservoir of the virus that triple-drug therapy cannot eliminate, the researchers say. "We studied patients whose viral loads had been undetectable for prolonged periods of time," says Joel Gallant, M.D., director of the AIDS outpatient clinic. "That kind of success in keeping levels so low was achieved by the combined efforts of our AIDS Service staff and highly motivated patients. That was important in our ability to study HIV in their resting CD4+ cells." Several Hopkins scientists, led by Joseph B. Margolick, M.D., Ph.D., used a sophisticated cell-sorting technique called flow cytometry to produce very pure populations of resting CD4+ cells from the partially purified cells provided by Siliciano. "We have a special facility for sorting out cells from HIV-infected people, while minimizing hazard to laboratory workers," Margolick says. "Using the highly purified cells, we found that even after triple-drug therapy reduced HIV to undetectable levels,  AIDS virus genetic material remained "hidden" inside "resting" CD4+ lymphocytes," says Diana Finzi, a graduate student working with Siliciano, and lead author of the study. "The team also showed that when the resting cells were stimulated to reproduce, the AIDS virus also replicated." The multi-institutional study also found that "cocktail" therapy increased the numbers of healthy, uninfected CD4+ cells in all patients--strong evidence that the treatment was successful despite the potentially deadly reservoir of HIV in resting CD4+ cells. "Fortunately, however, HIV in these resting cells doesn't appear to mutate into drug-resistant forms during triple-drug therapy," Siliciano says.  "And because the virus mutates only when it's replicating, this lack of drug resistance suggests the virus is not replicating. So this is a strong argument for not taking these patients off triple-drug therapy." Other authors of the paper include Martin Markowitz and David Ho (Aaron Diamond AIDS Research Center,  New York, N.Y.); Douglas D. Richman (University of California, San Diego); and Monika Hermankova, Theodore Pierson, Lucy M. Carruth, Christopher Buck, Richard Chaisson, Thomas Quinn, Karen Chadwick, and Ronald Brookmeyer (Johns Hopkins).
--------
136-> New Theory Provides Explanation For Flowing, Liquid Water On Ancient Mars
There is ample evidence from photographs--provided by Viking, Mars Pathfinder and Mars Global Surveyor--of deep channels on the surface of Mars presumably cut by flowing liquid water. How could Mars--at Pathfinder's landing site a chilly minus 100 F--once have been warm enough to have liquid water on its surface? The answer, says a University of Chicago climatologist and his French colleague, is reflective carbon-dioxide ice clouds that retain thermal radiation near the planet's surface. The scientists' theory is published in the Friday, Nov. 14, issue of the journal Science. "This is a problem that has perplexed scientists ever since the '70s, when Viking provided the first detailed images of Mars," said Raymond Pierrehumbert, University of Chicago Professor of Geophysical Sciences. "How can you account for Mars being warm enough to have flowing water, especially when the sun was actually fainter early in Mars' evolution?" Pierrehumbert collaborated with French climatologist François Forget, from the Laboratoire de Météorologie Dynamique du CNRS in Paris. Previous models of the atmosphere of ancient Mars have incorporated carbon dioxide in the atmosphere to use effects similar to global warming to heat the planet. "The problem was," said Pierrehumbert, "when you try to put enough CO2 in the atmosphere to warm it sufficiently, the carbon dioxide condenses out. It was thought that the thick clouds that form as a result would reflect sunlight back to space and actually cool the planet. "When we re-examined this, we found that this dry-ice `blanket' actually warms the planet because it reflects infrared light back to the surface more than it reflects solar radiation outward." The curious property of carbon dioxide ice clouds, as opposed to the water ice clouds found on Earth, is that the particles are large enough to scatter infrared light more effectively than visible light coming from the sun. Ordinary, Earth-type clouds absorb heat from the planet's surface and re-emit it both back to the surface and to outer space, losing half of the heat in the process. "But the carbon dioxide clouds act like a one-way mirror, and, although not a lot of sunlight gets through to the planet's surface, what does reach the planet is converted to heat, which the clouds then reflect back to the surface," said Pierrehumbert. "This mechanism produces a large enough effect that it can, in fact, warm the planet to the point where it is possible to have liquid water." Pierrehumbert said this climate model provides some clues as to the types of life forms that might have evolved on Mars. "If we're going to be looking for analogues of terrestrial life forms on Mars," he said, "then we should be looking for the kinds of organisms that might evolve in extreme environments, like the bottoms of oceans or in caves. "The conditions on early Mars--some four billion years ago--were a little more like the conditions at the bottom of the ocean than like a rainforest. It would have been dark, warm enough for liquid water, but without a large energy source for photosynthesis," he said. Pierrehumbert and Forget's model also extends the habitable zone on extrasolar planets and increases the likelihood that life exists outside our solar system. Previously, scientists thought that only planets orbiting within 1.37 astronomical units (one AU is the distance between Earth and the Sun) of a star could have water above the freezing point. But if the planets have carbon-dioxide ice clouds, they could have liquid water as far away as 2.4 AU. Mars is 1.52 AU from the Sun. Similarly, carbon-dioxide ice clouds could have played a role in warming Earth when the Sun was fainter than it is today, preventing a global freeze that could have kept Earth locked forever in ice. If the Earth had ever cooled to the point where its oceans had all frozen, it would never have warmed up again because too much solar radiation would have been reflected back to space by all of the surface ice. Pierrehumbert and Forget say their model fits well with a theory proposed by Carl Sagan and Christopher Chyba, and published in Science earlier this year, that a methane and ammonia atmosphere warmed early Mars. "The problem with methane," said Pierrehumbert, "is that it breaks down very quickly when exposed to sunlight, so you need a biological engine--life on Mars--to feed the atmosphere as the methane is depleted. Our model provides the starting conditions under which life could have evolved and started the production of methane gas. And once the gas forms, the carbon dioxide ice clouds actually shield the methane from sunlight and keep it from breaking down as quickly." Pierrehumbert and Forget next plan to tackle the problem of what weather might have been like on early Mars, including the possibility of carbon dioxide blizzards and carbon dioxide-ice glaciers.
--------
137-> Study Findings May Lead To Earlier Diagnosis And Treatment Of Atherosclerosis
PITTSBURGH, Nov. 11 -- Earlier diagnosis and treatment of atherosclerosis may be possible using specially engineered, gas-filled microbubbles, according to a study by researchers at the University of Pittsburgh Medical Center (UPMC). The study will be presented Nov. 11 by Flordeliza S. Villanueva, M.D., assistant professor of medicine in the division of cardiology, at the annual scientific session of the American Heart Association in Orlando, Fla. Microbubbles, gas-filled microspheres the size of red blood cells, are used in contrast echocardiography, an ultrasound technique used to detect blood flow to the heart muscle in conditions such as angina or heart attack. One of the first processes leading to atherosclerosis involves the inflammation of the endothelial cells which line blood vessels. The researchers wanted to find a way to identify these abnormal endothelial cells which are harbingers of atherosclerosis. To simulate the inflammation which occurs on endothelial cells during early atherosclerosis, cultured endothelial cells were experimentally stimulated to produce a protein on their surface called ICAM-1. ICAM-1 is thought to be centrally involved in the development of atherosclerosis. "Currently, we have no techniques for identifying this potentially reversible, major change in endothelial cells in humans," Dr. Villanueva said. The study, performed in collaboration with William Wagner, Ph.D., assistant professor of surgery and chemical engineering at the UPMC's McGowan Center for Artificial Organ Development, attempted to develop contrast echocardiography as a method to study this very early abnormality which occurs in patients who subsequently develop coronary artery disease. In their study, the researchers cultured human coronary artery endothelial cells on lab coverslips. Three types of microbubbles were made; one containing anti-human ICAM-1 monoclonal antibody, one with non-specific murine immunoglobulin, and one with no added proteins. Some of the endothelial cells were stimulated by interleukin-1 while others were not. Both groups were then exposed to one of the microbubble preparations. Researchers then counted the number of microbubbles which bound to the endothelial cells. According to the study, binding of microbubbles to normal endothelial cells was minimal, however, there was a 40-fold increase in adherence of the microbubbles containing anti-ICAM-1 to the activated endothelial cells. These adherent microbubbles can then be detected using ultrasound imaging (echocardiography). "This may allow us to localize an area of the artery where atherosclerosis is just developing so that we can intervene at a much earlier disease stage than is currently possible," said Dr. Wagner.
--------
138-> Scientists Close To Finding Gene That Controls Growth Of Lung Cancer
DURHAM, N.C. -- In what may move scientists a step closer to locating a gene that helps control the growth of lung cancer, researchers at Duke University Medical Center have found in a new study that fragments of a portion of a human chromosome slow tumor growth in mice and in cell cultures. The strand of DNA that was the focus of the study was chromosome 11. The researchers said they believe a specific section of that chromosome contains a tumor suppressor gene that controls the spread of lung cancer. The finding was published in the September/October issue of the international journal Anticancer Research. "Whatever is in this region on chromosome 11 is able to change the growth and morphology of already formed cancers, and that's an important aspect of this study," said Dr. Gerold Bepler, associate professor of medicine at Duke and senior author of the report. "It means that, whatever is broken in that system, if you repair it, you may be able to change the biologic behavior of the existing cancers." About 177,000 people in the United States are expected to be diagnosed with lung cancer this year, making it the leading cause of cancer death for men and women in the nation. More people die each year of lung cancer than of colon, breast, and prostate cancer combined, and annual treatment costs amount to about $5 billion, according to the American Cancer Society. The research was supported by grants from the Jimmy V Foundation, the North Carolina Biotechnology Center, and the National Cancer Institute. Bepler began looking at chromosome 11 as a possible location for a gene or genes that cause lung cancer several years ago. He and his colleagues had found that a large percentage of patients were missing a portion of chromosome 11. This region is called LOH11A and is associated with the spread of tumor cells. Therefore, he said, that segment of chromosome 11 probably contains a gene that controls the aggressiveness of lung cancer. The scientists were looking for tumor suppressor genes, which play a key role in whether a patient gets cancer. Tumor suppressor genes are normal genes that act to inhibit the formation of cancerous cells, but if the genes become mutated and are unable to do their job, there is nothing to stop the tumor from growing. In this study, the researchers took a normal segment from the LOH11A region and inserted it into tumors that were then studied in mice and in liquid cell cultures in laboratory dishes. They found that half of the tumors did not grow at all, and half demonstrated greatly suppressed growth. They used chromosome 12 as a control, since it has not been implicated in lung cancer, and found that the tumors injected with the control chromosome grew at the usual rate. As a result, they believe that a tumor suppressor gene may be within the LOH11A region of chromosome 11. Bepler, who also serves as chief of hematology/oncology services at the Veterans Administration Medical Center in Durham, said the discovery "provides further confirmation that a tumor suppressor gene is located in LOH11A on chromosome 11. If you put this piece of chromosome 11 back into a cancer cell line, it grows much more slowly, if at all." He said the study is "an entirely different approach" to finding the tumor suppressor gene that causes lung cancer than previously taken by his group. In the past, the researchers focused on DNA at the molecular level, whereas the new study takes a biological approach, looking at the tumors themselves. Bepler and his colleagues hope their work could eventually lead to new treatments for lung cancer patients after further study and refinement. The pieces of chromosome used in this study are too large to insert into tumors in patients, he said. That's why it's important to find the gene itself, which is small enough to be injected into the tumor cells without being rejected. Currently, lung cancer is treated with surgery in the early stages, or surgery combined with radiation therapy and chemotherapy in the advanced stages. About 75 percent of patients who have surgery in the early stages will eventually have recurrent disease. The five-year survival rate for all stages is 14 percent. Symptoms often do not appear until the disease has advanced, so early detection is difficult. Bepler said the next step is to find the tumor suppressor gene, and his team continues to search for a gene or genes responsible for the disease. Other authors of the paper were Kathy O'Briant, Ethel Jolicoeur, Jennifer Garst, Mike Campa, and Gilbert Schreiber, all of Duke.
--------
139-> U-M And U-Ill. Chemists Create Molecular Antenna To Harvest Light
ANN ARBOR---Imagine your roof covered with a thin film of organic molecules busily converting sunlight into electricity. Visualize tiny molecular flashlights illuminating the DNA of living cells. Picture microscopic optical sensors that change color when exposed to trace amounts of chemicals. Science fiction? Scientists at the University of Michigan and the University of Illinois at Urbana-Champaign don't think so. They have developed a new class of large dendrimer supermolecules which, they say, could one day be used for all these applications and more. "Normally, light energy disperses randomly throughout a molecule," said Raoul Kopelman, the U-M's Kasimir Fajans Professor of Chemistry, Physics and Applied Physics. "But these molecules have a specific tree-like structure which allows them to funnel light energy through the branches and direct it to a central point." When photons of ultraviolet light hit a group of light-harvesting atoms on a branch of one of these supermolecules, the absorbed energy travels down the branch in the form of energy packets called excitons. Losing a small amount of energy at each branching point, excitons keep falling toward the center of the molecular tree until they finally drop, one at a time, into a molecular "trap," which is attached to the dendrimer's center. In the "nanostar"---the most optimally designed version of these dendrimers to be developed so far---photosensitive molecules in the trap convert exciton energy back into visible light with up to 99 percent efficiency. "It works like a miniature quantum well in a semiconducting circuit," said Stephen F. Swallen, U-M postdoctoral fellow in chemistry. "The excitons don't have the extra energy to climb back up the molecule, so they just keep falling into the trap." Synthesized from repeating molecular units called phenylacetylene monomers, which branch out from a central core, dendrimers are among the largest structurally controlled organic molecule ever created, according to Jeffrey S. Moore, professor of chemistry at the University of Illinois at Urbana-Champaign. The biggest molecule they have synthesized so far contains 127 chromophores or light-harvesting units. Each dendrimer is custom-made by Moore and his colleagues to Kopelman's specifications to produce different chemical and physical properties for different applications. One of the most significant properties of the new molecules is their ability to resist photobleaching. "Anyone who has ever had a sweater fade or disintegrate after exposure to sunlight has experienced photobleaching," Kopelman said. "Molecules can only absorb and emit photons a limited number of times before they fall apart. Photobleaching is a particularly important factor for these dendrimers, because they interact with light very strongly." Their specific chemical composition and physical structure make it possible for the dendrimers to resist photobleaching, according to Swallen. "While most organic molecules will decompose if multiple excitons are concentrated at the same spot, the nanostar can protect itself by diverting some excess energy away from the center back to the outer parts of the dendrimer," he explained. "Because the molecule is never hit with more energy than it can handle, it lasts much longer than ordinary molecules when exposed to light." Research funding for the project is provided by the National Science Foundation and the Office of Naval Research. Collaborators included Michael R. Shortreed of Iowa State University, Zhong-You Shi of the University of Michigan; Weihong Tan of the University of Florida, Gainesville; Zhifu Xu of PPG Industries; and Chelladurai Devadoss and Pamidighantam Bharathi from the University of Illinois, Urbana-Champaign.
--------
140-> HIV Persists And Can Replicate Despite Prolonged Combination Therapy
HIV persists and can replicate in patients who have no detectable virus in their blood as a result of combination antiretroviral therapy, according to a new report from researchers at the National Institute of Allergy and Infectious Diseases (NIAID) and theircolleagues. "Our findings indicate that an inducible reservoir of HIV exists in infected patients despite prolonged treatment with highly active antiretroviral therapy (HAART), and suggest that the time required for eradication of HIV from the body, if indeed possible, may beconsiderably longer than previously predicted," says lead author Tae-Wook Chun, Ph.D., of NIAID's Laboratory of Immunoregulation (LIR). Adds senior author Anthony S. Fauci, M.D., NIAID director and LIR chief, "These results underscore the importance of developing more potent antiretroviral drugs, as well as treatment strategies that specifically target latently infected cells that serve as hiding places for the virus.  Although our current armamentarium of antiretroviral drugs has served many patients well, at least in the short-term, more progress must be made in the area of HIV therapeutics if we are to speak of a cure for HIV disease." Drs. Chun, Fauci and colleagues report their findings in the Nov. 25 issue of the Proceedings of the National Academy ofSciences (PNAS).  The embargo date for the PNAS paper has been moved to Nov. 13 at 4:00 p.m. ET to coincide with the publication of two related reports in the journal Science from the laboratories ofNIAID grantees Robert F. Siliciano, M.D., Ph.D., of Johns Hopkins University in Baltimore, and Douglas D. Richman, M.D., of the University of California, San Diego. In their experiments, Drs. Chun, Fauci and colleagues studied 12 HIV-infected patients who were taking three-drug antiretroviral regimens consisting of a protease inhibitor (indinavir, ritonavir or saquinavir) combined with two nucleoside analogues (3TC, d4T, AZT or ddI).  A thirteenth patient received two protease inhibitors and two nucleoside analogues. These 13 patients had been taking HAART for an average of 10 months.  In addition, four HIV-infected patients receiving no therapy and one taking 3TC only were included in thestudy population. Of the 13 patients receiving HAART, nine had levels of HIV RNA in their plasma below 500 copies/cubic milliliter (ml), the detection limit of the branched DNA (bDNA) assay used in the study. The researchers isolated highly purified, resting CD4+ T cells from all 18 patients, and used a sensitive laboratory technique called the polymerase chain reaction to detect HIV DNA in an integrated form (i.e., inserted into the genes) in cells from each individual. "Interestingly, levels of integrated HIV DNA were not significantly higher in untreated patients than in HAART-treatedindividuals," notes Dr. Chun.  "As others have postulated, this finding suggests that resting CD4+ T cells with integrated DNA do not decay rapidly in patients receiving HAART, and therefore may serve as a stable 'reservoir' of virus." In addition to integrated HIV DNA, the investigators found unintegrated DNA in cells from all patients. "The presence of unintegrated HIV DNA suggests that a low level of viral replication may continue even in the setting of HAART," notes Dr. Fauci.  "In HAART-treated patients, we found that levels of unintegrated HIV DNA were 28 times higher than integrated HIV DNAlevels.  This suggests that even when HIV is undetectable in the plasma, a low degree of viral replication contributes to the maintenance of a reservoir of HIV-infected CD4+ T cells." The investigators activated the resting, purified CD4+ T  cells from all study patients and induced replication-competent virus from each patient's samples, including from the nine with no detectable virus in their blood.  Of note, the virus they induced from the cells of three of nine HAART-treated patients with undetectable virus was"syncytium inducing" -- it efficiently killed cells in culture by causing them to clump together. "Activation of at least some latently infected resting CD4+ T cells in patients receiving HAART can result in the production of cytopathic virus," says Dr. Chun. Co-authors of Drs. Chun and Fauci include Lieven Stuyver, Ph.D., of Innogenetics N.V., Ghent, Belgium; Stephanie B. Mizell,R.N., Linda A. Ehler, R.N., and JoAnn M. Mican, M.D., of the NIAID Laboratory of Immunoregulation; Michael Baseler, Ph.D., of Science Applications International Corporation-Frederick, Md.; and Alun L.Lloyd, Ph.D., and Martin A. Nowak, Ph.D., of the University of Oxford, England. NIAID is a component of the National Institutes of Health (NIH).  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, malaria, tuberculosis, asthma and allergies.  NIH is an agency of the U.S. Department of Health and Human Services.                                                              ### Reference:  Chun T-W, et al. Presence of an inducible HIV-1 latent reservoir during highly active antiretroviral therapy. Proc Natl Acad Sci USA 1997;94:13193-7. Press releases, fact sheets and other NIAID-related materials are available on the Internet via the NIAID home page athttp://www.niaid.nih.g 
--------
141-> Mars Penetrators Successfully Complete Crucial Subsystem Test
 Two miniature science probes designed to penetrate the Martian surface and analyze the water vapor content of the planet's subterranean soil in 1999 have successfully completed a crucial subsystem test deep in the New Mexico desert. This successful check of the batteries and soil collection drill of the mission known as Deep Space 2 (DS2) provides a "green light" for subsequent integrated system tests next spring, said Sarah Gavit, DS2 project manager at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA.  The DS2 mission hardware will be launched in January 1999, mounted on the Mars Surveyor '98 Lander.  Both missions will arrive on Mars in December 1999. DS2 is the second scheduled launch in NASA's New Millennium Program, which is designed to test new advanced technologies prior to their use on science missions in the 21st century.  DS2 will validate the ability of small probes loaded with sensitive, miniaturized instruments to analyze the terrain of planets and moons throughout the Solar System. In the late October test, a 4.4-pound (two-kilogram) prototype probe containing a soil collection drill and a circular group of eight lithium thyonal chloride cells -- forming two batteries -- was shot into the ground at more than 400 mph (644 kilometers per hour).  The drill survived a 20,000-G impact, and the batteries, nestled inside a custom-designed casing, survived a 45,000-G impact intact.  Both continued to function as designed.  One G is the normal force of gravity on Earth. "The Mars Pathfinder lander experienced about 19 G's when it hit the Martian terrain in July, so you can see that we are working at enormous rates of deceleration," explained Gavit.  "One of our biggest challenges has been to find a way for our components to survive such a high deceleration force.  The items at highest risk are the batteries, their packaging and the motor drill assembly. "Although the recent test was one in a long series, it was the first test using flight-like hardware and packaging, so it served as a complete qualification of the battery and drill subsystems," she added. The probe design features two modules:  a circular aftbody, five inches (13 centimeters) in diameter, containing the batteries, that remains atop the surface; and a four-inch-long (10-centimeter) forebody, containing the drill and a soil analysis instrument, that should burrow up to six feet (1.8 meters) into the Martian soil.  The two modules are connected via a flex cable that unravels as the forebody dives into the soil after a freefall impact. Once in the ground, the soil collection drill slowly twists out from the side of the forebody and retracts a tiny soil sample into a chamber within the forebody, where it is analyzed by a water detection instrument.  This instrument's key feature is a miniature tunable diode laser, similar in principle to the lasers used in consumer CD players.  The soil sample is then heated, creating a vapor that passes through the path of the laser beam if water is indeed present.  This resulting change in the intensity of the laser light indicates the amount of water, if any, to be found in the Martian soil sample. The aftbody features batteries developed just for DS2.  These batteries can operate down to minus 112 degrees F (minus 80 degrees Celsius), making them the only batteries of this type with the dual capability of being able to survive the strong impact and work in low temperatures.  The aftbody also includes a micro-telecommunications system that, together with miniaturized electronics in the forebody, will relay the probe's findings to the orbiting Mars Global Surveyor spacecraft for transmission to Earth via NASA's Deep Space Network. The Oct. 29 test took place at the New Mexico Institute of Mining Technology's Energetic Materials Research and Test Center in Socorro, NM. It was the 53rd test of DS2 hardware since the spring of 1996, beginning with early tests of preliminary battery and drill designs, among many other components. Additional information about DS2 can be obtained by visiting the project's World Wide Web site at URL:  http://nmp.jpl.nasa.gov/ds2/ JPL manages the New Millennium Program for NASA's Office of Space Science and Office of Mission to Planet Earth, Washington, DC.  JPL is a division of the California Institute of Technology, Pasadena, CA.
--------
142-> New Study Shows Devastating Losses To Florida's Coral Reefs During Past Year; Causes Still Unclear, Scientists Say
ATHENS, Ga. -- New information gathered last summer shows that diseases on Florida's coral reefs have dramatically increased with potential long-term consequences for the coral reef ecosystem. The study, part of the Environmental Protection Agency's Coral Reef Monitoring Program, found that the incidence of the disease has increased by 276 percent from 1996 to 1997. Perhaps even more ominous, the number of coral species with diseases has increased 211 percent in the same time period. "In the late 1980s, we were following five or six diseases on Florida's coral reefs, but we now know of 13, some of which are entirely new to science," said Dr. James W. Porter, an ecologist from the University of Georgia who is a principal investigator for the project. "We are really stunned at what we found. There is no precedent for what has happened in the past year." Porter will report on the team's findings on Tuesday, Nov. 18, from 4-5:30 p.m. in the Carmichael Auditorium of the Smithsonian Institution's American History Museum in Washington, D.C. His speech is sponsored by the Ecological Society of America, the National Oceanic and Atmospheric Administration, the Smithsonian and the EPA. Other members of the team investigating the coral reefs are Phil Dustan of the College of Charleston and Walt Jaap of the Florida Marine Research Institute in St. Petersburg, Fla.. The new information comes from 160 monitoring stations that range from Key West to Key Largo. Porter said that the widespread and increasing damage to the reefs was obvious to the naked eye but that final data shocked even the scientists. In 1996, 25 monitoring stations showed signs of disease, while in 1997, that had risen to 94 stations. In addition, nine of 44 species showed disease in 1996, but a startling 28 species showed diseases a year later. Porter does not believe that the newly discovered coral diseases have recently evolved. Instead, they may have existed in the oceans for some time, but the coral may not have been susceptible to them. While there is no evidence that coral have anything analogous to a mammalian immune system, some change in the coral ecosystem has apparently made them susceptible to a wide range of diseases. "On one reef near Key West, some 80 percent of the Elkhorn coral were killed between 1994 and 1997," said Porter. "This is of great concern, since Elkhorn coral is the primary frame builder of the reef." The problem extends far beyond the damage to the coral itself. While coral is an animal related to the sea anemone, it carries in its tissues a symbiotic algae that allows the corals to produce more oxygen than they consume. This productivity is crucial to the overall health of the coral reefs, which support fishes and sea life crucial to the area's economic stability. While widespread damage is obvious, the scientists are stymied in understanding much about the 13 diseases, having discovered the origins of only three of those coral diseases. Early in the study, they considered that human interference such as chemical dumping might have caused the problems, but that theory has largely been discredited. In fact, the team has shown that the diseases can be transmitted from coral to coral simply by touching an uninfected coral with a diseased one. "We are beginning to identify the disease species, but most of them are without proper scientific names," said Porter. Instead, the team has casually divided the diseases into "stompers" and "jumpers." Porter said "stompers" are diseases that infect fewer reefs but cause extremely high mortality. "Jumpers" are diseases that cause low-level infections but which move from area to area very rapidly. The researchers also discovered last summer a disturbing new concern -- diseased fishes swimming on the reefs. Porter, who has been diving in the Florida reefs and studying them for many years, said that the etiology of these diseases in the area is unknown. Some fish are showing red spots on their undersides that could be related to fish-disease outbreaks seen earlier in North Carolina estuaries. Reasons for the sudden decline in the coral reefs are many, but none has yet been proved. One idea proposed by Dr. Drew Harwell of Cornell University is that the fungus Aspergillus is being transferred by runoff from the land into Florida Bay. This is a method of direct infection, but there are also those who propose more indirect methods of infection. By these theories, poor water quality may be influencing the resistance of the corals to disease. The problem is that no one knows if lower invertebrates even have an immune system, much less how certain infections affect them. "The entire situation is really puzzling and alarming," said Porter. "If these diseases increase in the next two years as fast they have is the past year, coral mortality rates could begin to threaten the entire reef ecosystem." In addition to Porter, experts from the sponsoring organizations will be available before and after his speech at the Smithsonian.
--------
143-> Earth Cools In Persistent, 1,500-Year Rhythm, Say Columbia Scientists, Working From Sea Cores
Earth's climate cools significantly and abruptly every 1,500 years or so in a persistent, regular rhythm, a team led by scientists at Columbia University's Lamont-Doherty Earth Observatory reports in the Nov. 14 issue of the journal Science. The newfound naturally occurring climate cycle has continued uninterrupted over at least the past 32,000 years, said the scientists, who believe the last such cycle may have taken place 300 years ago. The periodic sudden cold spells have occurred both when the Earth was covered with massive glaciers during the last ice age and have persisted even after human civilization began to flourish in a relatively warm, ice-free era that scientists had previously thought was resistant to dramatic climate shifts. The newly discovered cycle appears to be "a pervasive component of the Earth's climate system," the scientists wrote. "The cycle may well be the pacemaker of rapid climate change." The discovery will prompt a search to explain this recurring, large-scale climate pattern, and finding the cause will provide a fundamentally new understanding of how Earth's climate system can shift abruptly and dramatically, said Gerard Bond, a paleoclimatologist at Lamont-Doherty, Columbia's earth sciences research institute in Palisades, N.Y. The finding of abrupt climate shifts in the modern era adds an important new factor in predicting future global climate change, he said. And it throws new light on historical events, such as the Little Ice Age, a cold spell that gripped the world in the 17th and 18th centuries and might prove to be the most recent manifestation of the phenomenon. The scientists re-analyzed sediments cored decades ago from the bottom of the Atlantic Ocean by Lamont's legendary research vessel, the Vema, and preserved in Lamont's deep-sea core repository, which holds the world's largest collection of ocean sediment cores from every ocean in the world. The scientists found evidence that on average, every 1,470 years, plus or minus 500 years, cold, ice-bearing waters, which today circulate around southern Greenland, pushed as far south as Great Britain. The polar waters penetrated a warm North Atlantic current that prevails today, and may have disrupted the global ocean circulation pattern that keeps the North Atlantic region warm. The ocean circulation disruption may well have had far-flung, worldwide effects, they said. The ocean sediment evidence agrees with chemical clues from Greenland ice cored by other researchers, which show that the air above Greenland cooled in precisely the same pattern. The 1,500-year cold snaps dropped average temperatures throughout the North Atlantic region within a century or two, and probably faster, the scientists said. Temperatures stayed cold for several hundred years, then warmed again as quickly as they cooled. Reporting the finding with Dr. Bond, the lead author, were: Maziet Cheseby, Rusty Lotti, Peter Almasi, Peter deMenocal, Paul Priorie and Heidi Cullen, all of Lamont-Doherty; William Showers of North Carolina State University; and Irka Hadjas and Georges Bonani of ITP ETH in Zurich, Switzerland. The scientists analyzed two ocean sediment cores from opposite sides of the North Atlantic, one from off the southwest coast of Greenland and the other more than 600 miles to the south, off the coast of England. The found regularly spaced layers of microscopic rock particles that originated from Greenland and Svalbard, an island in the Arctic Ocean, as well as glass from Icelandic volcanoes. The tiny particles had been transported by glacial icebergs and sea ice to the North Atlantic, deposited on the seafloor and buried by subsequent sediments. At times of coolings, the number of particles doubled or tripled in both ocean sediments, indicating that the amount of floating ice increased and extended further south. At the same time, the scientists also analyzed the sediments for the skeletal remnants of microscopic marine plankton. They found that the abundance of cold-water-loving plants increased and the amount of warmer-water plankton decreased in the same 1,500-year cycle. That indicated that the North Atlantic surface water temperatures dropped as far south as Great Britain. The increase in floating ice may have resulted from cooler air temperatures that caused glaciers to advance and sea ice to spread. Or cooler ocean temperatures may have allowed more ice to survive long transits before they melted. The melting ice, in turn, may have added fresh water to the North Atlantic and disrupted the delicately balanced global ocean circulation system, known as the Great Ocean Conveyor, which is set in motion by the sinking of denser, salty water in the North Atlantic. The team was only able to confirm the pattern of abrupt climate shifts to 32,000 years ago, the limit of radiocarbon dating techniques. However, the scientists are currently seeking to learn whether the cycles persisted even before the last ice age began, as far back as the Eemian Period, more than 115,000 years ago, when the Earth's climate was relatively warm like today's. Dr. Bond, Dr. deMenocal and William B.F. Ryan of Lamont-Doherty will lead an expedition this spring to collect new ocean sediment cores to see if the climate trend has continued to the present. They will use a new coring device that does not ruin the top sections of the sediments, which represent the most recent times, as it is thrust into the ocean floor. The research was supported by the National Science Foundation and the National Oceanic and Atmospheric Administration. Lamont's Deepsea Sediment Repository is supported by the NSF and the Office of Naval Research. Lamont-Doherty Earth Observatory is part of the Columbia Earth Institute, launched this year to develop innovations for wise stewardship of our planet.
--------
144-> University Of Washington Geneticist Clones Gene For An Inherited Form Of Deafness
A postdoctoral fellow in the laboratory of University of Washington geneticist Dr. Mary-Claire King has succeeded in cloning a gene which, when mutated, causes an inherited form of deafness. The findings of Dr. Eric D. Lynch and colleagues are reported in the Nov. 14 issue of the journal Science. The mutation in the autosomal dominant gene, DFNA1, is responsible for progressive hearing loss in a large extended family in Costa Rica. Of 196 family members identified in eight generations, 147 are still living and all participated in the research; 78 family members are deaf. Onset of deafness commences between age 6 and 20, and is complete by age 30. The gene mutation that causes their total hearing loss has been traced to a common ancestor, a man born in Costa Rica in 1713. The mutation causes no abnormalities other than deafness, and is found equally in males and females. "There are implications for general knowledge of hearing mechanisms," said Lynch, who in 1992 mapped the gene to the long arm of chromosome 5, and completed cloning it just last month. "We understood that the actin cytoskeleton is critical to normal hearing, but we didn't know how it was being formed and maintained. This gene give us some insight." The gene encodes a protein called human diaphanous 1, which interacts with a major structural protein called actin. Actin helps to stiffen an array of filament-like projections at the ends of the stereocilia, the hair cells of the inner ear that turn sound waves into electrical impulses that stimulate the auditory nerves. The projections are perturbed or depolymerized by sound waves, and normally are repolymerized by actin in order to function again. The researchers believe the gene may not allow the actin to repolymerize, preventing the hair cells from responding to sound waves. "While the mutation may be unique to this family, mutations in rare families hold the clues to universal biology," said King, professor of medicine and genetics at the UW, who mapped the first gene for inherited breast cancer (BRCA1) in 1991. "We know more about DFNA1 one week after it was cloned than we know about BRCA1 three years after it was cloned. DFNA1 is a mutation of an ancient gene descended from a gene in yeast, fruit flies and mice; it is critical to basic functions of cell division." King praised Lynch, who has worked in her lab since 1991, for the quality of his work. "This is a pure example of the use of genomic sequencing to find genes. We mapped the gene, then captured 800,000 base pairs in clones. Eric personally did all of the sequencing. A single researcher can do this, because of the informatics and the equipment available here at the University of Washington." King also singled out another post-doctoral fellow in her lab, biostatistician Dr. Ming K. Lee, who integrated a series of existing computer programs to facilitate the search for new gene sequences. Dr. Pedro E. Leon of the Center for Research in Cellular and Molecular Biology at the University of Costa Rica identified the family whose inherited deafness led to the discovery of the gene. "This was a very successful international collaboration," King said. "Pedro Leon's analysis of the hearing and his characterization of the genealogy were perfect. Any gains to be made as a result of identifying this gene will be shared with the family." King also commented on the challenges of studying the genetics of deafness. "It's very difficult because deaf people tend to marry other deaf people, and there may be more than one cause of deafness within a family." In the case of the Costa Rican family, however, with the later onset of deafness they tended not to marry other deaf people, simplifying the search for the single gene. "Now that this gene is cloned, many groups will be able to test for variations in it," said King. "The research is blossoming at an extraordinary pace." Further research will involve introducing the mutated gene into a mouse model. Additional co-authors are Jan E. Morrow and Dr. Piri L. Welsch of the King lab. The research was supported by the National Institutes of Health and the Markey Foundation. In an accompanying News and Views article in Science, Elizabeth Pennisi describes a number of research efforts underway to find this and other genes involved in hearing loss.
--------
145-> Blunt Blows From Baseballs, Hockey Pucks Cause Sudden Death In Young Athletes
ORLANDO, Nov. 12 -- Young athletes who drop dead without warning of unsuspected heart defects are widely publicized. But another type of sudden death on the playing field also kills many young sports participants each year -- and its victims have perfectly normal hearts. At the American Heart Association's 70th Scientific Sessions, researchers report today on the first large study of "comotio cordis," a syndrome in which the heart stops beating after a direct blow to the chest from a baseball, hockey puck or other "high velocity objects." Barry J. Maron, M.D., director of cardiovascular research at the Minneapolis Heart Institute Foundation and lead researcher in the study, says by focusing attention on comotio cordis, he and his colleagues hope to make coaches, athletes and bystanders more aware that it can occur and that quick recognition and response are essential to survival. "Just realizing that this is a real problem is important," Maron says. "In many cases onlookers simply assume that it is not a serious situation and treatment is delayed until its too late. We need to educate people involved in sports about this risk. "It appears that the blunt chest impact disrupts the rhythm of the heart," adds Maron. "It can be triggered by a blow from a baseball, softball or hockey puck and also by a collision with another player or an inanimate object such as a goal post." In their study, researchers examined 55 cases of sudden cardiac arrest among young sports participants, 90 percent of whom were 16 years of age or younger. Twenty-five were playing in organized athletic events such as baseball, softball and ice hockey at the time, and 30 others were engaged in informal sports activities at home or school or on the playground. None of the youth showed evidence of any heart defect or disease. "The blows they received caused no identifiable structural injury to the ribs, sternum or the heart itself and were, in effect, a relatively common occurrence in the games they were playing," says Maron. "Fewer than one in 10 young athletes survived the incident, although all had normal, healthy hearts," Maron says. "But with faster recognition and prompt action, a large percentage of commotio cordis cases are potentially reversible with cardiopulmonary resuscitation (CPR)." Response time is a critical factor in resuscitating victims of commotio cordis, Maron emphasizes. Of the five survivors in the study, four received CPR within one minute or less. At present, better education and faster reaction are undoubtedly the best ways to reduce fatalities, but the issue of how to prevent potentially deadly chest blows from occurring in the first place also needs to be addressed, Maron adds. "Making baseballs and softballs softer is one possibility," he says. "So is having batters in youth baseball wear chest protectors, but this may not be realistic. Altering equipment and the way games are played isn't a simple matter. For now, one of the best ways to save lives is through increased public awareness."
--------
146-> Scientists Find Millions Of Tiny, Tentacled Predators Threatening Already Vulnerable East Coast Fish
 SAN FRANCISCO -- Tiny, tentacled sea creatures, rarely seen drifting in the ocean, have been discovered thriving by the millions off New England's vulnerable Georges Bank over the past few years, threatening valuable cod and haddock, species that have already been decimated by overfishing in the area. Normally rooted to the sea bottom, the voracious animals, called hydroids, have been found floating free in concentrations as high as 100 per gallon of water, said Steve Bollens, associate professor of biology at San Francisco State University and a leader of the team studying the predatory animals. Each about a tenth of an inch across, they eat most of the daily production of small crustaceans, or copepods, which the fish larvae rely on. As a result, the hydroids have become one of the chief competitors of the commercial fish and may threaten their survival, Bollens said. Adding insult to injury, the hydroids also appear to kill the young fish directly. "We've seen them with their tentacles engulfing the head of larval cods," Bollens said. "When you add their potential impact as a predator of the fish, you can't ignore their importance." Bollens, who also holds a position at SFSU's Romberg Tiburon Center for Environmental Studies, presented the latest understanding of the Georges Bank hydroids at a seminar Wednesday (Nov. 12) at the Southwest Fisheries Center of the National Marine Fisheries Service in Tiburon, California. He is part of a team of marine scientists from seven institutions in Canada and the U.S. studying the hydroids' impact on the already-threatened Georges Bank cod and haddock populations. Other team leaders are Laurence Madin, chairman of the biology department at Woods Hole Oceanographic Institution, and Barbara Sullivan, professor of oceanography at University of Rhode Island. Hydroids are related to jellyfish and have two major life stages, one sedentary and one drifting. But although the predatory Georges Bank hydroids are drifting through the waters, they are clearly in their normally sedentary life stage. Some still trail tendrils that normally secure them to the ocean floor. Why and how they have become free-floating, uprooted armies is a major part of the group's research focus. Until now, no one has examined this behavior and its impact on local fish populations. "When we first recognized how many were in the waters, we asked each other how could this not have been studied before," Bollens said. "We wonder if this kind of predation has a significant impact in other areas." The new research is part of the five-year, $25-million Global Ocean Ecosystem Dynamics project, or GLOBEC, funded by the National Science Foundation and the National Oceanic and Atmospheric Administration to study the Georges Bank and its threatened fishery. The hydroids may have been ripped from their moorings by seasonal storms, or, more ominously, by commercial trawlers, Bollens said. Every square foot of the massive Georges Bank region has been scraped by the heavy chains used to hold down trawling nets and stir up fish. The chains are known to disturb the habitat, and they may account for a sizable number of the dislocated predators that plague the fish and their prime food source. A huge, traditionally rich fishing region off Canada and New England, the Goerges Bank has for generations been one of the world's most productive fishing waters. But in the past 10 years, fishing has declined so precipitously that much of the area has been closed off, in hopes the fishery will recover . The Romberg Tiburon Center for Environmental Studies is the marine sciences research arm of San Francisco State University, the second largest of the nationally recognized 23-campus California State University System.
--------
147-> Laser That Drills Holes In The Heart Cuts Chest Pain, Hospitalizations
ORLANDO, Nov. 12, 1997 -- Using a laser to drill tiny holes in the heart to provide new blood flow dramatically reduces chest pain and cuts hospitalizations for individuals whose heart disease makes them poor candidates for surgery or angioplasty, according to a report today at the American Heart Association's 70th Scientific Sessions. The procedure, called transmyocardial revascularization (TMR), allows blood from the pumping chamber of the heart to percolate up through the laser holes and supply the surrounding heart muscle with blood. TMR is available at only a few medical centers conducting Food and Drug Administration-approved investigations. Keith B. Allen, M.D., a cardiothoracic surgeon at St. Vincent Hospital in Indianapolis, Ind., says of the multicenter study, "A lot of these individuals have diabetes or severe heart disease or they have had multiple heart operations and have reached the end of the road as far as the potential for further interventions to be successful. TMR offers real hope for these patients." If the current study's results are supported by future research, Allen estimates between 50,000 and 100,000 U.S. patients could benefit from TMR each year. Those patients are in the Class IV category. Their heart muscles are so deprived of oxygen they experience chest pain even at rest and their activities are extremely limited. "We don't know if it will make people live longer or decrease the incidence of heart attacks," he says, "but it clearly improves their ability to function and their quality of life." The researchers studied 162 individuals with severe chest pain, or "refractory angina." Angina, or chest pain, is caused when the heart muscle does not get enough oxygen-rich blood. Of the 76 assigned to TMR, 74 underwent the procedure. Surgeons drilled about 40 holes, each one-millimeter in diameter, through each person's left ventricle. Another 86 people received only medical treatment, which included multiple drugs. After three months, angina had improved from Class IV to Class II or better for 86 percent of the TMR patients compared to only 12 percent of those treated with medication alone. Chest pain is rated on a scale of I-IV, with I representing the least pain and class IV being the worst. Those improvements continued at six months, with 85 percent of the TMR patients still reporting improvement versus 18 percent of the medically managed group. In contrast to the extreme debilitation seen with Class IV angina, Class II patients have only slight limitation of normal activity, Allen says. Another significant difference between the TMR and non-TMR treated was in rehospitalizations due to heart disease. At three months, 20 percent of the TMR patients had returned to the hospital compared to a 43 percent rehospitalization rate reported in the medication-only group. No significant difference in mortality was reported between the two groups. Co-authors include Tommy L. Fudge, M.D., Terrebonne General Medical Center, Houma, La.; Samuel L. Selinger, M.D., Sacred Heart Medical Center, Spokane, Wash., and Robert D. Dowling, M.D., Jewish Hospital, Louisville, Ky.
--------
148-> NASA Invites Public To Send Names On Roundtrip Mission To Comet
Through November, NASA is inviting individuals to submit their names to be etched on a microchip and flown aboard Stardust, a daring roundtrip robotic spacecraft mission to a comet. The Stardust project, managed by NASA's Jet Propulsion Laboratory in Pasadena, CA, is collecting up to 300,000 names by Nov. 30, 1997.  The names will be electronically etched onto a fingernail-size silicon chip in the Microdevices Lab at JPL, where the Stardust mission is managed.  The collection of names is being coordinated with the assistance of The Planetary Society, a non-profit space interest and education group based in Pasadena. Now beginning assembly and scheduled for launch in February 1999, the Stardust spacecraft will embark on a five-year journey through the coma and to approximately 150 kilometers (100 miles) of the nucleus of Comet Wild-2 (pronounced "VILT-2"), gather cometary dust particles and deliver them back to Earth. "This is a chance for people to take a vicarious trip to a comet and back again," said Gloria Jew, coordinator for the Stardust mission's public outreach efforts at JPL. Names on the chip will be so small that the width of the type used measures 10 times smaller than the width of a human hair and can be read only with the aid of an electron microscope.  Names may be submitted electronically to the Stardust web page at http://stardust.jpl.nasa.gov/ or in writing, mailed to The Planetary Society, 65 N. Catalina Ave, Pasadena, CA 91106-2301.  Those submitting their names are granting permission for the Stardust project and its partners to use the names submitted in possible future exhibits and/or publications. Stardust will be the first space mission to gather dust and other material from a comet and bring it back to Earth for scientific analysis. In January 2006, an atmospheric reentry capsule housing the comet sample will plunge through the skies over Utah and parachute softly to the Earth's surface. A direct sample of a comet has been long sought by planetary scientists because comets are thought to be  nearly pristine examples of the original material from which the Sun and planets were born 4.6 billion years ago. Stardust's scientific bounty from its five-year voyage will also include samples of the interstellar dust that passes through our solar system.  Return of this interstellar material will provide scientists with their first opportunity for laboratory study of the composition of the interstellar medium. "Stardust has 'double-barreled' science objectives to capture samplesof two deep-space phenomena, comets and interstellar dust," said Dr. Kenneth Atkins, Stardust project manager at JPL. Both the comet and interstellar dust samples will be collected in a special material called aerogel, a lightweight transparent silica gel, the lowest density solid material in the world.  (Aerogel was most recently used as a lightweight insulating material to protect the Mars Pathfinder Sojourner's electronics from the harsh, cold climate of Mars.) As a Discovery-class mission, Stardust is one of NASA's new "faster, better, cheaper" missions.  "Stardust also represents a reversal in traditional exploration technique," said Atkins. "Instead of taking expensively-packaged instruments to the target of interest, Stardust will bring samples of the targets to laboratories on Earth where existing instruments with the latest techniques can be used to examine them. This saves money and provides opportunities for more investigators to participate." Comet Wild-2 is a 'fresh' comet which was recently (in 1974) deflected by Jupiter's gravity from an earlier orbit lying much farther out in the solar system.  Having spent most of the last 4.6 billion years in the coldest, most distant reaches of the solar system, Wild-2 represents a well-preserved example of the fundamental building blocks out of which our solar system formed. Stardust is the fourth NASA Discovery mission to be chosen and follows the Mars Pathfinder, Near Earth Asteroid Rendezvous (NEAR), and Lunar Prospector missions. The goal of NASA's Discovery Program is to launch many small missions that perform focused science with fast turn-around times, cost less than $150 million (in FY '92 dollars) to build, and are joint efforts with industry, small business and universities. The principal investigator for Stardust is Dr. Donald E. Brownlee of the University of Washington, well-known for his discovery of cosmic particles in Earth's stratosphere. JPL's Dr. Peter Tsou, innovator in aerogel technology and maker of aerogel, serves as deputy investigator. Stardust is being built by Lockheed Martin Astronautics, Denver, CO.   JPL will provide the mission science payload that includes the optical navigation camera and manages the overall mission for NASA's Office of Space Science, Washington, DC.  JPL is a division of the California Insititute of Technology.
--------
149-> Columbia-SUNY Team Slices Magnetic Crystal; Applications Seen For Miniaturized Optical Devices
In laboratories at Columbia University, scientists are bondinglight and electricity. They have taken the first important step toward creating amicrochip that combines electronics and its optical equivalent, photonics.The technology could simplify fiber optic communications and lead to thedevelopment of such miniaturized optical devices as tiny lasers andimplantable medical sensors. The Columbia scientists, working with colleagues from the StateUniversity of New York at Albany, have bonded an ultra-thin sheet ofmagnetic garnet, a photonic material that transmits light in only onedirection, to a semiconductor, a component of microelectric circuitry. "Ultimately, manufacturers will be able to combine optical andelectronic capacity on the same silicon crystals, which are superiorelectronics platforms," said Richard M. Osgood, Higgins Professor ofElectrical Engineering and professor of applied physics and co-author ofthe research. A crucial step was slicing an ultra-thin sheet - 9 microns, ormillionths of a meter, thick - from the magnetic garnet crystal, thesubject of a scientific paper published in the Nov. 3 issue of AppliedPhysics Letters.  Columbia has applied for a patent on the new technology. Professor Osgood and the co-inventor of the new technology, MiguelLevy, senior research scientist at Columbia, have already begun to receiverequests for single-crystal magnetic garnet films from other laboratoriesaround the world, for such diverse research applications as microwaveelectronics and optical isolators.  Columbia is the only institution thatcan produce the thin films. The work took place at Columbia's Microelectronics SciencesLaboratory and at the Columbia Radiation Laboratory, both in the FuFoundation School of Engineering and Applied Science.  The research groupincluded two materials scientists at the State University of New York atAlbany, Hassaram Bahkru and Atul Kumar, who assisted in processing thegarnet used in the experiments at SUNY Albany's ion accelerator. "I'm excited that this technology can be used to build a whole newrange of miniaturized systems, from medical sensors to ultra-small,powerful laser systems," Professor Osgood said. Miniaturized optical processors for fiber optic telecommunicationsare also possible.  Currently, optic messages travel by laser light to anisolator that prevents destabilization of the laser by outsideinterference, then to a modulator that imprints a signal, then to amultiplexer that combines signals of different wavelengths, each of whichcan carry a different message.  A similar system is required at thereceiving end to decode the light message into sound or picture. "Right now, these are all very bulky devices," Dr. Levy said.  "Ifyou could put all these optic circuits on a chip, it would be cheaper, moreefficient and sturdier, and there has been a lot of research geared towardsintegrating these components.  Our work is an important step in thisdirection." Such integration between photonics and electronics had not beenpossible because garnet and other magnetic crystals cannot be grown on asemiconductor substrate.  Magnetic isolators cannot be made efficiently onany material other than magnetic garnets.  Thus the need to place garnetcrystals on semiconductors, providing a bridge to an already maturetechnology, the researchers said. The Columbia research team fired high-energy beams of helium ionsat a planar region that is just below the surface of the crystallinematerial, yttrium iron garnet (YIG), to loosen it from its substrate,gadolinium gallium garnet.  They then applied chemicals to the region tocut the bonds entirely, slicing off an ultra-thin sheet of magneticmaterial from a single crystal.  The sample was then lifted off and bondedto a high-quality semiconductor. The goal of this effort is to make devices that allow light to goin only one direction on a fiber optic microchip, Professor Osgood said.Light guides etched into the magnetic crystal, when exposed to a magneticfield, allow the light to travel in one direction only, making the lightguide an effective routing device in an optic fiber network. The work is the result of a collaboration between Columbia and theUniversity of Minnesota to create integrated photonic devices for use infiber optic communications systems.  The collaboration is funded by thefederal Advanced Research Projects Agency.
--------
150-> "Mighty Mice" Gene Is Mutated In Beefy Bovines
Gene's ability to slow muscle growth extends beyond mice The same genetic "secret formula" that gave unusually large muscles to the "mighty mice" engineered by Johns Hopkins is also at work naturally in specially bred cattle that have extra muscle, according to a new report from the researchers. "Mutations in the myostatin gene in two different species produced the same result," says Se-Jin Lee, M.D., Ph.D., an assistant professor of molecular biology and genetics. "This strongly suggests that the normal human form of the gene, which we've already identified, helps suppress muscle growth. If we can find a drug that blocks myostatin activity, patients with muscular dystrophy or muscle wasting due to AIDS or cancer may really benefit." Results of the study, which was supported by grants from the Edward Mallinckrodt, Jr. Foundation and MetaMorphix, Inc. are published in the Nov. 11 issue of the Proceedings of the National Academy of Science. Cattle breeders knew nothing of myostatin when they succeeded in developing more muscular cattle breeds like the Belgian Blue and the Piedmontese. Hopkins researchers went searching for mutant forms of myostatin in these cattle after discovering what eliminating it could do to mice. "We wondered right away if interfering with the gene in livestock could give us animals with more meat and relatively less fat," says Alexandra McPherron, Ph.D., a Hopkins postdoctoral fellow. "We first became aware that there might be some breeds of livestock that already have mutated myostatin when someone described a large-muscled breed of sheep to us." Through literature and Internet searches, researchers learned of the Belgian Blue breed of cattle. From genetic information available online, they could see that the cattle's altered gene appeared to be in the same spot on the genetic code as human and mouse myostatin. To confirm their suspicions, Lee and McPherron then analyzed DNA from cattle blood samples supplied by a ranch in Missouri. They also detailed the DNA blueprint of the myostatin gene from 12 non-double-muscled breeds of cattle and found that their copies of myostatin were all normal. Scientists also sequenced the myostatin gene in humans, chickens, pigs, turkeys, sheep, baboons, zebrafish and rats, and found that there were relatively few differences among the species. Rights to myostatin are owned by The Johns Hopkins University and exclusively licensed to MetaMorphix Inc. MetaMorphix was established in 1995 to capitalize on work by Hopkins and Genetics Institute, a private pharmaceutical company, in the field of growth and differentiation factors. Lee is a shareholder in and scientific founder of the company. Under an agreement between MetaMorphix and The Johns Hopkins University, McPherron and Lee are entitled to shares of royalty received by the University from MetaMorphix. The University, McPherron and Lee also own MetaMorphix stock, which is subject to certain restrictions under University policy. Lee is also a consultant to MetaMorphix. The terms of this arrangement are being managed by the University in accordance with its conflict-of-interest policies. 
--------
151-> Gene Therapy Generates New Blood Vessels
ORLANDO, Nov. 9 --Through gene therapy, researchers have grown new blood vessels for humans, according to a report presented today at the American Heart Association's Scientific Sessions. This new therapy, called therapeutic angiogenesis, was successfully used to grow vessels to bypass obstructions of blood flow in the legs of eight people. The blood circulation in the individuals' legs had become obstructed by atherosclerosis, the same disease process that creates the fat-filled plaques that clog coronary arteries, the blood vessels feeding the heart. In the experimental therapy, the gene or DNA that produces the growth factor that stimulates the creation of blood vessel cells during the development of the human embryo, is injected into muscles in the patient's legs. The injected DNA "instructs" existing blood vessel cells to regenerate new blood vessels. Jeffrey Isner M.D., whose team presented the research, conducted at St. Elizabeth's Medical Center in Boston, says the therapy soon will be evaluated in people whose coronary arteries are obstructed by atherosclerosis, putting them at risk for heart attack and death. "Since this gene therapy approach works in the leg, it should work in the heart," says Isner, who described his first patient in which gene therapy produced new blood vessels in a paper published in August 1996 in the journal Lancet. If gene therapy proves safe and effective in generating new blood vessels to create a natural bypass around blocked coronary arteries, cardiologists will be able to help patients for whom balloon angioplasty, bypass surgery, drugs and other treatments designed to restore blood flow are unsuccessful or represent a high risk. Whether this gene therapy will emerge as a primary treatment -- in conjunction with angioplasty, for example, or instead of bypass surgery -- is unknown and depends on future research, says Isner, professor of medicine and pathology at Tufts University School of Medicine and chief of cardiovascular research at St. Elizabeth's Medical Center. But for now, the gene therapy is helping people with severe atherosclerosis in their legs to avoid amputation. "For the people enrolled in the study, every therapy had been tried and failed," explains Isner. For individuals with critical limb ischemia, which is severe atherosclerosis in the blood vessels in the legs, amputation is often the only way to deal with deadly gangrene of the afflicted limbs. The study, which began one year ago, did not randomize the patients -- that is, assign them either to gene therapy or conventional therapy. Isner explains that randomization did not occur because for people with such severe disease there is no conventional therapy. Affecting 100,000 to 200,000 people in the United States, critical limb ischemia is the "most under-diagnosed entity in cardiovascular disease," says Isner. "It often is chalked up to old age, but can be a sign that there is something wrong with the vascular system." Many of his patients have atherosclerosis in their coronary arteries, carotid arteries (blood vessels to the brain that if blocked can cause a stroke) in addition to peripheral vessels in the limbs. The effectiveness of the gene therapy was gauged by before and after clinical assessments which included diagnostic angiogram, which produces an image that shows blood flow in vessels; magnetic resonance angiography; measurement of the ankle-brachial pressure, and, if possible, exercise testing. In eight of the 10 treated legs, improved blood flow was demonstrated by magnetic resonance imaging. Angiograms showed evidence of newly visible vessels in seven of the 10 treated limbs. At follow-up examinations, one to six months after the last injection, blood pressure in the individuals' ankles had increased from 0.33 to 0.47 ankle index. "The blood pressure in the ankle and the arm should be equal," explains Isner. "At the beginning of the study, the patients' ankle blood pressure was about one-third of the arm's pressure. The 14-point increase fulfills criteria ordinarily used to indicate success after surgery or angioplasty. To my knowledge, this kind of improvement has never been shown to occur without surgery or angioplasty in this group of patients. This kind of improvement does not occur spontaneously," he points out. Individuals were also asked to gauge the amount of resting pain (pain in the legs while resting) before and after the therapy. Individuals with severe atherosclerosis in their legs typically suffer a lot of resting pain that interrupts their sleep. Like angina, or chest pain, it is caused by impaired blood flow. Six patients reported experiencing less "rest pain." In four of the seven legs with skin ulcers resulting from reduced blood flow, healing or marked improvement occurred. The amount of time spent in walking a certain distance improved in all five individuals tested. Only one of the study participants had to undergo limb amputation. When the 39-year-old woman joined the study, she had severe atherosclerosis in both legs. "The front half of one foot was already black due to the onset of gangrene," Isner says. In the woman's other leg, gangrene had begun in her toe. Gene therapy was applied to both legs and halted the gangrene in the least afflicted leg but failed in the other leg "because it was too far gone," says Isner. "When she came to us, she was facing two lower limb amputations," he adds. "Without this therapy, she would have been a double amputee." The leg that was amputated was the only one of the two limbs in the study that deteriorated. Another woman in the study also avoided amputation as a result of the gene therapy, he notes. For one patient, there was no improvement. Other researchers previously found the growth factor produced by the gene therapy was released by human tumor cells. "To grow, tumors need a blood supply," explains Isner, "so tumor cells secrete vascular endothelial growth factor to generate new blood vessels. The factor also is produced in the developing embryo." The gene for this growth factor, which was derived from a human pituitary tumor, is being replicated in Isner's laboratory at St. Elizabeth's Medical Center, which funded the clinical trials of the nine patients. For the injections, the gene was not attached to a virus or another "Trojan horse" medium to transport the DNA inside the cell. The "naked" DNA was administered twice, four weeks apart. Co-authors are Iris Baumgartner, Ann Pieczek, Richard Blain, Orit Manor and Kenneth Walsh.
--------
152-> Presence Of Protein Extends Life; Potential Aging Mechanism Found
PROVIDENCE, R.I. -- Scientists have provided direct evidence that a class of proteins plays a role in extending life. Their study, published in last week's issue of the journal Nature, demonstrates that a brief genetic response to heat stress can increase a fruit fly's life span at normal temperatures. The finding uncovers a potential mechanism for aging because the capacity to moderate stress is a central function to regulating that aging mechanism. In the study, Marc Tatar and colleagues from the University of Minnesota exposed fly strains to short doses of nonlethal warmth, inducing expression of a protein dubbed hsp70. Flies bred to contain extra copies of hsp70 genes responded to the warmth by producing a lot of hsp70, which substantially increased their life span over a two-week period after heat treatment. Only a brief, low level of genetic expression was required to obtain a long-term improvement in survival of the flies, said Tatar, now an assistant professor of ecology and evolutionary biology at Brown University. Hsp70 is one of the body's many "chaperone" proteins, which promote the proper folding and shaping of other proteins during biological processes. Molecular chaperones, such as hsp70 or "heat-shock proteins," are thought to combat stress-related damage to protein function caused by exposure to heat or cold. The researchers think fruit flies produce hsp70 after exposure to warmth, because it may re-establish other proteins adversely affected by warming. Hsp70 may also interact with other stress response mechanisms. Transient but effective levels of hsp70 could be present when stress is routinely encountered, the researchers said. Hsp70 may repair and restore higher-order cell functions, which themselves would otherwise quicken the mechanism responsible for aging. However, people shouldn't think they will live longer by taking daily doses of heat or by sitting in endless saunas, Tatar said. "Our bodies tightly regulate hsp70 and other heat-shock proteins, he said. "Although heat, cold and all sorts of stresses can elicit these chaperone proteins, the normal level of stress actually produces the body's optimal amount of heat-shock proteins. So putting your body through a series of minor stresses, such as heat exposure, won't elicit any more of the proteins in the long run. Your body is controlling their threshold levels." Tartar and colleagues say the findings are a stepping stone to studies aimed at discovering which proteins are the exact targets of heat-shock genes. `We would like to find out why the heat-shock proteins evolved to do what they do," he said.
--------
153-> "Mugspot" Can Find A Face In The Crowd -- Face-Recognition Software Prepares To Go To Work In The Streets
Computer "eyes" are now up to such tasks as watching for fugitives in airline terminals and other busy locations. A sophisticated face-recognition system that placed first in recent Army competitive trials has been given the added ability to pick out faces in noisy or chaotic "street" environments. The new "Mugspot" software module developed at the University of Southern California automatically analyzes video images, looking for passers-by. When it finds them, it picks out the heads in the images and then tracks the heads for as long as they remain in the camera's field. Throughout this tracking process, the software is watching for the best possible view of the subject's face -- the one that shows him or her looking most directly at the camera. It selects the best view presented and passes it on to the main face-recognition program. This face-recognition software, developed at USC and the University of Bochum, Germany, and now in commercial use for clients such as Germany's Deutsche Bank, is robust enough to make identifications from less-than-perfect face views. It can also often see through such impediments to identification as mustaches, beards, changed hair styles and glasses -- even sunglasses. "Until now," says Christoph von der Malsburg, the computer scientist and brain theorist who developed the system, "face- recognition software has needed to have the raw material, the images of faces, given to it in a highly structured form: a clear still photograph of a subject looking right at the camera. "Our existing system is able to make identifications even with substandard images. With the addition of the 'Mugspot' video processing system, which expands its ability to capture images, I think it will prove useful in many real-life situations, particularly in law enforcement," says Dr. von der Malsburg, a professor in the USC School of Engineering's department of computer science. Cameras mounted in airports and bus stations, or aimed at oncoming cars at traffic intersections, might continuously watch for known fugitives, von der Malsburg says. Bank surveillance cameras could identify persons seen at previous bank robberies. The Mugspot system can scan eight video frames per second in real time, and takes about 13 seconds to select the best view, process it for identification, compare it to the several hundred faces in its memory and decide whether it has found a match. The three research associates who developed Mugspot with von der Malsburg -- USC graduate student Egor Elagin, postdoctoral researcher Hartmut Neven and Bochum University visiting graduate student Johannes Steffens -- believe further refinement of the system can shorten that time by half. Mugspot is only the latest improvement in the USC/Bochum face recognition software, developed with funds from the Army Research Laboratory (ARL) and marketed commercially in Europe under the trade-name ZN-Face. In tabulations released Aug. 19 by the ARL, the USC/Bochum system outperformed competitors from laboratories across the country including MIT, the University of Maryland, Rutgers, Michigan State University and three systems developed by the Army itself. The labs were ranked according to their performance on each of 12 separate runs, from 1 (best) to 12 (worst). The USC/Bochum system recorded six first, three seconds and two thirds, for a total of 18. The next best score was 24 -- a tie between MIT and the University of Maryland. The USC/Bochum system also shone in tests conducted under substandard lighting conditions: It lost only a small fraction of its accuracy, while competitors showed drastic falloffs in less- than-brilliant illumination. The USC/Bochum system uses an unusual approach that mimics the technique scientists believe the brain uses to recognize images. Von der Malsburg, whose principal research interests lie in the investigation of living brains, in fact carried out much of the original research on the system as part of an attempt to understand human face recognition. His research led to creating a computer model of the way the brain's visual cortex processes information.
--------
154-> Drilling Uncovers Ancient Eruptions That May Have Caused Global Warming
CHAPEL HILL -- Drilling into the sea floor south of Haiti has uncovered conclusive ashy evidence that multiple massive volcanic eruptions occurred roughly 55 million years ago in the Caribbean Basin. Those cataclysmic events appear to have caused abrupt inversion of ocean waters, triggering one of the most dramatic climatic changes ever, according to a geologist on the team that discovered the eruptions. The inversion caused release of massive amounts of sea floor methane into the atmosphere, leading to global warming and possibly speeding evolution of countless new plant and animal species, including many primates and carnivores, the scientist believes. At the same time, close to half of all deep-sea animals went extinct, asphyxiated in the suddenly warmer and stagnant deep waters. "We found multiple very distinct blue, green and occasionally red volcanic ash layers that were very different from whitish-gray sediments above and below them in the core samples," said Dr. Timothy Bralower, associate professor of geology at the University of North Carolina at Chapel Hill. "The time those ash layers -- direct evidence of volcanic eruption -- were deposited corresponds to the beginning of a known period of rapid warming of the Earth. This is the first evidence for a major volcanic episode at that time in the Caribbean." A report on the discovery appears in the November issue of the journal Geology. Core sampling to about 3,000 feet took place aboard the 470-foot JOIDES Resolution, the world's largest scientific drill ship, in late 1995 and early 1996. "Many geologists are interested in this interval 55 million years ago because we don't know of any other geologic period when warming occurred so precipitously, and warmth covered the globe like this," Bralower said. "The million-dollar question is what triggered the sudden burp of methane. A dramatic climatic change had to have occurred first." The new work shows a huge Caribbean volcanic eruption occurred just as the warming began, Bralower said. "That's a microsecond of geologic time, and the chances that the events are just coincidence is minute," he said. The geologists speculate that like most explosive volcanism, the Caribbean eruptions first led to minor cooling of the atmosphere and that the cooling was most severe near volcanoes in the tropics. They believe that temperature drop caused the tropical ocean waters to become denser and to sink, replacing the usual cold polar waters in the deep ocean and fomenting an oceanographic change of titanic proportion. "Sudden warming of the deep ocean would cause methane trapped in sediments under the sea floor to become unstable and rapidly rise into the ocean and atmosphere," Bralower said. "That would fuel further warming and instigate the dramatic environmental and evolutionary changes." Scientists already know that comparable volcanic activity occurred in the North Atlantic Ocean beginning some 61 million years ago, the geologist said. The new discovery suggests the Caribbean volcanism may have been even more important for the Earth and somehow acted in tandem with the earlier known eruptions farther north. Understanding major warming events in the past is one of the best ways of determining the possible effects of global warming, he said. "The giant Caribbean eruption provides a worst-case scenario of what could happen to Earth in the future." Co-authors of Bralower's paper are UNC-CH geology graduate student Debbie Thomas and faculty members at the universities of California at Santa Cruz, Rhode Island and Minnesota, Bremen University in Germany and Wesleyan University in Connecticut. The National Science Foundation and the Texas A&M University-based Ocean Drilling Program supported the research.
--------
155-> Americans' Lack Of Shame Nothing To Be Proud Of, Says UF Professor
Writer: Steve Orlando Source: James B. Twitchell, (352) 392-6650 GAINESVILLE, Fla. --- What led people as recently as the 1960s to hang their heads -- divorce, children born out of wedlock, failure to pay off debts -- has given way to shame ‘90s style: wearing furs, smoking in public, eating red meat and failing to recycle, a University of Florida professor writes in a new book. Shame still exists in American culture, but the things people get red-faced about have changed considerably during the past generation, said James B. Twitchell, a UF English professor and author of "For Shame: The Loss of Common Decency in American Culture," which is scheduled to arrive in bookstores this week. 	One major culprit, he says: the advertising industry. "I was teaching a class in advertising, and I began to notice that through the ‘40s, ‘50s and ‘60s shame was used to sell a whole strange variety of things -- house paint, cough drops, gasoline," he said. "Then I noticed that in the past 15 years there's been a change. People don't sell that way anymore." Twitchell, who also wrote the 1995 book "Adcult USA: The Triumph of Advertising in American Culture," says companies now must try to woo consumers who can simply click the remote if what they're watching makes them feel bad about themselves. Twitchell also points a finger at what he calls "shamelebrities" -- people with a history suitable for a spot in the hall of shame but who instead earn a book deal and a spot on the talk show circuit. Among the more well-known shamelebrities he cites are Watergate co-conspirator-turned-radio-personality G. Gordon Liddy, John Wayne Bobbitt of severed-member fame, Iran-Contra figure Oliver North, former presidential adviser Dick Morris, figure skater Tonya Harding and Long Island auto repairman Joey Buttafuoco. At the other end of the spectrum are the shamelebrity wanna-bes -- what Twitchell describes as "the barely literate trailer-park types who come forward [on afternoon talk shows] to recount their own tales of egregious behavior." "We love to watch shameless people," he said. "Shameless people are entertaining." The change in the nature of American shame has had far-reaching consequences, he said, not the least of which has been the decline of the nuclear family. "One of the things that keeps men in the family is the shame of departure, and that has virtually evaporated," Twitchell said. One thing that has helped people avoid at least one type of shame is technology, specifically the Internet, said Dan Kahan, a law professor at the University of Chicago who also studies shame and has written several articles on the subject. For instance, he said, pornography not only is abundant -- and frequently free -- on the World Wide Web, it also allows people to avoid the risk of being seen buying it in public. On the other hand, Kahan said, technology is a double-edged sword that can be useful in areas such as criminal justice and law enforcement. He cited the example of a Midwestern city that recently began posting on the Web the names of men convicted of trying to pick up prostitutes. "Shame is all around us," he said, "and what's more, it's a resource we can exploit." While the changing nature of shame so far seems to be peculiarly American, Twitchell says it likely will spread to other nations, surfing on the wake of popular American culture. "I think wherever television goes, which is all over the world, the reshifting of shame will soon follow," Twitchell said. "I don't see this as necessarily nefarious. I see this as the inevitable result of a commercial culture whose central focus is feeling good." The irony that he is a member of the postwar generation he holds partly responsible for the decline of shame isn't lost on Twitchell. "When it comes to shame," he writes in the book's preface, "I confess that I have become a graybeard, a bluestocking ... As a baby boomer, I know I should be ashamed of this, and oddly enough, to a degree, I am."
--------
156-> Scientists Getting Closer To Understanding How Cells Age
DALLAS -- November 11, 1997 -- Understanding how normal human cells age should help scientists develop new tools to stop the growth of cancer cells, which bypass the aging process. Normal human cells undergo a finite number of cell divisions before they "age" and can no longer divide. On the other hand, cancer cells divide indefinitely and are often referred to as immortal cells. In normal cells a biological clock keeps track of the number of cell divisions by checking the length of telomeres, special structures on the ends of chromosomes that protect the tips from degradation. In the November issue of the journal Genes and Development, Drs. Jerry Shay and Woodring Wright, UT Southwestern professors of cell biology and neuroscience, and Dr. Valerie Tesmer, a cell biology and neuroscience research fellow, offer new information about human telomere structure and regulation. "If we can more fully understand how the biological clock and timing mechanism works, we may be able to manipulate cancer and aging," Shay said. Chromosomes are made up of double-stranded deoxyribonucleic acid (DNA). During replication the strands separate and each strand is copied to make a new double-stranded molecule. One strand is the leading strand, the other the lagging strand. Because of the way DNA replicates, the enzyme that copies the lagging strand is unable to copy the DNA all the way to the end of the chromosome; therefore, the newly synthesized daughter strand is shorter than the parental strand. "It is like a painter in a closed room. He can paint the entire floor except for the square where he is standing," said Shay. For this reason there are no genes at the ends of the chromosomes; instead there are thousands of telomeric repeats. Scientists used to speculate that there were long telomere overhangs, or tails, on both ends of the chromosome. The new data dispute this finding and strongly point to a long telomere tail at only one end of the chromosome; the other end of the chromosome is blunt or has a short end. This is important because, in human cells, the way in which the telomere tail is generated during DNA replication is likely to regulate the rate of telomere shortening. "It is extremely important to understand the rate of telomere shortening if we are to understand some of the pathologies of aging and if we are going to develop new therapeutics for cancer," Wright said. Drs. Shay, Wright and their colleagues now are closer to understanding how telomeres erode. Reproductive cells and cancer cells have an enzyme, telomerase, that adds telomeric sequences to the chromosomal ends. This counters the shortening of the telomeres, so that these cells continue to divide and are in a sense immortal. In addition, different cells shorten their telomeres at different rates. Acceleration of telomere erosion in cancer cells, as well as inhibiting telomerase, may be a means of cancer therapy. "Since there are different rates of telomere shortening, it means that the rates are not fixed and immutable, and so we might be able to intervene and change those rates," Wright said. Drs. Stephen Levene and Kenneth Huffman of UT Dallas also contributed to the research.
--------
157-> Wild Tomatoes Yield Formula For Nontoxic Insect Repellent, Cornell Researchers Say
ITHACA, N.Y. -- Scratching the surface of wild tomatoes that bugs don'tbother, Cornell University scientists discovered the plants' chemicalsecret for repelling insect pests: a complex, waxy substance thatcommercially grown tomatoes have "forgotten" how to make. A simplified formulation of the wild tomatoes' chemical has been granted aU.S. patent on "Non-cyclic Esters for Pest Control" and could become thenext-generation nontoxic insect repellent for a long list of crops onhungry bugs' menu. The newly patented compounds may work, in part, because they create stickysurfaces that insects don't like, and also because the compounds break downto release short-chain fatty acids, which are known to repel insects. "We've made smaller versions of natural fats that are easily biodegraded tofatty acids," said Bruce Ganem, a Cornell chemist and co-inventor, alongwith Martha A. Mutschler, professor of plant breeding.  "These are similarin structure to the natural triglycerides in our bodies, only with shorterfatty acids, and the amounts that will be on crops seem unlikely to pose ahealth hazard to humans."  Ganem is the Franz and Elisabeth RoesslerProfessor of Chemistry in Cornell's College of Arts and Sciences. Two insect larval pests, the tomato fruitworm ( Helicoverpa zea ) andthe beet army worm ( Spodoptera exigua ), cause an estimated $30million a year in damage to the processing-tomato crop inin California.The grubs bore holes in tomato fruits, allowing decay organisms to enterthe skin and spoil the fruit.  But when the Cornell pest-control chemicalis sprayed on tomatoes, damage from tomato fruitworm and beet army worm isgreatly reduced or eliminated altogether. In addition to tomatoes, the patented chemical agents are expected toprotect a wide range of crop plants and ornamental plants against more than30 kinds of mites, beetles, leafminer flies and whiteflies, aphids,leafhoppers, mealy bugs, worms and thrips, the Cornell inventors said.  Andthe same  insect species that are repelled from eating the plants also areless likely to oviposit (lay eggs), thus breaking a cycle of plantdestruction, the scientists added. The Cornell scientists began their discovery process by selecting wildtomatoes  ( Lycopersicon pnennellii , the relative of a commonlycultivated tomato, L. esculentum ) with few  insect blemishes, thenwashing the fruit to obtain the natural compounds for chemical analysis.The exact mixture of glucose esters and other compounds would have been toocomplicated to duplicate, Ganem said, so they narrowed their formulation tosome simple analogs with common structural and physical properties. "Now the chemistry is easy," Ganem said, noting that the patent coversseveral similar formulations of the pest repellent.  The "non-cyclic" termmeans each compound's carbon atoms are arranged in chains, rather than inrings. Mutschler and Ganem hope to take their invention to the next stage -- amarketable product with all the emulsifiers and stabilizers that areexpected by consumers -- through a Technology Development Fund Grant fromCornell's Office of Economic Development.
--------
158-> Mars Global Surveyor Resumes Aerobraking, Heading Toward New Mapping Orbit
 NASA's Mars Global Surveyor spacecraft has successfully resumed aerobraking through the upper atmosphere of Mars, heading toward a new science mapping orbit that is the mirror image of its original target orbit, project officials announced today (Nov. 10). Aerobraking resumed Nov. 7 with a brief propulsive maneuver that changed Global Surveyor's flight path slightly.  A second maneuver was performed successfully on Nov. 9, with a third maneuver planned for Nov. 12.   These small adjustments at the farthest part of the spacecraft's orbit around Mars -- known as the apoapsis -- begin the process of lowering Global Surveyor's orbit into the Martian atmosphere more gradually than originally planned. The more gradual aerobraking strategy will lead to a new mapping orbit that preserves all of the original scientific objectives of the mission.  Selected by the mission's science team, the new orbit is essentially just the reverse of the original orbit:  data will be taken from the south to the north along the spacecraft's orbital track, rather than north to south, and mapping will begin one year later than originally planned. In this new mapping orbit, beginning one-half Mars year (equivalent to one Earth year) later than planned, Mars will be at a point in its orbit that is directly opposite where it would have been in the original mission.  From the spacecraft's point of view, the side of Mars that would have been dark will be sunlit and vice versa. "From the perspective of the science instruments, the orbit will look just like the original orbit, except that instead of taking data from north to south on the sunny side of Mars, Global Surveyor will be making its observations in a south to north direction in the sunlight," said Glenn E. Cunningham, Mars Global Surveyor project manager at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA.  "The new mapping orbit will take the spacecraft down over the Martian equator at 2 a.m. local Mars time during each orbit, rather than the originally planned orbit that would have crossed the Martian equator at 2 p.m." The new mapping orbit will take an additional year to achieve, due to both the more gradual pace of aerobraking and a six-month hiatus in the spring of 1998, while Mars moves into the correct alignment with the Sun for global mapping.  Rather than reaching its final mapping orbit in mid-January 1998, and beginning the science mission in mid-March 1998, Mars Global Surveyor will achieve its final orbital position in mid-January 1999, and mapping will begin in mid-March 1999. "Essentially, we will begin mapping the surface of Mars in mid-March 1999, during summer in the northern hemisphere," Cunningham said. "Originally we had planned to begin mapping on March 15, 1998, during summer in the southern hemisphere." During next year's hiatus, Mars Global Surveyor will remain in a fixed, elliptical orbit in which it will pass much closer to the surface of Mars during each periapsis -- or closest part of its orbit around Mars -- than it will in the final mapping orbit.  These close-range passes are essentially an opportunity for bonus science and will provide superb opportunities for data acquisition.  The spacecraft's full suite of instruments, including the laser altimeter, will be turned on during this time to study the planet up close. "We expect to gain some spectacular new data during this time," Cunningham said.  "The spacecraft's orbit will still be elliptical during this period, with a duration of between eight to 12 hours, but at periapsis, the surface resolution will be much greater, and the lighting angles will be excellent." Mars Global Surveyor's first two aerobraking maneuvers have gone well, giving the operations team confidence that the spacecraft's unlatched panel will be able to withstand an increased amount of pressure as it begins to dip lower into the Martian atmosphere.  The new pressure level (an average of 0.2 newtons per square meter) is about one-third the level of pressure originally planned for aerobraking.  Aerobraking is a technique that allows a spacecraft to lower its orbit without relying on propellant, by using the drag produced by a planet's atmosphere.  The technique was first demonstrated in the summer of 1993 during the final months of NASA's Magellan mission to Venus. Although these initial maneuvers have not changed Global Surveyor's orbital period significantly, they will soon begin to reduce the time it takes the spacecraft to complete one revolution around Mars. "The spacecraft's unlatched solar panel performed as expected during the two drag passes we've conducted so far," Cunningham said.  "Although we observed some slight movement during the passes, the panel returned to its initial position and its stiffness did not change.  That performance gives us confidence that the mission can proceed without further delay." A third, five-second burn with spacecraft's small thrusters to be performed at 2:30 a.m. EST on Nov. 12 will lower the spacecraft's periapsis by an additional 2.5 miles (four kilometers). With completion of that maneuver, Global Surveyor will begin the main phase of aerobraking well inside the upper atmosphere of Mars.  During this two-month main phase, the spacecraft will be circling Mars every 34.5 hours to start at a periapsis altitude of about 77 miles (125 kilometers), with the apoapsis starting at 27,500 miles (44,400 kilometers) and decreasing with each pass.   The final goal is a 248-mile (400 kilometer) circular mapping orbit. If additional problems arise with the aerobraking process, the new mission plan will offer the Surveyor team other opportunities to reach an elliptical orbit that will satisfy many of the mission's science objectives.  These so-called "off-ramps" from the aerobraking process, will be detailed in a new mission plan to be reviewed by NASA officials in February 1998. During a press briefing today at JPL, scientists also showed stunning new images of layered rock and sediment in the canyon walls of Valles Marineris on Mars.  Other images of an ancient valley hint at the presence of active sand dunes and dried-up ponds.  The new images are available on the Internet at URL: http://www.msss.com/ or http://barsoom.msss.com/mars/global_surveyor/camera/images/ Additional information about the Mars Global Surveyor mission is available on the World Wide Web by accessing JPL's Mars news site at URL: http://www.jpl.nasa.gov/marsnews/ or the Global Surveyor project home page at URL: http://mars.jpl.nasa.gov/ Mars Global Surveyor is part of a sustained program of Mars exploration known as the Mars Surveyor Program.  The mission is managed by JPL for NASA's Office of Space Science, Washington, DC.  JPL's industrial partner is Lockheed Martin Astronautics, Denver, which developed and operates the spacecraft.  JPL is a division of the California Institute of Technology, Pasadena, CA.
--------
159-> UF Researchers Seeking To Make Building Materials More Earth-Friendly
Source: Timothy Townsend, (352) 392-0846 GAINESVILLE, Fla. --- Roofing shingles, gypsum board and concrete blocks could join newsprint, milk jugs and aluminum cans in the recycling bin and may help the construction industry save money in the process, say researchers at the University of Florida. Timothy Townsend, professor of environmental engineering, and his student assistants hope to show contractors, consumers and state officials how to save money by putting useful construction wastes back to work rather than dumping them into landfills, where they are likely to contaminate groundwater as they break down. Florescent light bulbs, for instance, contain mercury, as do thermostats and certain types of wall switches. Roof vent flashing contains lead. "Construction and demolition waste, or C&D, has an environmental impact," said Townsend. "C&D wastes account for 23 percent by mass of the solid wastes in Florida and are now recognized as a source of groundwater contamination." But making the program succeed may depend more, at least in the beginning, on making it financially attractive rather than on touting its environmental benefits. "We know that recycling C&D will save money that can also be passed on to consumers in lower construction costs," Townsend said. "But separating the material at the construction site, rather than shipping it to a materials recovery facility, reduces the likelihood that recyclable material will end up at the landfill. "Recycling has become more important and potentially cheaper than putting C&D in landfills since the cost of using landfills has risen," he said. "Several Florida counties have even made it illegal to put C&D waste in landfills that do not have liners." Since February, Townsend and his students have been scrounging around construction sites in Alachua County, some in the shadow of the UF campus, separating all manner of debris at residential and commercial construction and demolition sites to see what is still useful. They also are  experimenting in the laboratory to determine over time what happens to C&D debris that ends up in landfills. Townsend simulates landfills by placing waste building materials in 7-foot-high metal cylinders and regularly testing the "fermentation" -- the odors and gasses they produce. Computerized tests confirm high amounts of sulfides and high acidity.  The "nose test" also confirms the presence of sulphur. Townsend said state environmental policy makers are striving to reach a balance between environmental protection and increased regulations and costs for C&D waste disposal. Indeed, the state Department of Environmental Protection (DEP) is working with Townsend and his team on the project and hopes to see it succeed. "We're very excited about it. We feel that, yes, we're headed in the right direction," said Tom Edwards, an environmental specialist with DEP and contact manager with the UF project. "C&D is very hard to recycle. We tend to see it as solid waste, not a recoverable material." Edwards and his department are helping Townsend get out the word to contractors and others in the construction and demolition industries. A workshop on changing state regulations on C&D waste was held in Tampa last month, and three more are planned during the next several months in other parts of the state. The study is scheduled to be finished by March. Until then, Townsend and his students will keep digging through building site throw-aways in hopes of making demolition and construction a little more earth-friendly. "No one wants to live near a landfill, and no one wants the water table contaminated," Townsend said. "So it behooves us to recycle and to develop new markets for recyclable materials."
--------
160-> Hospital Program Provides Support To Children With Life-Threatening Asthma
By Corrina Stevens	GAINESVILLE, Fla.---A program that identifies children and young adults with life-threatening asthma and teaches the correct response to an attack has better controlled asthma attacks in 77 percent of patients, said researchers at the University of Florida. In fact, the Red Alert program at Shands at UF has been so successful most of the patients enrolled were able to be discharged from the program, UF researchers reported in a recent journal article. Their asthmatic condition became better controlled through education and proper use of medication. In addition, the program created a "safety network" of trained family members, teachers and health-care professionals available to respond to an asthma attack properly. "The program is extremely worthwhile. We started the program because there was a need to assure patients that rapid access to medical care was available when a life-threatening attack occurred. Since then, the program has been very successful in giving patients and caregivers confidence that timely and appropriate assistance is there when needed," said Dr. James Sherman, chief of UF's Pediatric Pulmonary Center. The Red Alert team teaches caregivers the proper response to an asthma attack and notifies local ambulance services, hospitals and schools that a Red Alert patient lives in the area. Parents receive information for emergency workers that gives treatment instructions, a medication list, physicians to contact and validation their child is enrolled in the program. More than 93 percent of patient's parents surveyed said their anxiety about accessing medical care had decreased and they felt better prepared to treat their child's asthma as a result of the Red Alert Program, UF researchers reported in the August issue of the journal Pediatrics. School officials say they are happy to have assistance in dealing with the leading cause of school absences attributed to chronic conditions. When school nurse Linda Stamper, had a student who was enrolled in the program, she said it was reassuring to know help was only a phone call away. 		"The Red Alert Program was like working with a security blanket," Stamper said. Approximately 4.8 million U.S. children have asthma, according to the American Lung Association, and on average more than 350 children and young adults die from asthma attacks annually. Seventy-five patients have been enrolled in the Red Alert Program since it was created in 1988.  The program was created in response to the death of a UF Pediatric Pulmonary Center patient from an asthma attack while being treated at a rural hospital. "The child died before our pediatric pulmonary physician was contacted. Some rural hospitals aren't sure how to identify and treat a severe attack," said Cindy Capen, a UF pediatric pulmonary nurse. "Many hospitals don't have a pediatrician in the emergency room. Red Alert provides a safety net for children and their families." Only patients at UF's Pediatric Pulmonary Center are eligible for enrollment in the Red Alert Program. The center is one of seven in the United States funded by the nation's Bureau of Maternal and Child Health to teach health-care professionals how to treat pediatric pulmonary diseases. Davenia Griffin of Lake City said her 15-year-old daughter Daysha Williams is a good example of the program's success. 	Her family relied on the program's services so much that four years ago they struggled with the decision to leave behind the safety network and move cross-country. UF pulmonologists put the family at ease by contacting doctors in Washington state to tell them about Daysha's condition and the family decided to move. "I didn't want to leave Lake City. I didn't think she would get the attention out West that she gets here," said Griffin, who has since returned to Florida with her family. "The program has taught me what to do right away when Daysha has an attack," Griffin said. "She has suffered fewer attacks since being enrolled." ----------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
161-> New Type Of Oral Vaccine Against Botulism May Lead To Protection Against A Range Of Diseases
Molecular biologists at Thomas Jefferson University, Philadelphia, have created an oral vaccine against botulism. The researchers believe that such a vaccine could be used as a prototype in developing future vaccines for other diseases such as diphtheria, whooping cough and tetanus. Eventually, they say, their discovery may lead to a range of oral vaccines that could be inserted into common foods. Lance Simpson, Ph.D., professor of medicine, Jefferson Medical College, and director of the Jefferson Clinical Center for Occupational and Environmental Medicine, and his colleagues, Nikita Kiyatkin, Ph.D., and Andrew Maksymowych, Ph.D., used the sophisticated tools of molecular biology to create a modified and non-toxic version of botulinum toxin, which is nature’s deadliest poison. The toxin, which is the cause of the disease botulism, is ordinarily encountered as a form of food poisoning. When someone ingests the toxin, it survives the harsh conditions of the gastrointestinal (GI) system and moves into the general circulation. It is eventually delivered to the central nervous system and causes paralysis. The researchers have created a novel form of the toxin that retains the ability to survive the GI system and enter the general circulation, yet no longer can poison nerves. As a result, the novel molecule is an effective oral vaccine against botulism. The scientists, reporting in November in the journal Infection and Immunity, detail the results of experiments in which they successfully immunized mice against botulism. One immediate use of a botulism vaccine, Dr. Simpson notes, would be in veterinary medicine. Animals such as racehorses and farmyard chickens are susceptible to the disease, making such a vaccine of interest to the pharmaceutical industry. According to Dr. Simpson, there may be far greater applications of the work in both veterinary and human medicine. “The very properties that this molecule possesses are the ones that would be essential for all oral vaccines,” he explains. “The molecule could be used as a carrier to transport other potential vaccines from the gastrointestinal system into the general circulation, where they would evoke antibodies. If this were to work, the novel carrier molecule could be the critical element needed to create a host of new oral vaccines.” One use of this vaccine technology would be for common diseases such as diphtheria and tetanus. Dr. Simpson sees a possibility for an even more intriguing use. “There are Third World countries in which injectable or even oral vaccines are still not practical; the health systems and finances are inadequate,” he explains. “What might be a more practical solution is to put the genes for the carrier-vaccines into a plant such as a banana. As the banana grows, it would automatically synthesize the oral vaccines. Whenever a person ate the banana, that person would also be consuming oral vaccines. This might be a way to combat illnesses that are endemic to some parts of the developing world.” Dr. Simpson and his colleagues are now constructing the genes that will encode the carrier-vaccine molecules. They will test the ability of the molecules to act as oral vaccines in the laboratory. If the work is successful, the next step will be to conduct human trials.
--------
162-> Cornell University Rover To Land On Mars And Explore Martian Highlands In 2001
ITHACA, N.Y. --  Following a real-life space odyssey to Mars in 2001, alate-model lander and rover, equipped with a Cornell University scientificinstrument package called Athena, will roam and study a large corridor ofthe Martian highlands and ancient terrain, the National Aeronautics andSpace Administration (NASA) announced today (Nov. 7, 1997). The mission, to be launched in April 2001, will seek out the geologicalrecord of ancient Martian waterways and possible biology, according toSteven Squyres, Cornell professor of astronomy and the principal scienceinvestigator for the Mars 2001 Lander mission. The Cornell portion of the mission is being funded by NASA at a cost of $17million. James Bell, Cornell senior research associate of astronomy, will joinSquyres as one of 20 science team members from the United States, Germany and Denmark for theAthena project. Squyres begins work on the project at NASA's Jet Propulsion Laboratory inPasadena, Calif., on Monday.  "We're starting fast.  We're going to hit theground running," he said. The Athena rover payload on the Mars 2001 Lander/Rover has four scientificobjectives: -- to provide sharp, color stereo imaging of the planet's surface; -- to determine the fine-scale textural properties of the Martian landscape; -- to identify the elements and minerals of the dusty Martian countryside; -- to collect and store surface samples in the hope that the samples willbe retrieved later in the mission. Autumn has been nothing but gilt-edged for Cornell's role in space sciencehistory, as today's NASA announcement follows close on the heels of otherimportant space projects. On Oct. 21, NASA announced that Cornell will lead and direct a $154 millionmission to conduct close-proximity comet fly-bys, scheduled for launch in2002.  On Oct. 31, two Cornell astronomy professors announced the discoveryof two new moons orbiting the planet Uranus. "We are delighted that NASA has once again affirmed Cornell's leadership inspace studies by appointing Steve Squyres to lead Project Athena," CornellPresident Hunter Rawlings said.  "Athena is the ancient Greek goddess ofwisdom and guardian of the city of Athens, of whose enlightened citizensPericles wrote, 'We throw open our city to the world.'  Today, we can saythat we open our city -- our campus -- to the stars." Athena is designed to be larger and to last longer than Sojourner, whichsent back detailed images of the Martian surface this summer. Rover Athena is part of two Mars Surveyor 2001 missions. The first mission,to be launched in 2001, will be the Mars 2001 Orbiter, due for launch inMarch of that year. Athena is part of the second mission, called the Mars2001 Lander/Rover, which is scheduled for launch in April of that year. Prior to the Mars Surveyor 2001 missions, NASA will launch two otherrobotic Mars missions, now scheduled to blast off in late 1998 and early1999, the space agency said. Both of the Mars Surveyor 2001 missions are part of an ongoing series ofMars exploration spacecraft, which began with the 1996 launches of the MarsGlobal Surveyor and the Mars Pathfinder lander.  All the missions arecomponents of NASA's long-term exploration of the red planet, in which twomissions are launched approximately every 26 months, according to the spaceagency. An integrated science team from the Jet Propulsion Laboratory and LockheedMartin Aeronautics, Denver, will develop the missions. Cornell's Athena rover payload is an integrated suite of scientificinstruments designed to conduct onsite analyses of the surface.  Thoseinstruments include an imager and infrared spectrometer, giving theinstruments the ability to see through dust coatings that normally wouldobscure spectral analyses of the surface. Athena also will feature an Alpha-Proton-X-Ray spectrometer (APXS), aMossbauer spectrometer and a Raman spectrometer, all of which gathermineralogical data. The microscopic imager will reveal surface compositioninformation in detail. Rather than collect loose pebbles and Martian dust, a low-poweredmini-corer will drill through the Martian rock to accumulate intact samplesof rocks and boulders.  The mini-corer can drill at an angle and has beendemonstrated to cut through dense, basalt-type formations, according toSquyres. In addition to Athena, the Mars 2001 Lander will carry an imager to takepictures of the terrain during the lander's rocket-assisted descent to thesurface.  The images will render geologic information, important for therover's initial operations and traverses by the Athena rover.  NASA saidthat Michael Malin of Malin Space Science Systems Inc., San Diego, Calif.,will be the team leader for the Descent Imager science team.
--------
163-> Gene-Finding Method May Speed Search For Disease-Causing Mutant Forms
A new research tool -- developed at the University of Southern California by a collaboration between mathematicians and laboratory molecular biologists --promises to speed dramatically the hunt for disease-causing genes. Coupled with the use of DNA chips, the ExonPCR technique created by gene researcher Norman Arnheim, Ph.D., and computational biologist Pavel A. Pevzner, Ph.D., allows speedy reconstruction of the way genes are written on human chromosomes. The problem addressed is posed by the curious and still unexplained way in which the genetic message is concealed on chromosomes within a huge volume of nonmessage-bearing "junk" DNA. Genes consist of a length of DNA roughly 10,000 "letters" long in the four-letter A-C-G-T chemical alphabet of heredity.  Unfortunately for researchers, the message is not written in a single, continuous stretch, but divided up into as many as 50 segments called "exons," spaced out over a stretch of chromosome DNA 1 million letters long or even longer. Such exons are fused into a continuous message when the gene goes into actual use, creating what is called an "mRNA" or "cDNA" form of the gene. New DNA chip techniques have recently made it feasible to zero in on all cDNA from large regions on chromosomes suspected of carrying a disease-causing gene.  This  enables researchers to isolate a group of suspect genes for further testing. But knowledge of the exon borders from the original chromosomal form of these genes is still required to quickly compare genes from large numbers of people in order to find disease-causing mutant forms.  Researchers first must know how the genetic message actually appears on the chromosomes -- that is, into how many exons the message is broken up, and where the breaks occur. Since with existing techniques this information is invisible in the cDNA form, biologists are now forced to do time-consuming chromosomal DNA sequencing to reconstruct the "hidden" boundaries.  (The cDNA form is too elusive and expensive to detect in mass screenings.) And this is where USC's new technique comes into play.  Dr. Pevzner, a  professor of mathematics and computer science specializing in computational biology, will discuss the new technique Friday, Nov. 7, at the Gene Discovery in Silicon Conference in Atlanta, Ga. According to Pevzner, the technique resembles the old parlor game of "20 Questions" in which a series of "yes" or "no"answers is used to narrow the possibilities and solve a riddle. In the molecular biological form of the game, questions are asked using a technique known as the Polymerase Chain Reaction (PCR).  Dr. Arnheim, who heads the Molecular Biology Program in the USC College of Letters, Arts and Sciences, was one of the original developers of PCR.  The ExonPCR experimental protocol was developed in Arnheim's USC laboratory. Every query in the "game" measures the distance between two PCR primers -- specified pairs of "words" (groups of letters long enough to be unmistakably recognized) in the genetic message.  However, this distance may differ in cDNA and  chromosomal DNA since chromosomal DNA contains junk DNA between PCR primers. If the chromosomal DNA distance is greater, reasoned Pevzner, it's because  the two words are separated by junk DNA on the chromosomes and must therefore be carried on different exons. By repeating the process and starting at different words, the boundaries of the exons can be narrowed down.  Pevzner and computer science graduate student Sing-Hoi Sze have demonstrated mathematically that, on average, 30 such word queries can reveal an approximate map of the exons in cDNA.  Then, another technique, "ligation mediated PCR," can establish  the exact boundaries. The technique, which the researchers describe as "gene hunting without DNA sequencing," avoids expensive and time-consuming efforts to sequence the entire million-base-pair length of chromosomal DNA. Working on the "20 Questions" technique in the Arnheim laboratory were  postdoctoral researchers Guorong Xu and Cheng-Pin Liu, with computer scientist Sze coaching the ExonPCR software to  play the "20 Questions" game "We believe that the technique will greatly speed the identification of mutations, with direct applications for research into genetically based human disease," says Arnheim, who holds USC's George and Louise Kawamoto Chair in Biological Sciences. The research was funded by grants from the National Institutes of Health, the U.S. Department of Energy and the National Science Foundation.
--------
164-> Space Research Shines A Light On Tumors To Save Children's Lives
Special lighting technology developed for NASA's commercial plant growth experiments in space may help treat cancerous brain tumors in children. A treatment technique called photodynamic therapy is using tiny pinhead-size Light Emitting Diodes (LEDs) -- developed for NASA Space Shuttle plant growth experiments -- to activate light-sensitive, tumor-treating drugs. Experiments indicate that when special tumor-fighting drugs are illuminated with LEDs, the tumors can be more effectively destroyed than with conventional surgery.  The light source, consisting of 144 of the tiny diodes, is compact -- the size of a small human finger about one-half-inch in diameter -- and mechanically more reliable than lasers and other light sources used to treat cancer.  The entire light source and cooling system is only the size of a medium suitcase. Dr. Harry Whelan of the Medical College of Milwaukee, WI, has obtained Food and Drug Administration approval to use the LED probe for the treatment of children's brain tumors on a trial basis.  Dr. Whelan's therapy involves injecting the patient's bloodstream with a drug called Photofrin II.  Photofrin II attaches to the unwanted tissues and permeates into them, leaving the surrounding tissues unaffected.  Dr. Whelan then places the new solid-state LED probe near the affected tissue to illuminate the tumor and activate the Photofrin II drug.  Once activated by the light, the drug destroys the tumor's cells, leaving the normal brain tissues virtually untouched. "This new probe," said Dr. Whelan, "illuminates through all nearby tissues.  We've used lasers too, but they are often unreliable and limited in color spectrum.  Lasers also are very expensive and lose power in their fiberoptic cables." The LED probe can be used for hours at a time and remains cool to the touch.  The entire LED unit can be purchased for a fraction of the cost of a laser. The feasibility of using LEDs in cancer treatment was demonstrated through a NASA Small Business Innovation Research contract managed by the Technology Transfer Office at the Marshall Space Flight Center, Huntsville, AL.  The small business, Quantum Devices, Inc., of Banreveld, WI, developed the LEDs as a light source for a chamber used by NASA to conduct plant research in space.  These LEDs now form the tip of a new nine-inch neural probe. "We're very happy to be a part of this innovative procedure," said Rose Allen, manager of the Space Product Development Office at Marshall.  "It is exciting to see how NASA's commercial space research results in benefits on Earth.  Who would have thought that experiments searching for ways to improve agricultural products would lead to a medical procedure that could save children's lives?" said Allen. "The LED technology developed by NASA offers new hope to children with cancer," Dr. Whelan said.  "Every one of our cases will be a critical case with no hopeful alternatives.  We think this new probe will help give children with tumors a chance to live healthy, happy lives." After Whelan concludes the FDA clinical trials, he anticipates full approval of what soon could be the operating technique of the future.  Further research combining LEDs and new promising drugs is showing the possibilities of deeper tumor penetration with the probe, faster reaction times and shortened patient sensitivities to sunlight. LED's low-energy technology flew on the second United States Microgravity Laboratory Spacelab mission in October 1995, as part of the Astroculture Plant Growth Facility.  That experiment was led by Dr. Raymond J. Bula of the Wisconsin Center for Space Automation and Robotics in Madison, WI, a NASA Commercial Space Center.  Commercial Space Centers, supported by NASA, pursue opportunities for continued growth of U.S. industry through the use of space. "NASA has played a number of important roles," Dr. Whelan said.  "NASA has funded the development of these LEDs for space research over the years," he added.  "If it wasn't for the pre-existence of all that technology, it wouldn't have been possible for us to walk right in and use it to treat cancer."
--------
165-> "Glasphalt" May Pave The Way For Worldwide Aviation In The 21st Century
ROLLA, MO. -- A glass-and-asphalt paving material invented nearly 30 yearsago at the University of Missouri-Rolla is now being used in a new way topave airport runways and taxiways. For the first time, "glasphalt," which paved the way for recycling wasteglass into roads and parking lots, is being used to pave an airport runway,parking apron and taxiway. The project, at a general aviation airport inRolla, Mo., was completed in November 1996. One year later, the material isholding up exceptionally well, says Dr. Delbert E. Day, Curators' Professorof ceramic engineering at UMR and one of the inventors of glasphalt. Ozark Rivers Environmental Inc., a not-for-profit corporation, used a grantfrom the Missouri Environmental Improvement and Energy Resources Authorityto demonstrate how waste glass can be easily and economically substitutedfor some of the rock and sand used in ordinary asphalt paving, and inpaints used to mark airport runways and taxiways. "The purpose of the demonstration project is to show how some of the approximately 10 million tons of waste glass in the U.S. that cannotpresently be recycled into new glass products can be disposed of in alow-cost and beneficial way that avoids the costly disposal fees now beingpaid to put waste glass in landfills," Day says. Three faculty members from UMR provided technical help in paving therunway, taxiway and parking apron at the Rolla Downtown Airport, a smallgeneral aviation airport. After paving the 3,000-foot-long runway with four inches of glasphalt thatcontained 10 percent broken glass, it was painted with a paint that alsocontained waste glass as part of the pigment. According to Day, about 450 tons of waste glass, crushed to 1/4-inch andsmaller, that would otherwise have been buried in landfills, was used inplace of some of the rock and sand in the glasphalt paving material. "One of the advantages of glasphalt is that no special equipment is needed,and glass of any color and type from bottles, windows, glass used forbaking, and tableware can be used," Day says. The glasphalt was prepared ina commercial asphalt plant close to Rolla, and then placed using the sameequipment used for laying ordinary asphalt paving. "Glass recycling is difficult throughout Missouri since there are only afew glass plants in the state which will purchase scrap glass or cullet,"Day says. "In addition, the buyers of scrap glass are often long distances-- 100 miles or more -- from the communities where the scrap glass isrecovered, so transportation costs can exceed the value of the glass." All of the glass used in the airport project was collected from communityrecycling programs in south central Missouri. "Glasphalt offers the advantages of being able to use those types of wasteglass which would otherwise be buried in landfills," says Dr. DavidRichardson, a UMR associate professor of civil engineering, who supervisedthe installation and evaluation of the glasphalt being used in the airportdemonstration project. "Glasphalt is also a means of disposing of verylarge quantities of waste glass and even for small projects like a parkinglot or street repair, which can use several hundred tons of waste glass." In addition to demonstrating the usefulness and practicality of usingglasphalt for airport uses, the reflective properties of glasphalt willalso be evaluated. Glasphalt has been used extensively in Baltimore, Md.,for many years because the glass particles tend to reflect the streetlights and give the road surface a "sparkle." "The higher reflectivity of a glasphalt runway could be an advantage atnight since the runway should reflect the aircraft's landing lights and bemore visible than an ordinary asphalt runway," Day says. In addition, the tendency of glasphalt to dry faster after a rain thanordinary asphalt is an advantage for aviation use, and that will also beevaluated during the demonstration. The glass particles in glasphalt do notabsorb water like the rock in regular asphalt, Day says. "And in tests madeby the Missouri Highway Department, skid resistance of glasphalt was provento be 50 percent higher than typical asphalt, which is important toaviation when planes land and take off at high speeds," he says. The paint used to mark the glasphalt runway also used waste glass ground toa fine powder. Dr. Harvest L. Collier, a UMR professor of chemistry, hasformulated and produced a "glass paint" that uses the finely ground glassas part of the pigments. The properties of the glass paint meet thespecifications for use on highways, but it has never been used for markingairport runways and taxiways. Because of the glass it contains, this paintmay also be reflective. The long term durability of this paint to weatherconditions will also be evaluated during the demonstration. The information to be gained from this project and the technology beingdemonstrated could benefit many small Missouri communities that havedifficulty in disposing of waste glass and that want to avoid the cost ofputting the glass in a landfill. "There are more than 180 small airports in Missouri, and thousandsthroughout the U.S., which could benefit from the results of this project,"Day says. "Glasphalt offers the opportunity to dispose of large amounts ofwaste glass in a way that could improve the general aviation airports insmall communities. "These small airports often play an important role in industrialdevelopment," Day says.
--------
166-> Solar Mystery Nears Solution With Data From SOHO Spacecraft
 A likely solution to one of the major mysteries of the Sun has emerged from recent observations with the European Space Agency/NASA Solar and Heliospheric Observatory (SOHO) mission. The new findings seem to account for a substantial part of the energy needed to cause the very high temperature of the corona, the outermost layer of the Sun's atmosphere.  Since the corona's temperature was first measured 55 years ago, scientists have lacked a satisfactory explanation for why that temperature is three million degrees while the visible surface of the Sun is only 11,000 degrees Fahrenheit or about 6,000 degrees Celsius. It is physically impossible to transfer thermal energy from the cooler surface to the much hotter corona, so the energy transfer had to be in the form of waves or magnetic energy, but no measurement to date had found adequate energy to account for the coronal temperature. "We now have direct evidence for the upward transfer of magnetic energy from the Sun's surface toward the corona above.  There is more than enough energy coming up from the loops of the 'magnetic carpet' to heat the corona to its known temperature," said Dr. Alan Title of the Stanford-Lockheed Institute for Space Research, Lockheed Martin Advanced Technology Center, Palo Alto, CA, who led the research.  "Each one of these loops carries as much energy as a large hydroelectric plant, such as the Hoover dam, generates in about a million years!" "We now appear to be closing in on an explanation as to why the solar corona is over 100 times hotter than the solar surface -- the solution to a 55-year old puzzle," said Dr. George Withbroe, Director of the Sun-Earth Connection Program at NASA Headquarters, Washington, DC.  "These results underline the importance of long-term study of the changing conditions on the Sun from the superior vantage point of space." Energy flows from the loops when they interact, producing electrical and magnetic "short circuits."  The very strong electric currents in these short circuits are what heats the corona to a temperature of several million degrees.  Images from the Extreme ultraviolet Imaging Telescope (EIT) and the Coronal Diagnostics Spectrometer (CDS) on SOHO show the hot gases of the ever-changing corona reacting to the evolving magnetic fields rooted in the solar surface. The observations with SOHO's Michelson Doppler Imager (MDI) provided long-duration, highly detailed, and well calibrated time-lapse movies of the magnetic fields on the visible surface or "photosphere" of the Sun.  These revealed the rapidly changing properties of what Title calls "the Sun's Magnetic Carpet," a sprinkling of tens-of-thousands of magnetic concentrations.  These concentrations have both north and south magnetic poles, which are the "foot points" of magnetic loops extending into the solar corona. Like field biologists who study the populations and life cycles of animal herds, the SOHO researchers analyzed the appearances and disappearances of large numbers of the small magnetic concentrations on the solar surface.  "We find that after a typical small magnetic loop emerges, it fragments and drifts around and then disappears in only 40 hours," Title said.  "It's very hard to understand how such a short-lived effect could be driven by the magnetic dynamo layer that is over 100,000 miles beneath the surface of the Sun.  This may be evidence that unknown processes are at work in or near the solar surface that continuously form these loops all over the Sun." Professor Phillip Scherrer of Stanford University is the MDI Principal Investigator.  MDI was built at the LM Technology Center and is a project of the Stanford-Lockheed Institute for Space Research. The new observations were made with several instruments on SOHO, which is stationed about 900,000 miles (1.5 million kilometers) sunward of the Earth in interplanetary space, where it has an uninterrupted view of the Sun and of the solar wind particles blown from the Sun.  SOHO is operated from a control center at NASA's Goddard Space Flight Center, Greenbelt, MD.  SOHO was launched on Dec. 2, 1995 aboard an Atlas-IIAS expendable launch vehicle from Kennedy Space Center, FL.
--------
167-> First Oberservation of Space-Time Distortion By Black Holes
The next time you feel like you're barely dragging along, blame relativity. You'll be stretching the point, but it appears that Einstein was right: space and time get pulled out of shape near a rotating body. Einstein predicted the effect, called ``frame dragging,'' 80 years ago. Like many other aspects of Einstein's famous theories of relativity, it's so subtle that no conventional method could measure it. Using recent observations by X-ray astronomy satellites, including NASA's Rossi X-ray Timing Explorer, a team of astronomers is announcing that they see evidence of frame dragging in disks of gasswirling around a black hole. The discovery will be announced today at a meeting of the High Energy Astrophysics Division of the American Astronomical Society in Estes Park, Colo., by Dr. Wei Cui of the Massachusetts Institute of Technology, and his colleagues, Dr. Nan Zhang, working at NASA's Marshall Space Flight Center, and Dr. Wan Chen of the University of Maryland in College Park. Frame dragging is one of the last frontiers in relativity. More familiar and already proven are the conversion of mass into energy (as seen in atomic bombs and stars) and back, the Lorentz transformations that make objects near the speed of light grow thinner and heavier and stretch time, and the warping of space by gravity (as seen when light is bent by a massive object). Einstein also predicted that the rotation of an object would alter space and time, dragging a nearby object out of position compared to predictions by the simpler math of Sir Isaac Newton. The effect is incredibly small, about one part in a few trillion, which means that you have to look at something very massive, or build an instrument that is incredibly sensitive and put it in orbit. Cui, Zhang, and Chen followed the first path, looking at radiation coming from around black holes, once-massive stars compacted by an explosion to a diameter of a few kilometers. The gravitational field is so strong that everything - including light - goes in. While we cannot see black holes directly, we can detect them by the light emitted by gas as it spirals inward to the black hole's point of no return, called the "event horizon". Like an unruly crowd jamming a stadium entrance, the gas becomes heated as it gets closer to theevent horizon, and gives off radio waves, visible light, and - just before it disappears - x-rays. The best place to look for black holes is in binary star systems where a normal star feeds the disk of accreting matter crowding its way into the accompanying black hole. Cui's team looked at two black holes, called GRS 1915+105 and GRO J1655-40, that also emit superluminal gas jets. In an earlier paper authored by Nan Zhang, the team measured the spin of these black holes based on the highest energy radiation which would also come from the innermost, and last possible orbit before the event horizon. With the spin measured, the team turned to quasi-periodic oscillations, slight changes in the timing of the signals from the superluminal jets, and in other black holes. What they calculated is that the oscillations are caused by the frame dragging effect making the accretion disk precess. Precession is a very familiar effect, seen when a toy top both spins rapidly about it's own axis, yet at the same time, executes a slower circular motion about the local vertical axis. This second circular motion is precession, and it's not only found in toy tops, but also in the motion of celestial bodies such as the Earth, or accreting disks around black holes in distant space. What Cui, Zhang, and Chen found was a precession far greater than a simple mechanical effect could explain. In the case of GRO J1655-40, which is about 7 times more massive than our sun and spinning near the maximum allowed rate, the accretion disk precesses 300 times a second! GRS 1915+105, also spinning near the maximum rate, the disk precesses a mere 67 times per second. Two other black holes have very slow and variable precession rates, indicating that their accretion disks have not settled into a stable formation. Someone observing a safe distance away from the black hole binary system would see the accretion disk appear to wobble like a top out of balance. Zhang said the team is confident of its findings because spin calculations made in this work give the same answer as earlier spin calculations using a different approach. And speaking of d  
--------
168-> Scientists Discover New Breast Cancer Susceptibily Gene
NEW YORK, N.Y., Oct. 31, 1997--Mutations in the gene P-TEN can increase a woman's risk of breast cancer, according to scientists at Columbia University College of Physicians & Surgeons. The findings identify the third breast cancer susceptibility gene; the other two such genes are BRCA1 and BRCA2. The discovery could lead to better tests for early detection and more effective treatments. The study, published in the Nov. 1 issue of the American Journal of Human Genetics, was a collaboration between Columbia University scientist Dr. Monica Peacocke and Myriad Genetics in Salt Lake City, Utah. The P-TEN gene, also called MMAC1, is located on chromosome 10. The role of this chromosome in the development of various sporadic cancers has been investigated for nearly a decade. Dr. Peacocke and colleagues made their discovery while searching for the genetic basis of Cowden's syndrome, a little-known dermatological disorder. The autosomal dominant syndrome, which affects mainly women, causes skin rashes, tiny wart-like bumps, thyroid disease, and --beginning in the teen-age years-- severe benign fibrocystic disease. By their 40s, 50 percent to 75 percent of women with Cowden's syndrome develop breast cancer. "Cowden's syndrome is an under-recognized and under-diagnosed disorder. The identification of this gene will allow us to develop screening tests so that these women can follow early detection and prevention strategies and get prompt treatment of breast cancer," says Dr. Peacocke, associate professor of medicine and dermatology at the Columbia-Presbyterian Medical Center. Cowden's syndrome may also increase a woman's risk of endometrial cancer. Therefore, women with the genetic mutation who also have breast cancer might not be candidates for treatment with tamoxifen, which itself can increase the risk of endometrial cancer. Researchers are not sure of the exact incidence of Cowden's syndrome. Most cases of breast cancer are the result of sporadic, as opposed to inherited, mutations. "Just as not every woman with breast cancer has mutations in the BRCA1 or BRCA2 genes, not every case of breast cancer will involve P-TEN," says Dr. Peacocke. "But this is another piece of the breast cancer puzzle." "Based on our finding of P-TEN, we are currently testing women with a family history of breast cancer and thyroid disease for mutations of P-TEN, which would give early warning of cancer risk," says Dr. Peacocke. "This way we can provide more effective genetic counseling for families where there is a significant family history of breast cancer." The study's other authors were Hui C. Tsou, David H.-F. Teng, Xiao Li Ping, Valeria Brancolini, Thaylon Davis, Rong Hu, Xiao Xun Xie, Alexandra C. Gruener, Carolina A. Schrager, Angela M. Christiano, Charis Eng, Peter Steck, Jurg Ott, and Sean V. Tavtigian. The study was funded by the National Cancer Institute and the National Institute on Aging.
--------
169-> Great Lakes Intensify Ferocity Of Passing Storms, Scientists Say
CHAMPAIGN, Ill. -- The Great Lakes exert a significant influence on passing cyclones, causing storms to speed up and grow in strength, say researchers at the University of Illinois and the Illinois State Water Survey. Also, the number of potentially dangerous storms is on the rise, they report. "Cyclones that traverse the Great Lakes have important impacts on the physical environment and human habitation in the region," said James Angel, a climatologist with the Survey. "There is a lot of development along the lakes, and when the water level is high -- as it is now -- the area becomes extremely vulnerable to shoreline damage from these storms. A better understanding of how the Great Lakes affect passing cyclones may allow better forecasting of these storms and their potential effects." Cyclones are low-pressure storm centers, "often accompanied by high winds and heavy precipitation," said Scott Isard, a U. of I. professor of geography. "The ensuing storms can be huge, ranging in size from 800 to 1,500 miles in diameter." To study the effect the Great Lakes have on passing cyclones, Angel and Isard examined the rates of movement and the changes in intensity for 583 cyclones that passed over the region between the years 1965 to 1990. The researchers' findings, published in the September issue of Monthly Weather Review, identify several important features regarding the lakes' influence on these storm systems. "In general, we found that cyclones accelerated as they approached the Great Lakes region and increased in intensity over the lakes," Angel said. "This effect was most pronounced from September to November, when the surface waters of the lakes are warmer than the surrounding air and can provide a major source of both moisture and heat that energizes passing storms." From January to March, when broken ice cover is generally present on the lakes, cyclones accelerated less and did not intensify, Angel said. However, cyclones that traversed the region during May and June did speed up and grow in strength. "This surprised us, because the lakes are usually cooler than the overriding air mass during spring and summer, and have not generally been considered as an important energy source for cyclones at that time," Angel said. "We don't yet have a satisfactory explanation for this phenomenon." In another study (to appear in the journal Climate), Angel and Isard analyzed trends in storm strength for the years 1900 to 1990. "We are seeing evidence of an increase in the number of stronger storms, particularly in the months of November and December," Angel said. Historically, some of these cyclones have produced hurricane-force winds and caused extensive damage to shipping. The "great storm of 1913," for example, sank a dozen ships and claimed more than 250 lives. More recently, the ore carrier Edmund Fitzgerald -- popularized in a ballad by Canadian singer and songwriter Gordon Lightfoot -- sank in Lake Superior during a major storm on Nov. 10, 1975. All hands were lost.
--------
170-> A Real McCoy 'Tricorder' -- Researchers Develop Affordable, Hand-Held Biosensor For Diagnostics
A portable, hand-held biosensor capable of detecting a wide range of medically important chemical compounds has been created by a team of researchers from The Scripps Research Institute (TSRI) of La Jolla, California and the University of California, San Diego. The biosensor, which changes colors to signal the presence of specific molecules, may represent a new type of practical and affordable device for a variety of medical applications. Potential uses range from the screening of chemicals for drugs to diagnosing illness at the bedside without having to send samples to the lab. The work, "A Porous Silicon-Based Optical Interferometric Biosensor," was published in today's issue of the journal Science. According to M. Reza Ghadiri, Ph.D., Associate Professor, Department of Chemistry and The Skaggs Institute for Chemical Biology, TSRI, and study co-author, "It is exciting to be able to adapt such inexpensive and readily available material for use in this new technology. We are hopeful that we will see commercial applications within two to five years." "One can envision something like a Star Trek medical 'tricorder' that a nurse might bring to the bedside of a patient," said Michael Sailor, Ph.D., professor of chemistry and biochemistry at UCSD, and co-author of the study. For non-trekkies, a medical tricorder is a hand-held device that performs all the duties of a clinical laboratory, capable of sampling, analyzing, reporting and otherwise diagnosing a patient's ailments. "In the original television show, Dr. McCoy would point the device at a patient and it would take a sample and read out all his problems," Sailor explained. "Our device was inspired by that image--a small, sensitive diagnostic unit that is very easy to use." Also collaborating in the study were Victor S.-Y. Lin, and Kianoush Moteshari, researchers with TSRI; and, Keiki-Pua S. Dancil, a graduate student in Sailor's laboratory at UCSD. As reported in the Science article, the new biosensor is able to detect many of the classic biological reactions that involve the recognition and binding of one molecule to another partner molecule. In their tests, for example, the biosensor was able to match tiny concentrations of specific DNA sequences to its complementary strand, suggesting a potential role for a variety of genetic studies and tests, including DNA fingerprinting for clinical and forensic applications. Another biosensor proved sensitive to the binding of certain antibodies, manufactured by the body's immune system, to small amounts of their specific antigens--a class of molecules produced by invading organisms that include viruses, bacteria, in addition to toxins and allergens. The biosensor was able to detect DNA concentrations at levels of down to 9 femtograms per square millimeter. (A femtogram is a millionth of a billionth of a gram.) By comparison, current technologies are only capable of detecting amounts about 100 to 1,000 times greater than the new biosensor. "We have found nothing as simple or practical as this device with as much sensitivity," said Ghadiri. "The results show that we can sense very small molecules that in other systems do not produce a very big change. In our system, we see a huge change." The new biosensor is based on work conducted during the past few years in Sailor's laboratory with porous silicon, small chips of silicon sculpted through a chemical etching process into a forest of tiny trees. When a one centimeter-square of this silicon forest is stretched out, its surface area would be about as large as a standard desktop.e discovery of some "new physics" inside the porous silicon film. Though not fully understood, the scientists speculate that the binding of molecules to the surface significantly alters the refractive index of the silicon matrix itself, resulting in a major increase in sensitivity. "It's as if the color of the film itself is changing because we induce this change in the silicon nanoparticles," said Sailor. "So that's the amazing thing. That was the Eureka thing." Funding for the research was provided by the Office of Naval Research and the National Institutes of Health.
--------
171-> Galileo Finds Arizona-Sized Volcanic Deposit On Jupiter's Moon Io
 Observations taken by NASA's Galileo spacecraft five months apart reveal a new dark spot the size of Arizona on Jupiter's moon Io, indicating that dramatic volcanic activity occurred during that time. "This is the largest surface change on Io observed by Galileo during its entire two-year tour of the Jovian system," said Galileo imaging team member Dr. Alfred McEwen, a research scientist at the University of Arizona in Tucson. The visible change took place during the five months between Galileo's seventh and tenth orbits of Jupiter. The change is manifested as a dark spot about 249 miles in diameter, surrounding a volcanic center named Pillan Patera, which is named after the South American god of thunder, fire and volcanoes. Dark features at the center of the deposits may be new lava flows. These changes appear in images taken by the Solid State Imaging system aboard Galileo, with marked differences between the pictures taken on April 4, 1997 and September 19, 1997. In June of 1997 an active plume was observed over Pillan by Galileo and the Hubble Space Telescope with a height of 75 miles, and both Galileo and ground-based astronomers observed an intense hot spot. "Most of the volcanic plume deposits on Io show up as white, yellow or red due to sulfur compounds. However, this new deposit is gray, which tells us it has a different composition, possibly richer in silicates than the other regions," McEwen explained. "While scientists knew that silicate volcanism existed on Io from high temperatures, this may provide clues as to the composition of the silicates, which in turn tells us about Io's evolution." "Io is probably primarily composed of silicates, which is the type of volcanic rock found on Earth, " McEwen added, "but the extreme volcanism of Io may have led to the creation of silicate compositions that are unusual on Earth." The Io images showing the changes in Pillan Patera also reveal alterations in the plume deposit of Pele, the large red oval southwest of Pillan, which may indicate that both plumes were active at the same time and interacted with one another. A dark region southwest of Pele, which appears similar to the Pillan deposits, has been present since the Voyager flybys in 1979. Io is the most volcanically active body in the Solar System. Scientists hope to learn more about the fiery satellite when Galileo continues its studies over the next two years, during a mission extension known as the Galileo Europa Mission. The extended mission will include eight additional encounters of Europa, four of Callisto, and two close Io flybys in late 1999, depending on spacecraft health. Galileo will pass very close to Pillan Patera in the first of the two Io flybys, so high-resolution images can be acquired over a small portion of this area. Galileo was launched in 1989 and entered orbit around Jupiter on Dec. 7, 1995. The final satellite encounter of its two-year primary mission will occur on Thursday, Nov. 6, 1997 at 3:32 p.m. EST, when the spacecraft swoops over Europa at an altitude of 1,269 miles. "The Galileo Orbiter is performing flawlessly and all 11 of its sophisticated science instruments and the radio science investigations are still providing excellent data," said Galileo Project Manager Bill O'Neil of NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA. "A great bounty of Jupiter system science has been obtained and the continuing study of these data will surely add many important discoveries.  While not all of the original objectives could be met due to the antenna failure, I believe that the overall science return from Galileo will easily exceed what was envisioned at project inception 20 years ago, because our team of scientists and engineers has done such a superb job of capturing the most important observations." The Galileo mission is managed by JPL for NASA's Office of Space Science, Washington, DC. JPL is an operating division of California Institute of Technology, Pasadena, CA. Images of Io and other data received from Galileo are posted on the Galileo home page on the World Wide Web at URL: http://www.jpl.nasa.gov/galileo
--------
172-> New Cancer Treatments May Improve Survival Rates, Reduce Radiation Side Effects
MEMPHIS, Tenn., November 6, 1997 -- Doctors at St. Jude Children's Research Hospital today announced new brain tumor research protocols they hope will improve survival rates and reduce side effects of radiation therapy among pediatric cancer patients. The protocols rely on three dimensional imaging (CT imaging or MR imaging) to define and target tumors more accurately. Not only is a lower radiation dose to normal tissue made possible, but treatment of sensitive areas of the brain is more easily avoided. "Because these children will undergo extensive testing prior to radiation therapy to identify side effects caused by the tumor, surgery, or other causes, this study will help us identify which side effects are specifically caused by radiation," says Thomas E. Merchant, D.O., Ph.D., Clinical Director in the Department of Radiation Oncology at St. Jude Children's Research Hospital. "We'll also determine more precisely the amount of radiation that causes a particular side effect and improve our ability to decrease or avoid radiation-related side effects altogether, " added Dr. Merchant. Radiation therapy is a first-line treatment for primary brain tumors, which comprise more than half of the central nervous system tumors in children. Unfortunately, radiation therapy is associated with severe side effects, including behavioral problems, decreased IQ, decreased growth and development, and hearing loss. Because some of these problems may in fact be due to the brain tumor, the investigators have planned extensive endocrine, psychological, and other testing for these patients which should reveal new knowledge about the effects of tumors on children. One of the protocols specifically addresses the second most common childhood brain tumor type, medulloblastoma, and also involves the use of anticancer drugs. "By giving average risk patients reduced dose radiation more precisely, and high dose chemotherapy with therapy to hasten the recovery of bone marrow cells, we hope to increase the number of patients who survive and to reduce side-effects like learning difficulties, hearing loss and endocrine problems," says Amar Gajjar, M.D., a member of the Division of Neuro-Oncology at St. Jude Children's Research Hospital. "For the high risk patients, we will treat them with a promising new drug, called topotecan, followed by the same precise standard dose radiation therapy and high dose chemotherapy. We hope this combination of therapies will increase survival rates and reduce side effects." Like the radiation therapy, the chemotherapy used in this study will be given to patients in a unique manner. All patients will receive four courses of high dose chemotherapy using drugs which are very effective in treating this tumor. Following each course of chemotherapy, the patients will receive special therapy to help restore their bone marrow, and which will allow them to receive chemotherapy on an optimal timetable of every four weeks. Patient enrollment for studies involving both protocols is underway. All costs of treatment beyond those reimbursed by third party insurers, and total costs for families who have no insurance, will be covered. To be eligible for enrollment in the study involving medulloblastoma, patients must be at least three years old, have medulloblastoma and have received no prior radiation therapy and chemotherapy. Patients who have received surgery without radiation therapy or chemotherapy can be enrolled provided they can start the protocol no more than 28 days after surgery. To be eligible for the protocol involving radiation therapy targeting, patients must be at least 18 months old, have a primary brain tumor that requires only focal irradiation, and have had no prior radiation therapy. Patients who have received or will receive surgery and chemotherapy can be enrolled. St. Jude Children's Research Hospital, in Memphis, Tenn., was founded by the late entertainer Danny Thomas. The hospital is an internationally recognized biomedical research center dedicated to finding cures for catastrophic diseases of childhood. The hospital's work is primarily supported through funds raised by the American Lebanese Syrian Associated Charities (ALSAC). All St. Jude patients are treated regardless of their ability to pay. ALSAC covers all costs of treatment beyond those reimbursed by third party insurers, and total costs for families who have no insurance.
--------
173-> Expert System To Address Problems Of Electromagnetic Interference
ROLLA, Mo. — Electrical engineers at the University of Missouri-Rolla areworking with several private companies to create a software programdesigned to catch and fix electromagnetic glitches during the design ofprinted circuit boards used in computers, automotive parts and a broadarray of other electronic products. The three-year project, now in its second year, will result in "expert"software products that will help electronics makers meet federal standardson electromagnetic emissions. The expert system should also save circuitboard makers a lot of time and money by allowing them to catch and fixproblems before the circuit boards are manufactured. "Computer systems are getting faster and faster, and the faster they get,the more likely they are to act as tiny radios and emit signals," says Dr.Todd Hubing, an associate professor of electrical engineering at UMR. "Whatwe have to do is make them extremely inefficient radiators." Hubing is one of four UMR electrical engineering researchers involved inthe UMR EMI Expert System Consortium. EMI stands for electromagneticinterference. The UMR research team also includes one visiting scholar, 15 graduatestudents and five undergraduate students. The consortium is a three-year project between UMR and nine diversebusinesses -- from equipment manufacturer Caterpillar to computer giantsIntel and Sun Microsystems. The consortium's goal is to develop software toeliminate electromagnetic interference problems during the design phase ofcomputer circuit boards. The project has more than $1 million in fundingfrom consortium members. In the personal computer's early days, the circuit boards that ran the PCsoften would interfere with the music of an office radio. That's because thecircuit boards act as miniature radio stations and broadcast signals. Theresult is radio static. This is one common example of how electronic noise can disrupt theoperation of everyday products, and this problem, for the most part, hasbeen taken care of by manufacturers of both PCs and radios. But newproblems of electromagnetic interference are likely to arise as portableelectronic products -- such as compact-disc players, laptop computers andhand-held computers -- become more commonplace. Signals from these gadgetscould potentially wreak havoc on the computer systems of airplanes,automobiles and other complex electronic systems. At UMR, the researchers test a variety of products in its ElectromagneticCompatibility (EMC) Laboratory, analyze the results, and write thealgorithms that will be used to develop an expert software system that canbe used by any circuit board designer. The UMR researchers then hand offtheir algorithms to the consortium's software partners. Those partners, inturn, develop computer-assisted design software products to be used bycircuit board designers in the industry. All information is shared amongthe consortium's members, and all hardware companies in the consortiumreceive free evaluation copies of the early versions of the software. When completed, these expert systems will diagnose circuit board designs,catch any potential problems, predict the extent of those problems, andrecommend ways for designers to fix them. "Through this consortium, we're developing software that does the samething that an EMC engineer would do, looking at things the way a humanwould," Hubing says. The need for an expert system is great because circuit board designersoften know little about EMI concerns, Hubing says. There are few EMIengineers in the world, but many circuit board designers, he adds. "If you had a human EMC expert looking over the shoulder of circuit boarddesigners, then you wouldn't have a problem," Hubing says. "But circuitboard designers have a lot of other things to concern themselves withbesides EMI problems. "As a circuit board designer, you've got thermal considerations, EMIconsiderations, cost trade-offs and manufacturing considerations to takeinto account-- plus you must keep up with the latest in digital technology," Hubingadds. "Circuit designers can't be experts in all of these areas, and sothey're having to rely on tools to catch certain things automatically." Already, the UMR EMI Expert System Consortium has developed prototypesoftware that all partners in the consortium are evaluating. Hubing and his colleagues in UMR's electrical engineering department --Drs. Tom Van Doren, James L. Drewniak and Richard E. DuBroff -- first gotthe idea for developing an expert system after working with Boeing on asimilar project. With Boeing, the UMR researchers developed software tolocate EMI "design rule violations" in circuit board designs. The expertsystem software now under development not only locates potential problems,but also analyzes them and proposes specific solutions. Working with the four UMR professors is Dr. Sergiu Radu, a visitingprofessor from Romania.
--------
174-> 'Indiana Jones' Of Tomatoes To Receive World Prize
Renowned geneticist and plant breeder Charles Rick, whosehalf-century of research at UC Davis has forged a fundamentalunderstanding of tomato genetics, has been selected toreceive the first $200,000 Maseri Florio World Prize forDistinguished Research in Agriculture. The award, created to recognize outstanding achievement inagricultural research, will be presented Nov. 11 inWashington, D.C.  It includes $100,000 for Rick, a professoremeritus at UC Davis, and a matching amount for theinstitution or research program of his choice. Now 82, Rick is known internationally among scientists andagriculturists as something of a modern-day Charles Darwinand Indiana Jones, all rolled into one.  His researchexpeditions have taken him from the Galapagos Islands to theheights of the Andes where he has collected hundreds of wildtomato species. In the wild tomatoes, Rick has identified 42 disease-resistance genes, many of which have been bred intocommercial tomato varieties.  He also established the largestand most valuable collection of tomato seeds in the world. "Dr. Rick has been a research pioneer whose findings have hadworldwide significance, said Clayton Yeuter, former U.S.Secretary of Agriculture and co-chair of the Maseri FlorioWorld Prize Advisory Board.  "His contributions havebenefited almost every other vegetable and fruit crop grownaround the world."
--------
175-> Chernobyl Workers Benefit From University Of Georgia Research
AIKEN, S.C. -- Research conducted in the Ukraine by University of Georgia professor Ron Chesser has resulted in a rather unusual gift for the workers at Chernobyl -- radiological uniforms and respirators. Chesser, who works at the University's Savannah River Ecology Laboratory, helped organize an effort to donate excess anti-contamination clothing and related items to the Ukraine. The items were no longer being used at the Department of Energy's Savannah River Site (SRS) where the Ecology Lab is located. Chesser has conducted radioecology studies in the Chernobyl area since 1992. He learned of the excess material at the DOE site in 1996, when a contract employee at the SRS saw his research featured on CNN and approached him about the excess items. The worker, George Brodie, told Chesser about the 2,000 bags of uniforms and more than 3,000 respirators that were available. "Protective clothing for radiation is in very short supply at Chernobyl," says Chesser. "We wondered if we could find a way to give the materials to Chernobyl workers." The material includes white radiological uniforms. The Department of Energy, consistent with commercial and naval nuclear program standards, no longer uses white protective clothing for radiological work. Yellow clothing is used instead. Also available were full and half mask respirators. Although the equipment was in good condition, the standards for that equipment has also changed. During an August 1996 trip to Chernobyl to conduct research, Chesser took examples of some available items to administrators at the Chernobyl nuclear power plant, where clean up from the 1987 reactor accident is underway. There Chesser inquired about their interest in the materials. When it was determined that they wanted the equipment, plans were made to ship the uniforms and respirators. The clothing and other equipment were combined with items from the Department of Energy's sites at Oak Ridge, Tenn., and Hanford, Wash., for shipment to the Ukraine. The arrangement is also beneficial to the Department of Energy, according to Larry McLean, manager of general services at SRS, who noted that disposal of the items would be very expensive. "This is a great win-win proposition," says MacLean. MacLean estimates that conventional disposal methods would cost SRS about $1 million. All of the clothing, including lab coats, coveralls, cloth hoods and shoe covers, is in excellent condition, notes Chesser. Some of the uniforms cost more than $200 each. Although some of the clothing contains trace levels of contamination, it is low enough easily to allow re-use by radiological workers and is within radiological release guidelines. Paramount to everyone involved in the effort, says Chesser, was a desire to make sure that the Ukrainian government really wanted and needed the equipment. "We wanted to be very careful that we weren't just unloading our discarded materials on the Ukraine," says Chesser. "And once they got it, we wanted to make sure they could maintain it." Therefore, he says, an extra step was taken and DOE sent washing machines and special detergent with the uniforms. All of the materials were shipped in March and are now making their way from St. Petersburg to Chernobyl. Funds for the shipment were provided by the Department of Energy through Pacific Northwest National Laboratory in Richland, Washington. Chesser is involved in studies of the effects of radiation on wildlife living in and around the site of the nuclear accident in the Ukraine. He looks forward to his next visit to the site when he will see the items being put to use in the reactor areas. "This project really made good sense," says Chesser.
--------
176-> Mars Pathfinder Winds Down After Phenomenal Mission
 After operating on the surface of Mars three times longer than expected and returning a tremendous amount of new information about the red planet, NASA's Mars Pathfinder mission is winding down. Flight operators at NASA's Jet Propulsion Laboratory, Pasadena, CA, made the announcement today after attempting to reestablish communications with the spacecraft over the last month. With depletion of the spacecraft's main battery and no success in contacting Mars Pathfinder via its main or secondary transmitters, the flight team cannot command the spacecraft or the small rover named Sojourner that had been roving about the landing site and studying rocks. "We concede that the likelihood of hearing from the spacecraft again diminishes with each day," said Pathfinder Project Manager Brian Muirhead. "We will scale back our efforts to reestablish contact but not give up entirely. "Given that, and the fact that Pathfinder is the first of several missions to Mars, we'll say 'see you later' instead of saying goodbye," he said. At the time the last telemetry from the spacecraft was received, Pathfinder's lander had operated nearly three times its design lifetime of 30 days, and the Sojourner rover operated 12 times its design lifetime of seven days. "I want to thank the many talented men and women at NASA for making the mission such a phenomenal success.  It embodies the spirit of NASA, and serves as a model for future missions that are faster, better, and cheaper.  Today, NASA's Pathfinder team should take a bow, because America is giving them a standing ovation for a stellar performance," said NASA Administrator Daniel S. Goldin. Since its landing on July 4, 1997, Mars Pathfinder has returned 2.6 billion bits of information, including more than 16,000 images from the lander and 550 images from the rover, as well as more than 15 chemical analyses of rocks and extensive data on winds and other weather factors. The only remaining objective was to complete the high-resolution 360-degree image of the landing site called the "Super Pan," of which 83 percent has already been received and is being processed. The last successful data transmission cycle from Pathfinder was completed at 3:23 a.m. Pacific Daylight Time on Sept. 27, which was Sol 83 of the mission. "This mission has advanced our knowledge of Mars tremendously and will surely be a beacon of success for upcoming missions to the red planet," added Dr. David Baltimore, president of the California Institute of Technology, which manages JPL for NASA. "Done quickly and within a very limited budget, Pathfinder sets a standard for 21st century space exploration." The Mars Pathfinder team first began having communications problems with the spacecraft on Saturday, Sept. 27.  After three days of attempting to reestablish contact, they were able to lock on to a carrier signal from the spacecraft's auxiliary transmitter on Oct. 1, which meant that the spacecraft was still operational.  They locked on to the same carrier signal again on Oct. 6, but were not able to acquire data on the condition of the lander. At that time, the team surmised that the intermittent communications were most likely related to depletion of the spacecraft's battery and a drop in the spacecraft's operating temperatures due to the loss of the battery, which kept the lander functioning at warmer temperatures. Over the last month the operations team has been working through all credible problem scenarios and taking a variety of actions in attempting to recover the link with Pathfinder. With all of the most plausible possibilities exhausted, the team plans to continue sending commands and listening for a spacecraft signal on a less frequent basis. "Basically we are shifting to a contingency strategy of sending commands to the lander only periodically, perhaps once a week or once per month," said Mission Manager Richard Cook. "Normal mission operations are over, but there is still a small chance of reestablishing a link, so we'll keep trying at a very low level." Although the true cause of the loss of lander communications may never be known, recent events are consistent with predictions made at the beginning of the extended mission in early August, Muirhead said. When asked about the life expectancy of the lander, project team members predicted that the first thing that would fail on the lander would be the battery; this apparently happened after the last successful transmission September 27. After that, the lander was expected to begin getting colder at night and go through much deeper day-night thermal cycles. Eventually, the cold or the cycling would probably render the lander inoperable. According to Muirhead, it appears that this sequence of events has probably taken place. The health and status of the rover is also unknown, but since initiating its onboard backup operations plan a month ago, the rover is probably circling the vicinity of the lander, attempting to communicate with it. The rover, which went into a contingency mode on Oct. 6, or Sol 92 of the mission, had completed an alpha proton X-ray spectrometer study of a rock nicknamed Chimp, to the left of the Rock Garden, when it was last heard from. The rover team had planned to send the rover on its longest journey yet -- a 165-foot (50-meter) clockwise stroll around the lander -- to perform a series of technology experiments and hazard avoidance exercises when the communications outage occurred. That excursion was never initiated once the rover's contingency software began operating. Now known as the Sagan Memorial Station, the Mars Pathfinder lander was designed primarily to demonstrate a low-cost way of delivering a set of science  instruments and a free-ranging rover to the surface of the red planet. Landers and rovers of the future will share the heritage of spacecraft designs and technologies first tested in this "pathfinding" mission. Part of NASA's Discovery program of low-cost planetary missions, the spacecraft used an innovative method of directly entering the Martian atmosphere. Assisted by a 36-foot-diameter (11-meter) parachute, the spacecraft descended to the surface of Mars on July 4 and landed, using airbags to cushion the impact.  The spacecraft's novel entry was successful. Scientific highlights of the Mars Pathfinder mission are: * Martian dust includes magnetic, composite particles, with a     mean size of one micron. * Rock chemistry at the landing site may be different from     Martian meteorites found on Earth, and could be of basaltic     andesite composition. * The soil chemistry of Ares Vallis appears to be similar to that     of the Viking 1 and 2 landing sites. * The observed atmospheric clarity is higher than was expected     from Earth-based microwave measurements and Hubble Space Telescope     observations. * Dust is confirmed as the dominant absorber of solar radiation     in Mars' atmosphere, which has important consequences for the     transport of energy in the atmosphere and its circulation.    Frequent "dust devils" were found with an unmistakable     temperature, wind and pressure signature, and morning turbulence;     at least one may have contained dust (on Sol 62), suggesting that     these gusts are a mechanism for mixing dust into the atmosphere. * Evidence of wind abrasion of rocks and dune-shaped deposits was     found, indicating the presence of sand. * Morning atmospheric obscurations are due to clouds, not ground     fog; Viking could not distinguish between these two possibilities. * The weather was similar to the weather encountered by Viking 1;     there were rapid pressure and temperature variations, downslope     winds at night and light winds in general. Temperatures were about     10 degrees warmer than those measured by Viking 1. * Diversity of albedos, or variations in the brightness of the     Martian surface, was similar to other observations, but there was     no evidence for the types of crystalline hematite or pyroxene     absorption features detected in other locations on Mars. * The atmospheric experiment package recorded a temperature     profile different than expected from microwave measurements and     Hubble observations. * Rock size distribution was consistent with a flood-related deposit. * The moment of inertia of Mars was refined to a corresponding     core radius of between 807 miles and 1,242 miles (1,300 and 2,000     kilometers). * The possible identification of rounded pebbles and cobbles on     the ground, and sockets and pebbles in some rocks, suggests     conglomerates that formed in running water, during a warmer past     in which liquid water was stable. Engineering milestones of the mission included demonstrating a new way of delivering a spacecraft to the surface of Mars by way of direct entry into the Martian atmosphere. In addition, Mars Pathfinder demonstrated for the first time the ability of engineers to deliver a semi-autonomous roving vehicle capable of conducting science experiments to the surface of another planet. The Mars Pathfinder mission is managed by the Jet Propulsion Laboratory for NASA's Office of Space Science, Washington, DC.  The mission is the second in the Discovery program of fast track, low-cost spacecraft with highly focused science goals. JPL is managed by the California Institute of Technology, Pasadena, CA.
--------
177-> Study Shows Hereditary Legacy Of Radiation Exposure
Ever since the atomic bombs dropped on Japan created theworld's largest experiment on the effects of radiation onhumans, people have puzzled over not only just what theseeffects could be, but also if they could be passed on to thechildren of those exposed. In the past, researchers haveshown in mice that some effects -- in the form of geneticmutations -- can indeed be passed to offspring and causehealth effects. Now Lynn Wiley and her colleagues at the University ofCalifornia, Davis, and Lawrence Livermore National Laboratoryhave used a very sensitive model they developed todemonstrate that if a male mouse is exposed to radiation, hemay pass on detrimental effects not only to his children, butalso to his grandchildren, and even great-grandchildren. Wiley will present her work at a conference Nov. 8-9 in Japancalled "Bioregulation of Radiation Response: GeneticInstability." Most of the information she presented waspublished this summer in the journals Radiation Research andMutation Research. Wiley says that her "environmentally relevant" assay -- usingamounts of radiation that compares to what a person mightreceive during radiation therapy for cancer -- confirms whatthe Japanese have been saying for years; that the effects ofradiation can be passed down through generations. Her resultsare controversial but she says, "so far, no one's been ableto knock it down ... Every molecule of that paper has beenturned over, and it hasn't been shot down. "There is a big difference between transmission, which meanspassing on effects to the children, and heritability, whichmeans passing it on to all future generations," said Wiley, aprofessor of medicine with the campus Institute of Toxicologyand Environmental Health. "Heritability means that it hassurvived a complete round of DNA replication, and that it isstable in the DNA of the sperm." The method that Wiley and her colleagues used is much moresensitive than those used in conventional mouse studies,which use hundreds of thousands of mice. Hers uses only about75 mice at a time. According to Wiley, what is new about herfindings is that she saw the radiation effects in the smallnumbers of mice she used, indicating that the radiation isaffecting DNA non-specifically; in other words, it'saffecting many genes. Wiley exposed eight or so male mice at a time to theradioisotope Cesium-137, and allowed these mice to mate withfemales once a week for eight weeks, to cover the sperm-making history of the father. The sons of these irradiatedfathers were allowed to mate with females beginning at eightweeks of age to produce the grandchildren that were used inWiley's study. In the assay developed by Wiley more than 10 years ago,embryos consisting of only four cells are removed from themother. These cells are then combined with four cells fromanother embryo -- one without a history of radiation -- andallowed to multiply several times. Then the scientists countthe total number of cells (one of the embryos has a specialmarker so it can be distinguished from the other). If thereare fewer cells from the cells that received radiation, thenthey have a growth disadvantage from inherited DNA damage,according to Wiley. Wiley said she found a significant reduction in cellreproduction and growth in the offspring of mice that hadbeen irradiated six or seven weeks before conception,corresponding to a sensitive stage in sperm development.These grandchildren mice also weigh less than normal mice andtheir sperm are less efficient at fertilization. Wiley suspects her fairly simple, yet exquisitely sensitive,cellular assay could be used to predict inherited effects ofradiation in future generations of animals. The reproductivetoxicology professor is now continuing her studies to look atlower doses of radiation, and to determine on a genetic levelwhat the changes are that are induced by radiation. "The human side of these studies is that we already have inmice documented irradiation effects that are passed on tofuture generations, ones that are causing cell growth andreproduction changes," she said. "If you mess around withthat, you can't help but wonder if these changes will turnout to be cancerous or impair reproduction." Wiley's work was funded by the National Institutes of Health.
--------
178-> Search And Destroy -- Molecular Cancer Drug Delivery System Shown To Reduce Toxicity
Chemotherapy works because it kills cancer cells.  Unfortunately, thedrugs can also kill healthy cells as they pass through the body on theirway to the cancerous target.  Many are so toxic they never make it tomarket. But researchers at the University of Maryland School ofPharmacy are developing a new drug delivery system that greatly reducestoxicity. Parshant Chikhale, Ph.D., assistant professor, and colleagues reportthat their system delivers anti-cancer drugs directly to tumor sites,controls the delivery speed, and will not harm brain tissue. The researchers are reporting on three studies that indicate the noveldelivery system will release the drugs only in the presence of a tumor.Drug release can be controlled with this system because the bond betweena novel carrier molecule and the drug can only be broken in theenvironment found in the presence of cancerous tissue. By modifying thestructure of the molecule, the researchers also were able to decreaseand increase the speed of the chemical reaction releasing the drug.Chikhale also reports that binding amino acid-based anti-cancer agentsto their molecule rendered the drugs unable to permeate the blood-brainbarrier, avoiding toxicity to the brain. Chikhale will present the findings at Annual Meeting of the American Association ofPharmaceutical Scientists this week in Boston.
--------
179-> Researchers Report Estrogen Hastens Healing
By Melanie Fridl Ross GAINESVILLE, Fla.---Estrogen speeds wound healing in older postmenopausal women, report researchers from England's University of Manchester and the University of Florida in this week's issue of the journal Nature Medicine. "Based on our results, hormone replacement therapy may prove to be very beneficial to wound healing processes in elderly women," said Roy Tarnuzzer, a research assistant professor in the division of endocrinology and metabolism at UF's College of Medicine and a member of UF's Institute for Wound Research. "Not only does it appear to accelerate the wound healing process, but it may also have effects on chronic wounds that are very difficult to heal in some elderly patients." Studies have shown that aged skin typically does not repair itself as well or as quickly as in younger individuals, he said. Tarnuzzer developed a key laboratory technique used in the study  -- one of the first reports to examine hormonal regulation of normal skin healing after wounding. The method enables researchers to use very small tissue samples to track how wounds heal. Researchers studied 10 postmenopausal women ages 55 to 65 who were taking estrogen, 10 postmenopausal women the same age who weren't taking estrogen and 10 premenopausal women ages 20 to 39 who were not taking oral contraceptives. By removing a 4-mm skin sample from the underside of participants' arms, researchers were able to study how the wounds healed over time. "We found that elderly postmenopausal women who were on estrogen replacement therapy appeared to heal much the same as the younger women, whereas the postmenopausal patients we studied who were not on hormone replacement therapy showed delayed wound healing," Tarnuzzer said. Researchers also found striking differences in the amount of collagen and growth factors -- both key players in the healing process -- present at the site of the wounds depending on whether the participant was on estrogen. Collagen keeps skin supple and helps scar formation. Growth factors affect cells' ability to grow and repair wounds. "There was a lot more collagen in the patients on the hormone replacement therapy, equal to the amounts seen in the young, and decreased levels in those elderly patients not on estrogen. Scar formation and skin tone had changed in these patients," Tarnuzzer said. "There was a similar pattern when we looked at the level of a crucial growth factor produced at the site of injury. The level was similar in patients on estrogen compared with the younger group; those not on hormone replacement therapy showed very low levels of this particular growth factor. "The inflammatory response -- the cells of the body recruited into the site of injury to orchestrate the wound healing process -- also appeared to differ significantly in the elderly patients who were not taking estrogen," Tarnuzzer added. The findings suggest hormone replacement therapy or even topi 
--------
180-> Research Changes National Recommendations For Ferret Quarantine
MANHATTAN, Kansas -- New research findings at Kansas State University may mean the difference between life and death for ferrets that have bitten humans. Speaking from the Rabies in the Americas conference this week in Kingston,Ontario, Deborah Briggs, director of Kansas State University's RabiesLaboratory, said that findings on the virus shedding period for ferretswere presented to the Compendium of Animal Rabies Control Committee attheir annual meeting in October. As a result of three years of research on the pathogenesis of NorthAmerican rabies virus strains, the Compendium of Animal Rabies ControlCommittee voted to change regulations to allow quarantine of ferretsrather than requiring euthanasia in bite cases. This research wasconducted as a joint effort between the Centers for Disease Control inAtlanta and Kansas State University. Recommendations by the Compendium of Animal Rabies Control Committee areused by public-health veterinarians to make policy recommendations ondisposition of ferret bite cases, so Briggs' research will have wideimplications for the ferret community. Until now, rabies control recommendations from the Compendium of AnimalRabies Control Committee required that ferrets that have bitten humans beeuthanized. The change in the recommendations concerning ferrets that bitehumans will impact most, if not all, state rabies regulations, Briggssaid. The Kansas Department of Health and Environment is currently in theprocess of rewriting the rabies regulations in Kansas to reflect these newrecommendations. Briggs research suggests that ferrets may be observed for a period of 10days, identical to the period recommended for dogs and cats in bite cases. Although the first licensed rabies vaccine was approved for use indomestic ferrets in 1990, healthy, vaccinated ferrets that bite humansroutinely have been euthanized and examined for rabies rather than beingheld and observed. That happened, Briggs said, because there was a lack ofinformation on ferret response to rabies virus infection. "Until we completed this research we didn't know how long the virusshedding period was for ferrets," Briggs said. The shedding period is thetime an infected animal can pass the virus to another, most commonlythrough biting.The three-year project was supported by the Morris Animal Foundation,Intervet Inc., Rhone Merieux Inc., and Marshall Ferret Farms, withcooperation from the Centers for Disease Control. Briggs' laboratory does most of the testing of animals in the UnitedStates going to rabies-free areas in the world. "We conduct all rabies serological testing for animals owned by civiliansgoing to Hawaii," Briggs said. "Last year we tested 30,000 samples andthis year we will exceed that amount. We test most animals going toAustralia, New Zealand, British Virgin Islands, the Bahamas, Hong Kong,and other rabies-free countries like Norway. Animal samples are submittedfrom throughout the world. In addition we continue to conduct mostserological testing for humans that have been vaccinated. We are currentlyinvolved in testing samples from France, Thailand, and are collaboratingon a study to investigate the immune response of immunosuppressed humansto rabies vaccines. "The laboratory is also the only rabies diagnostic laboratory in the stateof Kansas. We work closely with the Centers for Disease Control as far assurveillance of rabid animals in Kansas is concerned."
--------
181-> NASA's Solar-Powered Aircraft Begins Science Missions In Hawaii
 Pathfinder, NASA's solar-powered, remotely piloted aircraft, has begun conducting a series of up to four science mission flights to highlight the aircraft's science capabilities while collecting imagery of forest and coastal zone ecosystems on Kauai, Hawaii. Remotely piloted aircraft similar to Pathfinder could spend long periods of time over the ocean, monitoring storm developments to provide more accurate predictions of hurricanes.  These aircraft also could be used to monitor major croplands, forests and other large, remote expanses to provide early warning of crop damage or fires. The Pacific Missile Range Facility at Barking Sands, Kauai, is the staging base for these flights as part of NASA's Environmental Research Aircraft and Sensor Technology (ERAST) program, based at NASA's Dryden Flight Research Center, Edwards, CA.  Kauai was chosen as an optimum location for testing Pathfinder due to high levels of solar irradiance, available airspace and radio frequency, and diversity of terrestrial and coastal ecosystems. Major science activities of Pathfinder, the first flight of which occurred on Oct. 25, include detection of forest nutrient status, forest regrowth from Hurricane Iniki, sediment/algal concentrations in coastal waters and assessment of coral reef health.  The science activity is being coordinated by NASA's Ames Research Center, Moffett Field, CA, and involves researchers at the University of Hawaii and University of California.  The flights will conclude just before Thanksgiving. The flights will test two new scientific instruments, a high spectral resolution Digital Array Scanned Interferometer (DASI) and a high spatial resolution Airborne Real-Time Imaging System (ARTIS).  The remote sensor payloads were designed by Ames to support NASA's Mission to Planet Earth science programs.  The flights will be conducted at altitudes between 22,000-49,000 feet. "This will be the first time that we have flown these two new sensor systems," said Steve Wegener, Ames' manager of the payloads and science element of the program. DASI, a remote sensing instrument that looks at reflected spectral intensities from the Earth, will be used to study such things as plant stress, constituents in coastal zone waters and coral reef health.  Measuring 30 inches long and ten inches in diameter, DASI weighs less than 25 pounds and mounts beneath Pathfinder's wing. The ARTIS payload is built around a digital camera, which has a six-million-pixel array, enabling it to take high quality digital photographs.  The camera has a variety of potential science and commercial applications, such as documenting flood surges, geologic features and crop stress, according to Wegener. Both sensors are designed to be small, lightweight and interactive, in compliance with ERAST program goals of miniaturizing flight payloads.  "These new sensor technologies are being developed for use in the next generation of remotely piloted aircraft," Wegener said.  These and other new sensor systems are designed to complement high altitude studies of atmospheric ozone, land-cover change and natural hazard studies conducted by NASA's Earth Resources Survey aircraft. Pathfinder recently set an altitude record for propeller-driven flight of over 71,500 feet.  "Pathfinder's performance to date has exceeded our wildest expectations," said the programÕs manager Jenny Baer-Riedhart.  "We beat our altitude milestone by 6,500 feet in the first two flights this summer and demonstrated the capability for science mission demonstrations in a remote, tropical location." Pathfinder is one of several remotely piloted aircraft being evaluated under the ERAST program.  The program focuses on developing technologies required to operate subsonic unpiloted aircraft at high altitude for long-duration flights. "Remotely piloted aircraft have the potential to do the dull, dirty and dangerous missions where you wouldn't want to put a pilot at risk," Wegener said. Pathfinder is a flying wing with a span of 99 feet.  Small pods extending below the wing's center section can carry a variety of scientific sensors.  Solar arrays on the upper wing surface can provide as much as 7,200 watts of power at high noon on a summer day to power the craft's six electric motors and other electronic systems.  A backup battery system can provide power for up to five hours to fly the craft after sundown.  Pathfinder was designed, manufactured and is operated by AeroVironment, Inc., of Simi Valley, CA, under a jointly sponsored research agreement with NASA.
--------
182-> Gene Therapy Hold Promise For Sickle Cell Disease And Beta Thalassemia
Researchers from Columbia University College of Physicians & Surgeons have demonstrated the long-term transfer and high level long-term expression of the normal human beta globin gene in an animal model for the first time. The study, published in the Nov. 1 issue of Blood, may lead to gene therapy for the treatment of sickle cell disease and beta thalassemia, a related disorder. Senior author Arthur Bank, M.D., FACP, professor of medicine and genetics & development and director of the division of hematology at Columbia University, and colleagues put a human beta globin gene into a safe retrovirus and added the virus to mice bone marrow cells in vivo. The modified cells were then transplanted into mice. The researchers were able to detect the presence of the human beta globin gene up to eight months later. In addition, the researchers documented high levels of expression of the gene. In one mouse, 20 percent of the total beta globin it produced was from the human beta globin gene. "If we could attain that level of normal human beta globin gene expression in a patient with sickle cell disease or beta thalassemia marrow cells, it would be enough to expect to ameliorate, if not cure, the anemia of patients with sickle cell disease and beta thalassemia," says Bank. In sickle cell disease, the beta globin gene produces an abnormal form of hemoglobin, the oxygen-carrying molecule in the blood. The damage causes red blood cells to distort and alter their shape. In beta thalassemia, the gene produces inadequate levels of hemoglobin. Theoretically, gene therapy that inserts a normal form of the beta globin gene into the bone marrow cells of patients could cure these diseases. "For more than 10 years researchers have been looking for a stable delivery system to transfer and express the human beta globin gene for extended periods of time. This is the first time researchers safely and efficiently transferred the normal globin and ensured that the gene produced normal levels of its protein over long periods of time," says Dr. Bank Researchers are investigating better gene transfer systems in mouse models of sickle cell disease and beta thalassemia and developing better ways to transfer retroviruses into human hematopoietic stem cells. In addition to Dr. Bank, the authors of the paper were Dr. Harry Raftopoulos and Maureen Ward of Columbia Univertsity MC, and Dr. Philippe Leboulch of Harvard Medical School and the Massachusetts Institute of Technology. The study was funded by the National Institutes of Health; the Cooley's Anemia Foundation; and the Ahepa Anemia Foundation.
--------
183-> Ships Among Highest Air Pollution Sources, Say Carnegie Mellon University Researchers
PITTSBURGH--Air emissions from trade-carrying cargo ships powered by diesel engines are among the world's highest polluting combustion sources per ton of fuel consumed, according to Carnegie Mellon University researchers James Corbett and Paul Fischbeck in their Oct. 31 Science magazine article, "Emissions From Ships." The authors, researchers in the Department of Engineering and Public Policy, assert that anthropogenic emissions from cargo ships provide an alternate explanation to an emissions pattern generally attributed to persistent continental pollution. The authors say that multinational policies to address the problem will be implemented soon by the International Maritime Organization (IMO), although new NOx regulations will apply only to new ships or major ship conversions on or after Jan. 1, 2000. Based on calculations used to obtain a conservative figure on total emission from shipping, the authors' findings conclude that "worldwide ship nitrogen emissions are equal to nearly half of the total emissions from the United States, 42 percent of nitrogen emissions from North America, 74 percent of emissions from the Organization for Economic Cooperation and Development (OECD) Europe and 190 percent of those from Germany. They are equal to 100 percent of nitrogen emissions from U.S. mobile sources and 87 percent of nitrogen emissions from U.S. stationary sources." They add that "ship sulfur emissions equal 43 percent of total sulfur emissions from the United States, 35 percent of sulfur emissions from North America, 53 percent of emissions from OECD Europe and 178 percent of those from Germany. Most of the continental sulfur emissions are from stationary sources." According to Bryan Wood-Thomas, Marine Policy Advisor, Office of International Activities, U.S. Environmental Protection Agency (EPA), "the research and analysis undertaken by Corbett and Fischbeck represents the most thorough examination of sulphur oxide and nitrogren oxide emissions associated with international shipping. While some studies have modeled emissions at the local and regional level, this study represents a rigorous analysis and estimation of emissions on a global scale." Taking into account ship nitrogen and sulfur emissions, the authors estimate that these emissions affect global background pollution levels. Air over the North Pacific is more polluted than air over the South Pacific, and ship traffic is more concentrated in these areas studied. The authors assert that the concentration of contaminants such as sulfur, ash asphaltenes and metals in the residuals (or marine fuels) has increased over the decades, especially since the 1973 fuel crisis when residual fuels were starting to be made using secondary refining technologies to extract the maximum quantity of refined products (distillates) from crude oil. Other ship fuels are distillate oils of higher grade; however, these are often blended with residuals. Seventy to 80 percent of commercial shippers prefer to use the cheaper residual fuels. Data from three well-regarded industry sources were used to assess global ship emissions: marine exhaust emission test data that report fuel-based emission rates for sulfur and nitrogen, international marine fuel usage information, and the engine characteristics of the world's registered commercial ships weighing 100 gross registered metric tons or more and those of naval ships. Although global emission limits were approved by the IMO diplomatic session in September and this will eventually result in multinational consensus on the principles of ship emission control, the authors report that "a measurable reduction in nitrogen emissions will not occur for many years," based on a 1.5 percent yearly fleet replacement rate. They assert that "for NOx controls that reduce emissions by 30 percent to 50 percent, IMO regulations would reduce emissions by less than one percent per year." Further, they add, "IMO language limits fuel-sulfur levels 4.5 percent. This provides little reduction, if any, and practically codifies the status quo, since the International Organization for Standardization (ISO) limited fuel to five percent sulfur in 1987." Additional policy concerns cited by the authors include the IMO selection of the Baltic Sea as the first SOx Emission Control Area, which represents a relatively small percent of annual ship sulfur emissions within potential transport distance to land; the registration of ships by many nations, resulting in a difference between the country in which the ship is owned and the country in which it is registered, thereby limiting policy enforcement; and open-market interests and treaty commitments affecting the flow of trade. Air emissions such as these may play a role in global climate change. Research in this area is continuing at the Center for Integrated Study of the Human Dimensions of Global Change at Carnegie Mellon, with funding from the National Science Foundation (grant SBR9521914) and academic funds from the university.
--------
184-> New Study Casts Doubt On Controversial 'Bell Curve' Theories
A new study examining verbal ability and socioeconomic success casts doubt on theories advanced in the controversial 1994 book The Bell Curve. The study, published in the September 1997 issue of Social Science Research, found that cognitive ability - or a person's academic ability - has not created growing differences among socioeconomic classes in the United States, as argued by The Bell Curve authors, Charles Murray and the late Richard Herrnstein. Murray and Herrnstein contend in The Bell Curve that a person's IQ largely determines their socioeconomic status, that IQ differences in race are partly genetic and that African-Americans generally have lower IQs than whites or Asians. A growing number of scholars are disputing their findings. "We would not for a moment deny cognitive ability an important place in the stratification process, but that place appears to be limited mainly to its role in determining how far people go in school, and that role appears to have been pretty much the same throughout this century," write the study's authors, Robert M. Hauser and Min-Hsiung Huang of the Center for Demography and Ecology at the University of Wisconsin-Madison. "Our findings suggest that, if there is a key variable in the American class system, it is educational attainment, not cognitive ability," add Hauser, a professor of sociology at UW-Madison, and Huang, of the Institute for European and American Studies, Academia Sinica, Taipei, Taiwan. The authors say the distribution of schooling has become more equal throughout this century. Hauser and Huang examined the claims made in The Bell Curve along with data from a short verbal test administered to about 12,500 adults nearly every year between 1974 and 1994 as part of the General Social Survey of the National Opinion Research Center. Using the verbal test data, they analyzed how social background and educational attainment affect verbal ability and how verbal ability affects occupational status and income. In all cases, they found little or no evidence that the effects of verbal ability on socioeconomic outcomes have increased in the past two decades. "Herrnstein and Murray have offered precious little evidence to support their story line, and we find equally little support in the trend data from the General Social Survey," Hauser and Huang write. The authors discovered that there has been almost no change in how social background influences verbal ability, except for a declining negative effect on those born in the South or on farms. And they found few differences in verbal ability between high school graduates and college graduates born since the Great Depression, which they say reflects a combination of larger postsecondary enrollments and more relaxed college admission standards. Hauser and Huang also determined that there were no changes in the effects of verbal ability on occupational status between the 1970s and the 1990s, except for small decreases among African-American men, white men younger than 45 and middle-aged white women. Effects of ability on occupational status did increase some for older white women, they found. There were no changes in the effects of verbal ability on earnings as well, according to the study. Hauser and Huang say their analyses show that verbal ability affects a person's income primarily through their level of education. The authors admit that data from the General Social Survey does have weaknesses, including the narrow content of the verbal test, that it has no measure of childhood ability and that it doesn't represent either very wealthy or very poor sections of the American population in substantial numbers. But they emphasize that the survey's verbal test offers consistent data because it was administered regularly over a 20-year period. And they add that the survey obtained standardized, measurable information on social background and socioeconomic outcomes.
--------
185-> University Of Florida Physicians Use Minimally Invasive Techniques To Correct Spinal Problems
By Melanie Fridl Ross, Shands Public Relations GAINESVILLE, Fla.---Sam LoPalo had suffered back problems for years, but nothing prepared him for the day he bent over and couldn't straighten again. Excruciating pain radiated down his leg. For days afterward, he barely could hobble from his bed to a recliner. Once in the chair, he'd stay there for hours. LoPalo took pain-relievers on a regular basis, but nothing -- not even physical therapy -- brought him relief. Tests revealed two fragments of a lumbar vertebral disc were pressing on a nerve root. "If you want to put one word on it, I was miserable," said the 60-year-old Gainesville resident. Conventional surgery would have been a lengthy procedure, involving a long incision and a long hospital stay. Risks would have ranged from significant blood loss to infection.University of Florida neurosurgeons and orthopedists offered LoPalo an alternative: a minimally invasive approach to back surgery that helps patients with many kinds of spinal conditions, from slipped discs to scoliosis. In February, using tiny incisions and guided by a small video camera, they operated on LoPalo at Shands at the University of Florida. The next day, he walked down the hospital hallway. Twenty-four hours after surgery, LoPalo no longer needed pain medicine. Through procedures like this one, also known as endoscopy, UF neurosurgeons are revolutionizing back surgery. While endoscopy has been commonplace in general surgery for several years, only recently has it been adapted for spinal surgery, said neurosurgeon Richard Fessler, a professor in the departments of neurosurgery and neuroscience at UF's College of Medicine, the UF Brain Institute and the UF Shands Neurological Center. He also is medical director of the Shands Spinal Cord Injury program and co-surgical director of the SpineCare Center. The development of specialized instruments and refinements in video camera clarity have led the way for new and improved minimally invasive approaches to spinal surgery, he said. Thanks primarily to smaller incisions, benefits to the patient include decreased blood loss and risk of infection, reduced postoperative pain and recovery time, shorter hospital and intensive care unit stays, a quicker return to normal activities and lower health-care costs. "Most patients return to completely normal activities within two weeks," Fessler said. "Patients have far less pain, their hospitalization is about half as long and the cost tends to be about half as much overall. "Some of these techniques are very new and very ground-breaking," he added. "We are among the first in the nation to use this approach for such a wide selection of procedures." For example, surgeons can now avoid making a large incision and splitting the chest to operate on the thoracic spine, widely exposing the operative area. Instead, they use a tiny camera called a thoroscope and a series of small incisions. Using probes equipped with light-emitting diodes, information is relayed back to a computer and displayed on a video screen, showing surgeons what they might not otherwise be able to physically see. "The camera gives us an excellent ability to see exactly what we're doing but without directly exposing the area," Fessler said. The method also can be used to remove infections or to fuse the spine to strengthen it after previous failed back surgery. "Not all patients can opt for a minimally invasive technique, but a large percentage with isolated problems can be helped," said Dr. Michael MacMillan, an associate professor of orthopedics at UF's College of Medicine and co-surgical director of the SpineCare Center. For LoPalo, the decision was easy. "To me, this was a no-brainer," he said. "This was definitely the way to go. I'm really grateful. It was a very positive experience." Founded in 1958, Shands at the University of Florida is a 576-bed not-for-profit tertiary- and quaternary-care facility that serves as one of the Southeast's leading treatment and referral centers. Shands offers a full complement of medical, surgical, pediatric, obstetrical and psychiatric services. Shands was recognized among the top hospitals in the United States and Canada in the most recent edition of "The Best Hospitals in America." A recent issue of U.S. News & World Report listed Shands as one of "America's Best Hospitals," specifically in the areas of neurology, gastroenterology, cancer and otolaryngology. ---------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
186-> Glowing Fruit Flies Reveal Secrets Of Development -- Research Will Help In The Understanding Of Human Birth Defects, Say Duke University Medical Center Scientists
 DURHAM -- Most people might figure an eerie, green glowing fly for a Halloween prank, but scientists at Duke University Medical Center have inserted a glowing jellyfish protein tag onto a key cell structural protein in fruit flies to reveal how they transform from embryos to larvae to adults. The scientists believe their research will also help in understanding birth defects in humans. The researchers have just published studies that use the glowing flies to shed light on how cells cinch shut in the fly's dorsal flank during development, a process comparable to neural tube closure in developing mammalian fetuses. The Duke scientists used a time-lapse camera and high-resolution light microscope to take the first video of dorsal closure in flies as it occurred. They believe the new information gained will help them understand the causes of spina bifida, a birth defect in which the spinal column doesn't close properly during development, leaving a hole in the spine that must be closed surgically after birth. The Duke researchers, including Kevin Edwards, Maddy Demsky, Ruth Montague and Nate Weymouth, and led by Daniel Kiehart, associate professor of cell biology, report their findings in a Nov. 1 cover story of the journal Developmental Biology. The research was funded by grants from the National Institutes of Health and the March of Dimes. The researchers created the glowing flies by inserting a gene constructed in the lab into fly eggs. The new gene is a hybrid between a fly gene that contributes to cell structure during development and the green fluorescent protein (GFP) gene from the jellyfish Aequorea victoria. GFP emits bright green light when exposed to ultraviolet or blue light. The research team used GFP to tag the protein, which attaches to the cell's actin cytoskeleton, a rich meshwork that helps cells keep their shape and migrate from one place to another during the transformation from fertilized egg to adult fly. All the flies that made the fluorescent protein appeared remarkably normal, researchers said. "Previous cell staining methods required toxic fixatives, which means each image is only a snapshot of what is happening in the cell," Kiehart said. "We wanted to follow movement in a dynamic way, and this fluorescent protein allowed us to do that. It's like going from photographs to a full-length motion picture." Fruit flies contain much of the same basic genetic programming that choreographs the intricate journey from a fertilized human egg into a healthy baby. But because mammals gestate their young inside the body, it is very difficult to follow key developmental steps. So studying fruit flies, technically known as Drosophila melanogaster, can tell us about our own development, Kiehart said. Kiehart and his colleagues are zeroing in on how and why cells move during development. He wants to identify which genes are crucial for normal movements and cell shape changes during development, and why, when gene products don't function at the right time, birth defects can result. One key protein, he says, is non-muscle myosin, a kind of molecular motor that drives changes in cell shape and powers cell movements as a fertilized fly egg grows and develops legs, eyes, wings and all its other body parts. Scientists also know that myosin is vital to daily cell maintenance in both flies and people. Kiehart has already identified one type of non-muscle myosin that, when missing in flies, results in a defect in the way cells change shape, comparable to spina bifida in people. By watching the fate of the glowing cells in his experimental flies, Kiehart and his colleagues have already confirmed some of their previous hypotheses about cell movement during dorsal closure. They also have provided a powerful tool for other researchers studying development, because the glowing protein is also concentrated in the developing eye, nervous system, the forming gut, the sensory organs, and particularly, the leading edges of migrating cells in all organ systems. For example, the Duke researchers can now observe directly the actin-rich microvilli -- or little fingers -- form in the developing eye, particularly in the light receptor cells, retina and optic lobe. "This localization may make it easier to study formation of the eye, and to find genes involved in eye development," Kiehart said. Kiehart and his lab group are expanding the use of this glowing protein to help find out how skin cells move to cover an open wound. He has begun experiments to put the glowing protein in human and mouse skin cells in laboratory dishes. The human cells actively produce the fluorescent protein, and it doesn't appear to be toxic to them, Kiehart said. "We believe this new tool for studying cell shape change will provide a rich source of information that will open up one of the final frontiers of developmental biology: morphogenesis or cell growth and maturation," he said. "The ability to observe cell shape and structure should contribute to our understanding of human disease as well."
--------
187-> UC Irvine Researchers Identify Gene Associated With Increased Risk Of Schizophrenia
Findings Being Presented at 'Late-Breaking Research' Session of American Society of Human Genetics Annual Meeting Irvine, Calif. -- UC Irvine researchers and their collaborators at the University of Pittsburgh and in Europe have identified a gene they believe is responsible for increasing the risk of schizophrenia, a psychiatric disorder that afflicts 60 million people worldwide, including three million in the United States. This gene also may enhance risk for manic-depressive illness (also called bipolar disorder), which affects 60 million to 100 million people worldwide. The findings are being presented Friday, Oct. 31, at the 47th annual conference of the American Society of Human Genetics in Baltimore, and will appear in the January 1998 issue of Molecular Psychiatry. George Chandy and Jay Gargus, professors of physiology and biophysics and human genetics, at the UC Irvine College of Medicine, and George Gutman, a UCI college of Medicine professor of microbiology and molecular genetics, said they may have isolated one of a series of elusive genes that scientists believe may increase susceptibility for these mental illnesses. However, they cautioned that many previous reports by other investigators had turned out to be false leads. "Additional studies involving greater numbers of patients are needed to verify what role the new gene may play in mental illness," Chandy said. "We located the candidate gene in a region of a chromosome long thought to be associated with these diseases, and the job this protein normally carries out makes it reasonable that it could contribute to such disorders," Gargus explained. Specifically, the gene the team identified encodes a protein, called a potassium ion channel, that controls electrical activity in nerves. Alterations in its function could change brain behavior. "This is a significant step toward understanding the origins of mental illnesses. If our results are confirmed by further studies, this discovery could lead to the development of new tests to identify those at risk for these diseases, and possibly to a new generation of highly targeted drugs with which to treat them," Gargus said. Research material from U.S. patients and ethnically matched control subjects were provided by Drs. Vishwajeet Nimgaonkar and Rohan Ganguli from the Western Psychiatric Institute at the University of Pittsburgh. Studies were independently performed on European patients with this gene by Drs. Deborah Morris-Rosendahl, Oliver Wittekindt (both from the University of Freiburg, Germany) and Marc-Antoine Crocq (Centre Hospital, Rouffach, France). Other scientists at UCI involved in the study were Emmanuelle Fantino, Katalin Kalman, Lili Tong and Than-Hien Ho, all in the department of physiology and biophysics. The new ion channel protein works as an "off-switch," dampening electrical activity in the brain. For example, this channel shuts off signals triggered through the NMDA receptor in nerves. Toxic "street" drugs (e.g. PCP) that have long been recognized to cause a schizophrenia-like syndrome block the NMDA neuroreceptor, while therapeutic anti-psychotic drugs activate it. Psychiatrists have therefore begun to consider schizophrenia a disease caused by too little activity of this receptor. Genetic tests, however, have shown that the genes encoding NMDA-receptors are very unlikely to cause mental illness. These genes have not been found in those places on human chromosomes that have been associated with mental disorders. The newly discovered ion channel gene is found at the right place on the chromosome in a region called 22q. Previous studies by a large number of investigators, especially those in the international consortia studying schizophrenia and bipolar disorder, have identified the 22q region as containing genes that enhance risk of mental illness. "Attempts to identify a specific gene out of the thousands of genes present have so far proven unsuccessful," Gutman said. This ion channel gene may represent the critical gene in this region. "Excessive activity of the ion channel could indirectly cause an effect like PCP, that is by shutting down NMDA receptors and thereby increasing risk for schizophrenia," Chandy explained. The suspect gene identified by these researchers contains another remarkable feature, a tell-tale unstable DNA sequence that encodes abnormally long stretches of the repetitive sequence, technically known as CAG. The CAG sequence is the genetic code for an amino acid (a unit of a protein) called glutamine. Many CAGs in a row produce a simple protein sequence called polyglutamine. Long stretches of polyglutamines in a number of different proteins cause neurodegenerative diseases, including Huntington's disease and imbalance-disorders called ataxias. Studies by several researchers have implicated polyglutamine-containing proteins in mental illnesses, although the specific protein(s) have yet to be discovered. The newly discovered ion channel has the tell-tale polyglutamine-stretch, and may be the elusive protein that scientists have been seeking. "Many neurodegenerative disorders, including Huntington's disease, get progressively more severe from one generation to the next, with the illness beginning earlier and earlier in life in successive generations," Chandy said. This phenomenon is called "anticipation." A similar worsening of mental illness from one generation to the next also has been recognized. Anticipation is caused by progressive lengthening of polyglutamine repeat sequences in proteins from one generation to the next. The presence of the polyglutamine stretch in the newly discovered ion channel might therefore help explain anticipation in mental illness. The UCI researchers and their collaborators studied the CAG repeats in the new gene, hSKCa3, in 150 patients with schizophrenia from Europe and the United States, and a similar number of carefully matched unaffected adults. They found a significant excess of genes containing longer CAG repeats in patients. Therefore, the channel proteins in these patients would contain longer polyglutamine-stretches, possibly contributing to the molecular origins of this illness. Studies with a smaller number of patients with bipolar disorder also show the same trend toward longer polyglutamine stretches in patients. "With a more precise understanding of how this molecular difference contributes to mental illness, we may be able to develop genetic screening tools and more effective therapies," Gutman said. The UCI group plans to use the cloned gene to take the first steps in that direction. "By expressing this gene in cultured cells, we plan to determine the effect of longer polyglutamine repeats on the channel's function", Gargus said. "Modern techniques available in the laboratory now allow the identification of subtle differences caused by longer polyglutamine repeats, even at the level of single molecules," Chandy said. In collaboration with other scientists at UCI, these investigators plan to determine the precise areas of the brain that express this channel, and whether there exist differences in these areas between the brains of schizophrenia patients and unaffected donors. Finally, these investigators are planning to extend their analysis by studying more patients and their families.
--------
188-> Berkeley Scientists Develop Mouse Model For Sickle Cell Research
BERKELEY, CA -- Genetically engineered mice that fully mimic all thesymptoms of human sickle cell disease have been developed by scientists at theLawrence Berkeley National Laboratory.  With this new mouse model, medicalresearchers finally have a means of effectively testing experimental treatmentsfor the disease. A team led by Dr.Chris Paszty of Berkeley Lab's Life Sciences Division hasreported the creation of a new strain of mice that carries human hemoglobingenes with no counteracting mouse genes.  This enables the mice to develop allclinical manifestations of the sickle cell disease. The research has been reported in this week's issue (October 31) of themagazine Science.  In addition to, P‡szty, other members of the team includedCatherine Brion, Mary Stevens, Mohandas Narla, and Edward Rubin of Berkeley Lab,plus Ewa Witkowska of the Children's Hospital Oakland Research Institute andElizabeth Manci of the University of South Alabama Doctors Hospital. Each year approximately 100,000 babies in the world, mostly of Africandescent, are born with sickle cell disease, a painful and debilitating conditioncaused by a mutant hemoglobin gene.  Although sickle cell disease has beenextensively studied, there is still no effective treatment -- a failureattributed in part to the lack of an animal model that accurately reproduces thedisease's symptoms. "This work marks the end of an almost decade long effort to create mice thatfaithfully model human sickle cell disease." says Paszty. Transgenic mice containing the human sickle genes have been engineeredbefore, but these mice developed only mild symptoms of the disease. The problemwas that in addition to carrying the mutant human genes responsible for sicklecell disease, these strains also carried normal mouse genes which counteractedthe defective human genes. "Through a series of complex transgenic and gene knock-out manipulations wewere able to add the appropriate human genes as well as delete the(corresponding) mouse genes," says Paszty.  "The end products are mice withirreversibly sickled red blood cells, anemia, and multi-organ pathology. Incontrast to the limited studies that can be performed in humans, these animalsprovide an opportunity for rapidly performing a wide range of experiments.  Theyshould play an important role in furthering our understanding of sickle celldisease and in developing improved therapies for treating sickle cell patients." Sickle cell disease was once referred to as sickle cell anemia but the term"anemia" was dropped because it emphasized only one manifestation of thecondition.  Victims inherit from both their parents a gene that makes a mutantform of hemoglobin, the iron-containing protein in red blood cells which carriesoxygen from the lungs to the rest of the body. This mutant form of hemoglobin is called "hemoglobin S."  Under certain physiological stresses, such as a decrease in oxygen, thehemoglobin S protein will polymerize, forming a rigid chain that may distort ablood cell into the shape of a "sickle."  Lacking the flexibility of normaldisc-shaped cells, these sickled cells are unable to squeeze throughcapillaries.  This impairs the flow of blood, reducing the body's supply ofoxygen.  Damage from the reduction in oxygen accumulates, causing cell death invarious tissues, most notably in the kidneys, liver, lungs, and spleen.  Thisultimately results in organ dysfunction and death of the individual. All hemoglobin is made up of two polypeptide chains -- an alpha globin and abeta globin chain.  Sickling occurs when a hemoglobin protein with a normalalpha globin chain and a mutant beta S globin chain precipitates out of solutionduring a state of deoxygenation. Creation of the new sickle cell mouse model began about five years ago whenBerkeley Lab researchers set out to engineer two new strains of knock-out mice,one which would no longer produce mouse alpha globin and one which would nolonger produce mouse beta globin.  At about the same time they succeeded increating knock-out mice which did not produce any mouse alpha globin chains, aresearch group led by Dr.Tim Townes of the University of Alabama at Birminghamsuceeded in creating knock-out mice which did not produce any mouse beta globinchains. "Rather than duplicating each others' work we exchanged knock-out mice andthen went our seperate ways in terms of creating the human sickle hemoglobintransgenics," says Paszty.  "It worked out well for both of our groups becauseafter the long process of breeding these three strains of mice together we bothmanaged to create mice with sickle cell disease." Townes and his collaborators also have a paper describing their sickle celldisease mice in the October 31 issue of Science magazine. With experts predicting a worldwide surge in the incidents of sickle celldisease, the perfection of this mouse model is extremely timely. Mice are highlyvalued for medical research because their physiology is quite similar to that ofhumans, they are fast-breeding, and their small size makes them easy to maintainand handle in large numbers. Development of the sickle cell mouse was funded by grants from the NationalHeart, Lung, and Blood Institute, and the National Institute for Diabetes,Digestive, and Kidney Diseases. The Berkeley Lab is a U.S. Department of Energy national laboratory locatedin Berkeley, California.  It conducts unclassified scientific research and ismanaged by the University of California.
--------
189-> NASA "Virtual Laboratory" Expands Research In Aerospace Safety
Astronauts and engineers have successfully concluded tests on a computer-generated virtual laboratory that will allow researchers -- located anywhere in the world -- to study potentially dangerous aircraft and spacecraft situations without risking human life. In the past, pilots, aerospace engineers and scientists who were directly involved in tests had to be physically present in a building that houses the world's largest flight simulator at NASA's Ames Research Center, Moffett Field, CA. "The lab can enable research organizations and many other parties to collaborate long-distance for the first time," said the lab's project manager, Tom Alderete. "It could also be used by universities, research laboratories and industry to develop a wide variety of products beyond the aerospace field," he said. Ames' simulator is able to move airplane and spaceship cockpits in all directions, including 60 feet vertically and 40 feet horizontally.  There are five interchangeable cockpits that are used to simulate the Space Shuttle, helicopters, airplanes and other aerospace vehicles. Researchers study aerospace controls, guidance, cockpit displays, automation and handling qualities of existing or proposed aircraft or other vehicles.  The simulator creates a convincing environment for a pilot and is controlled by computers programmed to represent each aircraft. Computers calculate correct aircraft response when a pilot changes simulator cockpit controls.  In real time, responses by the simulator include cockpit motion, images in the windshield, sounds and control readouts.  Simulations are monitored from control labs at Ames. "From a place miles away, you can use the hand controller to 'walk around' a three-dimensional, computerized world that represents our test facilities here at Ames.  You can even move into the cockpit,"  said Julie Mikula, of Ames' simulations operations branch. "A teleresearcher can see a computer animation of the cockpit's motion and can even view what the pilot sees out of the cockpit," she added.  Any kind of a vehicle -- a car, boat, plane, train, or spaceship -- can be simulated and "recreated" practically any place around the world, said Mikula. The virtual laboratory's data communications are enabled by the NASA Research and Education Network.  According to the network's project manager, Christine Falsetti, "Experience with real time computer files that the virtual lab uses also helps us learn how to better use computer networks to help do research in the future."  The virtual laboratory and the "world" it creates exists partly in computer memory and other physical gear. In June, astronauts made simulated Space Shuttle landings using a huge motion simulator at Ames while NASA engineers in Houston monitored the sessions using the three-dimensional "world" that includes video screens, computer video, two-way video conferencing, shared whiteboards, remote data access and even a pilot's out-the-window scene. Future uses of the laboratory also being considered include design of new spacecraft and training for astronauts.
--------
190-> Never Seen A Ghost? Then TV May Be Your Teacher, Says Purdue Researcher
WEST LAFAYETTE, Ind. -- This season's prime-time television lineup of angels, space aliens, witches and other oddities may influence people to believe in such creatures, according to a survey by a Purdue University communication expert. Glenn Sparks, professor of communication, and colleagues conducted a random telephone survey of 120 people in a small Midwestern city. The researchers wanted to know whether exposure to paranormal phenomena on television affected belief in such things as unidentified flying objects, ghosts, devils and extra-sensory perception. Sparks says belief in the paranormal is more complicated than it might seem. He says many factors such as age, family, religion and education influence one's beliefs. "After all these other variables are considered, the fact that television even factored in is kind of remarkable," he says. "Television may explain 10 percent of the belief in the paranormal." Television viewing was not found to be an influence for people who reported real life experience with paranormal phenomena. However, for those who had no such experiences, belief in supernatural beings was related to the viewing of paranormal programming. "People tend to rely on their own personal experiences rather than the media -- when they have those experiences to rely on. When they don't, then the media may become a more important source of information and may become more influential," Sparks says. His findings were reported in the summer 1997 edition of the Journal of Broadcasting and Electronic Media. As part of the survey, respondents were asked to agree or disagree with several statements that measured their tendency to believe in the paranormal. They also were asked whether they had experienced anything that might be considered outside the realm of normal existence. To gauge possible television effects on their beliefs, respondents were asked about their exposure to several television shows that routinely feature paranormal themes. They also were asked to estimate the amount of time they spent watching television in general. Sparks says people tended to put paranormal phenomena into two groups. One group includes creatures that Sparks labels as supernatural beings, such as ghosts, space aliens and angels. The other group consists of psychic phenomena, such as ESP, astrology and the ability to move objects with the mind. "If people endorsed one member or aspect of a group, then they tended to accept them all. It was usually all or none," he says. Sparks says he thinks television's influence may be tied to how realistically it depicts the paranormal. "Because we saw a connection between supernatural beings and television -- and no such connection between psychic powers and television programming -- we think it may have something to do with the fact that television provides more vivid coverage of ghosts and space aliens. Things like ESP may be harder to depict on TV in such a vivid fashion," he says. Sparks says belief in paranormal phenomena was quite common among the study's respondents. "For example, over 50 percent of them indicated a belief in ghosts; nearly one-third reported that sometimes they had been able to read another person's mind through extrasensory perception; and nearly 45 percent believed in UFOs from outer space," he says. Those percentages are similar to national poll results. However, as far as Sparks is concerned, why people come to believe in such phenomena is just as important as what they actually believe. Sparks' research shows that the media do exert some influence on paranormal beliefs. "We are hoping to draw attention to the ways in which people arrive at their beliefs about the nature of the world," Sparks says. He says charges that the media have not exercised enough caution in disseminating information about paranormal events may be justified if it's proven that the media have undue influence in shaping society's beliefs. Television shows with paranormal themes are not new. Sparks compares today's "Third Rock From the Sun" with the 1960's "My Favorite Martian" -- both of which he says are strictly for laughs. However, he says many programs today take their paranormal depictions more seriously. That's the case in the show "X Files" which is fiction, and in the nonfiction program "Unsolved Mysteries." "I would be most critical of shows that I call 'infotainment.' They masquerade as 'news documentaries' but really seem to be designed primarily for entertainment," Sparks says. As far as this season's apparent upswing in paranormal programming, Sparks sees it as another case of the chicken and the egg -- which came first? "The public seems to be expressing an interest in this type of programming, and the media's increasing tendency to offer these programs tends to create a larger public appetite for them," he says.
--------
191-> Two New Moons Of Uranus Discovered
A team of astronomers has discovered two distant moons orbiting around the planet Uranus. "This discovery is significant because Uranus was the only giant planet without distant moons on irregular orbits," says Brett Gladman of the Canadian Institute for Theoretical Astrophysics at the University of Toronto and the lead investigator on the team that made the discovery. Other members of Gladman's team of astronomers are Philip Nicholson and Joeseph A. Burns of Cornell University and J.J. Kavelaars of McMaster University. All giant planets in our solar system have regular and irregular satellite systems. Regular satellites orbit near the planet's equator, while irregular satellites orbit out of this plane. Until now, Uranus was the only giant planet with no known distant moons circling it on irregular orbits. Prior to these discoveries, Uranus had 15 known moons, ten of which were found by the Voyager spacecraft during its 1986 flight through the Uranian system. The other five moons were identified by ground-based telescopes, with the last one being discovered in 1948. These known moons travel along nearly circular equatorial orbits that lie close to the planet, between 50,000 km and 583,000 km away. The new Uranian satellites are the faintest ever detected without the aid of a spacecraft, and their discoveries were made possible by the use the large Hale 5-metre telescope on Palomar Mountain near San Diego, California. The findings were scheduled to be announced by the International Astronomical Union on Friday, Oct. 31. For more information, visit Brett Gladman's web site at: http://www.cita.utoronto.ca/~gladman 
--------
192-> New X-Ray Technique Might Boost Breast Imaging, Cut Cancer Deaths
CHAPEL HILL -- By creating significantly sharper, more detailed pictures of breast tissue, mice and other objects, a technical advance in radiography could dramatically improve mammography and other medical and materials imaging, new studies suggest. The ultimate goal will be to cut the number of breast cancer deaths by diagnosing tumors earlier. A team of scientists from the University of North Carolina at Chapel Hill, the Illinois Institute of Technology in Chicago, Brookhaven National Laboratory in Upton, N.Y., and N.C. State University in Raleigh are developing the new imaging method using a single-energy X-ray source. Such sharply defined pictures have never been produced through conventional X-ray machines. "Mammography presents difficult imaging problems because the densities of the tissues are similar, and the lack of contrast often masks tumors," said Dr. Etta Pisano, associate professor of radiology at the UNC-CH School of Medicine and the research team physician. "With our new method, which we call defraction-enhanced imaging, or DEI, we have produced images showing improved detail of cancerous tumors in human breast tissue," said Pisano, also mammography chief at UNC-CH and a UNC Lineberger Comprehensive Cancer Center member. "The detail is just outstanding -- it's like casting a sharper shadow when the sun shines down on you. "While much work remains to be done before we can use this with patients, we are absolutely excited about the possibilities," she said. "This has never been done before, and we know of no reason why it couldn't work on other parts of the body as well." A report on the findings appears Friday (Oct. 31) as the lead article in the November issue of Physics in Medicine and Biology, a professional journal. Besides Pisano, authors of the report are Drs. Dean Chapman, director of the IIT's Center for Synchrotron Research and Instrumentation; Eugene Johnston and David Washburn of radiology at UNC-CH; William Thomlinson and Zhong Zhong of Brookhaven's National Synchrotron Light Source; and Dale Sayers of physics at N.C. State University. Diffraction-enhanced X-ray imaging was pioneered at Brookhaven and improved at Argonne National Laboratory's Advance Photon Source, Chapman said. In conventional mammography, differences in tissue densities and composition are shown through absorption as contrasting areas in the image, allowing doctors to see tumors or changes in tissue, he said. The problem is that differences between healthy and cancerous tissues are very small, and X-ray scattering can lead to lower contrast, making it difficult to detect small tumors. With synchrotron radiation, the DEI method employs a single-energy fan beam of X-rays instead of the broad-energy beam of conventional radiography. The beam is passed through the object or tissue under study. Eventually, that will be a patient. "This method of line-scan imaging reduces scatter and helps us visualize low-contrast areas that otherwise would be lost," Chapman said. "The key to the new method is an analyzer crystal placed in the beam of X-rays that has passed through the object on its way to the imaging plate detector." The analyzer can differentiate angle differences much less than one microradian, equivalent to an ant viewed from a mile away. The refraction image shows changes in X-ray refraction, or bending, as it passes through a target and highlights the edges of structures in that target. Objects having little absorption contrast may have strong refraction properties, which the image will highlight. An example is the fine, thread-like fibers extending from some malignant tumors. Normally difficult or impossible to detect, they are clearly visible in the refraction image. The second of two images DEI creates -- the apparent absorption image -- appears similar to a normal X-ray of the object but shows improved contrast due to the scatter-free method. In studies of the American College of Radiology test object, or "phantom," used for quality control in mammography, researchers have observed better than 25-fold contrast enhancements. "During recent experiments at the Advanced Photon Source, we also showed that our method is energy independent for the refraction image," Chapman said. "Imaging breast tissue samples at 30 keV produced the same high-quality images as at 18 keV, which is the energy used in conventional mammography. Imaging at a higher energy means less dose or absorbed radiation for the patient." While the technology has not been used on patients, preliminary results from studies of human breast tissue also show markedly higher contrast than conventional images, Pisano said. If the DEI method works as well in the future as current studies suggest it could, it might be used clinically within a decade, she said. Besides mammography, possible applications include non-destructive materials testing, airline baggage screening and defense. The team is investigating medical and other applications of the technology. Early studies looking at defects in airplane parts also have produced significantly better pictures than conventional X-rays. The research is supported in part by a grant from the U.S. Army Breast Cancer Research Program, the U.S. Department of Energy and individual departments of research team members.
--------
193-> Tree-Ring Study Enables Researchers To Link Massive American Earthquake To Japanese Tsunami In January 1700
Stumps of long-dead western red cedar trees are revealing new details of a cataclysmic earthquake along North America's west coast more than 100 years before the arrival of the first European occupants. Two University of Washington researchers believe that evidence in the dead wood confirms that in the year 1700 a great earthquake struck the Pacific Northwest coast and set off a tsunami, a train of massive ocean waves, that flooded coastal Japan. The scientists are reporting in the Oct. 30 issue of Nature magazine that they have dated the demise of six trees, along 60 miles of the Washington coast, by "reading" the annual ring patterns in the trunks and roots of the stumps. They found that each of the trees produced its final ring in the 1699 growing season. No further rings were evident, indicating that the trees were dead by the spring of 1700. "We are saying this huge earthquake really happened," says David Yamaguchi, a UW dendrochronologist, or tree-ring analyst. Last year Japanese scientists reported that a tsunami that hit Honshu island on January 27, 1700, was probably caused by an earthquake on the Cascadia subduction zone, a 600-mile coastal fault stretching from British Columbia to northern California. Based on the size of the tsunami, the Japanese researchers estimated the earthquake at magnitude 9, even though no Cascadia fault earthquake of magnitude 5 or above has ever been recorded by seismologists. The Nature article concludes that the tree dates "mean that the northwestern United States and adjacent Canada are plausibly subject to earthquakes of magnitude 9." The second author of the paper, Brian Atwater of the U.S. Geological Survey and an affiliate UW professor, says the new dates clinch the argument that massive earthquakes can occur where the Juan de Fuca plate, an Oregon-sized slab of crust, collides with a large block of continental crust called the North America plate. The Cascadia fault forms the boundary between the two plates. Over the past decade, Atwater and other researchers have discovered geologic evidence of repeated magnitude 8 or larger earthquakes along the Cascadia fault. However, the size of the 1700 earthquake remains a subject of much debate, which the tree-ring dates do not resolve, says Atwater. Some scientists have proposed a ceiling of magnitude 8; others have suggested a maximum magnitude of 9.5. Only a handful of magnitude 9 earthquakes have occurred globally this century. The largest earthquake in the Pacific Northwest in historic times was a magnitude 7.4 in the north Cascade mountains in 1872. This was not on the Cascadia fault. Yamaguchi first "read" the cedar stumps to show that a great earthquake happened some time after 1690. UW researcher Minze Stuiver then pinned the earthquake to between 1695 and 1710 with precise radiocarbon dating. This led the Japanese scientists to propose the Cascadia fault as the likely origin for the 1700 tsunami. To test the Japanese theory, the UW researchers dug up the roots of a dozen cedar stumps from the Copalis River south to the Columbia River. In half of these stumps, the dating was inconclusive, but in six they found evidence that the trees had died before the start of the 1700 growing season.
--------
194-> Scientists Closing In On How Increased Alzheimer's Risk Is Linked To Fat And Cholesterol Transport In The Brain
Scientists studying the brain are learning how the removal of cholesterol and the proper delivery of fatty compounds are vital for the healthy function of the brain, in an effort to understand how these processes gone awry can lead to Alzheimers disease. Despite the fact that the brain is 70 percent fat, scientists have known little about how fats, or lipids, are metabolized and transported within it. The interest intensified several years ago with the surprising discovery that an increased risk of Alzheimers disease was linked to a natural genetic variant of a key fat-transporter molecule called apolipoprotein E, or apoE. Now a team of scientists led by Mary Jo LaDu in the department of pathology at the University of Chicago Medical Center has shown that the apoE-containing fat transporters found in brain cells are very different from the apoE particles found elsewhere in the body and contain most of their cholesterol in a different form. The study may give new insights into how one variant, apoE4, found in 15 percent of the population, can increase a person's risk of developing Alzheimers. People who inherited a copy of the apoE4 gene from one parent have been found to have a three-fold greater risk of the disease, while those who inherited a copy from both parents have eight times the risk. The new findings were reported at the annual meeting of the Society for Neuroscience in New Orleans on October 27. The brain is constantly moving around huge amounts of fat and cholesterol because these compounds are major components of cell membranes, which the nervous system must constantly rearrange as it makes and breaks links from cell to cell. "If there's one organ in your body that needs to be plastic and adaptible, its your brain," LaDu says. "It's constantly making new synaptic junctions that allow you to form a thought or hold a memory." The brain must have a dependable source of cholesterol, LaDu says, because it is a vital component of membranes; however, the brain needs to be able to clear the excess because it is also very toxic to the sensitive nerve cells. How the brain is able to maintain such exquisite balance has been perplexing. In the blood, fats and cholesterol are packaged, with key protein components, into particles called lipoproteins. But the brain is shielded from these particles by the so-called blood-brain barrier. Instead, the brain makes its own supply of lipoprotein particles using some of the same protein components, including apoE. LaDu's team analyzed lipoproteins found in the cerebrospinal fluid (CSF) that bathes the entire nervous system. They also compared the CSF lipoproteins with those secreted by astrocytes, helper cells in the brain that nourish and support the firing nerve cells. The differences between the lipoproteins secreted by astrocytes and those found in the CSF suggest that the astrocytes produce particles that help the brain rid itself of excess cholesterol in addition to helping deliver membrane components to the nerve cells. "We think this is an early but landmark study that opens up the field of brain research to the analysis of lipoproteins, which are clearly crucial to normal function," LaDu said. "ApoE also gives us another tool to try to dissect the causes of Alzheimers disease." LaDu's team at the University of Chicago includes Catherine Reardon, Ph.D., Godfrey S. Getz, M.D./Ph.D., Vi Cabana, Ph.D., Sean Gilligan, and John Lukens, as well as Linda Van Eldik, Ph.D. at Northwestern University Medical School and David Holtzman, M.D. at Washington University School of Medicine. The work was funded by the National Institutes of Health, American Health Assistance Foundation, and the Alzheimer's Association.
--------
195-> New Research Finds Link Between Religion And Health In The Elderly
NEW HAVEN, Conn., Oct.31, 1997--For the elderly, religion may do more than ease the soul. In fact, attendance at religious services may actually improve physical health and psychological well-being. That according to two new reports, co-authored by Ellen Idler, Ph.D., associate professor of sociology at Rutgers' Institute for Health, Health Care Policy and Aging Research, and Stanislav Kasl, Ph.D., professor of epidemiology in the department of epidemiology and public health at Yale University School of Medicine. The reports reveal the findings of a 12-year study conducted by Yale public health faculty and funded by the National Institute on Aging (NIA). The study sampled 2,812 people age 65 and over from Protestant, Catholic, Jewish and other religious backgrounds in New Haven, Conn. Subjects were interviewed annually from 1982 to 1989 and again in 1994. The two reports will be published in the Nov. 15 issue of the Journal of Gerontology. The first report, Religion Among Disabled and Nondisabled Persons I: Cross-sectional Patterns in Health Practices, Social Activities and Well-being, explores the impact of participating in religious services on risky health behaviors, friendships and family ties, and depression. The three major findings for elderly people who participated in religious services are:
--------
196-> Study Suggests Possibility Of Universally Effective AIDS Vaccine
A study by a research team based at the Massachusetts General Hospital (MGH) suggests that it may be possible to develop an AIDS vaccine that will be effective against the different versions of the virus found around the world. As reported in the November issue of the Journal of Virology, the researchers found that the immune system's killer cells, called cytotoxic T-lymphocytes (CTLs), are capable of recognizing different strains, or clades, of the human immunodeficiency virus (HIV).  In the past it has been feared that the prevalence of different HIV strains in different parts of the world would require developing different vaccines targeted to each strain. CTLs have become the focus of HIV vaccine research in recent years, as earlier vaccine strategies based on the activity of antibodies have not proven successful.  The immune system teaches these killer cells to target a specific type of virus, bacteria or other foreign material.  Cells targeted to a specific virus seek out and destroy virally infected cells by recognizing peptides — small fragments of the proteins that make up that virus — that are displayed on cell surfaces. CTLs are not infected by HIV and usually mount a defense against the virus soon after the initial infection.  In most patients, however, the levels of CTLs eventually decrease, allowing HIV levels to rise and AIDS symptoms to develop. Recent research has produced evidence that CTL activity is likely to be be a key immune response against HIV.  High CTL levels have been seen in long-term nonprogressors — individuals who remain healthy despite being infected for many years — and CTLs that target the virus have been found in people who remain uninfected despite many exposures to HIV.  In addition, CTLs seem to play an important role in the immune response against other viral disease, like cytomegalovirus and Epstein-Barr virus. "There really is a growing consensus in the field that generating a strong, virus-specific CTL response will be important in developing any successful vaccine against HIV," says Bruce Walker, MD, director of the Partners AIDS Research Center based at the MGH and senior author of the report.  "Since those parts of world most affected by this disease do not have the resouces to take full advantage of current therapies, a vaccine is the only way we're going to be able to eliminate AIDS globally." Most HIV-infected individuals in the United States and Europe are infected with clade B, while several other clades — the most common are A, C, D and E — predominate in Africa and Asia.  The researchers tested CTLs taken from indivi duals infected with clade B HIV and tested whether they would recognize viral peptides from all of the major clades.  All of the tested CTLs recognized peptides from at least one non-B clade virus, and most reacted against peptides from all clades tested. The team also tested CTLs from 14 infected individuals from Senegal, 10 of whom were infected with clade A virus, three with clade G and one with clade C.  CTLs from all 14 individuals reacted against proteins from clade B viruses. "We were very surprised to see this striking amount of CTL cross-reactivity," says Walker.  "But this result is supported by previous observations that people infected with one strain seem be protected against other strains of HIV." Walker notes that CTL-based vaccines are just beginning to be tested in human volunteers, and many questions remain to be answered.  For instance, it is far from certain whether CTL activity alone would be sufficient to protect against either HIV infection or progression to AIDS.  Future studies are needed to define exactly which immune system responses will be most important for protection against HIV. Walker's coauthors include Huyen Cao, MD, first author, and Spyros Kalams, MD, from the MGH; Phyllis Kanki, DVM, Jean-Louis Sankale, MD, and Abdoulaye Dieng-Sarr, of the Department of Cancer Biology at Harvard School of Public Health; Gail Mazzara, PhD, of Therion Biologic Corporation in Cambridge; Bette Korber, PhD, of the Los Alamos National Laboratory in New Mexico; and Souleymane Mboup, MD, of University Cheikh Anto Diop in Dakar, Senegal.  The research was supported by grants from the National Institutes of Health.
--------
197-> Plant Growth Surges After Global Temperature Spikes, Scientists Report
Study Highlights Importance of Regional Analyses El Nino events or volcanic eruptions can boost or depressglobal temperatures within months, but their strongest impacts onthe earth's biosphere may not occur until one to three yearslater, according to a paper published in the October 31st issueof Science. Regional analyses show that a global warm spell's initialboost in plant activity is clustered in polar and temperateareas.  On the other hand, heat-stressed tropical and semiaridregions may show an initial drop in plant production. The results, reported by scientists affiliated with theNational Science Foundation (NSF)-funded National Center forAtmospheric Research (NCAR) in Boulder, Colorado, lend credenceto the notion that biological effects of global change can varysubstantially across the globe. According to NCAR's David Schimel, one of the paper'sauthors, the results highlight the power of new data sets onglobal change, as well as the usefulness of computer models thatconnect the atmosphere and biosphere. "We were looking specifically for delayed ecosystemresponses in this study because they had been predicted by themodels," Schimel notes. The global temperature record revealed several multiyearpatterns, including warming associated with El Nino events in the1980s.  These patterns were correlated globally with carbondioxide levels and regionally with vegetation growth.  Globalcarbon dioxide levels, which are steadily rising due to humanactivities, tended to rise more quickly over the first few monthsafter a global temperature peak.  The carbon dioxide levels roseat a slower pace during the one-to-three-year period after thetemperature peak, followed by another gradual acceleration. The authors studied the temperature-vegetation relationshipby region at data points separated by one degree latitude andlongitude (roughly 85 by 110 kilometers, or 50 by 70 miles).  Atthe peak of a warm period, plant growth tended to increase inpolar and temperate regions and decrease at lower latitudes,including tropical rainforests and drier savanna/grasslandregimes.  "This contrast suggests that . . . temperature may havedirect negative impacts on plant growth, or may increase waterstress in semiarid ecosystems," the authors note. However, in the one-to-three-year period after a temperaturepeak, the patterns appear to reverse:  plant growth is enhancedin the warmer and drier regions and limited at higher latitudes.Thus, low-latitude plant growth appears to be driving theenhanced uptake of carbon dioxide during this period. The paper highlights the importance of regional analyses ofclimate change to detect areas where effects may run counter to aglobal average.  This is the first data-based study to considerregionally-specific ecosystem responses on a global scale, saysSchimel.  The results show that ecosystems are sensitive totemperature perturbations. Co-authors of the paper include Schimel, and Rob Braswell,Ernst Linder and Berrien Moore, of the University of NewHampshire (UNH).
--------
198-> Back On Track -- Mars Global Surveyor To Resume Aerobraking
After a two-week hiatus, NASA's Mars Global Surveyor (MGS) flight team will resume lowering the spacecraft's orbit around Mars beginning Nov. 7.  The effort will proceed at a more gradual pace than before, which will extend the mission's aerobraking phase by several months, and will change Global Surveyor's final science mapping orbit. The decision to resume aerobraking came after intensive engineering analysis, computer simulations and tests with representative hardware to characterize the current condition of one of the spacecraft's two solar panels, which began to flex more than expected during the spacecraft's lowest dip into the Martian atmosphere on Oct. 6. Under normal circumstances, the spacecraft's two 11-foot-long (3.5-meter) solar panels should remain fixed and nearly motionless during each aerobraking pass through the upper atmosphere of Mars.  One of the panels, which did not fully deploy and latch after launch, moved past its latched position and has shown slight movement during the spacecraft's last three closest approaches to the Martian surface. "After sufficient time to study the observed motion, we concluded that it is possible to perform additional aerobraking at a slower rate, without putting undue stress on the solar panel in question," said Glenn E. Cunningham, Mars Global Surveyor mission manager at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA.  "This changes Mars Global Surveyor's final mapping orbit, but it should not have a significant impact on the ability of Global Surveyor to accomplish the mission science objectives." The spacecraft's scientific instruments have performed flawlessly and continue to return new information about Martian magnetic properties, its atmosphere, surface features, temperatures and mineralogy since Mars Global Surveyor entered orbit around the red planet on Sept. 11. The spacecraft is currently in a 35-hour elliptical orbit which brings it 107 miles (172 kilometers) above the surface of Mars at its closest approach to the planet.  The operations team at JPL and Lockheed Martin Astronautics, Denver, CO, will begin to reduce that orbit using a more moderate level of aerobraking that will slowly bring the spacecraft into the desired nearly circular mapping orbit.  Aerobraking, a technique first demonstrated in the summer of 1993 during the final months of the Magellan mission to Venus, allows a spacecraft to lower its orbit without relying on propellant, by using the drag produced by a planet's atmosphere. "There are several types of desirable orbits for us to consider in the next several weeks that will give us global coverage of the planet and yield all of the science data we expected to return," Cunningham said.  "In the meantime, the instruments are performing marvelously, and we will continue gathering new science data as we begin to reduce the spacecraft's altitude and bring it down into the upper Martian atmosphere.  Even if we wind up in an elliptical orbit, we will have an opportunity to study Mars at closer range than we originally planned because the spacecraft's periapsis -- or closest passage over Mars -- will be closer than the 234-mile (378-kilometer) circular orbit that was to be its original mapping distance." The spacecraft's current orbit was raised Oct. 12 after the flight operations team observed that the unlatched solar panel had moved more than 20 degrees and beyond what should have been its fully deployed and latched position.  Significant movement was observed on periapsis 15 -- or the 15th closest pass over Mars, which occurred on Oct. 6 -- when the Martian atmosphere had become twice as dense as it had been during previous passes.  The thickness of the atmosphere amounted to a 50 percent increase in pressure over what was expected on the spacecraft's solar array. Although atmospheric variations like these were anticipated as the seasons change on Mars, the spacecraft's orbit was raised by about seven miles (11 kilometers) to adjust the pressure level.  Subsequent motion of the panel at periapsis 16 through 18 caused the flight team to raise the orbit further on Oct. 12, taking the spacecraft out of the atmosphere altogether. "The investigation of the unexpected motion of the unlatched panel led us to identify a secondary source of damage in the yoke, a piece of structure that connects the solar panel to the spacecraft," Cunningham said.  "This secondary source of damage was a result of the failure of the damper arm that jammed in the panel's hinge joint shortly after launch, when the solar panels were initially deployed." Mechanical stress analysis tests suggest that the yoke -- a triangular, aluminum honeycomb material sandwiched between two sheets of graphite epoxy -- probably fractured on one surface.  The analysis further suggests that the fractured surface, with increased pressure on the panel during aerobraking, began to pull away from the aluminum honeycomb beneath it. "Aerobraking will be reinitiated at 0.2 newtons per square meter (0.00003 pounds per square inch), which is about one-third of the original aerobraking level," Cunningham said.  "This is a pressure that we currently believe is safe but we will continue to work with ground tests, analysis and close monitoring of in-flight spacecraft data to assure that it is safe." "Aerobraking will take much longer, perhaps eight to 12 months, at this more gradual rate.  In the meantime, we will continue collecting science data and work in the next several weeks toward selection of the best possible orbit to fulfill the science objectives of the mapping mission," Cunningham said. A new color image from the MGS Mars Orbiter Camera of the giant volcano Olympus Mons is available on the Internet at the following URL: http://barsoom.msss.com/mars/global_surveyor/camera/images/index.html Additional information about the Mars Global Surveyor mission is available on the World Wide Web by accessing JPL's Mars news site at URL: http://www.jpl.nasa.gov/marsnews or the Global Surveyor project home page at URL: http://mars.jpl.nasa.gov. Mars Global Surveyor is part of a sustained program of Mars exploration, known as the Mars Surveyor Program.  The mission is managed by the Jet Propulsion Laboratory for NASA's Office of Space Science, Washington, DC.  JPL's industrial partner is Lockheed Martin Astronautics, Denver, CO, which developed and operates the spacecraft.  JPL is a division of the California Institute of Technology, Pasadena, CA.
--------
199-> Potential Test For Lou Gehrig's Disease At Hand
Good results in preliminary studies of a potential diagnostic test for amyotrophic lateral sclerosis (ALS) have led Johns Hopkins scientists to call for an expanded trial immediately.	At this week's meeting of the Society for Neuroscience in New Orleans, Hopkins neurologist Jeffrey Rothstein, M.D., Ph.D., is asking physicians "to send us cerebrospinal fluid from their patients to give us a larger sample to evaluate the test." Currently, diagnosis of ALS, also known as Lou Gehrig's disease, is indirect, requiring months of tests to exclude other diseases.  "During this time, motor nerve cells are dying," says Rothstein.  "If our new test works, doctors can check for ALS at the first sign of ALS-like symptoms and begin treatment much earlier." A drug called riluzole, approved in 1995 by the Food and Drug Administration, can slow the disease, although it is unable to halt it.  Other drugs are under study, and experts believe that earlier application of those treatments could significantly improve the quality of patients' lives. The test is based on findings by Rothstein and his colleagues last year that about 65 percent of ALS patients have mutations involving abnormal or mutant forms of EAAT2, a protein that normally deactivates and recycles glutamate.  Glutamate is a chemical nerve cells use to send messages.  ALS patients often have little or no EAAT2 in certain areas of the brain and spinal cord, creating an excess of glutamate that kills the nerves that control muscles. The usual result is gradually increasing paralysis and death in two to five years.  Nearly 30,000 people currently have the disease.  It is largely sporadic, and there are no laboratory tests useful for its early diagnosis. To test the mutations' value as a way of detecting ALS, Hopkins researchers looked for it in the cerebrospinal fluid of 18 ALS patients and 38 non-ALS patients with multiple sclerosis, stroke, headache or other problems.  They found it in 12 of the 18 ALS patients, and none of other patients. "That's a pretty good rate, and it matches what we find in brain tissue post-mortem, but to get a real feel for the potential of this test we need to see what it can do in a much larger population sample," says Rothstein. The studies that identified EAAT2 abnormalities were funded in part by the Cal Ripken/Lou Gehrig Fund for Neuromuscular Research, a fund for research into ALS and other neuromuscular diseases created in 1995 when Ripken broke Gehrig's long-standing record for consecutive games played.  Additional funding comes from the National Institutes of Health, the Muscular Dystrophy Association, and the ALS Association.
--------
200-> Ghost Ants Can Be More Trick Than Treat For Homeowners
GAINESVILLE--- Florida homeowners may be haunted by more thanthe usual ghouls and goblins this time of year as ghost ants show up inkitchens in search of a sweet treat. Ghost ants are pesky little insects who got their name by looking muchlike tiny, white apparitions who suddenly appear and seem to disappearjust as quickly. They don't sting or bite, but like any good trick-or-treater, ghost ants do have a sweet tooth and prefer nibbling on goodiessuch as cakes, candy and cookies. Phil Koehler, an entomology professor with the University of Florida'sInstitute of Food and Agricultural Sciences, said ghost ants are both fastand small, averaging about 1 mm in length or about the size of a pinhead. Ghost ants are most deserving of their name, Koehler said. With a blackhead and thorax and a pale, gray body, they are almost transparent,move quickly and are hard to track. With no effective method for eliminating the critters, a home can beoverrun with little ghost ants in no time, said David Williams, anadjunct professor of entomology at UF/IFAS. "They are often found in plant material brought into your home. Theygenerally live in just about anything outdoors -- in plants, plantproducts, wood and soil," Williams said. "In the indoors, they can moveinto interior walls or live in book bindings. They can live just aboutanywhere." He said the search for a way to elimate ghost ants is as elusive as thepests themselves. Over the past few years, Williams has been trying to develop baits toattract ghost ants and kill their colonies. He said they are testing anattractant now, but there is no effective bait or insecticide at this time. Koehler said some liquid baits containing boric acid available over thecounter can work well, but should be diluted so the ant has time to getback outside to the colony before it dies. The best thing forhomeowners to do is to track where ghost ants may be entering thehome or building and seal off the opening to keep the ants outdoors,Koehler said. "We could turn these ghost ants into real ghosts by killing them, but thebaits need to work slowly to affect ghost ants. Because they are sosmall, a normal bait would kill the ant too fast before it could get backoutside," Koehler said. "Consequently, most baits we have now don'twork well because of their high dosages, which kills the ants beforethey can get back to the nest to the others." Koehler said ghost ant sightings occur mostly in warm climates and canbe a big problem in tropical areas of the world. In Florida, they arefound mostly from Orlando south, although they do occur as far northas Gainesville. A good ghost? Although they can be a pest, they can also be beneficial in certain instances. For example, Koehler said, they do prey on and control mites that attack plants.
--------
201-> Hubble Catches Up With A Blue Straggler Star In The Core Of A Globular Cluster
 Astronomers have long been mystified by observations of a few hot, bright, apparently young stars residing in well-establishedneighborhoods where most of their neighbors are much older. With the help of NASA's Hubble Space Telescope, astronomers now have evidence that may eventually help solve the 45-year-old mystery of how these enigmatic stars, called blue stragglers, were formed.  For the first time, astronomers have confirmed that a blue straggler in the core of a globular cluster (a very dense community of stars) is a massive, rapidly rotating star that is spinning 75 times faster than the Sun.  This finding provides proof that blue stragglers are created by collisions or other close encounters in an overcrowded cluster core. Astronomers studied a blue straggler in the tumultuous heart of the nearby globular cluster 47 Tucanae (47 Tuc), located 15,000 light-years away in the southern constellation Tucana.  The observation was made by astronomers Michael M. Shara of the Space Telescope Science Institute, Baltimore, MD; Rex A. Saffer of Villanova University, Villanova, PA; and Mario Livio, also of the Institute.  Their analysis will appear in the Nov. 1 issue of  the Astrophysical Journal Letters. "This is an extremely exciting result," Saffer said, "because it may help distinguish between competing theories of blue straggler star formation and evolution." "Since their discovery 45 years ago, blue stragglers have been assumed to be stars much like the Sun, although their bluer color and greater brightness imply that they are more massive and much younger than normal globular cluster stars.  Our analysis confirms that, but without having to make any assumptions about the state of blue straggler star evolution," Saffer said. Using Hubble's Faint Object Spectrograph (removed during the Second Servicing Mission in February), the astronomers analyzed the spectrum of one blue straggler, measuring its temperature, diameter, and rotation rate. The team then combined these measurements with the blue straggler's apparent brightness, taken from a Hubble Telescope Wide Field and Planetary Camera archival image, to obtain the star's mass.  The astronomers report the derived temperature and mass are consistent with the characteristics of a normal star with a mass about 1.7 times that of the Sun.  However, the star is spinning at least two to three times faster than stars of its kind. Astronomers now believe that blue stragglers are created by the merger of two low-mass stars.  But they have two different views of how these stars interact to create blue stragglers.  One merger theory proposes that a violent collision of two unrelated stars creates a blue straggler.  Another hypothesizes that a slow coalescence of a gravitationally bound pair creates the straggler star. Based on their analysis of the blue straggler in 47 Tuc, the team favors the slower, gentler merger scenario between binary stars.  In double-star systems where the stars are close enough to touch each other, the more massive star can cannibalize its partner, producing a single, even more massive star.  This process, astronomers believe, more likely results in a rapidly spinning merger product where the fast orbital motions of the binary star produces the rapid spin of the consolidated pair. The second merger scenario involves a collision between two unrelated stars, which run into each other by chance in the dense star cluster core. "It's a bit like a head-on wreck between two tractor trailers," Saffer explained, "where the enormous energy carried by the fast-moving stars is deposited in the debris from the collision." Saffer credits the Hubble telescope's superior spatial resolution with being able to peer into a swirling mix of stars to capture a blue straggler in the cluster core. "While some blue stragglers are found in globular cluster outskirts, in 47 Tuc the blue stragglers are only found in the cluster core," Saffer said.  "The crowding of the stars there is too severe for the current generation of ground-based telescopes to resolve them." Globular clusters contain up to 1 million stars packed into a swarm only about 20 light-years in diameter.  They also areamong the oldest stellar systems in the Milky Way Galaxy.  Stars speeding through the extremely crowded cluster core are far more likely to collide or pass near each other than stars in the sparse neighborhood of the Sun.  These processes can produce a zoo of stellar animals, such as X-ray binaries, pulsars, blue stragglers, and other exotic species, all of which have actually been observed in globular cluster cores. The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc., for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency. - end - NOTE TO EDITORS:  A photo and caption are available via the World Wide Web athttp://oposite.stsci.edu/pubinfo/PR/97/35.html and via links inhttp://oposite.stsci.edu/pubinfo/Latest.html orhttp://oposite.stsci.edu/pubinfo/Pictures.html Images are available via the World Wide Web at URL: http://oposite.stsci.edu/pubinfo/gif/bss19.gif (GIF),http://oposite.stsci.edu/pubinfo/jpeg/bss19.jpg (JPEG). Image files also may be accessed via anonymous ftp from oposite.stsci.edu in /pubinfo:  gif/bss19.gif (GIF) and jpeg/bss19.jpg (JPEG).  Higher resolution digital versions (300 dpi JPEG) of the release photograph are available in /pubinfo/hrtemp: 97-35.jpg (color) and 97-35bw.jpg (black &white).  Full resolution TIFF images are available in/pubinfo/tiff/1997/35a.tif and 35b.tif.
--------
202-> Wider Use Of 'Aspirin-A-Day' Will Save Lives Of People With Cardiovascular Disease
DALLAS, Oct. 21 - If more people would take an aspirin when they experience chest pain or other symptoms of a severe heart attack, 5,000 to 10,000 lives could be saved in the United States each year, according to an American Heart Association scientific statement published today in the association's journal Circulation. "There is clear and conclusive evidence of the benefits of aspirin," says Charles Hennekens, M.D., one of three internationally recognized medical leaders on heart disease and stroke who authored the statement titled, "Aspirin as a Therapeutic Agent in Cardiovascular Disease." "It doesn't matter what brand, just as long as aspirin is used," says Hennekens, chief of preventive medicine at Brigham and Women's Hospital and professor of medicine at Harvard Medical School. Individuals undergoing a heart attack should take a full tablet (325 milligrams) of aspirin to obtain a "rapid clinical effect," he adds. For those who have had a heart attack and want to prevent another one, "it appears that 50 to 100 milligrams a day or a commercial baby aspirin is sufficient." Aspirin prevents blood platelets from sticking together and forming blood clot masses. By blocking blood vessels, these clots can cause heart attacks and strokes. The American Heart Association issued the statement, also authored by Mark L. Dyken, M.D., and Valentin Fuster, M.D., to guide physicians on the use of aspirin in the treatment and prevention of cardiovascular disease, the nation's No. 1 killer. It also encourages more doctors to recommend aspirin to patients whom research studies have shown could benefit from this relatively inexpensive over-the-counter drug. The association's statement calls for a wider use of aspirin than does the Food and Drug Administration. While the FDA has approved package labeling that points out that aspirin can help prevent another heart attack in individuals who have already survived one, the AHA recommends that aspirin be taken by anyone with atherosclerosis, regardless of whether he or she has had a heart attack. Atherosclerosis is the disease process that creates the obstructions in the blood vessels that can impair blood flow to the heart and brain, thus causing a heart attack or stroke. Blood vessels in the limbs, as well as to the heart and brain, are vulnerable to atherosclerosis. Along with several other health organizations, the AHA has asked the FDA to expand its approved uses of aspirin. Two studies in the past decade have revealed that 23 to 39 percent of heart attack survivors did not receive aspirin, despite its proven benefits. "We have a challenge to increase the use of aspirin in individuals having a heart attack as well as those who have a wide range of blood vessel, or vascular, diseases," says Hennekens. The American Heart Association recommends that aspirin be taken when a heart attack occurs and to prevent repeat heart attack in survivors. Since heart attack survivors are at risk for stroke, taking an aspirin daily also can lower risk for suffering a "brain attack," the No. 1 cause of major disability in the United States. Research studies have not clearly demonstrated aspirin's value in preventing heart attack and stroke in healthy people without cardiovascular disease. "Additional data are needed for complete assessment of aspirin's benefit-to-risk ratio in apparently healthy persons," says Hennekens. In deciding whether to recommend aspirin to a patient, physicians should consider the patient's risk for cardiovascular disease, the benefits of aspirin and side effects. However, no one should regard aspirin as a substitute for a heart-healthy lifestyle that includes a low saturated-fat diet, regular physical activity and no cigarette smoking. "Unfortunately in the United States people would rather pop a pill, than change their unhealthy lifestyles," says Hennekens. "Individuals should check with their doctors to determine whether they are candidates for aspirin and the dose they should take," he says. "Aspirin has the best benefit-to-risk ratio as well as benefit-to-cost ratio of any drug therapy for heart disease." The American Heart Association does recommend that people who have not suffered a heart attack or stroke but who have experienced repeated episodes of unstable chest pain or mini-strokes (transient ischemic attacks) should take aspirin to reduce their risk for having a heart attack or stroke. Individuals whose coronary arteries are obstructed by atherosclerosis and who undergo angioplasty and coronary bypass surgery to restore blood flow to the heart also should take aspirin, according to the statement. In writing the scientific statement, Drs. Hennekens, Dyken and Fuster reviewed studies on the role of aspirin therapy. One such study, the Antiplatelet Trial Collaboration overview, which analyzed results of randomized trials of therapy to prevent platelets from accumulating in 54,000 individuals who were at high risk for heart disease, found aspirin therapy reduced by one-fourth the risk of subsequent non-fatal heart attacks and strokes. Other studies, comparing other antiplatelet agents to aspirin showed that use of ticlopidine resulted in a 21 percent decrease in stroke over aspirin at three years. However, ticlopidine is more expensive and causes more side effects than aspirin. Another study showed that clopidogrel used in people with heart attack, stroke and peripheral vascular disease produced a slightly lower rate of death with no major differences in side effects than aspirin. But the use of aspirin to prevent heart or stroke in those who are healthy remains less clear. In the U.S. Physician's Health Study, 22,071 physicians were given an alternate day dose of 325 milligrams of aspirin, resulting in a 44 percent reduction in the risk of first heart attack. The findings for stroke and overall heart and stroke death rates were inconclusive, but raised the possibility of small increased risk of stroke caused by bleeding in the brain, says Hennekens. A British trial among male physicians found no significant effects of aspirin, but the trial had only one-fourth the number of physicians as the U.S. trial. Combined, the two trials report a 32 percent reduction in the risk of heart attack by taking aspirin. An ongoing trial of low dose 50 milligrams aspirin in 40,000 U.S. female health-care professionals -- the Women's Health Study -- will provide further information to develop a rational policy for recommending aspirin use in healthy people to prevent first heart attacks. Dyken is professor of neurology, Indiana University; and Fuster, president-elect of the AHA, is professor of medicine, Mount Sinai Medical Center.
--------
203-> Florida Sexuality Education Programs Fall Short, UF Research Shows
Writer: Cathy Keen Source: Michele Johnson Moore, (502) 745-4797 GAINESVILLE, Fla. --- Sexuality education programs in Florida's public high schools fall short in teaching students what they need to know to stem the high rates of teen-age pregnancy and disease, a new University of Florida study finds. "The good news is that teachers surveyed like teaching sexuality education and are emphasizing abstinence," said Michele Johnson Moore, who did the research for her doctoral dissertation in health and human performance at UF. "The bad news is, they don't spend much time on, or cover in much detail, some of the other methods of prevention, such as birth control and condoms, or have students practice skills necessary to make healthy, responsible decisions about their sexuality." Using both the state's sexuality guidelines and those put forth by national sexuality professionals, Moore surveyed 261 teachers in 64 of Florida's 67 school districts in 1996 to determine the scope and nature of these programs in the public high schools. The state has required human sexuality education since 1990. In general, the focus in the classroom is on the negative consequences of sexuality, not promoting a healthy perspective on human sexuality, Moore said. Studies show that teen-agers with negative feelings about their sexuality are less likely to protect themselves against pregnancy and sexually transmitted diseases, she said. Florida school programs also lack instruction in life skills, yet research shows that learning to negotiate, be assertive, make decisions and clarify values help students avoid unprotected and unwanted sexual activity, Moore said. School-based programs have been found to go beyond increasing knowledge to actually delaying intercourse, she said. While nearly all teachers surveyed (94 percent) said they felt it was the appropriate role of the school to teach sexuality education, lack of time in the curriculum appeared to be a problem in adequately covering the subject, Moore said. In addition, the average two hours of training per year teachers received probably is not enough to keep abreast of changing information, teaching techniques and skills-building activities, Moore said. There also seems to be a lack of sufficient materials, as more than half the teachers reported creating some or all of their materials for class, she said. "This study is one of only a handful that investigate how sexuality education is really implemented," said Barbara Rienzo, a UF health education professor who supervised Moore's research. "Unfortunately, it shows that it is being carried out in less than an ideal manner. Many people, including our legislators, support sexuality education in our state because they really want to do something to reduce teen pregnancy and sexually transmitted diseases, but teachers lack sufficient time, resources and training to adequately address the problem." The study found that slightly less than two-thirds of teachers (64 percent) included birth control in their curriculum, but some of the methods addressed were not necessarily the most appropriate. Less than half of teachers described or showed proper use of a condom, for example, or addressed student concerns about condom use, possibly because of political reasons or personal discomfort with the topic. On average, only about half the available birth control methods were reviewed, and some of the methods addressed were the least practical, Moore said. "More teachers taught about the intrauterine device, which is not appropriate for adolescents, than the newer technologies of Norplant implants and Depo-Provera injections, which are more desirable for teens because of their high effectiveness rates," she said. "And only half discussed how to communicate with a partner about birth control, which is so important in avoiding sexually transmitted diseases, AIDS and unwanted pregnancies." Research shows that more than half (53 percent) of all high school students have had sexual intercourse, with the average first time happening at just under age 15, Moore said. U.S. teen-agers have the highest rate of sexually transmitted disease among any age group and one of the highest pregnancy rates among Western industrialized countries, she said.
--------
204-> Inactivation Of Key Gene Allows Worms To Develop Without Insulin
Researchers at the Massachusetts General Hospital (MGH) have announced an important new insight into how the lack of insulin causes diabetes.  The research team, led by Gary Ruvkun, PhD, reports in the journal Nature their discovery — based on molecular genetic analysis in the worm C. elegans — of previously unsuspected human genes that may be misregulated or defective in diabetics.  These genes represent new candidates for the underlying cause of diabetes and define novel targets for new diabetes therapies. Two months ago, the Ruvkun lab reported that a gene equivalent to the human insulin receptor gene regulates the metabolism of worms.  The match between the worm and human insulin receptors suggested that the detailed genetic analyses of worm metabolic control could be applied to human metabolic diseases such as diabetes.  In the October 30 issue of Nature, the Ruvkun team announces the first new insight into the mechanism of diabetic disease to emerge from the discovery that worms use an insulin-like signal to control their metabolism. The team — which also includes first author Scott Ogg, PhD, Suzanne Paradis, Shoshanna Gottlieb, PhD, Garth Patterson, PhD, Linda Lee, and Heidi Tissen baum, PhD — discovered that insulin may control metabolism via inactivation of a second gene, daf-16.  The researchers found that, although insulin normally is required to regulate metabolism in the worm C. elegans, as in humans, the animal no longer needs insulin if it also carries a mutation in daf-16.  This gene encodes a DNA-binding protein that passes along insulin signals within the cell to control the production of enzymes that metabolize sugars and fats.  The team proposes that in the absence of insulin, the DAF-16 protein becomes unregulated, and that its runaway activity may be the key cause of metabolic disease in diabetes. In support of this model, the research team shows that metabolic defects in worms with defective insulin signaling are "cured" by the inactivation of the daf-16 gene. Thus C. elegans insulin genetics yield the surprising result that these animals can live quite well without their version of insulin, if they also carry an inactive or less active daf-16 gene.  The team also reports that humans carry two daf-16 equivalent genes that may similarly pass along insulin signals.  Neither of these human genes had been previously suspected to be involved in insulin control of metabolism.  The researchers suggest that these human daf-16 equivalents may be defective in some diabetics and that drugs which inactivate the human daf-16 gene or its product may be therapeutic in diabetes. The Nature paper also shows that another metabolism-regulating hormone, encoded by the gene daf-7, conspires with insulin to regulate C. elegans metabolism and suggests that the human equivalents of the other genes in this parallel signaling pathway may also be defective in diabetics. Another team from the Ruvkun lab — including Patterson, Allison Koweek, Arthur Wong, and Yanxia Liu — published this month a related paper in the journal Genes and Development, reporting that inactivation of another DNA-binding protein, encoded by the gene daf-3, "cures" the metabolic defects caused by lack of the daf-7 hormonal signal.  Ruvkun and his team propose that the DAF-16 and DAF-3 DNA-binding proteins integrate the insulin-like and daf-7 endocrine hormonal signals to control metabolic gene expression in the worm.  They suggest that human equivalents of these genes may define previously unsuspected hormones and signaling pathways that conspire with insulin to control metabolism. The knowledge of the exact identity of these key worm genes that act together with worm insulin could speed discovery of the molecular causes of and therapies for diabetes.  A major effort has been underway to identify human genes that might be the cause of diabetes, but the fact that many genes are involved makes the effort difficult and expensive.  Ruvkun and his colleagues are now beginning to search diabetic patients for mutations in the human genes that are the closest relatives of these worm genes.  "Our discovery that animals do not need insulin signals if they also carry an inactive daf-16 gene was completely unexpected," says Ruvkun, "and points the way for the development of an entirely new class of anti-diabetes drugs that could target human equivalents of these worm genes."  For example, worms that carry the human equivalent of daf-16 could be used to screen for drugs that inactivate the human DAF-16 protein, allowing the animals to grow rather than to arrest in an immature state, as they do when this human protein functions in the worm.  If the researchers' hypothesis is correct, such drugs may treat both type 1 or juvenile-onset diabetes, in which no insulin is produced, and type 2 or adult-onset diabetes, in which insulin responses are abnormal. The Nature paper also suggests that human genes equivalent to the worm gene daf-7 may define an injectable diabetes therapy analogous to insulin.  Ruvkun and his colleagues suggest that, if defects in the production of the human version of daf-7 underlie the lack of insulin response in obese people — who are at increased risk for developing type 2 diabetes — injection of this human hormone could be a diabetes and obesity therapy.  Ruvkun cautions that this theory is unproved in humans and that drug development is a long and complex process. "Although there still are a lot of questions to answer, we believe that our research reveals important new insights into the causes of diabetes and suggests novel avenues for its treatment," Ruvkun says.
--------
205-> HIV Subterfuge Revealed -- Virus Uses Devious Strategy To Undermine Immune System
Researchers at the National Institute of Allergy and Infectious Diseases (NIAID) have discovered a devious strategy used by the human immunodeficiency virus (HIV) to undermine the immunesystem. The scientists found that even when HIV does not enter a cell, proteins in the outer envelope of the virus can bind to a molecule called CCR5 on the cell's surface and initiate a biochemical cascade that sends a signal to the cell's interior.  This signalling process mayactivate the cell, making it more vulnerable to HIV infection.  It alsomay cause cells to migrate to sites of HIV replication, thereby increasing their vulnerability to infection.  If the cell is already infected with HIV, activation may boost its production of the virus. Drew Weissman, M.D., Ph.D., formerly of the NIAID Laboratory of Immunoregulation (LIR) and now an assistant professor at the University of Pennsylvania; Ronald L. Rabin, M.D., of the NIAID Laboratory of Clinical Investigation; Anthony S. Fauci, M.D., NIAID director and LIR chief; and their colleagues report the new findings inthe Oct. 30, 1997 issue of the journal Nature. "These new data add to our understanding of the complex ways HIV causes disease," says Dr. Fauci.  "It is a truly formidable foe with many tricks up its sleeve."  Adds Dr. Weissman,  "Our findings suggest that HIV, even without infecting a cell, canprofoundly influence the  disease process by activating cells andinfluencing their movement and aggregation." HIV generally requires two receptors to enter a target cell: CD4, and either CCR5 or CXCR4, depending on the strain of virus. The strains of HIV most commonly seen early in HIV disease, known as macrophage-tropic (M-tropic) viruses, use CD4 and CCR5 for cellentry.  Many strains of the simian immunodeficiency virus (SIV), acousin of HIV that infects non-human primates such as monkeys, also use these receptors for cellular entry. As described in the Nature report, the researchers found that envelope proteins from four different M-tropic HIV strains and one M-tropic SIV strain induced a signal through CCR5 that caused cells to migrate in culture.  In contrast, envelope proteins from other strains of the viruses, known as T-cell tropic (T-tropic) strains, did not causesignalling. "HIV disease is characterized by persistent immune activation, and envelope protein-mediated signalling through CCR5 may contribute directly or indirectly to this heightened state of activation, with negative consequences for the HIV-infected person," Dr. Faucisays. Not only are HIV replication and spread more efficient in activated cells, but chronic immune activation during HIV disease may result in a massive stimulation of a person's B cells, impairing the ability of these cells to make antibodies against other pathogens. Chronic immune activation also can result in a form of cellular suicideknown as apoptosis, and in the increased production of signallingmolecules called cytokines that can themselves increase HIV replication. Co-authors of Drs. Fauci, Weissman and Rabin include James Arthos, Ph.D., Andrea Rubbert, M.D., Mark Dybul, M.D., Ruth Swofford, Sundararajan Venkatesan, M.D., and Joshua M. Farber, M.D., all of NIAID. NIAID is a component of the National Institutes of Health (NIH).  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, malaria, tuberculosis, asthma and allergies.  NIH is an agency of the U.S. Department of Health and Human Services. ### Reference:  Weissman D, et al.  Macrophage-tropic HIV and SIVenvelope proteins induce a signal through the CCR5 chemokinereceptor.  Nature 1997;389:981-5. Press releases, fact sheets and other NIAID-related materials are available on the Internet via the NIAID home page at http://www.niaid.nih.g 
--------
206-> Battle Dry Skin During The Winter By Following Tips From National Jewish Medical And Research Center
Between cold air, reduced humidity and furnaces, winter is a tough time for skin. But tips from the National Jewish Medical and Research Center can keep skin soft and moist through the worst winter storms. "With the drop in humidity and the cold air, there’s a rise in dry skin throughout the country," explains Noreen Nicol, R.N., M.S., F.N.P., an expert in skin care issues and director of Nursing at National Jewish. Lack of water, not grease or oil, causes dry skin, she says.  "Soaking and sealing" is the best way to keep skin from drying out during the winter or any other time of the year.  Soak skin in water—whether taking a shower or a bath—then immediately seal it with a moisturizer to keep skin soft. "If you’re only going to do one thing after your daily bath or shower, ‘soak and seal,’" Nicol says.  "Put on moisturizer from head to toe." Ask a pharmacist for an over-the-counter ointment-based moisturizer; its texture is similar to petroleum jelly.  If an ointment is too greasy, try a thinner creme or an even more-diluted lotion.  The thinner the moisturizer, the more often it needs to be applied to be effective. People who have dry skin all year round could be facing a different and more substantial skin problem that needs specialized medical treatment.  "If a person has dry skin throughout the year, not just during the winter, and it seems to be associated with allergies, it could be atopic dermatitis," she says.  Atopic dermatitis is a chronic skin disease that primarily affects children; one in every 10 children has atopic dermatitis.  Characterized by red, dry, cracking, itchy skin, this disease can be caused by food allergies, such as egg, peanut, milk and fish, or worsened by irritants, such as detergents, soaps or fabrics. For more information on these topics, call LUNG LINE, (800) 222-LUNG.
--------
207-> New Experiments Show Genes Play Significant Role In Fear
A group of faculty, graduate and undergraduate students at the University of Colorado at Boulder have found new evidence that genes play a key role in individual differences regarding fear-related learning in a study of two genetic strains of mice. Twin studies in humans have provided evidence for a "substantial genetic component" underlying differences in susceptibility to extreme reactions to fear-inducing events, said Jeanne Wehner, a professor at CU-Boulder's Institute for Behavioral Genetics. "Our primary interest is individual differences in learning and memory," she said. "Animal models allow us to map the genes much more quickly and easily." In a series of experiments, the CU researchers exposed two strains of mice to light electroshocks in conjunction with an audible clicking sound. Since the primary fear reaction of mice is to freeze, each rodents' freezing behavior was charted when the animals were later subjected to the clicking sound alone, to the environment in which the sound and shock were administered together, and in an altered physical environment, Wehner said. The researchers identified the genetic links by analyzing genetic similarities and differences between mice exhibiting extreme fear conditioning with mice exhibiting significantly less fear. The strongest link was on a portion of chromosome 1, which may contain hundreds of genes, she said. There also were weaker links to chromosomes 10 and 16. The genetic research has implications for human disorders like post-traumatic stress, assuming researchers can pinpoint analogous genes for fear conditioning in humans, she said. New pharmacological agents developed specifically to target human genes implicated in fear-related disorders could be used in treating a variety of human emotional problems. A paper on the subject by CU-Boulder's Wehner, Richard Radcliffe, Shelby Rosman, Steven Christiansen, Duffy Rassmussen, David Fulker and Michelle Wiles appears in the November 1997 issue of Nature Genetics. The group used 84 DNA markers, unique chemical road signs on each chromosome that allow researchers to track associated genes. CU researchers have begun sequencing the genes in a search for likely candidates. A companion paper in the November issue of Nature Genetics by a group from the State Department of Health in Albany, N.Y., also concluded chromosome 1 was significantly involved in fear conditioning in mice. The same region of chromosome 1 was implicated in a 1995 study by Oxford University's Jonathan Flint and CU-Boulder's John DeFries, David Fulker and Allan Collins. The study focused on emotionality in mice following a series of experiments that exposed mice to brightly lit open areas. In addition, a 1997 study by an international research team led by Howard Gershenfeld of the University of Texas Southwestern Medical Center in Dallas showed similar results. "There are now four separate studies on fear responses in animals that implicate this portion of chromosome 1," said Wehner, whose research is funded by NIH. "The thing we need to do now is get at the gene or genes involved." In 1992, Wehner was part of a national team that identified a gene associated with spatial learning in mice. "We are very interested in complex learning behavior," she said. "In this case we chose the fear-conditioning component for testing as a way to try and understand individual genetic differences in learning."
--------
208-> Duke Lemurs Arrive Safely In Madagascar After Arduous Journey
DURHAM, N.C. -- Five lemurs from the Duke University Primate Center were resting safely in a cage in the depths of a Madagascar rain forest preserve Friday, sampling local foods, after an arduous four-day journey by air, truck and being hand-carried in traveling cases through miles of trackless jungle. The captive-born, black-and-white ruffed lemurs have begun an historic journey, the first of their species ever to be returned to the wild. They are part of a project by the international Madagascar Fauna Group (MFG) to systematically repatriate as many as 20 of the adaptable lemurs to their ancestral island nation over the next three years. The first five lemurs, after being held in an outdoor cage to allow them to acclimate to local foods, will be released about Nov. 10, to join a dwindling population of their wild cousins. The MFG researchers said they hope the lemurs will interbreed with the threatened local population of about 30, enhancing the gene pool of ruffed lemurs in the preserve. Black-and-white ruffed lemurs, known for the fur that frames their faces and the lush coats of black and white fur, are among Madagascar's most endangered. They are regularly hunted for food on the island. The five Duke lemurs -- Janus, Letitia, Praesepe, Sarph and Zuben'ubi -- departed from the Primate Center on Oct. 17 for the 5,000-acre Betampona Natural Reserve in Madagascar. They were accompanied by veterinarian Graham Crawford of the San Francisco Zoo. Charles Welch, the MFG project's director, reported that the air leg of the journey, which included layovers in Atlanta, Paris, the Madagascar capitol Antananrivo, and the city of Tamatave, went well, with the animals readily accepting food and water. In Tamatave, "the lemurs and Graham happily settled in for one night of peace and sleep at our house, after the lemurs were pampered with morsels of their first fresh tropical fruits (mangos, papayas and tiny mandarin oranges)," wrote Welch in an e-mailed report. The next morning the lemurs in their carrying cases and their human companions departed for the Betampona reserve. "It rained and rained," reported Welch. "The drive from Tamatave was slow going on a bad road, lots of mud and deep ruts ... We arrived at the village of Fontsimavo at the end of the road, about 2:30 p.m. There, we were met by project research coordinator Adam Britt, all five of our conservation agents and a bevy of 11 local porters. After everyone in the village had a chance to ogle the lemurs, we all left on foot for the base camp at the edge of the Betampona reserve. "The lemur crates were each tied to the end of a long thick bamboo pole with a proud conservation agent hefting the middle part of the pole on his shoulder. After a slippery 1 1/2 hour walk up in intermittent rain, wading the same river seven times, we arrived at the Rendrirendry base camp. The ruffed lemurs were immediately transferred to the small cage at the camp, where they could stretch their legs, eat and settle down on perches for their second night in the country of their ancestors." The next morning, the lemurs were examined by Crawford and fitted with radio collars, Welch wrote. "After the exam and radio collar fitting, each animal was put back into his travel crate, again attached to bamboo poles, and carried another 1 1/2 kilometers into the reserve where they were released into the recently completed habituation cage," Welch wrote. "In the forest cage, the lemurs are being fed bananas, mangos, pineapple and monkey chow, but will get increasing amounts of native forest fruits in the days to come, as the chow and cultivated fruits are gradually reduced. "Their appetites are good. Two keepers from Zoo Ivoloina are camped out next to the cage (rather miserably right now, with all of the rain, mud and leeches), and a rotation of Ivoloina keepers will have lemur duty on through until the release to assure security and full-time care and observations of the lemurs. "Already in the first day, the lemurs are feeding on wild "Romendafa" fruits, so we're optimistic that they will readily adapt to wild foods," Welch wrote. "Careful records are being kept of all food offered and eaten, and the animals will be weighed when they're examined again in a week," he wrote. Primary collaborators in the Betampona restocking project include some of the MFG's key member organizations: the Duke Primate Center, Philadelphia Zoo and Roger Williams Park Zoo in the United States; and the Jersey Wildlife Preservation Trust, Marwell Preservation Trust and Zoological Society of London in Great Britain. The American Zoo and Aquarium Association also support the project. Madagascar collaborators include the National Association for the Management of Protected Areas, the Malagasy Department of Water and Forests, the University of Madagascar and Parc Ivoloina. The total budget for the first three-year phase will be $300,000. Almost half that money is already in hand due to fund-raising efforts -- principally by the Jersey-London-Marwell group, which has raised $120,000. In one notable example, actor-producer John Cleese donated the proceeds from the London premier of his comedy film Fierce Creatures, which featured captive lemurs in addition to its human cast. Other MFG members include: Aktiengesellschaft Zoologischer in Koln, Germany; Baltimore Zoo; Brookfield (Ill.) Zoo; Cincinnati Zoo; Colchester Zoo in Essex, England; Columbus (Ohio) Zoo; Denver Zoo; Fort Worth (Tex.) Zoo; Institut d'Embryologie, Strasbourg, France; Institute for the Conservation of Tropical Environments in Stony Brook, N.Y.; Knoxville (Tenn.) Zoo; Los Angeles Zoo; Micke Grove Zoo in Lodi, Calif.; Oklahoma City Zoo; Orgrod Zoologiczny Poznon in Poland; Parc Zoologique et Botanique Mulhouse in France; Point Defiance Zoo in Tacoma, Wash.; San Antonio Zoo; San Francisco Zoo; St. Louis Zoo; Transvaal Snake Park in South Africa; Wildlife Conservation Society in Bronx, N.Y.; Zoo Atlanta; Zoological Garden Zurich in Switzerland; and Zoologischer Garten der Landes in Saarbrucken, Germany. The Duke Primate Center, located in an isolated off-campus forest, is now home to 16 different endangered lemur species, as well as six other "prosimian" (pre-monkey) species such as lorises and bushbabies. The center is supported by the National Science Foundation, Duke University and private donations.
--------
209-> Study Shows How Chemotherapy Causes Female Infertility
A  research team based at the Massachusetts General Hospital (MGH) has discovered, for the first time, the molecular pathways involved in the destruction of oocytes or egg cells by a common chemotherapy drug.  The discovery eventually could lead to strategies for preserving fertility in girls and women treated with anti-cancer drugs. In the study in the November Nature Medicine, the team from the MGH and the Howard Hughes Medical Institute at Washington University School of Medicine in St. Louis describes its finding that treatment with the anti-cancer drug doxorubicin (DXR) causes mouse oocytes or egg cells to undergo apoptosis or programmed cell death.  Apoptosis is a natural process that usually involves the elimination of unneeded or worn-out cells from the body.  The researchers also confirmed the involvement of several participants in a known cell-death pathway in the DXR-associated death of oocytes and discovered that another common pathway for the destruction of tumor cells is not involved in oocyte death. "It's been known for years that women treated with chemotherapy become infertile, but we've never known what the mechanisms were," says Jonathan Tilly, PhD, associate director of the MGH Vincent Center for Reproductive Biology, the paper's senior author.  "While this research is a long way from clinical application, we hope it will lead us to ways of selectively short-circuiting the cell-death pathway in ovarian cells." In the first stage of the project the researchers exposed mouse oocytes to doses of DXR equivalent to levels seen in the blood of patients treated with this drug.  They observed changes in the cells characteristic of apoptosis, such as shrinkage and fragmentation.  In contrast, fertilized mouse oocytes exposed to DXR reacted differently, by halting the process involved in the growth and reproduction of cells. The process of cell death is known to involve the sequential activity of several genes and their protein products in a cascade eventually leading to the cell's destruction.  The researchers looked at several of these known molecular signals for apoptosis and found several indications of their activity in DXR-induced death of oocytes. One of the signals initiating the cell-death process involves the molecule ceramide, and the team found that use of a substance known to inhibit ceramide signaling prevented the death of oocytes exposed to DXR.  They also found that eggs from mice with a mutation in a cell-death-promoting gene called bax (part of a key group called the bcl-2 gene family) were almost completely resistant to DXR-induced apoptosis.  Inhibition of the activity of proteins called caspases, which function as cellular executioners by snipping apart other proteins, also inhibited apoptosis in DXR-treated oocytes. All three of these signals — ceramide, Bax and caspases — are involved in the same pathway leading to cell death. "I often describe it as though the cell is traveling along a network of roads that can lead either to cell death or to cell survival, which in the case of oocytes would mean continued fertility," says Tilly.  "The signals early in the process, such as ceramide, are like neighborhood streets along which the cell travels slowly and has a lot of ways to get off the cell-death route.  When it reaches the 'Bax boulevard,' it's traveling faster, and by the time a cell reaches the 'ICE interstate' [ICE is a specific caspase protein] there are very few 'off ramps' that would prevent it from reaching the point of apoptosis.  While we want to speed cancer cells along this route, we'd like to provide the oocytes with a detour to survival." The cell-death process also can be initiated by the activity of p53, a key tumor-suppressor protein. The researchers found, however, that oocytes from mice with a disruption in the gene for p53 responded normally to DXR treatment by undergoing apoptosis, indicating that p53 is not part of the pathway leading to DXR-induced apoptosis in these cells.  This finding suggests that anti-cancer drugs that depend on the activity of p53 might successfully destroy tumor cells without damaging oocytes. Improved understanding of chemotherapy-induced oocyte death also could lead to new knowledge about the normal death of these cells that occurs throughout a woman's life — starting before birth and eventually leading to menopause when the supply of eggs is finally depleted. Tilly's coauthors include Gloria Perez, DVM, PhD, first author, and Lucy Leykin, PhD, of the MGH, and Michael Knudson, MD, PhD, and Stanley Korsmeyer, MD, at Howard Hughes/Washington University.
--------
210-> University Of Maryland Researchers Report On Genetics Of Asthma, Adult-Onset Diabetes, Lethal Dwarfism, And Cardiovascular Disease
University Of Maryland Research, 47th Annual Meeting, American Society Of Human Genetics GENETICS OF ASTHMA At least two genes control bronchial hyper-responsiveness, a major characteristic of asthma, genetics researchers at the University of Maryland School of Medicine report. In a study of 123 Dutch families, Eugene Bleecker, MD, and Deborah Meyers, PhD, codirectors of the UM Center for the Genetics of Asthma and Complex Diseases, Jianfeng Xu, MD, DrPh, assistant professor of medicine at the UM medical school, and colleagues at University Hospital Groningen in The Netherlands, found one major locus and another modifier locus. The two genes account for 74.3 percent of the bronchial hyper-responsiveness in the Dutch families studied. The Maryland researchers will present a poster on their work on Wednesday, October 29 at the American Society of Human Genetics annual meeting in Baltimore. AMISH STUDY HELPS IDENTIFY GENES FOR ADULT-ONSET DIABETES Studies of 950 Amish volunteers from the Lancaster, Pennsylvania, area may help researchers at the University of Maryland School of Medicine identify the regions on chromosomes and specific disease-related genes for adult-onset diabetes. Alan Shuldiner, MD, head of the Division of Diabetes, Obesity and Nutrition at the Baltimore medical school, has been traveling the Amish countryside for the past five years, taking blood samples to test for diabetes and cholesterol. DNA from the blood is used to perform more than 400 different genetic tests on each sample.  	   Shuldiner treats study subjects diagnosed with diabetes, providing blood-glucose monitors and instruction on monitoring their blood-glucose levels at home, as well as information on proper diet and exercise.  	   He will report on the research, funded by Glaxo Wellcome Inc. and Sequana Therapeutics Inc., on Thursday, October 30, at the American Society of Human Genetics annual meeting in Baltimore. MUTATION LINKED TO CARDIOVASCULAR, KIDNEY DISEASE A genetic mechanism that may play a role in cardiovascular and kidney disease has been identified by University of Maryland School of Medicine genetics researcher Rong-Fong Shen, PhD, and colleagues. They will present a poster on their findings at the American Society of Human Genetics annual meeting in Baltimore on Saturday, November 1. Shen and his associates, S.J. Baek, K-D Lee and T. Fleisher, sequenced the gene for human thromboxane synthase, an enzyme that produces thromboxane A2—a compound that acts as a vasoconstrictor and induces platelet aggregation. They found two repetitive sequences that significantly suppressed the expression of the gene, said Shen.  A mutation in one of those regions could be a factor leading to overexpression of the thromboxane A2-producing enzyme, which in turn could result in the development of cardiovascular and kidney diseases due to excessive amounts of thromboxane A2. Shen is a research associate professor of human genetics and a researcher in the UM Center for the Genetics of Asthma and Complex Diseases.  He is an American Heart Association-Genentech special Awardee in Thrombosis. ULTRASOUND CAN DIAGNOSE LETHAL DWARFISMS IN FETUSES Ultrasound tests are a reliable way to diagnose rare but lethal genetic dwarfisms prenatally, University of Maryland School of Medicine genetics researchers say. In a study of 27 cases at the University of Maryland Medical Center,  Eric Wulfsberg, MD, and colleagues succeeded in diagnosing 93 percent of cases of lethal skeletal dysplasias, a rare group of genetic disorders that cause lethal dwarfism. The success rate was nearly double that of studies done 10 to 15 years ago, in which ultrasonography during pregnancy identified fewer than 50 percent of cases. The tests were much less helpful in making a specific diagnosis, which must be done in order to determine the risk of recurrence of the genetic defect. "This has not changed much over time and shows a continuing need for clinical geneticists and radiologists to make post-natal diagnoses to make recurrence risk counseling possible," said Wulfsberg, associate professor and head of clinical genetics at the University of Maryland School of Medicine. 	  Wulfsberg and colleagues will present their findings on Saturday, November 1, at the American Society of Human Genetics annual meeting in Baltimo  MUTATION LINKED TO CARDIOVASCULAR, KIDNEY DISEASE A genetic mechanism that may play a role in cardiovascular and kidney disease has been identified by University of Maryland School of Medicine genetics researcher Rong-Fong Shen, PhD, and colleagues. They will present a poster on their findings at the American Society of Human Genetics annual meeting in Baltimore on Saturday, November 1. Shen and his associates, S.J. Baek, K-D Lee and T. Fleisher, sequenced the gene for human thromboxane synthase, an enzyme that produces thromboxane A2—a compound that acts as a vasoconstrictor and induces platelet aggregation. They found two repetitive sequences that significantly suppressed the expression of the gene, said Shen.  A mutation in one of those regions could be a factor leading to overexpression of the thromboxane A2-producing enzyme, which in turn could result in the development of cardiovascular and kidney diseases due to excessive amounts of thromboxane A2. Shen is a research associate professor of human genetics and a researcher in the UM Center for the Genetics of Asthma and Complex Diseases.  He is an American Heart Association-Genentech special Awardee in Thrombosis. ULTRASOUND CAN DIAGNOSE LETHAL DWARFISMS IN FETUSES Ultrasound tests are a reliable way to diagnose rare but lethal genetic dwarfisms prenatally, University of Maryland School of Medicine genetics researchers say. In a study of 27 cases at the University of Maryland Medical Center,  Eric Wulfsberg, MD, and colleagues succeeded in diagnosing 93 percent of cases of lethal skeletal dysplasias, a rare group of genetic disorders that cause lethal dwarfism. The success rate was nearly double that of studies done 10 to 15 years ago, in which ultrasonography during pregnancy identified fewer than 50 percent of cases. The tests were much less helpful in making a specific diagnosis, which must be done in order to determine the risk of recurrence of the genetic defect. "This has not changed much over time and shows a continuing need for clinical geneticists and radiologists to make post-natal diagnoses to make recurrence risk counseling possible," said Wulfsberg, associate professor and head of clinical genetics at the University of Maryland School of Medicine. 	  Wulfsberg and colleagues will present their findings on Saturday, November 1, at the American Society of Human Genetics annual meeting in Baltimore.
--------
211-> Study Advances Development Of Gene Therapy For Chronic Granulomatous Disease
Gene therapy in patients with chronic granulomatous disease (CGD) can result in prolonged production of genetically corrected cells, a study by scientists at the National Institute of Allergy and Infectious Diseases (NIAID) has found.  A hopeful advance in thetreatment of this rare immunologic disorder, the finding is reported in the Oct. 28, 1997 issue of the Proceedings of the National Academy of Sciences (PNAS). "This is encouraging news for people born with CGD," says NIAID Director Anthony S. Fauci, M.D.  "While other therapeutic advances have improved the prognosis for CGD patients in recentyears, the development of effective gene therapy would represent a big step forward." One of more than 70 different inherited disorders known collectively as primary immune deficiencies, CGD is caused by a defect in an enzyme called phagocyte NADPH oxidase, or phox.  White blood cells use this enzyme to generate hydrogen peroxide, which the cells need to kill bacteria and fungi.  Mutations in one of four different genes can cause this defect, which leads to frequent and often life-threatening infections of the skin, lungs and bones with localized, swollen collections of inflamed tissue called granulomas. Approximately four to five of every million people worldwide have CGD, including about 1,000 people in the United States. In the study reported in PNAS, researchers led by Harry L. Malech, M.D., deputy chief of NIAID's Laboratory of Host Defenses(LHD), removed stem cells, the ancestral immune cells that give riseto white blood cells, from five people with CGD.  The researchersinserted the correct form of the phox gene into the stem cells and then transfused the corrected cells back into each patient.  Dr. Malech and his colleagues sampled the patients' blood at regular intervals to see if the stem cells were producing white blood cells with functional phox genes. "We detected phox activity in white blood cells from each patient for an average of three months after the gene-corrected stem cells were transfused," explains Dr. Malech.  "In one patient, phox activity was still present six months after transfusion.  On average, the corrected phox gene was present in one out of every 5,000 cells. While the numbers of gene-corrected cells were small, the study demonstrates unequivocally that gene therapy of stem cells can produce functionally normal blood cells in patients for a prolongedperiod." The finding could have important clinical implications for the treatment of CGD.  "Since life-threatening infections caused by CGD may require many weeks or months of therapy and relapses are frequent, use of gene therapy to provide even short- to medium-term production of phox-positive cells may be clinically beneficial," says Dr. Malech. Studies suggest that people having 3 to 5 percent phox-positive cells in their blood might be protected from infectionsassociated with CGD, he notes.  Although those levels are at least150-fold higher than levels attained in the current study, Dr. Malech predicts that they might be achieved within the next five to 10 years. "Until the tools are developed to achieve higher levels ofpermanent gene transfer to stem cells, our studies suggest that anachievable intermediate goal of gene therapy for CGD might be to augment white blood cell function in the treatment of severe infections," says Dr. Malech. In addition to advancing the development of gene-basedtherapy for CGD, Dr. Malech notes that some of the techniques used in this study could have broad application in gene therapy protocols for other diseases.  Designed to enhance the safety of gene therapy procedures involving stem cells, these techniques included the use of cell culture media containing no non-human proteins and a closed system of gas-permeable flexible plastic containers for culture andgene transfer. Animal proteins are widely used in most cell culture media. However, animal proteins taken up by human cells during prolonged culture can stimulate an immune response when the cells are transfused back into a patient undergoing gene therapy. The closed system of flexible plastic containers, similar to those used in blood banks, reduces the contamination risk associated with procedures where cells and culture media are transferred among flasks. "To our knowledge, this is the first human gene therapy trial targeting stem cells in which animal proteins were eliminated and stem cells were grown in sealed gas-permeable flexible plasticcontainers," says Dr. Malech.  "We showed that it is possible to incorporate these safety features without compromising stem cell viability or gene transfer efficiency." In addition to Dr. Malech, investigators involved in the study included John I. Gallin, M.D., chief of LHD and director of the National Institutes of Health (NIH) Clinical Center; other LHD and ClinicalCenter staff; as well as investigators at Baxter Healthcare, Inc., whocontributed stem cell technology, and Cell Genesys, Inc., whocontributed gene transfer technology. NIAID, a component of the National Institutes of Health (NIH), supports research on AIDS, malaria, tuberculosis and other infectious diseases, as well as allergies and immunology.  NIH is an agency of the U.S. Department of Health and Human Services. ### Reference:  Malech HL, Maples PB, Whiting-Theobald N, Linton GF,Sekhsaria S, Vowells SJ, Li F, Miller JA, DeCarlo E, Holland SM, Leitman SF, Carter CS, Butz RE, Read EJ, Fleisher TA, Schneiderman RD, Van Epps DE, Spratt SK, Maack CA, RokovichJA, Cohen LK, Gallin JI.  Prolonged production of NADPH oxidase-corrected granulocytes after gene therapy of chronic granulomatousdisease.  PNAS 1997;94:12133-8. Press releases, fact sheets and other NIAID-related materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov.
--------
212-> Shifting Weights May Improve Orbits Of Satellites, Accuracy Of Reentry Vehicles
 ALBUQUERQUE, N.M. -- A missile or space ship, spinning like a football or Olympic diver as it reenters Earth's atmosphere, ordinarily is designed to be perfectly balanced -- with tight control over the distribution of mass within it -- to avoid flight instabilities. Unguided weapons in particular need accurate preflight balancing if they are to come close to their intended targets. But, going against this tradition, rocket scientists at Sandia National Laboratories -- a US Department of Energy facility --have devised a method that purposefully unbalances the reentry vehicle to steer it closer to a target. The approach also could reorient a satellite in space. The unorthodox method is relatively cheap, easy to install, does not change the external shape of the vehicle, and requires neither jets nor fuel. Called the moving-mass trim-control system, the method achieves its effect simply by controlling the movement of two internal weights that rotate on a metal ring secured within the reentry vehicle. The positions of the weights will be determined by an onboard computer chip equipped to receive input signals from the omnipresent Global Positioning Satellite system. A guidance algorithm, fed precise data on the location of the vehicle, will alter the locations of the weights to create the trajectory needed to come down on target or to achieve a more effective orbit. Like a shifting load in an 18-wheeler truck Shifting weights alter the direction of a vehicle in a manner similar to that unintentionally achieved when unsecured cargo shifts in the van of an 18-wheeler, taking the truck in a new direction. In the case of the Sandia design, the control system must ensure that the motion of the shifted mass does not cause the reentry vehicle to become unstable. The design improves upon an earlier Sandia idea recently flight-tested in a Navy-sponsored joint Sandia/Lockheed-Martin project. In this earlier version, the moving weights were mounted to an extension of the vehicle, which changed its aerodynamic behavior. The newer design, intended for retrofit within existing vehicles, is smaller, requires less power to operate, and does not require new computations of the host vehicle?s flight capabilities. The research is funded internally by the Laboratory Directed Research and Development program, which funds speculative, defense-related research. Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national security, energy, environmental technologies, and economic competitiveness.
--------
213-> Apiculture Research Will Save Honeybee And Pollination Industries, Cornell Entomologists Predict
ITHACA, N.Y. -- Despite dramatic losses in wild honeybees and in coloniesmaintained by hobbyist beekeepers, Cornell University apiculturists say thepollination needs of commercial agriculture in the United States are beingmet -- for now -- by commercial beekeepers, although their supplies areprecarious. "Parasitic mite and mite-related diseases have caused the death of mostwild honeybees, and left the commercial colonies at tremendous risk," saidNicholas W. Calderone, head of the university's Dyce Laboratory for HoneyBee Studies and an assistant professor of entomology in the College ofAgriculture and Life Sciences at Cornell.  Calling the Varroa mite "thegreatest threat to beekeeping," Calderone said beekeepers have only oneregistered chemical (Apistan) to control Varroa mites, "and European miteshave already become resistant to that chemical, so we must assume the samething will happen in the U.S." Roger A. Morse, the recently retired Cornell professor of apiculture whotracked the mites and diseases for 25 years, concurs.  "The mites representthe greatest threat to beekeeping since European bees were brought to thiscontinent more than three centuries ago," Morse said.  "But if we can getthe results of research to the beekeepers, we can keep the crops growingand the honey flowing. "It's true that these mite diseases have caused the death of 95 to 98percent of the wild honeybee colonies.  And more than half the hobbybeekeepers have lost all or most of their colonies," Morse reported."However, commercial beekeepers in this country are surviving, though they,too, have had serious losses.  Research on the biology and control of beediseases is making it possible for the industry to cope and provide the 1.2million colonies needed for the pollination of crops we eat." Some 90 different crops -- ranging from apples to zucchini and cantaloupesto cucumbers -- depend on honeybee pollination.  To some extent, otherinsects will pollinate specific crops.  However, no insect is as widelyeffective as the honeybee, and with the disease losses among wild andhobbyist honeybees, the commercial honeybees are more important than ever,Morse observed.  The value added by honeybee pollination to Americanagriculture is estimated to range from $5 billion to $20 billion a year, hesaid. Crop pollination is a migratory enterprise, with honeybees followingseasonal crops -- week by week -- as trees and other plants bloom.  Manycommercial beekeepers' bees winter in Florida and travel on trucks thathold up to 500 colonies and 10 million to 15 million pollinators.Commercial beekeepers place their colonies near crops that need pollinatingand charge growers for the service.  Migratory beekeepers also sell thehoney and other bee products that result, but fees for pollination servicesare their main source of income. "We need to sustain a significant research effort to protect the safe andaffordable supply of fruits and vegetables to which people have becomeaccustomed," Calderone said.  "Mites are living organisms, and mitepopulations will eventually adapt to whatever control measures we develop.It is an ongoing struggle that can never be completely won." So research efforts at Cornell and other institutions are focusing on thebiology of the Varroa mite, trying to understand how it locates bees in thefirst place.  "If we can determine the host-location mechanism and discoverthe physical and chemical cues the mites use, we may be able to manipulatethose cues for a control mechanism that will protect the bees," Calderonesaid.  A number of natural products, including essential oils from herbsand spices, also are being examined for their potential in mite control, headded. But a genetic solution -- breeding bees that are resistant to mites -- willbe much more difficult, Calderone predicted.  Even if beekeepers start withdisease-resistant stock, it is almost impossible to control mating (withnon-resistant males) when new queens leave the colonies, he explained."Commercially viable, disease-resistant stock is the best answer, but thatis years away, at best," Calderone said.  'Nonetheless, it remains thelong-term focus of several research programs around the country." Meanwhile, commercial beekeepers are surviving by applying good managementtechniques in their craft, Morse said.  Dead colonies are replaced whenbeekeepers "split" their  surviving colonies each year to maintain thestock needed for pollination. "Growers who rent bees are well aware of the problems and are making planswith beekeepers for the colonies they will need for next spring'spollination," Morse said.  "At the same time, there continues to be a greatinterest in hobby beekeeping, and hobbyists also are learning to cope withmites and diseases by tapping into resources like Cornell's apicultureextension program."
--------
214-> Brazil Establishes World's Largest Rainforest Reserve
AMAZONAS, BRAZIL -- The Government of the Brazilian State of Amazonas has created a new reserve in the Amazon, thus establishing the world's largest contiguous block of protected rainforest, the Wildlife Conservation Society (WCS), headquartered at the Bronx Zoo, announced today (Oct. 27). Called the Amaña Sustainable Development Reserve, it is the third of a network of protected areas in the Central Amazon Basin that together, comprise over 22,000 square miles of unbroken habitat -- an area larger than Costa Rica. The reserve will be managed under a legal category in Brazil created in 1996 at the adjacent Mamirauá Reserve, which permits residence in protected areas and encourages local participation in their conservation. The Amaña region is known for its spectacular and untouched biodiversity including endangered Amazonian manatees, black caiman, river dolphins, anacondas, jaguars, black uakari monkeys, harpy eagles, and a wealth of plants and aquatic life. Dr. José Márcio Ayres, senior conservation zoologist with the Wildlife Conservation Society, designed and wrote the reserve's management scheme. "The creation of the Amaña Reserve is one of the most important measures taken in the Brazilian Amazon in the past decade. It establishes a new vision in conservation in the region, where rainforest corridors will protect not only species but entire evolutionary and ecological processes. It also preserves the unique biodiversity of the Amazon's black and white river systems. In addition, this solidifies the formation of the Central Amazonian Corridor that will protect Amazonian flooded and dryland forests," said Ayres.
--------
215-> Right Side Of Brain Does The Work For Worriers
Researchers at Johns Hopkins think they have identified sites in the brain where "worrying" takes place.   Using brain scans that measure blood flow variations, the scientists concluded that several structures on the right side are the site of anxious thoughts. For the study, presented at the annual meeting of the Society for Neuroscience, 10 volunteers made short tapes describing their worries: recent family crises, stress in the workplace, financial problems, or other troubles.  After volunteers listened to the same tapes, their brains were immediately scanned with a technique called functional positron emission tomography (PET), which detects differences in blood flow, an indicator of brain activity.	        Subjects also were scanned after listening to "neutral" tapes about flower auctions and flower arrangements. "We subtracted the scans to find the difference, and it was clear that several areas on the right became more active during worrying," says Rudolf Hoehn-Saric, M.D., director of the anxiety disorders unit at Johns Hopkins. "We saw an increase in the right frontal lobe, the planning and decision-making part of the brain, and in other areas on the right that are involved in arousal, self-examination and processing of new inputs," says Hoehn-Saric.  The other areas  included the basal ganglia, which coordinate and process messages from various parts of the brain; the cerebellum, whose functions include storing "routines"--frequently used patterns of thought or movements; and the pontine nuclei, which regulate arousal. The new finding makes sense in light of historic evidence that the left side of the brain is involved in analytical thinking and the right in emotional, according to Hoehn-Saric. "Worrying occurs when no easy solution is available, and the solution is often derived emotionally rather than rationally," he notes. Scientists plan to follow up with studies of patients with anxiety disorders, psychiatric conditions that disable them with overwhelming concern about a particular aspect of their lives, such as cleanliness or their physical surroundings.  Comparisons of the two studies could help scientists find anxiety disorders' origins in the brain. Other authors on the study were Thomas Zeffiro, Daniel McLeod, Fuji Yokoi, Sally Symanski, Godfrey Pearlson, and Dean Foster Wong.  This research was funded by the National Institutes of Health.
--------
216-> University of Florida Researchers Report Nerve Tissue Transplant Recipient Is Stable
By Melanie Fridl Ross GAINESVILLE, Fla.---University of Florida researchers, the nation's first to perform an experimental nerve tissue transplant to slow the progression of spinal cord damage in humans, report the condition of a 43-year-old North Florida man has not worsened since the procedure. The man received the transplant July 11 at Shands at UF. UF physicians announced the results Saturday (10/25) at the National Neurotrauma Symposium, held in New Orleans in conjunction with the annual Society for Neuroscience meeting. Last Wednesday (10/22), they discharged a second patient, a 50-year-old Central Florida man paralyzed after a motorcycle accident. The man, who underwent the procedure  Oct. 10, will continue to recuperate in a rehabilitation hospital. The experimental treatment involved injecting small pieces of human embryonic spinal cord cells directly into an expanding cavity -- also known as a cyst -- that sometimes forms at the site of a specific type of spinal cord injury. The condition can cause unbearable pain and progressive loss of sensation and movement. UF neurosurgeon Richard Fessler and his colleagues at the UF Brain Institute performed the procedures to test the safety and feasibility of the grafts, which in landmark laboratory studies have helped injured cats regain some use of their paralyzed limbs. Researchers say the test is an important first step in developing a future treatment that can restore at least partial use of limbs or organs left paralyzed by a crushing spinal cord injury. "This is very early in our evaluation stage," said Fessler, who performed the transplants. "Our first patient's cyst was very complicated; it was walled off into many small compartments. The areas in which we did not transplant look the same, but the areas in which we did transplant, the cyst did not recur, so we're very encouraged by that." Magnetic resonance imaging scans show that so far the cavity has not reopened or refilled with fluid in the regions where the tissue transplant was placed, said Dr. Ed Wirth, a research assistant professor in UF's department of neuroscience. "Even so, we feel it will take at least six months to a year to say for certain whether the transplant has successfully prevented the cavity from refilling and re-expanding," he said. The second patient's surgery was uneventful, Fessler said. "He's recovered very rapidly and is doing very well," he said. Eight more paralyzed volunteers will undergo the procedure as part of a four-year pilot study at UF. The transplant recipients' identities were not disclosed to protect their privacy. Only patients who have a chronic disorder called syringomyelia, characterized by expansion of a fluid-containing cavity within the damaged spinal cord, are considered for the transplant. Study participants receive the tissue grafts while undergoing standard surgery, which exposes the spinal cord and drains the fluid-filled cavity through a tube. The spinal shunts, or tubes, often do not permanently halt the cavity's expansion and many patients undergo the treatment repeatedly. The tissue was obtained from aborted tissue, 6 to 9 weeks old, which otherwise would have been discarded. Researchers said they used such tissue because of its exceptional ability to grow and fill lesion cavities, and because it develops into all of the cell types normally seen in the adult spinal cord. The tissue was obtained from health-care facilities not affiliated with the university. Doctors will continue to assess the patients' progress every few months, using a battery of tests to rate motor function and sensation, the ability of the spinal cord to transmit information, and level of pain. ----------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.h 
--------
217-> Network Of Underwater Sensors To Measure Dangerous Tsunamis In Real Time
ITHACA, N.Y. -- The sea may soon concede more of its seismic secrets. In last week's journal Science, university researchers report that a network of instruments will soon be deployed and placed on the ocean floor, giving humanity a precious tool to predict and track tsunamis in real time. Tsunamis -- giant seismic sea waves, sometimes as high as a five-story building -- can crash against coastal communities, kill thousands of people instantly and devastate property. They are produced by undersea earthquakes, or landslides or volcanic eruptions. "From locations all around the Pacific, we cannot now predict what kind of tsunamis form, where they are from, and how to accurately gauge their magnitude," said Philip L.F. Liu, Cornell professor of civil and environmental engineering. "With a new array of instruments, we can start to research tsunamis and perhaps we'll be able to save lives." Liu explained that tsunamis travel at speeds close to 600 miles an hour in the open ocean and at 100 miles an hour closer to the shore, and they are still difficult to predict. Thus, last spring, scientists gathered at the Natural Hazards Mitigation Program workshop, in Santa Monica, Calif., sponsored by the National Science Foundation, and formulated objectives to study tsunamis. The report from the workshop, "Tsunamigenic sea-floor deformations," appears in the journal Science (Oct. 24, 1997). It was prepared by Liu; Costas Synolakis, of the University of Southern California; George Carrier, of Harvard University; and Harry Yeh, of the University of Washington. One initiative of the workshop, now being reported, is that bottom-pressure recorders (BPR's) and seismic instrument arrays for real-time monitoring of tsunamic development will be deployed by next year. The instruments will be placed by the National Oceanic and Atmospheric Administration (NOAA) in strategic parts of the Pacific rim, such as south of the Aleutian Islands chain and along coastal areas of Asia. Another initiative from the workshop was to study sea-floor deformation characteristics, obtained from seismic data, during undersea earthquakes that turn into tsunamis. Liu explained that these natural, hydrologic terrors have devastated many parts of the world. The 1960 tsunami, resulting from an undersea earthquake near Chile, killed 5,000 people, and the tsunami traveled at airplane-like speed through the water to the Hawaiian island chain, where it killed 61 people and caused millions of dollars in property damage. After striking Hawaii, the tsunami continued nine more hours, finally striking Japan and killing 150 people. The tsunamis do not occur after every oceanic earthquake, said Liu. For example, if the sea floor shakes from side-to-side, then the effect on tsunami will be minimal. But, if there is an up-and-down motion, a tsunami develops. Liu said seismologists now detect several minor tsunamis annually.
--------
218-> Cocaine Studies Reveal New Medications For Addiction; How Brain Regulates Hunger
NEW ORLEANS--Researchers at the Yerkes Primate Center of Emory University have synthesized a compound that shows promise as a medication for people addicted to cocaine and amphetamines. Currently there is no treatment to help the millions of Americans who abuse these drugs. In related cocaine studies, the scientists also discovered that food intake in animals is controlled at least in part by a new group of neuropeptides, which may be useful in developing treatments for eating disorders such as obesity and anorexia. These and other studies by Yerkes scientists describing the neural pathways involved in cocaine addiction were presented this week at the annual meeting of the Society for Neuroscience in New Orleans. New Addiction Medication A new chemical candidate for treating cocaine addiction, called RTI-113, is similar in structure to cocaine. It is one of a new class of compounds called phenyltropanes, which alter the same neuronal systems targeted by cocaine and related drugs, but are thought to have a lower abuse liability and minimal side effects and toxicity. Once in the brain, RTI-113 selects and binds successfully to the same dopamine transporters that cocaine targets. It is potent, yet it enters the brain more slowly than cocaine. Most addicting drugs have a rapid entry to the brain, accounting for the "rush" felt by users. RTI-113 is also long-lasting, which facilitates an easy dosing schedule in a treatment setting. In monkeys, RTI-113 substitutes completely for cocaine, resulting in a reduction in the monkeys' cocaine self-administration, which is the best model of drug-seeking and drug-taking behavior in humans. In people, the medication would be taken orally to relieve craving for cocaine, and thus help manage the urge for "out-of-control," illegal, and destructive drug-seeking behaviors. "This type of therapy is a critical first step in getting an addict off cocaine and into a treatment and social support program," says Mike Kuhar, Ph.D., Chief of the Neuroscience Division at Yerkes. "It is not a cure, but a major step in reducing drug use and its enormous cost to society, in terms of physical and mental health, crime, and safety." The goal, he says, is to develop a medication that can be controlled and dispensed by a treatment center physician, and will act as a safe stepping stone in the process of withdrawal. It would provide the addict and the treatment-center staff the control needed to set in place a detoxification program. Many addicts leave treatment because of the persistent, demoralizing urge to find drugs. "A medication to break this cycle is essential," says Kuhar. Dr. Kuhar and his colleagues, particularly Dr. Ivy Carroll, a medicinal chemist, began synthesizing phenyltropanes 10 years ago. From nearly 500 compounds, they have narrowed the field to about 25 candidates for further testing. Because compounds cannot be tested in humans unless they are proven likely to be safe and effective, rat or monkey models are used. In the self-administration model, an animal is given the opportunity to obtain an injection of a drug by pressing a lever. If the animal likes the drug, it will press the lever again and again. However, the animals are permitted access to the drug only in very short intervals to avoid toxic effects and are closely monitored. Cocaine Studies Help Explain How Brain Regulates Hunger Studies on the effects of cocaine in the brain led to the discovery by Yerkes neuroscientists that feeding behavior and perhaps satiety is controlled at least in part by a novel group of naturally occurring brain peptides. Specifically, the peptides inhibit food intake in animals, and thus may be useful in developing medications to help treat obesity, bulimia and anorexia nervosa----serious, yet common illnesses that can be life-threatening and are often at the root of various other health problems, such as diabetes and cardiovascular disease. The brain peptides are made from an mRNA transcript named CART, for Cocaine and Amphetamine Regulated Transcript. CART was found by examining changes in the brain following cocaine or amphetamine administration. Neuroscientist Pastor Couceyro was one of the first to notice that CART mRNA increased with cocaine administration. Because they knew that behaviorally, cocaine use reduces food intake, the Yerkes team tested CART to see if it might be the agent responsible for the loss of appetite. "When we injected the CART peptide into the brains of rats, their food intake was significantly inhibited----by as much as 30 percent," explains Dr. Phil Lambert, who handled the behavioral aspect of the work. Similarly, when they blocked the brain's naturally-occurring CART peptides (by injecting antibodies which bind the to the peptides) the rats' feeding increased. "This antibody data is what makes us think CART is responsible in part for making you feel sated-----whether it's after eating, or after cocaine use," explains Dr. Lambert. When Yerkes scientists examined the location of CART peptides in the brain, they were in fact present in high levels in regions known to be involved in control of food intake. The next steps are to identify the precise structure of the CART peptides and to further explore their role in managing an animal's body weight. "We are very excited about this new potential neurotransmitter link to feeding," says Dr. Couceyro. "We can keep one eye on the mechanisms of cocaine addiction and one eye on basic physiology governing hunger." This could prove especially important to the 59 percent of Americans who, according to 1995 figures by the Institute of Medicine, are clinically obese. Yerkes scientists caution that CART is only part of the feeding story. They believe that there are many chemicals in the brain regulating food intake and that if one is knocked out of commission, the brain will eventually learn to compensate. Eating is too important an activity to have just one neurotransmitter responsible. The Yerkes team is looking for a final common pathway for the food-related chemicals and their receptors. "Examining food intake in humans is difficult because people don't necessarily eat just when they're hungry," explains Dr. Lambert. They are more dependent on social cues, timetables and taste than are animals. Generally, animals don't expend their energy unless they need to, and eat only when hungry. However, if fed certain sweet mixtures, taste does tend to take over. The Yerkes Primate Center is part of the Woodruff Health Sciences Center of Emory University, and is the oldest scientific institute in the world dedicated to primate research. Its programs cover a wide range of biomedical and behavioral sciences.
--------
219-> Embryo Studies Show Dinosaurs Could Not Have Given Rise To Modern Birds
CHAPEL HILL -- Careful study of bird, alligator and turtle embryos at early stages offer convincing evidence that the "fingers" of bird wings correspond to the index, middle and ring fingers of humans, while the little finger and "thumb" have been lost. Such developmental evidence of digit identity conflicts with the theory that modern birds arose from dinosaurs as some paleontologists have claimed since the 1970s. Dinosaurs had "fingers" corresponding to the first, second and third fingers on human hands, and as a result, it is almost impossible to envision how a bird wing could have evolved from a dinosaur hand. That's the view expressed in Friday's (Oct. 24) issue of the journal Science. Dr. Ann C. Burke, a developmental biologist who is assistant professor at the University of North Carolina at Chapel Hill, conducted the new studies and wrote the Science article with Dr. Alan Feduccia, professor and chair of biology at UNC-CH. Feduccia has been a strong critic of the belief that dinosaurs gave rise to birds. "The theory that birds descended from dinosaurs has become dogma in the past 20 years or so, and yet a large number of people do not accept it because there are insurmountable problems with that theory," Feduccia said. "First, there is the time problem in that superficially bird-like dinosaurs occurred some 30 million to 80 million years after the earliest known bird, which is 150 million years old." Most of the bird-like dinosaurs were "looking at the meteor some 65 million years ago," he said, a reference to the giant meteor believed to have struck the Earth then and killed off all dinosaurs within a short time. "Second, flesh-eating dinosaurs thought to have given rise to birds were large earth-bound creatures with heavy balancing tails and short forelimbs. This is absolutely the worse body plan for the evolution of bird flight." Third, he said, if one views a chicken skeleton and a dinosaur skeleton through binoculars they appear similar, but close and detailed examination reveals many differences. Theropod dinosaurs, for example, had curved, serrated teeth, but the earliest birds had straight, unserrated peg-like teeth. All dinosaurs had a major joint in the lower jaw that early birds did not. Birds have a reversed rear toe that opposes the front three toes and allows birds to perch. Dinosaurs had no reversed toe. Birds grow a girdle of bone in their chests quite different from dinosaur chests. The new work involved microscopic examination of early limb development in ostriches, chickens, cormorants, alligators and turtles and comparison of chick fore- and hindlimbs. "We know that dinosaurs developed "hands" with digits one, two and three -- which are the same as the thumb, index and middle fingers of humans -- because digits four and five remain as tiny bumps or vestiges on early dinosaur skeletons," Feduccia said. "Apparently dinosaurs developed a very specialized, almost unique "hand" for grasping and raking. "Our studies of bird embryos, however, show that only digits two, three and four develop, and this creates a new problem," he said. "How do you derive a bird "hand," for example, with digits two, three and four from a dinosaur hand that has only digits one, two and three" The answer is that you can't." Findings from the examination of alligator and turtle embryos were consistent with those of birds, the biologist added. Far more likely is that birds and dinosaurs had a much older common ancestor, he said. Many superficial similarities between birds and dinosaurs arose because both groups developed body designs for walking upright on two hind legs and began to resemble each other over millions of years. "The dinosaurian origin of birds is based on sloppy science," Feduccia said. "It is a fantasy by which one believes it's possible vicariously to study dinosaurs at the backyard bird feeder." In an accompanying commentary in Science titled "The Forward March of the Bird-Dinosaur Halted?", Dr. Richard Hinchliffe of the University of Wales said the new report calls into question the dinosaurs-to-birds idea and is a forceful statement of the opposing theory. "...The present paper gives the developmental evidence a sharp focus which makes it a timely contribution to current debate on bird origins," wrote Hinchliffe, the world authority on vertebrate limb development. "This convincing evidence of 2-3-4 wing digit identity will not be to the liking of ... supporters of a dinosaur origin of birds. "For the time being, this important developmental evidence that birds have a 2-3-4 digital formula, unlike the dinosaur 1-2-3, is the most important barrier to belief in the dinosaur-origin orthodoxy."
--------
220-> NASA Joins Crusade For Women's Health -- Spinoffs From The Space Program
WASHINGTON, D.C. -- NASA Administrator Daniel S. Goldin has unveiled dramatic new technological developments affecting women's health at two events on Capitol Hill.  The technologies, which grew out of spin-offs from the U.S. space and aeronautics program, will usher in a new era in detection and treatment of women's health problems ranging from breast cancer to osteoporosis to reproductive health. "As a husband, father of two daughters, and a grandfather, few subjects are as important to me as women's health," Goldin said.  "That is why I am so proud of how NASA technologies, originally developed for our space and aeronautics programs, improve health care for women, men and children around the world." In the first event, NASA signed an agreement enlisting NASA technologies to fight breast cancer and other women's illnesses.  The agreement was signed by Dr. Henry McDonald, Director of NASA's Ames Research Center, Moffett Field, CA, and Dr. Susan Blumenthal, Assistant Surgeon General and Deputy Assistant Secretary for Women's Health at the Department of Health and Human Services (HHS).  At the signing ceremony, Goldin and McDonald demonstrated for Blumenthal six advanced technologies resulting from the U.S. space and aeronautics program that can dramatically influence the state of women's health. The agreement between NASA and HHS establishes a cooperative framework between Ames and the Office on Women's Health to identify, develop and transfer NASA technologies to benefit women's health.  Major areas of concern are cancer, reproductive health, pregnancy, osteoporosis and education. The technologies demonstrated included the new robotic "Smart Surgical Probe";  technology to allow three-dimensional "planning" for breast reconstruction, as is currently done for facial reconstruction surgery; and a device to predict an individual's specific risk of contracting osteoporosis. At the second event, Goldin was the keynote speaker at a luncheon sponsored by the Congressional Caucus on Women's Issues discussing "Space Technology Contributions to Breast Cancer Research."  He highlighted several NASA research and technology programs that help scientists and doctors understand, diagnose and treat breast cancer. "Part of the breast cancer story is that it kills thousands every year," Goldin said.  "However, this tragic statistic does not tell the whole story.  The rest of the story is one of hope.  It's a story of strength and grace and awesome courage.  At NASA, we are proud to be part of this story.  Before today, Americans may not have connected NASA with the fight against breast cancer. They may not know that NASA is on the front line for women's health.  We are pushing the edge of the envelope, developing state-of-the-art technologies that will help save women's lives." NASA Astronaut Mary Ellen Weber, Ph.D., explained how NASA efforts to grow human cells and tissue in space help researchers understand cancer and the response of the human immune system.  Dr. Carolyn Krebs of NASA's Goddard Space Flight Center, Greenbelt, MD, provided information on the way technology allowing the Hubble Space Telescope to map distant stars is being used in doctors' offices today to easily detect tiny spots in breast tissue, using a needle for biopsy rather than surgery. More information on the NASA technologies described above can be obtained from the NASA home page at URL: http://www.nasa.gov/today/index.html
--------
221-> Scientists Find That Local Populations Are Going Extinct At A Rate 3 To 8 Times Faster Than Species Extinction
The cod is not in immediate danger of extinction, yet populations of cod in the Atlantic have been so badly depleted that fishing communities in North America and Europe have lost a traditional source of livelihood for generations to come. The blue spruce is not likely to be wiped off the face of the earth soon, yet every time a large forest is clear-cut, the loss affects not only the animals and other species that lived there, but communities damaged by downstream erosion and landslides, and the global balance of greenhouse gases that the trees would have helped to absorb. That is why the loss of populations of plants, animals and other species may be as, or more, significant than the extinction of an entire species, three Stanford scientists say in an article in the Oct. 24 issue of the journal Science. While species are being lost globally with alarming speed - the highest rate since the mass extinction that included the dinosaurs - they calculate in their study that separate populations that make up various species are going extinct at a rate three to eight times faster. "You could destroy all of a species' populations but one, and the species still exists," said Jennifer Hughes, lead author of the study. "However, you would have lost the benefits supplied by those populations. This is a tremendously important dimension of biodiversity which is often ignored." Hughes is an ecologist at Stanford's Center for Conservation Biology. She conducted the study with Gretchen Daily, Bing Interdisciplinary Research Scientist, and Paul R. Ehrlich, the Bing Professor of Population Studies, at Stanford. Hughes and Daily and will speak on Oct. 28 and 29 in Washington, D.C., at the National Academy of Sciences' second forum on biodiversity, "Nature and Human Society: The Quest for a Sustainable World." Their paper in Science is linked to an article on species extinction by Sean Nee and Robert May of Oxford University, and a "Perspectives" essay by British ecologist Norman Myers. "[A] mass extinction is now overtaking the world's biodiversity," Myers writes. In their study, Hughes, Daily and Ehrlich looked at the loss of biodiversity on a different scale - that of localized populations that make up a species - from the scale that scientists and policy-makers usually have considered. Biodiversity is the variety of life found at all levels of biological organization, ranging from individuals and populations to species, communities and ecosystems. "Although much of the current public and scientific concern over the extinction of biodiversity emphasizes the loss of species, species are only one aspect of biodiversity," Hughes said. "While species are important, many of the benefits that biodiversity confers upon humanity are delivered through populations. This means that species extinction rates do not accurately represent the loss of the benefits of biodiversity," she said. In the study, the Stanford scientists estimated the current rate of population extinction. A population is a group of individuals in a given location of the same species - a population that is genetically different from other such groups. Species are made up of one or more populations. The scientists calculated that there were one billion to six billion populations on Earth. They then estimated that, by a conservative calculation based on known rates of habitat loss, populations are going extinct at a rate of 0.8 per cent per year, or 1,800 populations per hour, in tropical forests alone. In contrast, species loss in tropical forests has been predicted in other studies to occur at a rate between 0.1 and 0.3 per cent each year, or 2 to 5 species per hour. The loss of populations therefore is occurring 3 to 8 times faster than species loss. The loss of populations is significant because most of the benefits provided by individual species, or species working together in an ecosystem, are local and regional. For example, each population of a seafood or timber species that survives is available as a stock to be harvested. Each population of a particular species of plant has a slightly different genetic makeup - genetic material that may make a difference in the development of pharmaceuticals or the improvement of agricultural crops. "About half of the annual increase in crop production comes from the incorporation of new genes from populations of wild relatives that confer enhanced resistance to pests, disease, soil salinity and so on," Hughes said. Perhaps the most important benefits that populations provide are in the form of ecosystem services, the authors write. "Natural ecosystems supply a wide array of services to society whose full value is enormous, but often ignored," Daily said. These include purification of air and water, stabilization of climate, detoxification of waste, generation and maintenance of soil fertility and pollination of crops. Daily's presentation at the biodiversity forum will discuss society's dependence on natural ecosystems, and how to factor that dependence into decision-making. One method for doing that, she said, is to factor into planning programs the cost to society when ecosystem services are lost. Local populations also deliver global ecosystem services, the Stanford scientists said. The impact of the loss of populations from an area will not always be restricted to the immediate area, but will often affect a wider region, and at times, the entire globe. "Although populations operate at a local scale, they are responsible for producing services that are far-reaching," Hughes said. The blue spruce is an example: "The large-scale destruction of tree populations from a Canadian coniferous forest would influence the global balance of greenhouse gases in the atmosphere even if no species were exterminated." The authors conclude that current conservation strategies, which focus on individual species, will not be sufficient to protect the benefits that humanity derives from biodiversity. "It is critical to go beyond saving certain species. Habitats must be conserved for the preservation of biodiversity and the life support systems that maintain human civilization," Hughes said. In his "Perspectives" essay, Myers states that Hughes' findings about population loss raise critical questions for the foreseeable future. "If we lose, say, half of all species plus 90 percent of the populations of surviving species, which will be more detrimental for the biggest [ecosystem] service of all, environmental maintenance of the biosphere?"
--------
222-> New Form Of Gene Therapy Holds Promise For The Future
DALLAS - October 23, 1997 - Scientists at UT Southwestern Medical Center at Dallas are one step closer to producing a "drug" that is internally regulated and activated only when needed. They have developed a system in mice in which the level of a genetically engineered protein responds to inflammatory signals produced by the mice themselves. This method of gene therapy, described in the October issue of Nature Biotechnology, may have great potential for treating chronic relapsing and remitting inflammatory diseases, such as rheumatoid arthritis, and organ transplant rejection. "Our long-range goal is to give patients the right amount of an anti-inflammatory protein, at the right time and in the right place, to control damaging inflammation by introducing the gene for the protein and allowing the body's own signals to control its production," said Dr. Robert Munford, professor of internal medicine and microbiology and holder of the Jan and Henri Bromberg Chair in Internal Medicine. According to Munford, who worked with Dr. Alan Varley, a research fellow in internal medicine, and research technician Steven Geiszler, "There are lots of hurdles to overcome, but Varley and Geiszler seem to have jumped the first one, showing that recombinant genes can actually be regulated in animals in response to inflammation." The investigators used a "reporter" gene - a gene that encodes an easily measured protein - to test the ability of a mouse's immune response to turn on that gene. The reporter gene they used was firefly luciferase, an enzyme that causes light emission and can be measured easily with a luminometer. In the laboratory, they inserted the luciferase gene into a genetically altered virus that could not reproduce. To stimulate and control the production of luciferase, the researchers inserted specific short pieces of deoxyribonucleic acid (DNA) in front of the luciferase gene. These short DNA elements respond to internal signals by turning genes on and off. The trick was to find the right combination of DNA elements to dramatically enhance production of luciferase in response to an inflammatory reaction. The successful combination consisted of three elements ? one from the mouse and two from a virus ? that worked in concert and greatly amplified the production of luciferase when the proper signals (in this case, an inflammatory reaction) were received. The luciferase gene preceded by the three short pieces of DNA was genetically inserted into the viral molecule and injected into mice. Researchers then induced two different types of inflammatory responses. They determined how successful their combination of elements was by measuring the amount of luciferase produced in the mouse's liver, spleen, lung, heart and kidney. If a gene for an anti-inflammatory protein is used in place of the luciferase gene, this type of gene therapy, in theory, would activate that protein in response to the body's own inflammatory signals. "The production level of the anti-inflammatory protein should reflect the intensity and duration of the inflammatory condition," said Munford. "If the gene can be delivered to a specific site, such as an inflamed joint or an organ about to be transplanted into a recipient, it may be possible to provide effective anti-inflammatory treatment while avoiding systemic immunosuppression with its risk of infection." Dr. Richard Gaynor, professor of internal medicine and microbiology, and holder of the Andrea L. Simmons Distinguished Chair in Cancer Virology, also collaborated in the studies.
--------
223-> Columbia Scientists, In Nature Article, Dispute Finding That Aug. 16 Event Was Russian Nuclear Test
Two seismologists at Columbia University's Lamont-Doherty Earth Observatory, writing in the British journal Nature, have concluded that a seismic event on Aug. 16 north of mainland Russia was an earthquake, not a nuclear test. Seismic monitoring stations detected the event, which appeared to be in the vicinity of Novaya Zemlya, an island that is the site of a Russian nuclear weapons testing facility. Newspaper reports quoted unnamed sources describing the event as having "explosive characteristics" and a Clinton Administration spokesman maintained that technical data "lend themselves to alternative explanations." Had the event indeed been a nuclear explosion, it would mean the Russian government had violated the terms of the Comprehensive Test Ban Treaty (CTBT), an agreement laboriously negotiated over the last two decades by the United States, Russia and other nations that bans such testing. Analysis by the two Columbia researchers, Paul Richards and Won-Young Kim, seismologists who specialize in nuclear test verification, shows the seismic event was a small earthquake. The research, published in the Oct. 23 issue of Nature, demonstrates that scientists have "excellent" capability to monitor such events in the vicinity of Novaya Zemlya, they said. Other scientific views at odds with the U.S. government's interpretation of the Aug. 16 event have been reported in the Washington Post and the New York Times. But the Nature study is one of the first independent tests of a new International Monitoring System that is being developed to verify the CTBT. The system, created by signatories to the treaty, is a global arrangement of sensitive instruments designed to detect the various physical and chemical fingerprints of nuclear weapons tests. Data from these instruments are to be analyzed by the nations participating in the treaty in order to determine compliance with the test ban. Since nuclear explosions can produce signals that may look like an earthquake, "we need to be able to differentiate the two," Dr. Richards said. Dr. Richards saw the Aug. 16 event as an opportunity to test the capabilities of seismological data to monitor nuclear tests under the test ban treaty. In the Nature article, he and Kim state: "The ease of location and identification of the 16 August event, with a magnitude of about 3.5, demonstrates that the CTBT can be monitored near the Russian test site down to magnitude 3, and maybe even lower. . . . So the 16 August event indicates excellent capability to monitor the CTBT." Seismologists use the earthquake Richter scale to measure the size of both explosions and earthquakes; a magnitude of 3.5 corresponds to an explosive yield of about one-twentieth of a kiloton. The Columbia seismologists drew on several lines of evidence to verify that the event was not an explosion. First, the scientists compared seismic recordings of the questioned event with the recordings of a known nuclear explosion set off by the former Soviet Union in 1990. Drs. Richards and Kim noted differences in the delay between the first arriving seismic shocks (P-waves) and ones arriving later (S-waves). The recordings, from a Finnish monitoring station west of Novaya Zemlya, showed that S-waves from the 1997 event took 8 seconds longer to reach the station than those from the 1990 nuclear test, indicating that the more recent event was in fact nearly 100 kilometers, or about 62 miles, east of the test site. Additional work by other seismologists located the epicenter some 50 kilometers to the southeast of Novaya Zemlya, in a part of the Kara Sea nearly 400 meters deep. An explosion of this size located under water would be associated with a large acoustic signature, as sound waves produced by the blast were picked up by a network of sensitive seafloor microphones maintained by the U.S. government. No such acoustic signature was observed. Neither the large underwater drilling apparatus that would have been necessary for such a test, nor any radioactivity, was observed. Drs. Richards and Kim further noted the presence of several aftershocks in the region, which would not be expected if the event had been a nuclear test. "Aftershocks are common for earthquakes, but would not be detectable at IMS stations after small nuclear explosions at Novaya Zemlya," Dr. Richards said. Drs. Richards and Kim also analyzed the seismic waves produced by the event and recorded on seismological monitoring stations scattered throughout Eurasia. These data are collected by various U.S. government and international programs and are openly available to the scientific research community. Using a method of analysis that carefully measures the size of shock waves at high frequencies, the seismologists found that the ratios of P to S waves were consistent with ratios for known earthquakes with epicenters near Novaya Zemlya. This technique, which has been carefully refined through years of research at Lamont-Doherty and elsewhere, provides the most definitive evidence that the Aug. 16 event does not have "explosive characteristics," the scientists said. To Drs. Richards and Kim, the data are clear: the event was an earthquake. However, they had the luxury of time to track down available data and use the most recent methods of data analysis. U.S. government officials, they said, must work within the framework of treaty monitoring. "It may be difficult for these officials to accept that data from non-IMS stations and data analysis by independent groups of seismologists have had such prominence," Drs. Richards and Kim write in Nature. "When the research community is able to demonstrate a good new method of discrimination, or the need for good communication to non-IMS stations with openly available data, the development must be assessed and operational procedures perhaps revised." The U.S. government needs to provide mechanisms that allow officials to draw on new research in their decision-making, the scientists said. "But there are more than ten thousand seismographic stations deployed around the world for the general purpose of research into earthquake hazard and the structure of the Earth's interior, so that supplementary data on problem events in the CTBT context will often be available," they wrote. Despite the U.S. government's refusal to acknowledge a mistake, both that government and the IMS have the technology to discern earthquakes from nuclear explosions, the scientists said. "Our capability to monitor the CTBT is magnificent. We have all these discriminants upon which knowledgeable decisions can be based," Dr. Richards said. Lamont-Doherty Earth Observatory is a part of the Columbia Earth Institute, founded this year to promote wise stewardship of the Earth's resources.
--------
224-> Mathematicians Combine To Solve Practical Problems
A new western-based organization is bringing mathematicians out of the ivory tower to help solve problems that affect daily lives. One result could be earlier detection of lung cancer. Established in 1996, the Pacific Institute for the Mathematical Sciences (PIms) aims to apply the mathematician's skill in ways that might, at first, seem unusual. "We want to bring mathematicians and industry together to solve practical problems," says Arvind Gupta, associate professor of computing science at Simon Fraser University, one of PIms' five founding universities. "A lot of emphasis recently has been placed on applied research and we felt that mathematicians have been left out of the loop." To help get mathematicians into the loop, PIms asked the industrial sector to submit problems to a workshop in August at UBC. Teams of faculty and graduate students from PIms were assigned to solve six of the 20 problems submitted. One, from the B.C. Cancer Agency, involved finding a better way to identify cancerous lesions in the lungs. "If we could find a quicker way of identifying the cells from the lesions as cancerous, we might be able to reduce the mortality rate which now stands at 85 per cent," Gupta explains. The team working on the problem included a pure mathematician, applied mathematician, statistician, physicist and two computer scientists from five western universities, including SFU, as well as cancer agency biologists. "The biologists were using a very complicated model to solve the problem," Gupta says. "What we, as mathematicians, could do that they hadn't done was identify the key components of the model. We quickly understood what model to use and were able to distill the important parameters. The biologists will be able to take our model and refine and make it more complex if necessary. "It took us a day-and-a-half to arrive at a common language so we could understand each other's terminology because we don't usually work with people in other disciplines," he adds. "While we haven't solved the problem yet, we continue to work on it and the cancer agency is quite excited by our progress." Another problem presented to the workshop involved stress levels for compressed gas containers such as propane or natural gas cylinders. Powertech Inc. wanted to find out how to tell when tiny cracks begin to show in these kinds of cylinders. The team working on this problem provided an answer before the week-long workshop ended. PIms was established in 1996 by SFU, the University of Victoria, University of Calgary, University of Alberta and UBC. It aims to foster new mathematical research, as well as to communicate better the work of mathematicians to educators and the public. Gupta says another workshop is planned for next summer when industry again will be asked to submit problems. He explains that the organization now provides its members with the resources of each university's faculty, as well as better communications with western Canada's far-flung universities. "In Ontario there are eight universities within an hour of Toronto, but at SFU, for example, there is only one. PIms helps give us the resources to tackle problems for business and provide greater resources for academics, educators and the public." PIms is supported by grants from the Natural Sciences and Engineering Research Council (NSERC) and the B.C. government, as well as the association's five member universities.
--------
225-> Scientists Conduct First Large-Scale Study Of Lake Superior
When the ice creaks, groans, and finally breaks up on Lake Superior next spring, a team of limnologists and oceanographers will launch a five-year study of a dramatic near-shore current in the lake. The current is called the Keweenaw Current because of its proximity to Michigan's Keweenaw Peninsula, and is considered the strongest current of its kind in the world. The $5.3 million study is funded by the National Science Foundation (NSF), and is dubbed KITES, for Keweenaw Interdisciplinary Transport Experiment. In KITES, researchers from six institutions will conduct one of the largest studies ever undertaken on Lake Superior. "Lake Superior contains some 10 percent of the freshwater on earth," explains program director Larry Clark of NSF's ocean sciences division, which funded the project. "That's more water than all of the lower lakes combined. Lake Superior also has the largest area of any lake on this planet. But, despite those facts, Lake Superior has not been adequately studied, in part because of the daunting environment it presents for researchers. KITES marks the first time that such an array of resources has been applied to Superior. What we learn from a comprehensive study of Lake Superior will have direct relevance to our understanding of many of the physical features of the world's coastal oceans." Scientists working on the KITES project will identify the physical processes that control the current's position and strength, and investigate how the current affects the distribution of nutrients, and therefore, plankton and fish, in a 150-mile study region. They will place current meters in Lake Superior as well as analyze its water chemistry, collect samples of plankton and juvenile fish and sample sediment distribution and transport along the western shore of Michigan's Keweenaw Peninsula from the Wisconsin border to the northernmost point in Michigan. "The Keweenaw Current forms a semi- permeable barrier along the 'coast' of Lake Superior that inhibits material from shore and from rivers flowing into the lake from crossing into Superior's central basin," explains limnologist Sarah Green of Michigan Technical University (MTU) in Houghton, the project's coordinator. "We expect the effects of this barrier to be apparent throughout the entire Lake Superior ecosystem." Adds the project's associate coordinator, scientist Elise Ralph of the University of Minnesota's Large Lakes Observatory, "Currents running parallel to shore are common in the oceans and in lakes, so what we learn here will help us understand similar processes in other aquatic environments. We have an excellent site to identify the effects of such a massive current." It's been estimated that the Keweenaw Current, at its peak flow, carries as much water as the outflow of the Mississippi River. KITES scientists say that water movement in the current is the primary means by which materials are transported from the lake's western to eastern basins, and is therefore likely to be important in processes throughout Lake Superior. Other institutions involved in KITES are the University of Washington in Seattle, the University of Georgia, the University of Maryland and the University of Wisconsin-Madison. KITES is also supported in part by the National Oceanic and Atmospheric Administration (NOAA).
--------
226-> University of Florida Physicians Use New Device to Purify Bone Marrow For Transplantation
By Melanie Fridl Ross, Shands Public Relations GAINESVILLE, Fla.---University of Florida physicians are testing a new way of purging tumor cells from bone marrow. The method could yield a "cleaner" bone marrow sample and reduce treatment-related side effects for patients undergoing bone marrow transplantation, UF researchers report. The technique, known as the CD-34 positive selection method, is used for patients who are donating their own bone marrow to be given back to themselves at a later date, also known as autologous bone marrow transplant. A 47-year-old North Florida man battling multiple myeloma was the first to undergo a transplant involving the new approach at Shands at UF. Multiple myeloma is characterized by the uncontrolled spread of certain white blood cells -- plasma cells -- in bone marrow. Plasma cells ordinarily make antibodies, disease-fighting agents that normally guard against infection. But because their immune system functions abnormally, patients with multiple myeloma are especially prone to infection. Despite weeks of chemotherapy, fully a third of the cells in the man's bone marrow were still malignant. So doctors took a two-step approach to cleansing the marrow's most primitive cells -- the stem cells. (These are in the earliest stages of development and have the ability to evolve into an array of blood cell types as they grow and mature.) First, the patient was given injections of growth factors daily for five days to move the stem cells into the blood and reduce the level of tumor contamination. The cells were collected by apheresis, a procedure that separates them from other blood components. This first step decreases the level of tumor cells mixed with stem cells but does not eliminate it. Secondly, the blood stem cells were run through the CD-34 device, similar to a long column with a collection area for cells at the bottom. The device was recently approved by the Food and Drug Administration. "With the CD-34 selection procedure, we use a column containing antibodies -- which recognizes a certain substance or 'antigen' that is unique to the membrane of stem cells," said John Wingard, director of the bone marrow transplant program at Shands. "That allows us to put about two liters of blood or bone marrow cells in the device and end up with a teaspoon that only contains the stem cells. Everything else -- the other cells not necessary for the transplant and malignant cells -- flows through." Previous methods used a bone marrow sample containing a wide variety of cells, and did not ensure the transplant was completely free of tumor cells, Wingard said. Moreover, those techniques typically damaged some normal stem cells. Thus, efforts to clean the sample prior to transplantation often prolonged the patient's hospital stay. "With this approach, we think we give a cleaner stem cell product that is less likely to have tumor cells in it," he said. "We are using it for selected cases where we believe there's a strong likelihood there might otherwise be significant amounts of tumor cell contamination." Other possible benefits: a lower risk of rejection and reduced side effects from transplantation. Because stem cells alone are used, the sample's volume is naturally smaller, reducing the amount of preservative needed to protect the cells when they are frozen for storage prior to transplantation. The preservative can cause side effects in some patients, Wingard said. If it works, the approach also could benefit patients stricken with cancer or other blood disorders, including non-Hodgkin's lymphoma, multiple myeloma, some breast cancer cases, and possibly tumors such as neuroblastoma that involve the bone marrow. ---------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
227-> Missions To Gather Solar Wind Samples And Tour Three Comets Selected As Next Discovery Program Flights
A mission to gather samples of the wind flowing from the Sun and a mission to fly by three near-Earth comets have been selected as the next flights in NASA's Discovery Program of lower-cost, highly focused scientific spacecraft. The Genesis mission is designed to collect samples of the charged particles in the solar wind and return them to Earth laboratories for detailed analysis.  It is led by Dr. Donald Burnett from the California Institute of Technology, Pasadena, CA, at a total cost to NASA of $216 million. Due for launch in January 2001, it will return the samples of isotopes of oxygen, nitrogen, the noble gases, and other elements to an airborne capture in the Utah desert in August 2003.  Such data are crucial for improving theories about the origin of the Sun and the planets, which formed from the same primordial dust cloud. The Comet Nucleus Tour (CONTOUR) will take images and comparative spectral maps of at least three comet nuclei and analyze the dust flowing from them.  CONTOUR is led by Dr. Joseph Veverka of Cornell University, Ithaca, NY, at a total cost to NASA of $154 million.  It is scheduled for launch in July 2002, with its first comet flyby to occur in November 2003.  This flyby of Comet Encke at a distance of about 60 miles (100 kilometers) will be followed by similar encounters with Comet Schwassmann-Wachmann-3 in June 2006 and Comet d'Arrest in August 2008. "This was a very difficult selection, given the first-class science proposed by all five teams," said Dr. Wesley Huntress, Associate Administrator for Space Science at NASA Headquarters, Washington.  "We picked two based on our distribution of resources and the excellent fit of the timetables for these missions with other robotic space science explorers.  Genesis will give us a sample of the Sun as we are preparing to receive samples of a comet and asteroid from other missions.  Meanwhile, CONTOUR will help us better understand the breadth of the 'family' of comets, which are believed to be quite individual in their properties." The selection of these missions is the second step of a two-step process.  In the first step, NASA selected five proposals in April 1997 for detailed four-month feasibility studies.  Funded by NASA at $350,000 each, these studies focused on cost, management and technical plans, including small business involvement and educational outreach. The selected proposals were among 34 proposals originally submitted to NASA in December 1996, in response to a Discovery Announcement of Opportunity (AO) issued on September 20, 1996.  As stated in the AO, the initial cost estimates were allowed to grow by a maximum of 20 percent between the April selection and the detailed final proposals. The investigations proposed in response to this announcement (AO-96-OSS-02) were required to address the goals and objectives of the Office of Space Science's Solar System Exploration theme or the search for extrasolar planetary systems element of the Astronomical Search for Origins and Planetary Systems theme.  A selected mission was required to be ready for launch no later than September 30, 2002, within the Discovery Program's cost cap of $280 million total per mission, including development, launch and operations. CONTOUR and Genesis follow four previously selected NASA Discovery missions.  The Near Earth Asteroid Rendezvous (NEAR) spacecraft was launched in February 1996 and returned sharp images of the asteroid Mathilde from a distant flyby in June of this year, on its way to orbit the asteroid Eros in early 1999.  The Mars Pathfinder lander, carrying a small robotic rover named Sojourner, landed successfully on the surface of Mars on July 4, and since has returned hundreds of images and thousands of measurements of the Martian environment. The Lunar Prospector orbiter mission to map the Moon's composition and gravity field is scheduled for launch in January 1998, and the Stardust mission is designed to gather dust from Comet Wild-2 in 2004 and return it to Earth, following a planned February 1999 launch.
--------
228-> Bell Labs Innovative Germanium-Recovery Process Is Economically, Environmentally Friendly
ATLANTA -- An innovative process from Bell Labs is making it possible for Lucent Technologies to improve the recovery and recycling of an important natural resource -- germanium -- from the waste products of optical-fiber manufacturing and to save millions of dollars at the same time. Bell Labs is the research and development arm of Lucent Technologies. In optical-fiber manufacturing, a silicon-containing vapor, such as silicon tetrachloride, and a germanium-containing vapor, such as germanium tetrachloride, undergo a high-temperature chemical reaction with oxygen to produce  silicon oxide - germanium oxide glass. The precise use of these vapors allows control of the refractive-index profile of an optical fiber, so the lightwave signals traveling through the fiber will stay within the fiber’s core for hundreds of miles.  This use of germanium accounts for more than 35 percent of today’s global industrial consumption. Optical fiber, hair-thin ultra-pure glass, is used in communications systems to carry voice, data and video signals that have been converted into the ones and zeros of digitized information and transmitted as pulses of light. Its use has increased dramatically in the past decade and is increasing at an accelerated rate.   "Worldwide, the rate of optical-fiber manufacturing exceeds 1,000 miles an hour, every hour of every day.  By the turn of the century, that number is expected to double," said Alastair Glass, director of Bell Labs Photonic Components Research Lab. The Bell Labs recovery process is part of a system that removes all hazardous wastes from the gases exhausted from fiber manufacture. "This timely development represents a significant contribution to the environment," said David Kalish, Optical-Fiber Development and Engineering director, Network Systems - Lucent Technologies. "Moreover, the recycling of germanium has allowed us to continue to serve our customers at a time when germanium has been in short supply." Optical fiber is about 96 percent silicon dioxide (the main component of sand) and about 4 percent germanium dioxide, with small amounts of other elements. Lucent Technologies, a global leader in optical-fiber manufacturing, has recovered germanium from fiber-optic production since the mid-1980s.  Lucent’s Atlanta Works was the first optical-fiber manufacturing facility to recycle germanium. The process was improved significantly in 1995, with the recovery and re-use of  more than 70 percent of the wasted germanium, resulting in multimillion-dollar savings in germanium purchase costs.  Improvements to the process now underway will  bring the percentage recovery to more than 80 percent The germanium-recovery process was developed by Bell Labs researchers Dave Mixon and Mike Bohrer, of the Polymer and Chemical Engineering department, and scaled up for commercial operations in collaboration with colleagues Lisa Green and Ed Nelson of the Optical Fiber Development and Engineering organization in Lucent’s Network Systems operating unit. Lucent Technologies designs, builds and delivers a wide range of public and private networks, communications systems and software, consumer and business telephone systems and microelectronics components. More information about Lucent Technologies, headquartered at Murray Hill, N.J., is available at http://www.lucent.com.
--------
229-> Different Alzheimer's Genes Create Same Problem In Mouse Brain
Brain plaques, long used for post-mortem diagnosis, appear to have fundamental early role in AD A new study suggests the amyloid plaques that form in the brains of Alzheimer's disease patients are not the end products of the disease but the beginning of it, according to Johns Hopkins scientists. Researchers showed in genetically engineered mice that a gene linked to a form of Alzheimer's disease that runs in families dramatically increased the speed at which amyloid peptides were made and clumped together to form plaques. "This gene is not the only force behind accelerated deposition of the plaques, but our findings add to the growing body of evidence supporting the view that this deposition is an early and critical event in Alzheimer's disease," says David Borchelt, Ph.D., an associate professor of pathology. The findings add to the hope that stopping the early changes with drugs might stop the development of Alzheimer's disease, according to Borchelt. The study was supported by the National Institutes of Health, the U.S. Public Health Service, and private organizations including the Alzheimer's Association, the Develbliss Fund and the Adler Foundation. Researchers worked with two mutated human genes that cause AD in patients whose disease runs in their families and starts earlier in life than the more common, non-inherited form of AD. Amyloid-precursor protein (APP) provides the raw material that forms plaques.  The other gene, presenilin 1, is linked to a highly aggressive inheritable form of Alzheimer's, but how it causes the disease is less clear. 	When the researchers generated mice with a mutated form of APP linked to Alzheimer's disease, the mice developed amyloid plaques at the end of their normal lifespan. A second group of mice with both mutated APP and presenilin developed numerous amyloid deposits at a much younger age, indicating that presenilin accelerated the rate of plaque formation. Borchelt says brain levels of amyloid-beta peptide, the substance that clumps to form the plaques, only moderately increased in the second group of mice.  However, that increase was enough to halve the time it took for plaques to form. "A drug that can create a modest reduction in amyloid-beta peptides in the human brain might therefore be able to slow the start of Alzheimer's for many years or even decades," speculates Sangram Sisodia, Ph.D., associate professor of pathology and neuroscience. Mice for the study were bred by researchers at the National Cancer Institute's Frederick, Md., research center. Other authors on the paper were Tamara Ratovitski, Judy van Lare, Michael Lee, Vicki Gonzales, Nancy Jenkins, Neal Copeland and Donald Price.
--------
230-> University Of Maryland researchers report on herbal brain-cell armor, pain pathways, and depression
News Tips -- University Of Maryland Research, 27th Annual Meeting, Society For Neuroscience HERBAL BRAIN-CELL ARMOR -- Two compounds isolated from a type of ginseng may be potent neuroprotectors, researchers from the University of Maryland School of Medicine and the Seoul National University have found. Tae H. Oh,  PhD, professor of anatomy and neurobiology at Maryland, and Young C. Kim, Ph.D., from Seoul National University in Korea, studied the effects of ginsenosides Rb1 and Rg3 on cortical cells from rats.  The compounds effectively inhibited overproduction of cell-killing nitrous oxide, which routinely follows nerve-cell poisoning by a naturally occurring amino acid byproduct called L-glutamate. They also inhibited formation of a dangerous compound called malondialdehyde and raised diminished levels of helpful superoxide dismutase in glutamate-treated cells. Oh, a researcher at the medical school in Baltimore, and Kim, a Korean colleague, will present a poster on their findings on Wednesday, October 29, 1997, at the Society for Neuroscience annual meeting in New Orleans. PAIN IS A TWO-WAY STREET -- Pain messages are transmitted up the nerves from pain receptors through the spinal cord to the brain, following routes known as ascending neural pathways.  Another important kind of message—pain modulation, which affects how we react to pain—is transmitted downwards from the brain, along descending neural pathways. Now Ronald Dubner, DDS, PhD, and colleagues Ke Ren, MD, PhD, and Fong Wei, PhD, at the Dental School, University of Maryland, have determined that after inflammation and injury, the descending neural pathways in the spinal cord contain both kinds of neurons: ones that enhance pain messages and others that inhibit them.  When they destroyed neurons that originate in one region of the rats’ brainstem, called the nucleus raphe magnus, the rats experienced more pain.  But when neurons from the nearby nucleus gigantocellularis were destroyed, the animals experienced less pain. Dubner is chairman of the Department of Oral and Craniofacial Biological Sciences. Ren, an assistant professor, and Wei, a postdoctoral fellow in the same department, will report their findings on Wednesday, October 29, 1997 at the Society for Neuroscience annual meeting in New Orleans. WHERE (EXACTLY) DOES IT HURT? -- No matter whether you smash your thumb with a hammer, splatter hot cooking oil in your face or slash your foot on a sliver of broken glass, your perception of pain arises from activity in your brain. New research being conducted by neuroscientists at the Dental School, University of Maryland, is closing in on the regions of the brain responsible for the perception of pain. In a study analyzing the sensory capacities and extent of brain damage in six individuals with injuries involving two parts of the brain commonly believed to be pain processing regions, Joel D. Greenspan, PhD,  assistant professor in the Department of Oral and Craniofacial Biological Sciences, and colleagues Roland R. Lee, MD, and Fred A. Lenz, MD, found that a central region of the cerebral  cortex called the posterior parietal operculum plays a key role in our recognition of injurious stimuli as painful. Another region suspected to have some role in pain responses—the insular cortex—in fact can be damageed extensively without altering the threshold of pain, Greenspan said.  Other  studies suggest, however, that the insular cortex may play a role in people’s emotional responses to pain. He will present a poster on their preliminary findings on Sunday, October 26, 1997 at the Society for Neuroscience annual meeting in New Orleans. HELPLESS RATS HELP TEST DEPRESSION DRUG THERAPIES -- In an animal model of depression developed by researchers at the University of Maryland School of Pharmacy, cytochrome oxidase - an enzyme that limits the rate of mitochondrial oxidative metabolism - can be used to map synaptic activity and to study specific responses to new drug therapies at a cellular and local level in the brain. Emmeline Edwards, PhD, associate professor, and colleagues in the school’s Department of Pharmaceutical Sciences, found baseline differences in brain metabolic capacity using a learned-helplessness rat model of depression.  The researchers’ model was systematically bred to foster increased susceptibility to learned helplessness and is in its 40th generation.  Cytochrome oxidase histochemistry in this study indicated a decreased capacity for oxidative energy metabolism in the cingulate cortex, a limbic system structure implicated in depression, Edwards will report on Tuesday, October 28, 1997 at the Society for Neuroscience Annual Meeting in New Orleans. Edwards also will report on findings that the depression model can be used to study specific opioid mechanisms in depression.  She hopes this will enable researchers to assess genetic susceptibility to depression linked with drug abuse.  Future studies may lead to alternative strategies for treating those with both depression and addiction. The Maryland researchers are presenting two additional posters highlighting other applications of their depression model.    WHERE (EXACTLY) DOES IT HURT? -- No matter whether you smash your thumb with a hammer, splatter hot cooking oil in your face or slash your foot on a sliver of broken glass, your perception of pain arises from activity in your brain. New research being conducted by neuroscientists at the Dental School, University of Maryland, is closing in on the regions of the brain responsible for the perception of pain. In a study analyzing the sensory capacities and extent of brain damage in six individuals with injuries involving two parts of the brain commonly believed to be pain processing regions, Joel D. Greenspan, PhD,  assistant professor in the Department of Oral and Craniofacial Biological Sciences, and colleagues Roland R. Lee, MD, and Fred A. Lenz, MD, found that a central region of the cerebral  cortex called the posterior parietal operculum plays a key role in our recognition of injurious stimuli as painful. Another region suspected to have some role in pain responses—the insular cortex—in fact can be damageed extensively without altering the threshold of pain, Greenspan said.  Other  studies suggest, however, that the insular cortex may play a role in people’s emotional responses to pain. He will present a poster on their preliminary findings on Sunday, October 26, 1997 at the Society for Neuroscience annual meeting in New Orleans. HELPLESS RATS HELP TEST DEPRESSION DRUG THERAPIES -- In an animal model of depression developed by researchers at the University of Maryland School of Pharmacy, cytochrome oxidase - an enzyme that limits the rate of mitochondrial oxidative metabolism - can be used to map synaptic activity and to study specific responses to new drug therapies at a cellular and local level in the brain. Emmeline Edwards, PhD, associate professor, and colleagues in the school’s Department of Pharmaceutical Sciences, found baseline differences in brain metabolic capacity using a learned-helplessness rat model of depression.  The researchers’ model was systematically bred to foster increased susceptibility to learned helplessness and is in its 40th generation.  Cytochrome oxidase histochemistry in this study indicated a decreased capacity for oxidative energy metabolism in the cingulate cortex, a limbic system structure implicated in depression, Edwards will report on Tuesday, October 28, 1997 at the Society for Neuroscience Annual Meeting in New Orleans. Edwards also will report on findings that the depression model can be used to study specific opioid mechanisms in depression.  She hopes this will enable researchers to assess genetic susceptibility to depression linked with drug abuse.  Future studies may lead to alternative strategies for treating those with both depression and addiction. The Maryland researchers are presenting two additional posters highlighting other applications of their depression model.  
--------
231-> Oral Vaccine Protects Infants From Severe Rotavirus Diarrhea
An oral vaccine against rotavirus -- the most important cause of life-threatening diarrhea in children under age 2 -- reduced severe diarrheal illness by 88 percent in a study of more than 2,000 infants in Venezuela.  This is the largest and most successful trial to date of arotavirus vaccine among children in a developing country. Worldwide, rotavirus diarrhea affects 130 million infants and children each year, some 18 million of whom have moderate to severe disease, resulting in 873,000 deaths. The study was conducted by Albert Z. Kapikian, M.D., head of the Epidemiology Section of the Laboratory of Infectious Diseases (LID), part of the National Institute of Allergy and Infectious Diseases (NIAID); Irene Perez-Schael, M.D., chief of the Laboratory of Enteric Disease at the Instituto de Biomedicina, Universidad Central de Venezuela in Caracas; and their co-workers.  Results are reportedOct. 23 in The New England Journal of Medicine. "This is the first study designed to determine if the vaccine prevents severe illness in a developing country where rotavirus circulates year-round rather than seasonally," explains Anthony S. Fauci, M.D., NIAID director.  "In this setting, the vaccine proved to be very efficacious." Although rotavirus infection is nearly universal, "The outcome and consequences of rotavirus illness in developed countries are very different from those in developing countries," Dr. Perez-Schael says.  Children in developing countries more often develop severe and fatal illness. Symptoms develop quickly and, in addition to diarrhea, include vomiting, fever and dehydration.  In severe cases, a child can experience 10 to 20 episodes of diarrhea and 10 to 15 vomiting episodes per day.  Dehydration can be reversed through oral rehydration therapy or, if more serious, through hospitalization and intravenous fluids.  Although effective, these therapies are not readily available or utilized in many parts of the developing world, Dr. Kapikian says.  Also, Dr. Kapikian notes, "Rotaviruses are veryegalitarian viruses.  Practically every child in the developed and developing world will be infected with rotavirus in the first few years of life, regardless of hygienic conditions." Dr. Kapikian has devoted a major part of his career to working on rotavirus since its discovery almost 25 years ago by Australian investigators.  He and his colleagues in NIAID's LID developed and patented the vaccine, which, with assistance from many outsidecollaborators, has been tested in nearly 18,000 people in the United States and abroad. "The development of the quadrivalent rotavirus vaccine evaluated in the study represents the culmination of a long andhighly creative process of research and development at the National Institutes of Health," comments Gerald T. Keusch, M.D., and Richard A. Cash, M.D., M.P.H., both affiliated with the Harvard Institute for International Development, in a companion editorial in the Journal. "To be there from the beginning has been a great privilege," Dr. Kapikian says.  "But what's most exciting and gratifying to me as a physician is to see that most babies can be protected from a severe disease with a product that has been developed in our laboratory." Dr. Fauci expresses his admiration for their achievement to date.  "Dr. Kapikian and others in the Laboratory of Infectious Diseases have been at the forefront of the effort to develop arotavirus vaccine.  Their ingenuity, perseverance and leadership havecontributed enormously to the development of this important vaccine." In the United States, rotavirus causes more than 3 million cases of childhood diarrhea during the cooler months of each year, leading to an estimated 500,000 doctor visits, 55,000 to 100,000 hospitalizations and 20 to 100 deaths.  Rotavirus illness costs theU.S. health care system an estimated $400 million in direct costs annually, rising to $1.4 billion when indirect costs, including lost work time for parents, are included. The potential benefits of a licensed vaccine in developed countries such as the United States are noted by Drs. Keusch and Cash.  "Studies in the United States indicate that the rhesus rotavirus-based quadrivalent vaccine is safe and can prevent nearly half of allrotavirus infections, 80 percent of severe episodes, and virtually allcases of dehydrating rotavirus illness." The candidate vaccine is currently being reviewed by the Food and Drug Administration (FDA) for licensure in the United States.  An FDA advisory committee will meet in early December to consider all the data and make their recommendation regarding licensure to the FDA. The World Health Organization is following closely developments here and in the European Union in an effort to determine how and when the vaccine might also be made available inthe developing world. ***Study Details*** The Venezuelan study, which began in March 1992, was conducted at a hospital specializing in obstetrics and pediatrics in a poor urban area southwest of Caracas.  The hospital team enrolled 2,207 full-term, healthy infants, each assigned at random to receive three doses total of either the vaccine or a placebo.  A small amountof reconstituted pink liquid vaccine or its look-alike was given by mouth to the infants at 2, 3 and 4 months of age.  Neither the study investigators nor the infants' parents knew which product a child received until the study ended. The babies were monitored at home by their parents and caretakers for episodes of diarrhea, defined as the presence of three or more liquid or semiliquid stools, or a single stool with blood, during a period of 24 hours, with or without vomiting.  Those who hadsignificant illness were brought to the hospital for treatment, evaluation and data collection.  Follow-up continued until age 2. Although the vaccine was only 48 percent efficacious against a first episode of rotavirus diarrhea of any severity, the vaccine reduced the incidence of severe rotavirus diarrhea by 88 percent and the most life-threatening symptom, dehydration, by 75 percent, and decreased hospital admissions by 70 percent. These findings, says Dr. Kapikian, are consistent with observations of natural infection, which confers better protection against severe disease than against mild illness.  "We would notanticipate that a live, attenuated vaccine would do better than wild-type virus," notes Dr. Kapikian.  "The concept of eliminating the virus, like  smallpox, will not occur with rotavirus," he says, "because reinfections are very common.  The purpose of this vaccine is to prevent the more severe illness." Aside from significantly greater incidence of fever in the vaccine group after the first dose only (15 percent in vaccinees versus 7 percent in controls), the two study groups experienced nodifferences in side effects, and the vaccine was safe and well-tolerated. ***The Vaccine*** The vaccine consists of a mixture of four viruses (hence the name tetravalent or quadrivalent) that together protect against the four most important clinical strains of rotavirus.  The NIAID team designed the vaccine by substituting a gene from a human rotavirus strain for one in a weakened rotavirus that infects rhesus monkeys. The gene contains instructions to make a protein on the virus' surface, where the immune system can easily recognize it and then tailor-make antibodies to fight that viral strain. When making the rhesus rotavirus-tetravalent (RRV-TV)vaccine, the NIAID researchers used this substitution strategy to create weakened forms of three of the four clinically important human rotaviruses.  The fourth human strain was represented by a weakened but unaltered rhesus rotavirus, which has a similar surface protein.  The vaccine was licensed to Wyeth-Ayerst Laboratories (St. Davids, Pa.), a division of American Home Products Corp., and is now manufactured by Wyeth-Lederle Vaccines and Pediatrics, a unit of Wyeth-Ayerst Laboratories. ***Background*** NIAID's Laboratory of Infectious Diseases has been involved in studies of gastroenteritis since the late 1960s.  "It's very exciting to see something from the beginning," says Dr. Kapikian.  "When we first started out, there was little or nothing written about viruses that cause gastrointestinal diseases." Dr. Kapikian, newly trained in electron microscopy, used this technique in 1972 to discover Norwalk virus, the first virus associated with gastroenteritis.  "Since then," he notes, "there have been thousands of papers about gastrointestinal viruses." Rotavirus was discovered by Australian scientists in 1973.  Dr. Kapikian and his collaborators first identified it in the United States one year later in stool samples taken from patients at Children's Hospital in Washington, D.C. Not only have these investigators been behind many key scientific discoveries, they also have been intimately involved with the many clinical trials done to test several rotavirus vaccine candidates.Initially, Dr. Kapikian, Robert Chanock, M.D., chief of LID, and their colleagues developed a monovalent vaccine against rotavirus in 1984.  Two years later, when it was considered that a monovalent vaccine might not protect against the four clinically important strains of the virus, the LID group developed the additional individualcomponents of RRV-TV. Through a cooperative research agreement with Wyeth-Ayerst Inc. in1987, commercial development of the RRV-TV vaccine began. "This vaccine didn't happen because of one person, it happened because of a lot of dedicated people," comments Dr. Kapikian.  "It's really been a fine effort around the world." NIAID is a component of the National Institutes of Health (NIH).  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, malaria, tuberculosis, asthma and allergies.  NIH is an agency of the U.S. Department of Health and Human Services. ### References: Perez-Schael I, Guntinas MJ, Perez M, Pagone V, Rojas AM, Gonz lez R,Cunto W, Hoshino Y and Kapikian AZ.  Efficacy of the rhesus rotavirus-based quadrivalent vaccine in infants and young children in Venezuela.  New Engl J Med 1997;337(17):1181-87. Keusch GT and Cash RA.  A vaccine against rotavirus -- when is too much too much?  New Engl J Med 1997;337(17):1228-29. Press releases, fact sheets and other NIAID-related materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov. ***TV Producers and Reporters: A video B-roll, including soundbites ofDrs. Kapikian and Fauci, is available.  For more information, call the NIAID Office of Communications at 301-402-1663. ***Print Reporters: Black-and-white photos and a color map showing theannual pattern of rotavirus illness across the United States are available.  For more information, call the NIAID Office of Communications at 301-402-1663.
--------
232-> First-Ever On-Board Gasoline Powered Fuel Cell For Automobiles
New Technology Discovery Promises New Market Opportunities, Greater Fuel Efficiencies, Near-zero Emission Levels and Lower Cost Fuel Alternatives For Automobile Industry Cambridge, MA – October 21, 1997 – The U.S. Department of Energy and Arthur D. Little, in conjunction with Plug Power and the Energy Department's Los Alamos National Laboratory, have successfully demonstrated a first-ever gasoline-powered “fuel cell” electric engine for the automobile. The new technology will allow the automotive industry to create new fleets of vehicles that can realize up to 80 mpg fuel economy with a near-zero exhaust emissions. This is the first time that fuel cell electricity has been generated by hydrogen from gasoline in a module that can be placed aboard a vehicle. The innovation heralds the next generation of engines to replace the internal combustion engine. “Technology is increasingly important as the nation focuses on environmental protection and climate challenges," said Secretary of Energy Federico Pena. "Today's breakthrough is just one example of cutting-edge technology that could be commonplace in the future -- reducing greenhouse gases and improving the air we breathe.” In addition to the economic and ecological advantages, gasoline-powered fuel cell technology has been long sought by the industry as a practical means by which automakers can realistically produce a new breed of cars by using the current $200 billion oil and gasoline distribution pipeline and infrastructure (e.g. trucking, service stations, etc.). “This invention will create new industries, and further leverages ADL's strength in recognizing a market breakthrough and mapping leading-edge product and service innovations to new industry opportunities,” said Charles R. LaMantia, CEO of Arthur D. Little. “The economic and market impact around this new capability is without precedence, and we are actively pursuing investors and venture capitalists in order to accelerate the pace at which we can bring this new technology to market,” he stated. “This is a great example of how we look carefully at the business strategy of each innovation, in addition to the scientific and engineering side of the equation,” said Jeffrey Bentley, inventor of this business concept and a vice president at Arthur D. Little. “Arthur D. Little recognized that auto manufacturers would only adopt this new technology if we could eliminate the risk associated with fuel availability,” he added.Fuel cells generate electricity through an electro-chemical process. The cell converts the chemical energy of hydrogen and air (oxygen) into electrical energy. The by-products of this process are water vapor and heat. This system produces negligible amounts of sulfur and nitrogen oxides and less than half the amount of carbon dioxide greenhouse gas compared to internal combustion engines. Because of the ecological and cost benefits of fuel cells, automakers have been scrambling to create a fuel cell technology to replace today's internal combustion engine. However, storing hydrogen, the key ingredient needed to produce the electricity that powers an on-board vehicle fuel cell, is not easily achievable in any practical or cost effective automotive system. By using gasoline in the on-board fuel processor, vehicles may now be able to house smaller gasoline tanks because of the increased efficiency of fuel cells. “This discovery is important in that it also incorporates a fuel flexible design,” stated Bentley. “Our fuel processor design is capable of converting a variety of hydrocarbon fuels such as gasoline and ethanol into hydrogen. Ethanol is commonly made from corn and offers great promise in the powering of electric vehicles. The operating cost of an automobile will also dramatically be reduced,” he added. The discovery is the result of a five-year program sponsored by the U.S. Department of Energy. The department partnered with Arthur D. Little, the project lead in advancing the development of on-board fuel processors and proving that fuel cell-based power systems are viable alternatives to traditional internal combustible engines. The State of Illinois and the Illinois Corn Marketing Board have also been partners in the development effort of creating new possibilities for cleaner and more efficient transportation for the 21st century. The Partnership for a New Generation of Vehicles (PNGV) is a cooperative research and development program between the federal government and the United States Council of Automotive Research (USCAR, a cooperative venture among Ford, General Motors and Chrysler). The goal of the PNGV is to develop technology that leads to a passenger automobile with 80 miles per gallon fuel economy. The Department of Commerce leads the PNGV with the Department of Energy providing major support. Arthur D. Little and Plug Power will work together under a $15 million cost-shared contract recently awarded by the Department of Energy to further develop this technology. Arthur D. Little, Inc. is an employee-owned global strategic consulting firm with more than 3,700 professionals in 30 countries. The Company links an organization's product and service innovation management, business process management, and knowledge management with its strategy to improve business performance. Arthur D. Little was founded in 1886 and its home page address is http://www.arthurdlittle.com. For further information on Arthur D. Little innovations in the automotive industry—http://www.adltranspotech.com Plug Power LLC is a joint venture of DTE Energy Co. (parent of Detroit Edison) and Mechanical Technology, Inc. (an early developer of fuel cell technologies). The company was created in June, 1997 to develop and manufacture fuel cells for automotive applications and residential electric power generation. For further information, call the company in Latham, NY at (518) 785-2200.
--------
233-> Discovery Suggests New Method To Halt Inflammatory And Autoimmune Diseases
DALLAS October 22, 1997 -- A steroid produced in the adrenal glands can halt production of a molecule integral to inflammatory and autoimmune afflictions such as rheumatoid arthritis and lupus, reported researchers at UT Southwestern Medical Center at Dallas. The scientists described their finding that the hormone glucocorticoid can inhibit expression of the tumor necrosis factor alpha (TNF-alpha) gene in the November issue of the journal Molecular and Cellular Biology. Glucocorticoid blocks an enzyme -- Jun n-terminal kinase (JNK)/stress-activated protein kinases (SAPK) -- that is part of the signaling pathway controlling cell behavior. "TNF has become a very interesting molecule because it plays such a central role in a variety of diseases, so anything affecting TNF production might potentially be a drug," said Dr. Thomas Geppert, UT Southwestern associate professor of internal medicine. "Current approaches to block TNF production are expensive and require repeated injections, but if we could come up with a pill that blocks TNF production it would be a real breakthrough." Previous research showed that glucocorticoids are among the most potent and clinically important immunosuppressant drugs, but it was not known how they inhibit inflammation. This research suggests a mechanism for this effect. "Glucocorticoids inhibit lipopolysaccharide (LPS)-induced TNF production," Geppert said. "It looks like steroids bar TNF production by blocking JNK activation. That is interesting because steroids play such an important role in the therapy of inflammatory disorders. Although steroids are frequently effective, they have significant toxicity. It is hoped a lot of that immunosuppressant effect of steroids might be through their effects on TNF and much of its toxicity might be mediated through other pathways." For example, although the glucocorticoids may decrease arthritis symptoms, they frequently cause osteoporosis, weight gain, cataracts, heart disease or diabetes because they regulate carbohydrate and protein metabolism, stimulate glucose production and elevate blood pressure. "Understanding how glucocorticoids work biochemically will lead to better drugs that don't have these side effects," Geppert said. Geppert's research team will next attempt to understand the mechanism by which steroids affect JNK activation. "We need to understand the whole signaling pathway in order to identify events that are unique to TNF production. If these events are specific to TNF production, drugs that inhibit them will be less likely to affect other signaling pathways leading to side effects. The development of drugs with the ability to block inflammation as well as steroids do but without the side effects is the dream of most physicians who deal with inflammatory disorders like arthritis, asthma or colitis." Other researchers who participated in the study were Dr. Melanie Cobb, professor of pharmacology and holder of the Jane and Bill Browning Jr. Chair in Medical Science, and Jennifer Swantek, research fellow in internal medicine. This study was funded in part by the American Heart Association.
--------
234-> Geologist Looks At Mystery Of Ancient Sea: Did The Iapetus Ocean Ever Exist?
Cincinnati -- Most people have heard about the mythical lost continent of Atlantis, but University of Cincinnati geologist Warren Huff is more interested in the disappearance of the ancient Iapetus Ocean, an ocean some believe may never have existed at all. During a presentation Wednesday, Oct. 22 at the annual meeting of the Geological Society of America in Salt Lake City, Huff will present evidence from ancient volcanic ash beds which he believes demonstrates a narrow Iapetus Ocean did exist during the Ordovician but closed off and disappeared by the Silurian 420 million years ago. "If you look at the younger beds 420 million years ago there is no more Iapetus Ocean," said Huff. "The question is whether there ever was one." The best way to determine whether the ocean existed is to look at the land masses which would have surrounded it. If large land masses were locked together, there would have been no room for an Iapetus Ocean to exist. If they were spread farther apart, the ocean would have filled the gap between ancient continents. There are three basic tools geologists have to determine how the ancient continents were spread out over the globe: paleo- magnetic data, the fossil record, and the ash beds left by massive, explosive volcanism. Paleo-magnetic data is difficult to interpret during the time period in question. The fossil record indicates strong similarities between what is now Texas and the southern Applachians and a portion of Argentina known as the Precordillera. Those similarities have led some geologists to argue that ancient North and South America were smashed together side by side. That would leave no room for the Iapetus Ocean. Huff and his collaborators have examined dozens of ancient volcanic ash beds, including 30 in the Argentine Precordillera. They find no similarities between ash beds in North and South America. "If two land masses were adjacent, the volcanoes should leave their mark on both continents," explained Huff. You ought to be able to find those ash beds and match them up. The problem is, when we go looking for volcanic ash beds down there of the same age as in the Appalachians, we don't find them." So, did the Iapetus Ocean exist? Huff says yes. "Based on our data, it was roughly 1,000 kilometers wide..about 600 miles." More important, Huff finds no evidence that North and South America were ever side by side. He explains the fossil similarities, using evidence collected by UC geology graduate student Maria Prokopenko. The evidence indicates part of North America broke away and eventually reassembled as part of South America. The fossils weren't formed in South America. They were carried there. "Maria is showing something rather interesting which we didn't know before. The volcanoes change their compositions during the time in which a whole series of these ash beds were being formed. That indicates the continent was shifting positions at the time." Huff believes the process is very similar to the modern day South Pacific where volcanic islands like Borneo and Sumatra are being driven toward Asia by plate tectonics. Huff's collaborators include Dennis Kolata of the Illinois State Geological Survey, Stig Bergstrom of Ohio State University and Argentine geologists Carlos Cingolani and Ricardo Astini.
--------
235-> Underwater Insects Tell The Tale -- Aquatic Invertebrates Provide Clues About The Case History Of Submerged 'Bodies'
NIKI MACDONELL SAYS the eight rotting pig carcasses she'll pull from streams and lakes in local forests next month hold important clues about deaths that occur in freshwater. For the past year, the Simon Fraser University graduate student in pest management has made routine visits to the clothed and submerged 'bodies' to study the life cycles of insects that colonize on them - everything from aquatic bugs to earthworms and even clams. Insects may be able to tell how long a body has been at a certain location, and whether it has been moved -vital information in determining the circumstances surrounding water-related deaths. With virtually no research in the field to draw on, Macdonell says pathologists are "basically taking an educated guess" when they estimate time of death in such cases. Macdonell examined 200 cases of freshwater deaths in B.C. in 1995/96, and now wants to see if what happens to the pigs is what happens to humans. "I'm trying to find out whether we can use some of these invertebrates to indicate a time line in deaths," says Macdonell. "It doesn't appear we'll be as accurate with these invertebrates as with those occuring on land. So little research exists that anything we learn will help." Macdonell identified more than 50 species of invertebrates and is now piecing together their activity patterns. She's found that populations are different between streams and lakes, for example, so determining where death occurred, if it's in question, is possible. Some aquatic insects are unpredictable, while others appear to be seasonal. "Unlike terrestrial insects, they may have other reasons for attaching themselves to bodies," adds Macdonell. "Bodies are a nutrient-rich source, but their decomposition and shape also make for great habitat." Macdonell, who wants to be a coroner, says the research will be useful, given the high number of water-related deaths in B.C. It's also groundbreaking. The first study of a body decomposing underwater took place in Tennessee only three years ago. No research has been done in Canada. In fact, Macdonell planned to remove her pigs months ago, figuring they would have decomposed by then. "We're still learning about this process in underwater situations," she says. Fascinated by forensic research as an undergraduate, Macdonell connected with SFU forensic entomologist Gail Anderson through the Internet. Anderson, who studies insect life cycles on murder victims' bodies, is well-known for assisting with local murder investigations. Her research includes studies of insects on clothed pig carcasses which have been buried or partially buried. Macdonell is also helping Anderson teach a course in forensic science, offered by the school of criminology. It's proving there are many who share Macdonell's fascination - the class has 85 students and a waiting list. 
--------
236-> Sports Scientists Say Weight Lifting Is Key In Preventing Severe Injuries
Writer: Karen Meisenheimer Source: MaryBeth Horodyski, (352) 392-0584 ext. 261 GAINESVILLE, Fla. --- University of Florida researchers studying football injuries at more than a dozen high schools have a message for coaches who want to keep players in the game: Hit the weight room. MaryBeth Horodyski, an assistant professor with UF's department of exercise and sports sciences, said a three-year study of athlete injuries shows that players who follow a controlled strength-training program reduce their chances of suffering from severe injuries. Seventy-eight percent of severe injuries to the upper body struck non-lifting athletes, or those students who were not in a controlled weight-lifting program, Horodyski said. And non-lifting athletes accounted for 64 percent of those with severe injuries to the lower body. "These are very significant numbers," said Horodyski, director of athletic training education at UF. "The bottom line is, those kids who did strength training typically did not have as severe injuries. They more often had mild or moderate injuries." Certified athletic trainers from UF are assigned to 13 high schools in north Central Florida along with physicians from Shands hospital at UF. The study's data includes 887 injuries to football players over the three-year span, allowing scientists to look at strength training and its effect on injuries. Researchers also examined injury incidence for spring football vs. fall football and other factors relating to sports injuries. Researchers defined a mild injury as anything that kept a player out of practice or a game for seven days or less. Downtime for a moderate injury was seven to 21 days, and a severe injury kept a player out of action for more that 21 days. "The take-home message for coaches is, they need to implement a well-structured strength-training program for their players throughout the entire season," Horodyski said. "It won't cut down on the total number of injuries, but time loss goes down drastically if the injuries are not severe." Horodyski said the number injuries to football players over the three-year period did not surprise scientists. National figures show that 25 to 50 percent of athletes playing football during a given year sustain some sort of injury. "We have roughly one-third of the players being injured," she said. "Football is a contact sport, and you would expect a high number of injuries." The UF study found defensive linemen are the most frequently injured, and the most common type of injury for all positions is a sprain, Horodyski said. Much fewer injuries were recorded during spring ball because typically it is not as intense as fall play, so players were exposed to fewer risks. However, Horodyski said they are concerned with the high number of concussions during spring practices. 	"We don't know why this is," she said. "It could be that new kids are trying to get on the team, and more head injuries occur when you have less-experienced players on the field." Keith Meister, an assistant professor with the department of orthopedics at Shands and a UF team physician, said football injuries follow a cyclical trend. "One year we'll see only one knee injury, while the next we'll have several," said Meister, who oversees residents from Shands' departments of orthopedics and family practice medicine who are contracted out to area high schools for all football games. "Conditioning and coaching are the two biggest factors we have seen that affect injuries." Jay Godwin, head football coach at Buchholz High School in Gainesville, said the availability of athletic trainers and physicians during games and practices translates to fast and accurate diagnosis when an injury does happen. "Strength training has become a big component in rehabilitation of injured players and in preventing injuries," Godwin said. "It seems the added emphasis on continuing weight workouts has made an impact." Godwin said upper body injuries, specifically shoulder separations, have increased during the last few years because of new restrictions against using the face and head to tackle or block, which are designed to protect the player's neck.
--------
237-> Hubble Space Telescope Reveals Stellar Fireworks Accompanying Galaxy Collisions
 NASA's Hubble Space Telescope has uncovered over 1,000 bright, young star clusters bursting to life in a brief, intense, brilliant "fireworks show" at the heart of a pair of colliding galaxies. "The sheer number of these young star clusters is amazing," said Dr. Brad Whitmore of the Space Telescope Science Institute, Baltimore, MD.  "The discovery will help us put together a chronological sequence of how colliding galaxies evolve.  This will help us address one of the fundamental questions in astronomy:  why some galaxies are spirals while others are elliptical in shape." "These spectacular images are helping us understand how globular star clusters formed from giant hydrogen clouds in space," added Dr. Francois Schweizer of the Carnegie Institution of Washington, Washington, DC.  "This galaxy is an excellent laboratory for studying the formation of stars and star clusters since it is the nearest and youngest example of a pair of colliding galaxies." By probing The Antennae galaxies (called The Antennae because a pair of long tails of stars formed by the encounter resembles an insect's antennae) and some of the other nearby galactic-scale collisions, Hubble is coming up with a variety of surprises: *  Globular star clusters are not necessarily relics of the earliest generations of stars formed in a galaxy, as once commonly thought, but also may provide fossil records of more recent collisions. * The "seeds" for star clusters appear to be huge clouds (tens of light years across) of cold hydrogen gas, called giant molecular clouds, which are squeezed by surrounding hot gas heated during the collision and then collapse under their own gravity.  Like a string of firecrackers being ignited by the collision, these reservoirs of gas light up in a great burst of star formation. * The ages of the resulting clusters provide a clock for estimating the age of a collision.  This offers an unprecedented opportunity for understanding, step-by-step, the complex sequence of events which takes place during a collision, and possibly even the evolution of spiral galaxies into elliptical galaxies. Earlier Hubble pictures show that nearly a third of very distant galaxies, which existed early in the history of the universe, appear to be interacting galaxies, like The Antennae.  In particular, the Hubble Deep Field (a "long-exposure" image from Hubble looking at galaxies far back into time) uncovered a plethora of odd-shaped, disrupted-looking galaxies.  They offer direct visual evidence that galaxy collisions were more the rule than the exception in the early formation period of the universe. These distant galaxy collisions are too faint and too small to study in much detail.  Astronomers say we are fortunate to have such a nearby example as The Antennae to study, since collisions between galaxies are relatively rare today.  "The degree of detail in these images is astounding, and represents both a dream come true and a nightmare when it comes to the analysis of such a large amount of data," Whitmore said. In addition to providing a window into how stars and galaxies formed in the dim past, the Hubble views also might offer a glimpse of the future fate of Earth's home galaxy, the Milky Way, when it either sideswipes or plows head-on into the neighboring Andromeda galaxy. The Hubble observations of The Antennae galaxies, as well as several other nearby colliding galaxies, were conducted by Whitmore and co-investigators Schweizer, Bryan Miller, Michael Fall, and Claus Leitherer over the past several years. Hubble's resolution and sensitivity allowed the team to uncover over 1,000 exceptionally bright young star clusters, sometimes called super star clusters, within The Antennae -- the prototypical galaxy smashup.  Ground-based images only were able to see the brightest of these clusters, and even in these cases were not able to show that the clusters were very compact with the sizes of normal globular clusters. Observing other galaxy collisions, the Hubble team discovered the presence of young star clusters which were very bright and blue in the case of ongoing collisions, but had faded to become fainter and redder for the older merger remnants.  This allowed them to place the snapshots of galaxy collisions into a chronological sequence. The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc. for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency.
--------
238-> UGA Researchers First To Determine That Leptin Causes Death Of Fat Cells
ATHENS, Ga. -- A team of researchers at the University of Georgia arethe first to determine that the hormone leptin causes the programmed death offat cells rather than simply reducing them in size. Their discovery helps explain why rats injected with leptin stay thinlong after treatment has stopped, and could play a significant role in the useof leptin for the treatment of obesity, according to Clifton A. Baile,distinguished professor of foods and nutrition and animal science at UGA. Research on leptin has exploded in the two years since it was firstdiscovered by Rockefeller University researchers. The hormone is produced by thebody's fat cells and travels through the blood stream to the brain. Animalstreated with leptin eat less, lose weight and expend energy at a higher rate. Pharmaceutical companies have invested hundreds of millions in researchon the use of leptin to treat obesity and it's expected that leptin-basedmedication will be available within five  years. The UGA team's findings about leptin's effect on fat cells began afterthe arrival of Dr. Hao Qian (pronounced Hall Chin), a post-doctoral fellow whojoined UGA a year ago after spending several months researching apoptosis --programmed death -- of cells in the spinal cord following spinal-cord injuries. In general, apoptosis is a routine process that occurs in most tissues.It is what causes leaves to fall from the trees in autumn and how the bodyeliminates diseased or unnecessary cells, such as a mother's milk-secretingmammary cells after a baby is weaned. Apoptosis was first introduced in the scientific literature in 1972;however, extensive research on the role it plays in a variety of organismsdidn't begin until 1992, which explains why Qian's hypothesis about leptin'srole in the destruction of fat cells was so novel. "When Hao first suggested that the fat cells' reaction to leptin lookedlike apoptosis, we didn't think he was right," Baile said. However, the teamdeveloped a series of experiments to test the hypothesis. In their research, the UGA scientists injected one group of rats withleptin, a second group was placed on a low-calorie diet, while a third was givennormal amounts of food and not treated with leptin. In comparing the DNA of the fat cells of rats treated with leptin andthe control groups, the fat cells of the leptin-treated rats clearly showedapoptosis. The DNA of the rats on the low-calorie diet and the control groupfailed to show any signs of apoptosis. "The only cells affected in the leptin-treated rats were the fat cells,"Baile said. "Cells in the liver, kidney and heart, as well as both smooth andskeletal muscle were not affected. This was true in male and female rats, youngrats and older rats. "A problem with most treatments for obesity is that once the treatmentis stopped, the individual begins gaining weight almost immediately," Baileexplained. "However, with leptin, that's not the case." Baile said it takes weeks for the leptin-treated rats to recover the fatthey lose. "We have had trouble finding any fat cells in rats within five days oftreatment," he said. The scientists will present their results Oct. 27-28 in San Diego at theAnnual Conference on Apoptosis. Some of the research also was presented at aSeptember workshop sponsored by the National Institutes of Health that focusedon the brain and fat cells.
--------
239-> New Drug Could Ease Shortages Of Crucial Blood Product
Denver, Oct. 20, 1997 -- Researchers at Washington University School ofMedicine in St. Louis announced today that a new drug may dramatically increasethe nation's supply of platelets, a chronically scarce blood product needed bymany cancer patients. A single injection of the drug, a synthetic human hormone calledPEG-rHuMGDF, can triple the number of platelets received from each donor, saysLawrence T. Goodnough, M.D., professor of medicine and of pathology at theSchool of Medicine. "Platelets are precious, and this drug could help ease theshortage," he says. Goodnough, a lead researcher in a multicenter study of thedrug, announced the findings today at the annual American Association of BloodBanks meeting in Denver. Platelets are blood cells that strengthen blood vessel walls and helpseal cuts. Healthy people have hundreds of thousands of platelets in each cubicmillimeter of blood. But chemotherapy and radiation therapy can quickly destroythe cells, leaving many cancer patients in dangerously short supply. Whenplatelets are low, microscopic vessels become weak and rupture easily. Patientscan have spontaneous nosebleeds, and merely brushing one's teeth can lead tosignificant bleeding. Today, platelet transfusions go hand-in-hand with chemotherapy. Thetransfusions are particularly critical for patients undergoing bone marrowtransplants, a procedure that usually involves heavy doses of chemotherapy. Itusually takes between four and 10 donations to collect enough platelets for asingle bone marrow transplant patient. Because Washington University School ofMedicine has one of the largest bone marrow transplant programs in the country,there's constant pressure on the stockpile of cells. "We have barely enoughplatelet donors to meet the current demand," Goodnough says. "Even people whodonate blood regularly don't realize the critical need for platelet donations." Platelet donors spend about 90 minutes hooked up to a special machinethat draws blood, spins it to separate platelets from other cells and thenreturns the rest of the blood back into the body. The machine processes aboutfour liters of blood, roughly the amount that most people have in their bodies.The procedure, called pheresis, is expensive. According to Goodnough, it costsabout $400 to harvest enough platelets for a single transfusion. Some patientsneed as many as 10 transfusions. Realizing that increasing the platelet payload from each donation wouldbe a boon to cancer patients, researchers began a multicenter trial ofPEG-rHuMGDF on volunteer donors. "Previous studies  had shown that the drughelped improve the recovery of platelets in patients undergoing chemotherapy,"Goodnough says. "We wanted to see if we could boost platelets in healthy peoplebefore they donated." The drug was developed by Amgen, Inc. of Thousand Oaks, Calif., abiotechnology company that also funded the study. Researchers at the Universityof Minnesota in Minneapolis and Massachusetts General Hospital in Boston alsoparticipated in the study. 
--------
240-> USGS Launches New Electronic Clearinghouse For Biological Data
Dr. Dennis B. Fenn, Chief Biologist, announced today (Oct. 21) that the U. S.      Geological Survey's Biological Resources Division has initiated a new      Internet-based clearinghouse that can be used to search for and locate      existing sources of biological data and information from a variety of      sources. This clearinghouse is part of the National Biological Information      Infrastructure (NBII), which is a cooperative effort led by the USGS      to increase access to biological data and information maintained by a      variety of Federal and State government agencies, universities,      museums, libraries, and private organizations. Through the NBII Clearinghouse http://www.nbii.gov/clearinghouse.html , Internet users can search      through an assortment of standardized descriptions of different      biological databases or information products to identify those that      meet their particular requirements.  These descriptions (metadata)      concisely convey such things as subject matter; how, when, where, and      by whom the data were collected; whom to contact for more information;      and how to access the database or information product. The NBII Clearinghouse includes metadata descriptions of biological      databases and information products developed and maintained by USGS      scientists, as well as data and information developed and maintained      by other NBII participants, including Federal and State government      agencies, universities, and private organizations.  The NBII      Clearinghouse also functions as a part of the National Spatial Data      Infrastructure (NSDI) Clearinghouse http://www.fgdc.gov/clearinghouse/index.html , as many of the      biological databases described in the NBII Clearinghouse employ      geospatial references. "We are very pleased to be offering this new service to the public,      resource managers and scientists, and anyone else interested in      locating existing sources of biological data and information,"  said      Fenn.  "This is a great opportunity not only for us to help get the      results of USGS biological science out to those who can use the data      and information, but also for us to provide a tool that our partners      and cooperators in NBII can use to help share their own data and      information." Users can search through the NBII Clearinghouse (much as they would      use a card catalog in a library) using a variety of criteria, such as      the name of the investigator or author who collected the data or      produced the information, subject-matter keywords, and spatial      coordinates for the location of the study/project.  Special biological      search criteria, including the ability to search for data or      information relating to a particular species or other taxonomic group,      are also provided. Metadata descriptions in the NBII Clearinghouse are developed      according to the NBII's biological metadata standard http://www.nbii.gov/current.status.html , which also serves as a      biological "enhancement" or "profile" of the Federal Geographic Data      Committee's Geospatial Metadata Content Standard. The mission of the USGS/BRD is to work with others to provide the      scientific understanding and technologies needed to support the sound      management and conservation of the Nation's biological resources.
--------
241-> Making The Crime Scene Blink: NIJ Asks Sandia To Develop Portable Evidence Finder
ALBUQUERQUE, N.M. -- Some evidence is hard to find, particularly the kinds ofevidence that can help police place the perpetrator at the scene of the crime --fingerprints, semen, urine, and other organic substances that carry clues to acriminal's identity. Now researchers at Sandia National Laboratories are developing anevidence-detection system that would -- with the aid of a flashing lamp and apair of modified 3-D video game goggles -- make organic substances appear toblink, allowing investigators to locate potential evidence more quickly and in alighted room if necessary. The National Institute of Justice, the research armof the Department of Justice, has provided $393,000 for the project. The researchers hope to begin testing a prototype of the system in 12 months andhave it available for licensing and manufacture in 18 months. The AlbuquerquePolice Department's crime lab has agreed to test a prototype system at actualcrime scenes. "If it works, this system would give us the ability to see things we haven'tbeen able to see more quickly and in ambient light," says APD CriminalisticsDirector Ann Talbot. An important feature of the system is its affordability, says Dave Sandison,lead researcher for the project. "We don't want to develop something the FBIwould have two of and nobody else could afford," he says. "It would beaccessible to police departments everywhere." The approach originates from a Department of Energy-sponsored weapons securityproject. Less thinking when it's blinking To locate certain organic evidence, fingerprints for example, police typicallyrely on optical aids such as powders, lamps giving off various wavelengths oflight, and yellow-tinted goggles that increase the evidence's visibility. Evenwith these aids, investigators typically must conduct their investigations atnight or in a darkened room. It can take hours to scour every inch of a crimescene. Most fingerprints that are discovered are lifted from smooth surfaces such asglass windows or polished furniture, says Talbot. Latent fingerprints on wallsand other textured surfaces are more difficult to find, and some kinds oforganic evidence, such as semen or urine, don't show themselves even withoptical aids. Sometimes fluorescent dyes are used in situations where they won't contaminateother evidence, but rarely and as a last resort. "If you use chemicals, youtypically have to spray down the entire room," Talbot says. "That can getexpensive." A lot of potential evidence can go unnoticed, she says. Sandia's proposed evidence-detection technique relies on the fact that all typesof organic substances give off weak fluorescent emissions, normally invisible tothe naked eye because other, much brighter sources of light interfere. Theproposed system takes advantage of the periodic dissonance between two signalsat slightly different frequencies -- an effect called heterodyning -- as well asthe human eye's natural affinity to anything that moves or blinks."We like to say, "There's less thinking when it's blinking," " says Sandison. On, off, on, off, on, off In a nutshell, the system's lamp is modulated at a specific frequency, say 100times per second, which is to say it flashes at a rate too fast for the humaneye to detect. The glasses, modified from a 3-D video game, shutter open andclosed at a slightly different frequency, say 102 times per second, whichessentially turns the user's eyes on and off at a rate also too fast to bedetected by the human eye. To the wearer, the lenses appear transparent.Every so often, about twice a second, the glasses shutter open at the exactmoment the lamp is "on," which for a split second drowns out most backgroundlight whose wavelengths are different than that of the lamp. With the backgroundlight masked, the net effect is that the fluorescing materials appear to flashbrightly at a rate that is distinctly noticeable to the human eye. From behind the shuttered glasses, the crime-scene investigator would see theroom lighted normally, but any organic substances would flash a few times persecond when illuminated by the system's lamp. It's like the combined sound two jetliner engines make, every once in a whilehumming in harmony and alternatingly reverberating in discord. The engines humwhen the acoustic wavelengths match up. They clash when they don't.The researchers may also test the system using a low-light video camcorder thatis more sensitive to the fluorescence than the human eye. Law enforcement practicality The APD crime lab tests are intended to help work out any bugs in the technique,define what kinds of evidence it can help find, and determine whether the systemwill be practical as a law enforcement tool. "Who knows, we may turn the system on and see thousands of fingerprints," Talbotsays. "If we see too much, we won't be able to sort out the real evidence."But if it works with some discretion and it's portable, it would be useful tous on a fairly frequent basis. The beauty of this approach is that it doesn'tcontaminate other evidence." It may be particularly useful at sexual assault crime scenes for identifyingsemen, which fluoresces much more brightly than the oils from fingertips. Theresearchers also hope to determine whether fresh fingerprints fluoresce morebrightly than organic substances that have been there for awhile. If so, thesystem might be good at screening out evidence that isn?t pertinent to aninvestigation. A related system is being used by a private company for detecting cancerouslesions in tissue samples. And Molecular Technologies Inc. (run by Ned Godshall,a Sandia researcher on entrepreneurial leave-of-absence) has appliedfluorescence to the problem of DNA sequencing. The heterodyning techniqueoriginates from an early 1990s Sandia weapons security project. Sandia is a multiprogram Department of Energy laboratory operated by LockheedMartin Corp. With main facilities in Albuquerque and Livermore, Calif., Sandiahas research and development programs contributing to national security, energyand environmental technologies, and economic competitiveness. 
--------
242-> Dinosaur Footprints Trek Across The Southwest
Salt Lake City, Utah -- The ghosts of dinosaurs still wander the vast openspaces of the American Southwest, as suggested by their fossilized footprints, aPenn State paleontologist said today (Oct. 20) at the annual meeting of theGeological Society of America in Salt Lake City. The elusive, giant beasts left a legacy 180 million years ago that cannow be seen at Pipe Spring National Monument near Moccasin, Ariz., along theUtah border. This monument preserves an historic fort and structures built byMormon pioneers during their settlement of the Southwest. "At many localities, dinosaur footprints are mentioned in theliterature, but no one has documented them," said Dr. Roger J. Cuffey, professorof paleontology in Penn State's College of Earth and Mineral Sciences. "Thereare more than 25 mentions of dinosaur prints in rocks of the same age as PipeSpring, but only 7 or 8 have been adequately published." Cuffey wasn't looking for new footprints at Pipe Spring. He was tryingto take a photograph of a dinosaur footprint reported there for hisundergraduate class in dinosaurs. "In a 1988 booklet on where to go to see dinosaurs, Professor WilliamLee Stokes mentioned a natural cast of a dinosaur footprint at the visitor'scenter at Pipe Spring National Monument," said Cuffey. "The people at the parkthought the cast was in storage, but asked me if I'd seen the dinosaurfootprints in place on the mesa." The footprints are on a mesa behind the ranch buildings, and are from athree-toed beast. They were only discovered in the mid-1990s. Two of thefootprints are nearly side by side about 1.5 feet apart and the other footprintis 8 feet in front. "I thought that these prints should be documented," said Cuffey. "Andthat they would be a good undergraduate project." Two undergraduates, Maria Di Nardo and Bryan Herzing, who have bothsince graduated, worked on identifying and documenting the footprints for seniortheses. Their literature search turned up a sizeable number of documented printsfrom the same period -- the early Jurassic -- in Connecticut and Massachusetts,but very little about footprints in the Navajo sandstone in the southwest. "The trackway was laid down at the base of the orange Navajo sandstoneat a time when that area was two or three days walk -- for a dinosaur -- fromthe shoreline to the west," said Cuffey. "The area was a desert created bywind-blown sand coming from the east, although there would have been a few smallponds of water between dunes for drinking." The Penn State scientist and his students compared the Pipe Springfootprints with outlines of other dinosaur footprints found elsewhere to try toidentify the animal that made them. He is fairly certain that they were made bya theropod, and most probably the kind known as Eubrontes. "Because of the 8-foot length of the stride, this was a medium   tolarge dinosaur," said Cuffey. The theropods include both the enormous Tyrannosaurus Rex and the nowfamous velociraptors as well as some smaller scavenger dinosaurs and medium-sizecarnivores. "One thing we did find out, was that the nice, clear outline drawings ofdinosaur prints are rather difficult to match to the ragged and somewhat blurrededges of the actual footprints," said  Cuffey. "A precise identification at thistime is therefore elusive." While the exact pedigree of the dinosaur tracks is still unknown, theyshould be available for viewing for quite a while. Currently, the Pipe SpringNational Monument personnel go up every few months to sweep away the fine gravelthat periodically blows across and obscures the prints. Cuffey has suggested tothe National Parks Service that a fence or railing be installed so that thefootprints can be viewed, but no one can inadvertently step on or damage them.
--------
243-> Small Molecule Blocks Cell-Surface Receptor Needed For HIV-1 Infection Of T Cells: New Generation Of Combination Therapies Suggested
In May and June of last year, scientists discovered severalnew receptors on the surface of immune-system cells that arerequired -- along with the long-known CD4 receptor -- forHIV-1 to enter and infect those cells. Now, little more thana year later, researchers at the University of PennsylvaniaMedical Center and the University of Texas Medical Branch atGalveston have identified a small molecule that blocks oneof these so-called coreceptors, preventing infection by anumber of the HIV strains that target T cells. These strainsof the virus are associated with progression from relativelyasymptomatic HIV infection to the disease AIDS. The discovery suggests that novel combination therapiesthat inhibit the full set of coreceptors could well proveeffective in preventing or treating HIV infection and AIDS.The findings are reported in the October 20 Journal ofExperimental Medicine. Two additional papers announcingsimilar results appear in the same issue. "The importance of these studies is that theyprovide proof of principle," says coauthor Robert W. Doms,MD, PhD, an assistant professor of pathology and laboratorymedicine at Penn in whose laboratory many of the experimentswere conducted. "They show that we can develop smallmolecules to inhibit these newly identified coreceptors thatHIV absolutely needs to get into cells, thus preventinginfection." The inhibitory molecule investigated in the study is asmall peptide called ALX40-4C, the anti-HIV activity ofwhich was first noted last year by senior author William A.O'Brien, PhD, at Galveston. Lead author Benjamin J.  Doranz,BA, a researcher in Doms' laboratory, performed experimentsindicating that ALX40-4C operated by blocking one of thecoreceptors, CXCR4, which is used by the strains of HIV thatinfect T cells in the later stages of disease progression,known as T-tropic viruses. Another coreceptor, CCR5, is usedby viral strains that show a predilection for macrophages inthe earliest stages of infection, referred to as M-tropicviruses. Over time, in an infected person, viruses evolvefrom using CCR5 to using CXCR4, from M-tropic to T-tropic. In one set of experiments, seven of ten strains of HIVisolated from patients by O'Brien used the CXCR4 coreceptor,and three of these relied on CXCR4 sufficiently to beblocked by ALX40-4C. "One or more small molecules like this might delay orprevent evolution of the virus from using CCR5 to usingCXCR4," Doms says, noting that it is the viral strains thatuse CXCR4 that correlate with dropping T-cell counts andprogression to AIDS. "We also hope to develop small-moleculeinhibitors of CCR5, the receptor used by viruses that startan infection. To be fully effective in countering HIV, wemight need a cocktail that included a small-moleculeinhibitor of CCR5 in conjunction with one against CXCR4." In addition to Doranz and Doms, the third Penn-basedcoauthor is Matthew P. Sharron, BA. Other coauthors on thepaper include Kathie Grovit-Ferbasi, Si-Hua Mao, and MatthewB. Goetz at the West Los Angeles Veterans Affairs MedicalCenter and the University of California at Los AngelesSchool of Medicine. Eric S. Daar with the Cedars-SinaiMedical Center and the UCLA School of Medicine is also acoauthor. ALX40-4C is manufactured by Allelix Inc.,Mississauga, Ontario, Canada. Grant funding for this work was provided by theNational Institutes of Health. Doranz was supported by apredoctoral fellowship from the Howard Hughes MedicalInstitute. The University of Pennsylvania Medical Center'ssponsored research ranks fifth in the United States, basedon grant support from the National Institutes of Health, theprimary funder of biomedical research in the nation -- $149million in federal fiscal year 1996. In addition, for thesecond consecutive year, the institution posted the highestgrowth rate in its research activity -- 9.1 percent -- ofthe top ten U.S. academic medical centers during the sameperiod.
--------
244-> State Officials Fear Imported Animals Might Introduce Deadly Tick-Borne Livestock Disease
GAINESVILLE---A University of Florida professor and the state veterinarian saylarge African tortoise ticks found on imported reptiles in Florida could carryand spread heartwater, an exotic disease that kills livestock and wildlife. To prevent a heartwater epidemic in the United States, they want to improvetesting procedures for imported wildlife and develop methods to detect ticks onreptiles. "Finding African ticks -- almost by accident -- on imported tortoises is awake-up call," said Michael Burridge, professor and veterinarian with the UF's Institute of Food andAgricultural Sciences. "It shows how easily pests that transmit the disease could get intoFlorida and the United States." Sandra Allan, a UF/IFAS assistant scientist who works withBurridge, identified the African ticks, which are twice the size of native ticks, on an injuredtortoise brought to the UF College of Veterinary Medicine by a Florida reptile breeder. Heartwater, which already has spread from Africa to the Caribbean, is considereda serious threat to livestock and wildlife in the United States. Heartwater attacks bloodvessels, particularly in the brain, causing fluids to accumulate in the lungs, around the heart and in thechest and abdomen. There is no practical treatment for heartwater once the disease is evident. Onceinfected, up to 90 percent of susceptible animals die. The disease does notaffect humans, horses or household pets such as dogs and cats, and it cannot betransmitted by eating meat or drinking milk from infectedanimals. "Heartwater will devastate the cattle, sheep and goat industries. If it getsinto the wild deer population, it would be impossible to eradicate," Burridge said. He now is working with Leroy Coffman, the state veterinarian with the FloridaDepartment of Agriculture and Consumer Services, to develop additional measures to keepheartwater-carrying ticks out of the country. They also are working with the Florida Game and FreshWater Fish Commission,  the U.S. Department of Agriculture Animal and Plant HealthInspection Services and other agencies to deal with the problem. "We must make the message clear," Coffman said. "This is a List A disease, whichmeans it's as serious as it gets. From a regulatory standpoint, it's one of the most importantanimal diseases in the world. The message here is that we must work together to close the door onthis disease." Florida Agriculture Commissioner Bob Crawford shares the concerns of Burridgeand Coffman about the heartwater threat and said finding ticks on imported tortoisesincreases the risk the disease will find its way into Florida. He has asked U.S. Secretary ofAgriculture Dan Glickman for help in fighting the threat of heartwater disease to the state and nation. "The department has already formed an interagency team to evaluate and findsolutions to this problem in Florida," Crawford said. "I strongly encourage the formation of anational working group to address heartwater disease." Burridge said the problem is driven by a growing market for exotic animals andreptiles imported from other countries. He urged veterinarians and other animal-careprofessionals, especially those working with imported animals and reptiles, to be on the lookout for ticksand said any unusual ticks should be sent to Allan at UF for identification. "Fortunately, in this case, the African tortoise ticks have not spread from theoriginal infested site in Florida," Burridge said. "But, this is just one isolated case in a statewhere thousands of animals are being imported every year. If we don't do something right away toprevent the introduction of exotic ticks, it's only a matter of time before they will becomeestablished in this country." Another complication, Burridge warned, is the native Gulf Coast tick. NewUF/IFAS research shows this tick, common in the southeastern United States, is capable oftransmitting heartwater disease under experimental conditions. The tropical bont tick has spreadheartwater in the Caribbean. He said the disease could also enter the country with infected animals importedfor zoos or conservation and breeding purposes. The disease is widespread in livestock andwildlife in Africa. Animals may look healthy, but some still can carry the disease. "We must keep exotic ticks out of the U.S. and make sure imported animals arenot infected with heartwater," Burridge said. "Imported animals can be screened for the diseasewith a new test we have developed, and I believe the time has come to begin using it." Burridge and UF/IFAS researchers are developing two new heartwater vaccines thatappear to be effective in preventing the disease. The first is a conventional inactivatedvaccine being tested in Africa by Suman Mahan, a UF/IFAS veterinary scientist.The second is a genetically engineered vaccine being tested by Anthony Barbet, a UF/IFAS molecular biologist inGainesville. UF/IFAS researchers also have developed a tick decoy, similar to a pet fleacollar, to control ticks on livestock. For deer and other wildlife, they have developed a feedingbin that applies pesticide to animals when they brush against the dispenser. Coffman said the exotic tick is yet another example of how increased commerceand mobility can bring new pests and diseases to the state and nation. He cited theMediterranean fruit fly, citrus canker, and  tomato leaf curl virus as other examples. 
--------
245-> Breakthroughs In Interstitial Cystitis
Nearly half a million women in the United States suffer from interstitial cystitis (IC), a chronic bladder disorder for which there is no cure and whose diagnosis involves a process so painful it can require general anesthesia. Dr. Susan Keay, associate professor at the University of Maryland School of Medicine, has identified two factors that could lead to a better understanding of the disease, as well as less painful methods of diagnosis and more effective treatment. Keay’s first discovery, presented at the recent meeting of the American Urogynecologic Society, determined that an antiproliferative peptide specifically present in the urine of IC patients inhibits bladder epithelial cell proliferation and regeneration. Based on this finding, she and her colleagues hypothesized that IC may result from impaired of regeneration these cells. Parts of the bladder wall that are void of epithelial cells are more prone to inflammation and disease. The presence of this antiproliferative peptide in the urine of IC patients suggests that a simple test for the presence of this peptide could significantly reduce the need for cystoscopy and bladder biopsy. Her second discovery, published in the November, 1997 issue of the Journal of Urology, revealed that urine specimens from IC patients show alterations in the levels of certain epithelial growth factors, including a strikingly low concentration of HB-EGF, a contributor to epithelial cell growth, when compared to urine specimens from asymptomatic controls or patients with other forms of urogenital disease. This discovery further supports Keay’s hypothesis that IC may result from the inhibition of epithelial cell growth and regeneration. In addition to publication, she will present this work at the upcoming International Symposium on Interstitial Cystitis, co-sponsored by the Interstitial Cystitis Association and the National Institutes of Health. "IC is very difficult to diagnose, and even more difficult to treat," says Keay. "Women often believe they have or are misdiagnosed as having a recurrent urinary tract infection, but because IC does not appear to be caused by bacteria, it doesn’t respond reliably to conventional antibiotic therapy. This can mean years of suffering. IC is an extremely painful, long-term, life-style altering problem that can continue for decades." Through the University of Maryland’s Office of Technology Development, Keay is working with scientists at UroCor, a leading urology disease management company which markets directly to urologists and managed care organizations a comprehensive range of integrated products and services designed to assist in detection, diagnosis, treatment and management of complex urological disorders including IC. Under the arrangement, UroCor is providing funding to further Keay’s research into the antiproliferative peptide. UroCor is responsible for development of commercial products based on this research and its clinical validation, and would have the to right to exclusively license related processes and products resulting from her work on the antiproliferative peptide. IC has no available cure at this time and no single treatment seems to work for everyone. There are a number of different treatments available. Sometimes treatment may be as simple as following prescribed dietary changes. In other cases, anti-inflammatory oral medications or even surgery are prescribed. It is initially diagnosed by ruling out other diseases that mimic its symptoms, including bladder cancer, sexually transmitted diseases, endometriosis, radiation cystitis, kidney problems, or vaginal infections. Cystoscopy involves the insertion of a cystoscope into the urethra and up to the bladder,  which is then distended by filling it with a liquid or gas, and can detect the kinds of inflammations, ulcers and pinpoint bleeding that indicate IC. Without anesthesia, this process is limited by either pain or a severe urge to urinate. A biopsy of bladder and urethra tissue is often removed during cystoscopy to help rule out bladder cancer and confirm bladder wall inflammation. Dr. Keay and her colleagues at the University of Maryland School of Medicine, Drs. John Warren, Harry Johnson, Jr., Richard Marvel and Toby Chai, have formed an IC Clinic to study the causes of and research treatments for this painful, enigmatic disease. For more information on how to participate in research on interstitial cystitis, call 410/706-7560.
--------
246-> NCAR Research Turns Commerical Aircraft Into Turbulence Sensors
BOULDER--Since mid-September, researchers at the National Center for Atmospheric Research (NCAR) in Boulder, Colorado, have been turning commercial aircraft into in-flight "sensing platforms" to measure and report turbulence. With funding from the Federal Aviation Administration (FAA), NCAR scientist Larry Cornman and his colleagues have created software that works with an aircraft's existing equipment to measure and report in-situ (in-flight) turbulence once every minute. United Airlines expects to deploy the software on more than 200 aircraft over the next six months. The data will be used to create turbulence forecasts to help pilots steer clear of bumpy air. NCAR's primary sponsor is the National Science Foundation. Until now, the only data on turbulence--the sudden, invisible gusts that buffet a plane and its passengers--came from pilot reports of bouncy or choppy air. "If we'd tried to come up with a new sensor to load onto the aircraft, it would have been too costly," explains Cornman. Part of that cost comes from testing new equipment to ensure that it does not affect flight operations. "So we looked for a way to use sensors, computers, and communications systems that were already on board, without interfering with their normal functions." Instead of measuring turbulence directly, the researchers use the aircraft's response to turbulence to deduce its magnitude. "We're solving an inverse problem," says Cornman. "If I measure what the aircraft's doing, I can infer what the turbulence must have been." The result is an in-situ turbulence algorithm, or mathematical problem-solving procedure, that uses measurements of how much the aircraft is bouncing up and down while accounting for its weight, air speed, altitude, and whether the plane is on autopilot or not. The algorithm is incorporated into software installed by Allied Signal, Inc., within Allied's onboard flight management system and aircraft condition monitoring system. The data are then transmitted to an FAA/National Weather Service (NWS) data base. On average, a significant turbulence incident happens every other day on a commercial flight somewhere in the United States. The result can be everything from spilled food trays to broken bones for flight attendants and passengers not buckled into their seats. In 1991, severe turbulence tore the engine off a 747 cargo plane departing the Anchorage airport. While a cause for the crash of United Flight 535 on final approach to Colorado Springs airport in 1991 has never been determined, turbulent winds and a rudder problem are thought to be the most likely explanations. Cornman and other scientists will use the data compiled on the FAA/NWS data base to create a turbulence detection product--a view of flight tracks showing what all of the aircraft in a given region have measured in a 30-minute period. That flight track information will be provided to United Airlines (and to other airlines as they become participants in the future), as well as to the NWS Aviation Weather Center in Kansas City, Missouri. As more aircraft report more data, Cornman expects forecasting products to improve to the point that "nowcasting," or turbulence warnings in real time, will be possible. "Having such a comprehensive and accurate data base will really boost our development of new forecasting tools," Cornman explains. The International Civil Aviation Organization (ICAO) will compare results from the U.S. in-situ turbulence detection program to ongoing research at the Australian Bureau of Meteorology. ICAO's goal is an international standard for turbulence measuring and reporting. NCAR is managed by the University Corporation for Atmospheric Research. -The End- Writer: Zhenya Gallon Find this and other UCAR news releases on the World Wide Web athttp://www.ucar.edu/ucargen/press/contents.html To receive UCAR and NCAR press releases by e-mail,telephone 303-497-8601 or e-mail butterwo@ucar.edu
--------
247-> Clues To Horse Extinction Point To Gritty Grass, Climate Change
Johns Hopkins paleobiologist Steven Stanley has sleuthed out clues to the evolution of horses, coming up with a new solution for an enduring mystery: What caused the extinction of many equine species and other mammals 6 million years ago? Like the protagonist in an evolutionary detective thriller, Stanley pursued a hunch that apparently had never occurred to other scientists. His long shot hit a bull's-eye, enabling Stanley to learn how shifting climate and changing vegetation likely altered the fate of horses in North America millions of years ago. Stanley, a professor in the Johns Hopkins Department of Earth and Planetary Sciences, pieced together the findings of other scientists and connected those data in a way no other researchers had done previously. When taken together, the data paint a picture of how Earth's changing climate and vegetation may have been directly involved in the dramatic evolutionary trends of horses and other animals. The time was marked by the largest extinction rate of North American mammals in the last 30 million years; about 60 genera, containing numerous species, perished. Some scientists believe that changing atmospheric concentrations of carbon dioxide could have helped bring about the climatic shifts that Stanley believes were directly linked to changes in the vegetation thriving in North America. Because the extinctions apparently were brought about by those changes in vegetation, the lesson is that carbon dioxide-linked global warming -- if it is occuring again today as many scientists believe -- could have a profound impact on future extinction rates. Stanley will touch on his theory during a 1:35 p.m. talk on Sunday, Oct. 19, at the start of the annual meeting of the Geological Society of America. The talk will be in the Salt Palace Convention Center, in Salt Lake City, Utah. Contrary to the popular belief that horses were foreign to the New World until they were brought here by the Spaniards, the animals actually evolved in North America, spreading to Europe by crossing the Bering land bridge that once connected Alaska and Siberia. But they later died out in North America near the end of the Ice Age. Well before their disappearance, however, their life history took an abrupt turn that killed off all but those horses with the longest teeth. In fact, numerous other mammals, including camels and rhinos, suffered the same fate in North America. Scientists have known that the extinctions were somehow related to expanding grasslands and shrinking forests. Grasses possess a gritty compound called silica, which is contained in sand and is used to make glass. As animals chew grass, the silica wears down their teeth. Therefore, animals with longer teeth live longer because their teeth don't wear down as fast, and they can continue to feed. For tens of millions of years, as the Earth's climate became cooler and dryer, the trend toward expanding grasslands and receding forests continued in North America. About 13 million years ago, the 15 or so species of horses in North America were split between those with long teeth and those with shorter teeth. Also at that time, a few new species emerged that had very long teeth. As grasslands expanded, the horses with long teeth lived longer because they were best adapted to eating grasses instead of leaves. Living longer enabled them to produce enough offspring to guarantee survival of their species and the evolution of new species. By 11 million years ago, only the horses especially adapted to eating grasses -- those with the long and very long teeth -- were living in North America. "Then, there is this sudden event, 6 million years ago, more or less, and what you see is a big extinction pulse, a big drop in total diversity, and the survivors are all the ones with very long teeth," Stanley said. The conventional wisdom has suggested that the long-toothed horses disappeared because of expanding grasses. But that just didn't make sense, Stanley said, because the horses with long teeth were especially adapted to eating grasses. "So, why would more grass be a problem for them?" Stanley asked. Somehow, something about the grasses must have changed, he reasoned. Meanwhile, other scientists had discovered that, as the climate became dryer and cooler, a different type of grasses began to dominate North America. Those grasses, known as C-4 grasses, which thrive in dryer climates, replaced many of the previously dominant grasses, known as C-3 grasses. "I thought, well, this seems like a long shot, but I wonder if there are on average more silica bodies in the C-4 grasses than C-3 grasses," Stanley said. His hunch proved correct. Stanley found that, on average, C-4 grasses contain about three times as many of the silica particles as do C-3 grasses. "Think about a species that was doing all right eating C-3 grasses. Maybe it lived 10 years on average and produced enough colts to reproduce the species. Well, what happens if that horse is suddenly only living seven years, or six years? It may not produce enough colts to perpetuate its species. "I think that's what happened. I think there was a big grind down." The title of his talk is, "Geobiology: Studying the deep history of the earth-life system."
--------
248-> Shuttle Landing Simulations To Improve With Smart Software
Even after each pilot astronaut makes 500 practice landings with a training aircraft that simulates the Space Shuttle Orbiter, landing the actual Shuttle for the first time is a challenging task.  To assist future Shuttle pilots, NASA will install new, intelligent software in the training aircraft to make its approach and landing 'feel' even more like a Shuttle landing. "Tests of the smart software in simulators on the ground with the Shuttle Training Aircraft hardware were extremely successful, proving that the trainer airplane using new computer coding will seem a lot more like a Shuttle as it comes in and lands.  Landing an orbiter for the first time will seem a lot more familiar to astronauts," said Dr.  Hamid Berenji, software project manager at NASA's Ames Research Center, Moffett Field, CA. The improvements are detailed in a technical paper recently presented in Barcelona, Spain.  Authors were Berenji and  Dr. Ping-Wei Chang, computer scientists at Ames, and Steven R. Swanson of the Shuttle Training Branch at the Johnson Space Center, Houston, TX. "In keeping with one of NASA's major goals to increase flight safety, the new software could be used to improve all kinds of simulators, from airplanes to simulations done in special machines," said Berenji. "We think private pilots, commercial pilots and even people learning to operate new machines could greatly benefit if the software is used to improve training simulators," he explained. The new software to be installed in the Gulfstream II Shuttle Training Aircraft refines the 'rules' that onboard computers use to simulate the Orbiter's descent from 35,000 feet to landing. The special software uses a form of 'adaptive fuzzy logic' that programs a computer with words as well as with numbers, explained Berenji.  In addition, it uses 'neuro fuzzy logic' to learn by experience, changing the patterns it uses to make decisions. Berenji says the new software is closer to human thinking than previous software, and computers equipped with neuro fuzzy logic can accurately be called rudimentary mechanical brains. Ground tests show that the trainer aircraft will handle about 20 percent better than before, according to Berenji.  This equals a 69 percent error reduction.  "We expect that new astronaut-pilot confidence will be much higher," he said.  "That means Shuttle safety will be improved,  too," he added.
--------
249-> AIDS Vaccine Program At St. Jude Children's Research Hospital Gets First Step FDA Approval
MEMPHIS, Tenn., October 17, 1997-- In the first step of a multi-tier AIDS vaccinedevelopment program at St. Jude Children's Research Hospital, the Food and DrugAdministration (FDA) has approved a Phase I safety trial of a new AIDS vaccinedesigned to trigger immune responses to multiple, differing isolates of HIVusing the harmless outer coating of HIV known as the envelope. Envelope vaccines have been shown in other laboratories to protect safelyprimates challenged with an immunodeficiency virus sharing the same HIVenvelope, as illustrated in August by research reported in the Proceedings ofthe National Academy of Sciences by scientists at Harvard Medical School.  TheSt. Jude multi-envelope AIDS vaccine strategy is unique in combining 23different envelopes that represent many different isolates of HIV. "Our ultimate aim is to discover the number and mix of HIV proteins, gatheredfrom HIV isolates found throughout the world, which will be effective inpreventing infection regardless of the isolate to which people are exposed,"says Julia Hurwitz, Ph.D., a co-developer of the St. Jude multi-envelope AIDSvaccine with Karen Slobod, M.D., respectively of the Departments of Immunologyand Infectious Diseases at St. Jude Children's Research Hospital. The Phase I safety trial approved in September by the FDA will get underwayimmediately, beginning with the recruitment and evaluation of 9-18 eligible,healthy human volunteers, and is expected to last one to two years. "At St. Jude Hospital we are very proud of the progress Drs. Slobod, Hurwitz andtheir colleagues have made in bringing the St. Jude multi-envelope AIDS vaccineto its first trial and they have our strongest possible support as they andtheir colleagues continue to pursue an AIDS vaccine," said Arthur W. Nienhuis,M.D., Director of St. Jude Children's Research Hospital. Although every viral envelope consists of proteins called gp120 and gp41, eachenvelope looks different to the immune system because the proteins vary, muchlike human faces differ from each other. These differences have been an obstacleto vaccine development. Scientists at St. Jude Children's Research Hospital have built upon theknowledge obtained by other vaccine research groups to select the buildingblocks -- or backbones -- for their HIV vaccine.  One backbone is the smallpoxvaccine that globally eradicated smallpox in humans by the late 1970s.  St. JudeChildren's Research Hospital is using 23 different HIV envelopes each containedin a smallpox vaccine backbone to constitute the first component of the St. Judemulti-envelope AIDS vaccine. The St. Jude research team is also developing vaccine boosters as part of thevaccine program.  Boosters include a DNA vaccine in which injected DNA promptsthe production by the body's cells of envelope proteins that then stimulate theimmune system.  The DNA vaccine strategy was co-developed by Robert Webster,Ph.D., chair of the Department of Virology and Molecular Biology at St. JudeChildren's Research Hospital.  Drs. Slobod and Hurwitz may also deliver abooster of purified envelope proteins. The incorporation of many envelopes in the St. Jude multi-envelope AIDS vaccinestrategy is aimed at representing a cross section of virus envelopes that haveemerged in developing and developed regions of the world during the 15-yearglobal epidemic. Collecting the HIV envelopes, isolating the envelope sequencesand other related research efforts were initiated at St. Jude Children'sResearch Hospital four years ago. "Although complete implementation of this vaccine strategy will take years, weare moving as quickly as possible without sacrificing attention to safety,quality and the St. Jude commitment to excellence," says Dr. Slobod. While testing the safety of the St. Jude multi-envelope AIDS vaccine during theupcoming Phase I trial, the St. Jude research team will also measure volunteers'immune system response to the vaccine by evaluating their B cell (antibody) andT cell (cellular) immune responses.  These data may be a preliminary indicationof volunteers' expected immune response to the vaccine during later trials.  TheSt. Jude team constructed the vaccine in a manner that will permit determinationof whether immune system responses are the result of vaccination or actual HIVinfection unrelated to the vaccination. Since the late 1980s, St. Jude Children's Research Hospital has also been activein developing treatments for children with AIDS.  It is part of the AIDSClinical Trial Group, a national cooperative research network which allowspediatric AIDS researchers across the country to share resources andinformation. St. Jude Children's Research Hospital, in Memphis, Tenn., was founded by thelate entertainer Danny Thomas.  The hospital is an internationally recognizedbiomedical research center dedicated to finding cures for catastrophic diseasesof childhood.  The hospital's work is primarily supported through funds raisedby the American Lebanese Syrian Associated Charities (ALSAC).  All St. Judepatients are treated regardless of their ability to pay.  ALSAC covers all costsof treatment beyond those reimbursed by third party insurers, and total costsfor families who have no insuran 
--------
250-> University Of Illinois At Chicago Pioneers Large-Skull Implant Design And Surgery
Experts at the University of Illinois at Chicago have pioneered a new procedure to repair the skulls of persons who have undergone brain surgery or have suffered serious head trauma, including gunshot wounds. Until now, little could be done for persons with holes in their crania larger than three square centimeters. UIC neurosurgeons recently performed large-skull implant surgery on a 35-year-old man who had been missing the front of his skull from above the eyes and from ear to ear (115 square centimeters). The man, injured by a bullet more than five years ago, had to wear a helmet for protection. This procedure, available only at UIC, draws on a combination of medical advances made by experts in  neurosurgery,  radiology,  biomedical visualization and computer engineering.  Among the new developments that have made this procedure possible is the ability of UIC biomedical visualization experts to design cranial implants using computed tomography (CT) and magnetic resonance (MR) data taken directly from the patient. They design and manufacture the implant before neurosurgeons operate on the patient. A local manufacturer makes a model of the patient's skull using a laser that instantly transforms liquid into plastic. UIC experts design the final implant from this plastic mold and cast it in medical-grade plastic.		Another advance critical to the success of the cranial implant surgery is the ability of experts to obtain an exact measurement of patients' brain blood flow, using UIC's Xenon gas CT technology. Blood flow in the frontal lobes of the gunshot victim improved 40 percent following closure with the  implant. When a portion of the skull is missing, numerous complications can arise depending on where the injury is located. Headaches, blindness, thought impairment and behavioral disorders are among the problems associated with this condition. The brain, in general, sinks because gravity pressing down on brain tissue is greater than the fluid pressures that surround the brain and hold it in place. These fluids, plus blood pressure in veins, arteries and capillaries, maintain the brain's shape. Scientists can use several materials, including titanium mesh and hydroxy apatite cement, to repair small  holes in the skull, but these methods are ineffective with large holes. Experts at UIC have been using this technique for over a year, performing the surgery on a dozen patients.
--------
251-> Japan Seeks Guidance From University Of Florida Organ Recovery Experts
By Melanie Fridl Ross GAINESVILLE, Fla.---As Japan Thursday legalized organ transplants from brain-dead donors, officials are turning to the University of Florida for guidance as they struggle to educate their citizens -- many of whom believe death occurs only once the heart stops beating. Since 1994, Charles McCluskey, executive director of UF's Organ Procurement Organization, has traveled to Japan to teach physicians and politicians about brain death. In turn, Japan has sent more than 30 visitors -- including health officials, physicians, organ procurement coordinators and members of the news media --  to UF and Shands hospital at UF to shadow its transplant team. They have logged sleepless nights flying as far as New York, Texas and Puerto Rico to recover organs, and have donned surgical scrubs to watch as the life-saving transplants were performed. One coordinator, who has spent the past year at UF, has traveled on more than 52 organ recovery missions. Two more surgeons arrive next week, McCluskey said. Early next year, Japan's deputy director from the Health Service Bureau's Office of Organ Transplantation, part of the Ministry of Health and Welfare, will visit. "They want to know how we keep track of donor and recipient information and how we share that information with other procurement organizations and transplant centers," McCluskey said. "The coordinators themselves are particularly interested in how we communicate with and counsel donor families. "They want to know how we perceive the family feels when we talk to them about donation and whether we provide any support to these families after donations. All of this is new to them." Japan's new law permits the transplant of hearts, livers and other vital organs from donors declared legally brain dead -- but only if they have given prior written permission. All donors must be at least 15 years old and their families must consent. "This has been the most important bioethics debate in Japan -- an enormous national debate just as big as the abortion debate on this side of the ocean and just as emotional," said medical anthropologist Margaret Lock, a professor at McGill University in Montreal. Lock, who spoke on transplantation before the upper chamber of the Japanese Diet earlier this year, is writing a book about the controversy. In the United States, the legal definition of brain death varies by state, but all recognize it as the irreversible cessation of brain function. Physicians conduct a battery of clinical and laboratory tests before declaring brain death. While transplants gleaned from living donors have been widely accepted in Japan for years, (for example, those involving the kidneys), up to now no clear guidelines existed for transplantation of other organs. This is partly because of deeply entrenched cultural traditions and spiritual beliefs. "This metaphor we live by, 'the gift of life,' just simply doesn't have any meaning in Japan because the idea of a gift is part of a traditional exchange system, a giving and receiving of obligations and reciprocal obligations," Lock said. "So the idea of giving something anonymously and not having it slotted into a system of exchange is really very odd. "Although in Buddhism the idea is you should be able to give to others, that has stayed very much more in a religious context rather than being extrapolated into modern society." Furthermore, many Japanese believe death only occurs once the heart stops beating. Yet organs removed after the heart stops beating are rarely healthy enough to be used in transplants. "In Japan, historically physicians had to wait for the heart to stop before the transplant could proceed," McCluskey said. "It's been difficult to get the elder political representatives to understand brain death and really make a tremendous move in medicine. The government has very strong control of how health care has been delivered." Many people fear doctors will try to remove organs before everyone's agreed the patient is dead, Lock said. Shunko Muroya, a visiting lecturer in UF's department of Asian languages and literature, said some Japanese view brain death as a Western idea. "A well-known Japanese cultural critic, Takeshi Umehara, gives the example of plants, grass and trees. They do not have a brain, but you can't say they are not alive," Muroya said. In addition, informed consent is not legally institutionalized in Japan, Lock said. "That's in fact why quite a number of Japanese intellectuals and cultural critics have been opposed to the brain deathconcept. They are not actually opposed to brain death but really want to push medicine into the 20th century and they've held brain death ransom over the larger issue of ethics in general." In transplantation's early history in the United States, all organ donors were pronounced dead when their hearts stopped beating. This changed in the late 1960s to early 1970s as brain death criteria were developed and applied, said Joel Newman, spokesman for the Richmond, Va.-based United Network for Organ Sharing. Physicians found that organ transplantation was more successful in cases where brain death occurs while the donor, though dead, is kept on a ventilator so that circulation and breathing are maintained mechanically until the organs are removed for transplantation, according to UNOS. This allows oxygenated blood to continue to pass through the organs, keeping them viable. "Clearly the experience of reluctant donors in the United States provides insight into what Japan needs to do," said UF transplant surgeon Dr. Mark Staples, who once lived in Japan. "It entails mostly education on a personal level at churches or religious groups and business organizations. The Japanese must develop confidence in their medical system to make these decisions of declaring brain death, and this is going to take time. "In our own country, there are still pockets of resistance to organ donation among some ethnic groups and among older donors, and among those who have not been educated in the process of organ donation," Staples added. "Some of it is related to spiritual beliefs, and some is related to a distrust of the medical community." In the United States, more than 55,000 people are awaiting a transplant, and 10 of them die each day. "Japan has a rich medical history, and this should begin a new era in that history," Staples said. "It may take some time for the Japanese culture to fully embrace the concept, but with good publicity and public education it should become a success." ------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
252-> Limits Of Life On Earth: Are They The Key To Life On Other Planets?
From scalding hot places that rival Dante's Inferno tofrigid locations colder than the dark side of the moon,scientists taking part in a $6 million National ScienceFoundation (NSF) research initiative are searching for life formson Earth that may provide insight about possible life on otherplanets.  The first NSF awards in this initiative -- which istitled Life in Extreme Environments (LExEn) -- involve more than20 research projects and some 40 scientists who will look at lifein Earth's most extreme habitats. "Life flourishes on the earth in an incredibly wide range ofenvironments," explains Mike Purdy, coordinator of the NSFinitiative.  "These environments may be analogous to the harshconditions that exist now, or have existed, on earth and otherplanets.  The study of microbial life forms and the extremeenvironments they inhabit can provide new insights into howthese organisms adapted to diverse environments, and shed lighton the limits within which life can exist." NSF's directorates of biological sciences; engineering;geosciences; mathematical and physical sciences; and office ofpolar programs are providing total funding of $6 million toexplore the relationships between organisms and the environmentsin which they exist.  A strong emphasis has been placed onenvironments that are near the extremes of conditions on earth.Funding will also support research about our solar system andbeyond, to help identify possible new sites for life beyondearth. Scientists are studying environments such as the earth'shydrothermal systems, sea ice and ice sheets, anoxic habitats,hypersaline lakes, high altitude or polar deserts, and humanengineered environments such as those created for industrialprocesses.  Projects involve finding techniques for isolating andculturing microbes found in extreme environments, developingmethods of studying these microbes in their natural habitats anddevising technologies for recovering non-contaminated samples. -NSF- Attachments:  Highlights of LExEn projects.              List of LExEn Awards. NSF is making a transition to a new form of electronicdistribution of news materials.  We will eventually replace thecurrent "listserve" with a new Custom News Service.  From thetoolbar on NSF's home page, (URL: http://www.nsf.gov), you cansign up to receive electronic versions of all NSF materials (orthose of your own choosing).  NSF is an independent federalagency responsible for fundamental research in all fields ofscience and engineering, with an annual budget of about $3.3billion.  NSF funds reach all 50 states, through grants to morethan 2,000 universities and institutions nationwide.  NSFreceives more than 50,000 requests for funding annually,including at least 30,000 new proposals.  Also see NSF newsproducts at: http://www.nsf.gov:80/od/lpa/start.htm,http://www.eurekalert.org/, and http://www.ari.net/newswise HIGHLIGHTS OF LExEn PROJECTS ú    Hyper-arid deserts are among the most extreme environmentson earth.  The Atacama Desert in Chile, with its rainlessregions, is one such hyper-arid desert here on earth.  LExEngrantees Frederick Rainey and John Battista of Louisiana StateUniversity will investigate the range of microorganisms living inthis hyper-arid desert, with the goal of shedding light on thesurvival of microorganisms in similar extreme environmentselsewhere on earth. ú    Recent investigations have identified microbial communitiesin various crustal environments down to 9,200 feet below theearth's surface.  Very few microbial samples exist from deepwithin continental crust, because coring is expensive.  But nowTullis Onstott of Princeton University has uncovered a uniqueopportunity to study microbial communities at depths more than10,000 feet below the surface:  in the gold mines of SouthAfrica.  Reconnaissance samples taken from a hole bored into auranium-rich, gold-bearing mine in South Africa have shown thepresence of intact microbial cells.  Onstott will examine therelationship between mineralogy and bacteria living in these deeprocks by conducting intensive research at one particular SouthAfrican gold mine. ú    Microorganisms may lie, Lazarus-like, viable but entombed inice sheets and ice caps of the Tibetan plateau, the SouthAmerican Andes, and the north and south polar regions.  A projectby Lonnie Thompson and Ellen Mosely-Thompson, glaciologists atOhio State University (OSU), and their colleagues willresuscitate microorganisms from ice cores kept at OSU's ByrdPolar Research Center, and use recovered DNA from the organismsto determine relationships to other organisms, as well asabundance and age.  The scientists will assess the longevity ofthe organisms as well as the diversity of tiny life-formsdeposited at the same geographical site thousands or evenhundreds of thousands of years apart.  The researchers hope touncover extinct genes or gene fragments to compare with moderncounterparts. ú    What is the telltale signature of past life in extremeenvironments? The University of Rochester's Ariel Anbar andcolleagues will study whether stable isotopes of key metabolicmetals fractionate -- and leave their "John Hancock" -- when themetals are taken up and metabolized by microorganisms.  If thisis the case, the method could be used to identify traces of lifein extreme environments where other "biomarkers," or signs oflife, cannot be used.  The study will focus on copper and zincisotopes expected to be abundant when these metals are taken upby microbes in a process catalyzed by enzymes, and iron isotopesexpected when iron is reduced in reactions mediated by microbes. ú    Many regions of the solar system where life is postulated toexist, such as the oceans of Jupiter's moon Europa, arecharacterized by pressures far greater than those experienced atearth's surface.  Relatively little data exists on the nature ofbarophilic (high-pressure-loving) life forms, or the pressureboundaries within which life may exist.  Douglas Bartlett of theScripps Institution of Oceanography in La Jolla, California, willconduct research on genetic components associated with survivalin high-pressure conditions.  In his studies, Bartlett will useso-called hyper-barophiles recently obtained from a high-pressurelocation at the bottom of the Japan Trench, a deep-sea locationwhere pressures reach many tons per square inch. ú    How does one study the ancient climate of Mars?  JamesKasting of Pennsylvania State University hopes to look backthrough time and see what the paleoclimate on Mars was like.Early Mars appears to have had a warm and wet climate, butexisting climate models have been unable to explain thishypothesis.  The answer may lie in methane, which, if added tothe Martian paleoatmosphere, may have brought the surfacetemperature above the freezing point of water early in theplanet's history.  But where would this methane have come from?Such a source could, in principle, have been provided by bacterialiving on the surface of early Mars. ú    Water, water, everywhere, and how critical to the existenceof life, but is it preserved as liquid beneath the icy crust ofCharon, Pluto's moon?  Until now, researchers have believed thatwater may be maintained on planetary surfaces through radiativeheating from nearby stars.  Douglas Lin from the University ofCalifornia and coworkers will examine whether a layer of watercan persist below the surface of a planet's moon, maintained asliquid by tidal interaction between planet and moon.  They willanalyze such interaction between Pluto and Charon as well asbetween Uranus and its "satellites."
--------
253-> Keys To Predicting Climate: Monsoons, Hippos And A Wet Stone Age Sahel
MADISON - Scientists have long known that six thousand years ago, in what is nowNorth African desert, hippos and crocodiles abounded, Neolithic fishermenthrived on the shores of numerous shallow lakes, and grasslands stretched to thehorizon. What they didn't know was why. Now scientists are a step closer to solving this climatological riddle of theearly Stone Age, and, importantly, their findings promise a helpful tuning ofthe sophisticated computer models used to predict future climate. Writing in the Oct. 17 edition of the journal Science, University ofWisconsin-Madison researchers John E. Kutzbach and Zhengyu Liu describe aNeolithic Sahel that was watered to a significant extent by shifting tropicalAtlantic monsoons, seasonal winds and rain that strongly influence climate overlarge regions of the Earth. "The northernmost reach of the monsoon marks the limit of vegetation in theSahel," said Kutzbach, a paleoclimatologist and director of the UW-MadisonCenter for Climatic Research. "There is a nice boundary where vegetation stopsand sand begins." Six thousand years ago, that boundary was 600 miles north, extending into aregion that is now a drought-stricken swath of desert that spans much of NorthAfrica. And for the past 15 years, Kutzbach and his colleagues have used some ofthe world's most intricate computer models of climate, developed at the NationalCenter for Atmospheric Research, to tease out clues about why such a significantexpanse of land experienced such a dramatic change in weather and climate. "Here, the thing that makes the monsoon work is sun shining on continents,producing a temperature contrast between land and ocean," Kutzbach said. "Sixthousand years ago, the monsoons were generally stronger because of changes inthe Earth's orbit" that brought the planet closest to the sun during theNorthern Hemisphere summer. "The summers were warmer, and the warmed air rose allowing moisture-laden airfrom the tropical Atlantic to penetrate significantly deeper into North Africaand increasing rainfall by as much as 25 percent," said Kutzbach. As a result, grasslands flourished in the Sahel, recycling moisture and drivingan even greater increase in precipitation. But those two phenomena - the shiftin the Earth's orbit and the increase in vegetation - were not enough to fullyaccount for the extremely strong monsoons of the early Stone Age. "There was something missing," said Kutzbach. "It prompted the question: 'Isthere something going on in the ocean that we need to take into account?' " By merging the ocean and the atmosphere in the supercomputer-driven climatemodel, Kutzbach and Liu found a slight warming of the oceans in the NorthernHemisphere. "By warming the region of the northern tropical Atlantic through increased solarradiation from the orbital change, the tropical convergence zone near theequator shifted north and the result was a deeper wedge of moist air that actedas a conveyor belt to feed more moisture into Africa." Rainfall increased by an additional 25 percent and brought the computersimulations into "reasonably close agreement with the picture we have of theancient landscape," Kutzbach said. The new study is important not only because it may finally lay to rest animportant climatological and archeological question, but also because theresults can be used to further sharpen the complicated models scientists arebetting on to predict future changes in climate. "Nature knows how the atmosphere, vegetation and the ocean interact," saidKutzbach. "We've been trying to mirror these interactions in computer models." And looking to the past, he said, where physical evidence can be matched to whatthe models say, is an excellent way to test th 
--------
254-> Scientists Solve Active Site Of Structure Of Enzyme That Produces Nitric Oxide
La Jolla, California. October 17 -- Scientists at The Skaggs Institute forChemical Biology and the Department of Molecular Biology at The Scripps ResearchInstitute, led by Drs. John Tainer and Elizabeth Getzoff, in collaboration witha team led by Dr. Dennis Stuehr at the Cleveland Clinic, have solved thestructure of the active site of the enzyme that regulates the activity of nitricoxide, or NO. Since NO is an unconventional biological signal whose activitiesrange from blood pressure regulation to antimicrobial defense to nervous systeminformation and memory, understanding the structure of the enzyme that producesit is crucial to designing drugs to turn NO on and off. Scientists predict thatNO inhibitors may be used to treat such diseases as high blood pressure, septicshock, stroke, cancer, and impotence. Given its role in neurotransmission, NOmay have an effect on treating memory disorders and learning. The paper, "The Structure of Nitric Oxide Synthase Oxygenase Domain andInhibitor Complexes," by Drs. Brian R. Crane, Andrew S. Arvai, Ratan Gachhui,Chaoqun Wu, Dipak K. Ghosh, Elizabeth D. Getzoff, Dennis J. Stuehr, and John A.Tainer, appears in today's issue of Science. According to Tainer, "Having this structure is the difference betweenworking blind and seeing what you're doing in terms of understanding and drugdesign." The structure of this key portion of nitric oxide synthase (NOS) helpsresearchers understand not only how NO is produced in the body but also how NOproduction is controlled. Nitric oxide is a small, short-lived, inorganicmolecule that functions in mammals as an essential chemical messenger for manyphysiological processes and as a protective poison against pathogens and cancer.At low concentrations it acts as a signal to control blood pressure, preventblood clotting, transmit nerve impulses in contractile and sensory tissues,process sensory input, form memories, and allow learning. In contrast, the immune system produces high concentrations of NO andexploits its reactive properties to combat bacteria, intracellular parasites,viruses and tumor cells. Due to its unstable and membrane diffusible nature, NOdiffers from other neurotransmitters and hormones in that it is not regulated bystorage, release or targeted degradation, but rather solely by synthesis. Because NO acts as a signal in low amounts and a toxin in high amounts,its production is carefully balanced in healthy humans depending on the state ofthe organism. Pathologies thought to involve too little NO production includehypertension, impotence, arteriosclerosis, and a susceptibility to infection.Diseases linked to excessive NO production include immune-type diabetes,neurotoxicity associated with aneurysm, stroke and reperfusion injury,inflammatory bowel disease, rheumatoid arthritis, cancer, septic shock, multiplesclerosis and transplant rejection. According to Dr. Solomon Snyder, a neuroscientist at Johns HopkinsUniversity whose research group was the first to clone and sequence NOS, "NOappears to be one of the most important messenger molecules in the body. Excessproduction appears to cause brain damage from stroke and also inflammatoryconditions. Drugs that block the enzyme could be important therapeutically; thisbreakthrough may allow scientists to begin to design drugs to inhibit it." The first three-dimensional structures of the catalytic site of NOS showin atomic detail how the enzyme recognizes the amino acid arginine, itssubstrate, and oxidizes it to form the biological signal NO. Stuehr stated, "Wenow have a clear understanding of where the reactive groups are located and howthe enzyme can control their interaction." The researchers believe that theunexpected discovery of two adjacent binding sites for the NOS inhibitorimidazole in the active site promises to aid in the design of drugs to modulateNOS activity and prevent NO overproduction. Dual-function inhibitors that simultaneously bind both of these siteswould block both arginine and oxygen binding, creating an expanded dual-sitebinding region to increase affinity and prevent the formation of toxic, reactiveoxygen species. Since the characteristics of NOS inhibition vary among differentNOS types, these dual-function inhibitors also may lead to new drugs that targetonly one of the various forms of NOS, thereby limiting potential side effects. The chemistry NOS uses to produce NO is complicated and unique inbiology, and its structure is completely different from other oxygenase enzymesinvolved in hormone synthesis and the detoxification of harmful compounds.However, a comparison provides insight into the aspects of these enzymes thatare key for the similarities and differences in the reactions they catalyze.According to Tainer, this should aid researchers in reproducing these biologicalreactions in the laboratory for the design of drugs or other desirablecompounds. A technique known as protein crystallography was used to determine theNOS structures. This involves diffracting x-rays off of crystals grown from thehighly purified enzyme. The x-ray diffraction experiment provides all theinformation necessary to create an atomic image of the protein. X-ray radiationwas needed in this experiment because the diffraction only occurs when the sizeof the object is similar to the wavelength size of the radiation. Funding for the study was obtained from the Skaggs Institute forResearch and the National Institutes of Health, the latter of which accountedfor approximately 15% of the resourc 
--------
255-> 3-D Computer Display Brings Precision To Burn Assessment
An easy-to-use, three-dimensional, computer graphics program is bringing a newlevel of accuracy, consistency and standardization to the evaluation of burnpatients, which should result in more precise treatment plans and betterevaluation of new therapies.  The program will be presented October 16th at theAmerican College of Surgeons' Clinical Conferene in Chicago. The software, developed by a team of researchers at the University of ChicagoHospitals' Burn Center, replaces the standard two-dimensional hand-drawn chartsof a patient's wounds with a morphable 3-D computer body image.  Using a mouseor graphic tablet, instead of pencil on paper,  the nurse or physician canadjust the diagram to match the contours of the patient's body, chart the extentand depth of the burn wounds as seen from any angle, compute the percentage oftotal-body-surface area burned, which facilitates treatment. "The computer program is more accurate and far more consistent than the standardsystem for determining burn surface area, especially for moderate burns, whereprecise information can make the most difference," said team leader Raphael Lee,M.D., Ph.D., professor of surgery and medical director of the Burn Center at theUniversity of Chicago Hospitals. Accurate assessment is a crucial early step in treatment planning.  The size anddepth of burn wounds are the most important predictors of clinical outcome.  The percentage of body surface area affected is used to calculate the patient'sfluid and nutritional needs-which can be enormous for those with severe burns. The initial assessment is also used as a benchmark to monitor a patient'sprogress and as a research tool to compare effects of different treatments. But burn centers have long had to rely on the doctor's pencil drawings on papercharts, known as Lund-Browder diagrams, which show a standard male or femalebody, child or adult, from the front and back.  Rough percentages for each bodypart are listed: for example 13 percent for the entire trunk or back, 9.5percent for one arm, 7 percent for an adult's head or 11 percent for a child's. Reliance on these two-dimensional charts results in wide variation in assessmentof identical injuries by different professionals. Burns near the sides are lessapparent on the charts and are often underestimated, while those right in frontcan be overemphasized.  And a patient's body rarely mirrors the idealized formson the standard charts. The computer, using software originally developed for architects, allows theburn team to begin assessment on a frame, assembled from 10,000 tiny triangles,that closely resembles the patient.  After keying in sex, height and weight, thephysician can manually adjust the resulting image to pull out a bigger abdomen,for example, or shrink the shoulders to match the burned patient's physique. The burns are then drawn directly onto the rotatable 3-D computer diagram with aresolution of 0.01%.  On the display, different colors indicate different wounddepths: yellow for superficial, red for deep-partial thickness or brown forfull-thickness burns.  Then the program computes the percentage of body surfacearea affected as well as fluid and nutritional requirements. Users can factor in other injuries or treatments that affect the patient'smetabolism, such as smoke inhalation or placement on a ventilator.  The computerprogram automatically adjusts for these variables and then calculatesnutritional requirements.  The computer is also able to zoom.  Body parts can bedisplayed separately or magnified for accuracy.  Wound diagrams can be updatedand compared as treatment progresses.  Skin grafts, biological dressings anddonor sites (which become partial-thickness wounds), can be included in thediagram. Studies comparing the computer with standard burn assessment found that thecomputer is much more reliable and consistent than the standard system,particularly for larger burns. In an initial trial, using a mannequin painted with burn wounds, six nurse orphysician observers rated the wounds using Lund-Browder charts and the computer. The computer was significantly more accurate and, for large burns, produced onefifth the amount of variation between observers. Subsequent tests with real patients in the University of Chicago Burn Unit haveconfirmed the computer's accuracy as well as the willingness of nurses andphysicians to use the program despite the time constraints of the clinicalsetting. The program requires few keyboard commands.  Most functions arecontrolled by a mouse and simple pull-down menus. "Accuracy is crucial for treating the patient," said Lee, "but consistency isessential for conducting research and communicating new findings.  We hope thatby gathering better information at the beginning of treatment, we can improveour ability to evaluate outcomes and perhaps speed the development of newtherapies." The research was sponsored by the Electric Power Research Institute, which willdistribute the software to burn centers. Also involved in developing and testing the software were programmers David Tuch(now in graduate school at M.I.T.), Patrick Jacobsen and Gregory Kicska;burn-unit fellows Mahesh Mankani, M.D. (now in private practice in Washington,D.C.), and William Brownlee, M.D. (now at Cook County Hospital); burn-unitnurses Tina Tinnin, R.N., M.S.N., Alison Boddie, R.N., B.S.N., and AnnemarieO'Connor, R.N., B.S 
--------
256-> Many Medical Screening Tests May Be Unnecessary.
ANN ARBOR---Doctors can face an ethical dilemma when patients request screening tests---such as those for breast cancer and prostate cancer---that may be ill-advised under certain circumstances. A University of Michigan physician and three co-authors explore that predicament in the article "Ethical Considerations in the Provision of Controversial Screening Tests," in the current issue of the Archives of Family Medicine . Physicians may face this quandary when patients claim entitlement to such tests under their insurance plans, when health advocacy and professional groups recommend their use, or when media attention heightens interest in the latest screening breakthrough, the article notes. These claims, however, may not be supported by scientific evidence demonstrating that the screening tests meet a minimum criteria of effectiveness. For example, the article points out that there is considerable disagreement in the medical community over the routine use of mammograms in women under the age of 50 and prostate specific antigen tests in men.  The ethical issue becomes more complicated when doctors provide controversial screening tests because they fear a future lawsuit by a patient who later develops a disease. The article describes several potential risks of screening tests with controversial benefits, including: ¤ Reliance on screening tests before their effectiveness has been corroborated by adequate research. ¤ Creating the impression that such exams can reduce a patient's risk to zero---possibly leading them to make uninformed medical decisions. ¤ Inaccurate, false positive results which can cause profound anxiety and require additional testing that can be increasingly invasive and costly. ¤ Depleting society's limited medical resources. The article asserts that physicians have a responsibility to inform patients of the limitations and risks of screening tests---and to refuse to order tests that would violate their medical and ethical judgment.  Physicians can counsel patients about the lack of scientific evidence regarding a test's benefits and the fact that no test can assure zero-risk of disease. Physicians also may choose to administer a test if initial scientific evidence supports a claim of benefit and the patient is aware of the risks.  Alternatively, the physician has the option to refuse to provide the test, or refer the patient to another doctor who will provide it. This education and negotiation process is intended to apprise the patient about which screening tests have been proven to be beneficial and which have not.  Such a discussion can result in patients making informed and learned health care decisions. "For most diseases for which there is a potential screening test, the effectiveness of screening is controversial," the article says.  "Physicians can use a 'preventive ethics' approach to explain that tests with controversial benefits are unlikely to be helpful." The lead author, David J. Doukas , M.D., is an associate professor in the U-M Department of Family Practice and associate director for clinical bioethics in the U-M Program in Society and Medicine .  Co-authors are Michael Fetters , M.D., and Mack Ruffin IV , M.D., both from the U-M Department of Family Medicine, and Laurence B. McCullough, Ph.D., of Baylor Medical Colle 
--------
257-> Less Noise At Home Makes For Better-Adjusted Kids
WEST LAFAYETTE, Ind. -- Parents wanting to help their children adjust to life's stresses may want to turn down the noise in their home, says a Purdue University professor of psychological sciences. "Kids who come from highly noisy or chaotic homes experience less cognitive growth, delayed language skills, have trouble mastering their environments and have increased anxiety," says Theodore Wachs. Wachs studies environmental influences on early childhood development. He helped create a questionnaire for parents to fill out to measure the level of physical disorganization in the home. The "chaos" questionnaire assesses what he calls "the noise confusion of the home." He says a chaotic home is one factor associated with adjustment problems in children. For example, in a study of preschool children's reaction to caregiver turnover in day care centers, those from more disorganized homes had more trouble adapting and functioning during the time of change. "The effects vary with the temperament and sex of the child," he says. "Those who have the most trouble associated with a chaotic home life are boys who are intense, fussy or negative." Wachs offers these suggestions for toning down "noise confusion" in the home:
--------
258-> Progressive Brain Changes Detected In Childhood Onset Schizophrenia
Evidence of progressive abnormal brain development in schizophreniahas emerged from the first longitudinal brain imaging study ever conductedin adolescents for any illness.  MRI (magnetic resonance imaging) scans revealed ventricles (fluid-filled cavitiesin the middle of the brain) enlarging between ages 14 and 16 in teens witha rare, severe, childhood onset form of the disorder, report Judith Rapoport, M.D., and colleagues of the National Institute of MentalHealth, in the October issue of the Archives of General Psychiatry. Also in this issue, NIMH's Theodore Zahn, Ph.D., Rapoport and colleagues report that the same adolescents, all of whom had experienced psychosis priorto age 12, showed autonomic nervous system abnormalities characteristicof adult schizophrenia. "These and other studies add to mounting evidencethat the childhood and adult forms are the same illness," said Rapoport,Chief of the NIMH Child Psychiatry Branch. "Understanding what's happeningin these young people during this period of highly volatile brain developmentmay provide clues about risk factors and neurodevelopmental abnormalitiesinvolved in the much more common adult onset schizophrenia. Adults withthe disorder may well have experienced the same kind of abnormal brainchanges during their teens." Affecting about 1 percent of adults, but only about .005 percent ofchildren, schizophrenia is the most chronic and disabling mental illness. It typically begins asa psychotic episode in young adulthood, with devastating hallucinations,delusions, social withdrawal, blunted emotionality and loss of social andpersonal care skills. A new generation of antipsychoticmedications , such as clozapine, has helped many patients manage theirsymptoms with fewer side effects. In the MRI study, the researchers compared scans of 16 ill teenagersparticipating in a clozapine trial with those of 24 age-matched controls.At the initial scan, the youths with schizophrenia tended to show enlargedventricles, reduced total cerebral volume, and other structural anomalies.After two years, a series of re-scans revealed "highly significant"increases in the size of ventricles among those with schizophrenia. Thecontrols showed no significant changes. Although adult schizophrenia patients tend to have enlarged ventricles,evidence for progressive brain changes in adults has been more equivocal.Absent signs of an ongoing illness process, one prevailing theory has heldthat schizophrenia likely stems from damage caused by a prenatal event– such as a viral infection in the womb, or some other environmental insultto the developing brain -- that interacts with normal brain developmentand life stresses, in genetically vulnerable individuals, to produce thedisorder in young adulthood. While not one of its original tenets, thefindings of progressive brain changes in adolescence are not inconsistentwith this "neurodevelopmental" hypothesis, say the researchers. Unlike in adults, schizophrenia usually emerges gradually in children,and is often preceded by developmental disturbances, such as lags in motorand speech development. Adolescents in the study who had histories of suchautistic-like behavior tended to show greater ventricular enlargement.Childhood onset schizophrenia also tends to be harder to treat and to havea worse prognosis than the adult onset form. However, in a series of studiesover the past few years, Rapoport's group has shown that affected childrenshare with adults a similar pattern of brain structure abnormalities andphysiological features. For example, in the study led by Zahn, the researchersreport that the ill children had skin conductance and heart rate anomaliessimilar to those seen in affected adults. In interpreting the imaging findings, Rapoport and colleagues suggestthat the scans captured changes in the brain during a critical period indevelopment when it is "uniquely sensitive" to effects of theillness. It's unlikely that the ventricles would continue enlarging atsuch a high rate, "as that would produce improbably large ventricularvolume later in life," they note. Also, the "possibility thatclozapine treatment accelerates adolescent brain change can not be ruledout," they add. The 16 affected adolescents in the study were thefirst to be re-scanned from a total of 30 patients in the clozapine trial.Their MRI scans were compared with scans from an ongoing NIMH study designedto provide data on normal brain development during childhood and adolescence. "The study of childhood onset cases presents a unique approachto schizophrenia," said Rapoport. "If we can understand whatturns on the illness in these rare cases, it may provide clues about howto turn it off for others." Also participating in the studies were: Drs. Jay Giedd, Sanji Kumra,Leslie Jacobsen, and Amy Smith, Paul Lee, Jean Nelson and Susan Hamburgerof NIMH; and Dr. Charles Gordon, University of Maryland; Dr. Kathleen McKenna,Northwestern University; and Dr. Jean Frazier, Harvard University. NIMH is a component of the National Institutes of Health, an agencyof the U.S. Department of Health and Human Servic 
--------
259-> Cassini Begins 7-Year Voyage To Saturn
The international Cassini spacecraft mission left Earth bound for Saturn this morning (Oct. 15) atop an Air Force Titan IV/B Centaur rocket in a picture-perfect launch at 4:43 a.m. EDT (1:43 a.m. PDT) from Cape Canaveral, FL. On time and on schedule for Wednesday's launch opportunity, the Titan solid rocket boosters ignited at the opening of today's launch window, setting the Cassini spacecraft on its nearly seven-year journey to the ringed planet.  All milestones during the rocket's ascent occurred as planned, culminating with a successful separation of the Centaur upper stage from the Cassini spacecraft at 42 minutes and 40 seconds into flight.  Flying on its own for the first time, the Cassini spacecraft opened its communications link with the NASA Deep Space Network communications complex near Canberra, Australia, about 10 minutes later, or about 52 minutes post launch. With the European Space Agency's Huygens probe onboard and communicating through a high-gain antenna provided by the Italian Space Agency, Cassini will arrive at Saturn  July 1, 2004.  The JPL-built Cassini orbiter flies a circuitous but necessary route to reach Saturn.  The spacecraft will perform two gravity-assist swingbys of Venus, one of Earth and one of Jupiter to gain enough speed to reach Saturn, which is 1.4 billion kilometers (nearly 1 billion miles) from the Sun.
--------
260-> UT Southwestern Study Finds Common Pain Reliever Can Cause Liver Damage, Especially Mixed With Alcohol
DALLAS -- October 16, 1997 -- High doses of acetaminophen, especially when mixedwith alcohol, caused liver injury in some patients, reported researchers atUT Southwestern Medical Center at Dallas in today's edition of The New EnglandJournal of Medicine. Dr. William Lee, professor of internal medicine, and his team ofliver-disease researchers reviewed the records of 589 patients who overdosed ondrugs and were treated at Dallas County's Parkland Memorial Hospital from 1992to 1995. From that group he found 71 patients who were hospitalized with liverdamage after taking acetaminophen, the most common cause of acute liver failure. Twenty-one patients in this group accidentally took an overdose of thecommon pain reliever, and in 13 of these alcohol was a factor in the toxicreaction. The other 50 in the group took an overdose of acetaminophen inattempts to commit suicide; 10, who also had consumed alcohol,  experiencedsignificant liver injury. Surprisingly, accidental overdoses compared to suicidal overdoses ofacetaminophen were more often fatal even though the amounts taken were lower.The median dose of an accidental overdose was 11 grams, and it proved fatal forfour patients. The median dose of a suicide attempt was 24 grams and provedfatal to one of the patients studied. Acetaminophen was found to be the mostcommon cause of acute liver failure during the study period. Liver injury resulting from suicidal intent is common in the UnitedKingdom, but in the United States it is more prevalent among alcoholic orfasting patients, who ingest smaller quantities of acetaminophen for pain reliefonly, Lee said. "Our study suggests we should be more diligent in educating the publicand physicians about the risks associated with acetaminophen because it'scommonplace for people to reach for a bottle of pain reliever without thinkingabout possible complications," said Lee, who directs the Liver Diseases ClinicalCenter atUT Southwestern's James W. Aston Ambulatory Care Center. Lee speculates that acetaminophen causes liver damage in alcoholic orfasting patients because alcohol and fasting deplete the body of glutathione, adetoxification agent normally found in large quantities in the liver. He cautions that even people who aren't alcoholics but consume alcoholbefore or after taking acetaminophen can experience liver damage. "In light of these findings, I think we should use this study not as acondemnation of over-the-counter pain relievers that contain acetaminophen butas a means to educate people that these drugs should be used responsibly," Leesaid. The majority of patients Lee studied purposefully or inadvertently tookamounts far greater than the 4 grams (eight tablets) per 24-hour limit listed onthe packages of most brands. Other findings of the study:
--------
261-> Yaba-Daba-Glue! Stone-Age Use Of Collagen Discovered
Collagen is one of the latest fads of today's cosmetics industry. Nowresearch at the Weizmann Institute of Science reveals that alreadyback in the stone age, humans were putting this organic compound touse, albeit not in rejuvenating cosmetics. Dr. Arie Nissenbaumdiscovered an 8,000-year-old cache of collagen used as glue bymysterious Neolithic cavemen who lived in the area of the Dead Sea. "No one knows who these people were and where they came from, but bystone-age standards they surely had mastered at least one type of advanced technology," says Dr. Nissenbaum. Nissenbaum added that the production of collagen glue placed the stone-age cavemen several thousand years ahead of the ancient Egyptians, a surprising technological feat for a group that had not yet mastered pottery. Nissenbaum studied findings from the Nahal Hemar cave, which was probably used for cult purposes by ancient humans. This cave, located on a cliff near the Dead Sea just northwest of Mt. Sedom, has provided some of the most important regional findings from the late stone age known as the Neolithic period. One of the striking features of the excavated objects is the use of a black substance originally believed to be asphalt. It was applied as a protective lining on rope baskets, containers and embroidered fabrics, as a crisscross-patterned decoration on tops of sculptured skulls and as an adhesive holding together tools and utensils. When Nissenbaum, who studied asphalt from different archaeological digs, conducted a chemical analysis of the blackish material, he was amazed to discover it was not asphalt at all but rather collagen, the most common fibrous protein in living organisms and a major component of skin, sinews and cartilage. Its chemical composition, as well as an electron microscope analysis of its structure, suggested it wasderived from animal skin Carbon-14 dating established that the collagen was about 8,100 years old, which coincided with the period when the cave was first used. Although collagen normally quickly converts into gelatin, the Nahal Hemar specimens were exceptionally well preserved due to the region'sextremely dry climate. Natural glues from animal and plant sources were extensively used from antiquity up to the early 20th century. With the Middle East's scarcity of trees, a common source of resin adhesives in ancient Europe, it is hardly surprising that cavemen turned to collagen as a glue. What is surprising, though, is that these people were far ahead of ancient Egyptians who used collagen in its gelatinous form as the basis for the "carpenter's glue" that held together furniture. While the Egyptians apparently produced their "carpenter's glue"through heating and alkaline solution treatment of animal skins, it'sunclear how the Dead Sea cavemen manufactured theirs. It is clear,though, that the stone age craftsmen supplemented the glue withplant-tissue additives, evidently in order to endow it with theappropriate texture. These findings, reported in the Hebrew-language Archeologia Umada'ei Hateva ("Archaeology and Natural Sciences"), add a new chapter to the history of adhesives and to humankind's technological history in general. (An English translation of the paper is available, as are color slides of the ancient decorated skull 
--------
262-> Genetically Altered Salmonella Bacteria May Offer Potential Cancer Treatment
NEW HAVEN, Conn.--A genetically engineered strain of thebacteria Salmonella potentially may target cancerous tumors, amplify withintumors and inhibit tumor growth, according to new research reported by YaleUniversity School of Medicine scientists and colleagues. The Yale concept, reported in the Oct. 15 issue of the scientificjournal Cancer Research, and licensed to Vion Pharmaceuticals Inc. in New Haven,Conn., involves the use of engineered strains of the common Salmonellabacterium, the same bacterium that, in its unaltered or wild type form, cancause food poisoning and septic shock.  The altered Salmonella, stripped of itspathogenicity, is nonetheless able to target solid tumors in laboratoryanimals in a similar manner to its wild-type parent, according to John M.Pawelek, Ph.D., senior research scientist in dermatology and a lecturer inpharmacology at Yale. However, the key is that the safe versions are still able to target solid tumorsin laboratory animals, much like the wild type parent, while at the same timehave little or no adverse effects.  "In fact," states Dr. Pawelek, "we can nowsignificantly prolong the life of mice with melanoma by injecting them with ourattenuated bacteria.  Although as few as 10 wild type bacteria are sufficient tokill a mouse, we can inject 10 million cells of our attenuated strains and themice show no symptoms of infection.  After the Salmonella are introduced intothe mouse blood stream, they seek out tumors, multiply there in great numbers,and--by mechanisms not fully understood--dramatically slow the rate of tumorgrowth and prolong life.  Furthermore, because the bacteria amplify within thetumor itself, anti-tumor genes that we introduce genetically into the bacteria are alsoamplified." Yale School of Medicine researchers John M. Pawelek, Ph.D.; David Bermudes,Ph.D., and K. Brooks Low, Ph.D., co-invented this radical new cancer therapy andworked hand-in-hand with a team of scientists from Vion Pharmaceuticals, Inc.,to prepare their invention for possible clinical trials in cancer patients. Dr. Pawelek, a cancer biologist who studies melanoma; Dr. Bermudes, aparasitologist, and Dr. Low, a bacterial geneticist who is professor of researchin therapeutic radiology, started collaborating in late 1992 onthis project when a University of Massachusetts colleague introduced Dr. Pawelekto Dr. Bermudes, who as a Yale associate research scientist was then workingonly three floors above him in the Infectious Diseases Unit at Yale.  Dr.Bermudes became interested in Dr. Pawelek's thoughts on an old theory on howmetastatic cancer cells seem to behave like white blood cells as they spreadthrough the body, and encouraged Dr. Pawelek to pursue the theoryexperimentally. After a few weeks Dr. Bermudes returned to Dr. Pawelek with an idea for a newtype of therapy: the use of white blood cell-specific parasites to seek outcancer cells.  They tested several parasites for their ability to infect humanmelanoma cells in culture, and soon settled on further work with Salmonella,which also readily infected the human melanoma cells in culture. Approached because of his expertise in bacterial genetics, Dr. Low wassupportive and favored testing the potential of Salmonella in this way.  Withinweeks, Dr. Pawelek began a sabbatical in  Dr. Low's lab where the trio pursuedthe development of safe Salmonella as an anti-cancer vector. A few months later,they obtained their first laboratory animal data, and Dr. Terrence W. Doyle,Ph.D., vice president for research and development at Vion Pharmaceuticals,Inc., became interested in the Yale-developed technology.  Vion entered into alicense agreement with Yale in December 1995, assisted with the patent filingand employed Dr. Bermudes as a senior scientist.  Now, several years later, theYale-Vion data were presented at the American Association for Cancer Researchmeeting last April in San Diego and published Oct. 15. The three scientists were motivated by the work of Professor Rakesh K. Jain andhis colleagues at Harvard University who, through the application of engineeringsciences to tumors, have shown that numerous physical barriers exist withintumors, prohibiting efficient delivery of anti-cancer agents. Explains Professor Pawelek, "Tumors have an irregular blood supply, with bloodvessels not reaching many regions.  They tend to be under positive pressure fromthe inside out.  Jain's group and others have shown that these characteristics present barriers that inhibit viruses, antibodies anddrugs from reaching the inner-most portions of the tumors.  In contrast,Salmonella, which can move by their own swimming motion, are less subject tophysical constraints and can reach and then multiply within deeper areas. WhenSalmonella particularly are armed with anti-cancer genes, they have thepotential to kill tumor cells in areas not easily reached by other therapeuticagents." "Most exciting is the potential use of our technology for human cancer therapy,"the three scientists agreed. "We've made the Salmonella both safe and effectivefor laboratory animals, and now the challenge is to do the same for humans. Thesafety issue seems under control, and the potential effectiveness seems highlypromising.&# 
--------
263-> New Clues To Early Neuron Damage In Alzheimer's Disease
NEW YORK, N.Y., Oct. 15, 1997--Columbia University College of Physicians& Surgeons scientists have discovered  a molecule, called ERAB, that provides animportant clue to how early neuron damage may occur in Alzheimer's disease. Thefindings, published in the Oct. 16, issue of Nature, may lead to a intracellulartarget for the eventual treatment of the disease. Alzheimer's disease is a progressive neurodegenerative disorder in whichnerve cells in the brain die. It is the fourth leading cause of death in theUnited States, affecting more than four million people. Scientists have longknown that amyloid-beta peptide, a precursor protein involved in Alzheimer'sdisease, collects in sticky clumps called "neuritic plaques" outside of nervecells in the brain, and eventually kills them.  The discovery may allowscientists to develop therapies that inhibit the interaction of ERAB andamyloid-B peptide and protect neurons from damage. Lead author Dr. Shi Du Yan, assistant professor in the department ofpathology, and senior author Dr. David Stern, professor with joint appointmentsin the departments of physiology and cellular biophysics and surgery, discoveredthat neuronal damage in Alzheimer's disease takes place even before increasedlevels of amyloid-beta peptide accumulate outside of cells. Since amyloid-beta peptide is produced within cells, scientists lookedfor targets within the cell via which the peptide causes early damage.Researchers identified the first intracellular target of amyloid-beta peptide and named it ERAB. "This study implicates ERAB as a participant in causing neuronaldysfunction in Alzheimer's disease," says Dr. Yan. The finding contributes to anewly emerging picture of how neuron damage occurs in Alzheimer's disease. Inthe traditional view, large extracellular accumulations of amyloid-beta peptide,as happens in the late stages of Alzheimer's disease, cause non-specificinjuries to neurons. "But the identification of ERAB is one indication that inAlzheimer's disease, the earliest disturbances in neuronal function may occurintracellularly and result from specific interactions of amyloid-beta peptidewith molecular targets," says Dr. Stern. "Identifying such changes at an earlystage may allow therapies to be initiated before neuronal loss and its severeconsequences become manifest." ERAB is found in a wide range of cells where scientists believe it isinvolved in the metabolism of fatty acids. The CPMC researchers found that whenERAB interacts with amyloid-beta peptide, it increases the toxicity of thepeptide. The researchers also found that blocking the interaction of ERAB andamyloid-beta peptide protects cells from damage."Given the apparent widespread distribution of ERAB throughout the body, thisfinding, while important in its own right -- for pointing toward mechanisms ofamyloid-induced neurodegeneration, also has the potential to contribute to amore complete understanding of vascular dementia," says Dr. Stephen Snyder,Health Science Administrator for the Neuroscience and Neuropsychology of agingprogram at the National Institute on Aging. The finding may allow scientists to develop therapies that inhibit theinteraction of ERAB and amyloid-B peptide, protecting neurons from damage. Drs.Stern and Yan are now working to identify specific cellular targets ofamyloid-beta peptide, which will help in creating such therapies. The study's other authors were Xi Chen, Jin fu, Claudio Soto, HuaijieZhu, Futwan Al-Mohanna, Kate Collison, Aiping Zhu, Eric Stern, Takaomi Saido,Masaya Tohyama, Satoshi Ogawa, and Alex Roher. The study was funded by the National Institute on Aging (NIA), part ofthe National Institutes of Health, and the Columbia University department ofsurgery research fund.  ###
--------
264-> Global Surveyor's Orbit Raised While Solar Panel Is Analyzed
The lowest point of Mars Global Surveyor's aerobraking orbit has been raised temporarily, and aerobraking has been suspended while the flight team analyzes data to understand why one of the spacecraft's two solar panels, which had not fully deployed, exhibited unexpected motion during a recent dip through the upper Martian atmosphere. The spacecraft's current 35-hour orbit around Mars, which was taking it down to 75 miles (121 kilometers) above the Martian surface during each of its closest passes over the planet, has been raised to 105 miles (170 kilometers).  The orbit was raised Oct. 12 by the operations team at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA, and Lockheed Martin Astronautics, Denver, CO, by performing a brief, 5.15-mile-per-hour (2.3-meter-per-second) propulsive burn at the farthest point of the spacecraft's orbit around Mars.  The panel's performance has had no effect on spacecraft power. "We're taking a hiatus from aerobraking for the next few weeks while we study data to try to model and understand the apparent deflection of the solar panel that never fully deployed and latched in place after launch," said Glenn E. Cunningham, Mars Global Surveyor project manager at JPL.  "This delay in the aerobraking process will probably change the spacecraft's final mapping orbit from the originally planned 2 p.m. local Mars time passage over the planet's equator to another time, and we are studying several other orbits that will give us nearly the same quality of science results." Preliminary data from the panel indicate that it has moved past what would have been its fully deployed and latched position, Cunningham said.  In addition, the panel has shown some movement, rather than maintaining its rigid position during aerobraking.  These changes occurred during the spacecraft's fifteenth close approach to Mars, on Oct. 6, when the density of the Martianatmosphere doubled unexpectedly. During the next few weeks, the Mars Global Surveyor flight team will leave the spacecraft's orbit in the current, 35-hour revolution around Mars, which will not take the spacecraft through the upper atmosphere of Mars, while they analyze data and simulate conditions in the Martian atmosphere to understand the behavior of the solar panel.  This hiatus also means the spacecraft's solar panels will not be reconfigured for each close pass over Mars, but will remain in the normal cruise position. "We can't yet explain what has happened," Cunningham said.  "We saw the unlatched panel move past the latched-up position, and it remains past that point now.  By raising the spacecraft's orbit above the upper atmosphere, the panel should not shift further because it will not be exposed to the aerodynamic forces of the Martian atmosphere." Several other mapping orbits are available to Mars Global Surveyor to carry out its science objectives.  The flight team will explore alternatives in the next few weeks to accomplish the lowest orbit possible and achieve a "sun-synchronous" orbit that will allow Global Surveyor to fly over the Martian equator at the same local solar time each orbit.  These sun-synchronous orbits are designed so that the spacecraft's instruments always see Mars at the same lighting angle on every pass over the surface. "As we step back from aggressive aerobraking temporarily, we will have the opportunity to study the situation until we fully understand it.  We will take advantage of this opportunity to return some spectacular data from the camera and laser altimeter," Cunningham said.  "The thermal emission spectrometer and magnetometer/electron reflectometer also will continue to collect data while we remain in this holding pattern." The Mars Global Surveyor atmospheric advisory group reported that the Martian atmosphere has more than doubled in thickness in the last week.  Global Surveyor is designed to withstand more than a 50 percent increase in atmospheric density, but began showing movement in the solar panel last week, during the fifteenth close approach on Oct. 6. Additional information about the Mars Global Surveyor mission is available on the World Wide Web by accessing JPL's Mars news site at URL:  http://www.jpl.nasa.gov/marsnews or the Global Surveyor project home page at URL:  http://mars.jpl.nasa.gov Mars Global Surveyor is part of a sustained program of Mars exploration, known as the Mars Surveyor Program.  The mission is managed by JPL for NASA's Office of Space Science, Washington, DC.  JPL's industrial partner is Lockheed Martin Astronautics, Denver, CO, which developed and operates the spacecraft.  JPL is a division of the California Institute of Technology, Pasadena, CA.
--------
265-> Therapeutic Effects Of Garlic Clarified At Weizmann
REHOVOT, Israel , October 14, 1997 -- Garlic is believed to work wonders, fromfighting disease to keeping away vampires. Now two studies conducted at theWeizmann Institute of Science have uncovered a molecular mechanism which maybe the basis for some of garlic's therapeutic effects. The researchers were able to study how garlic works at the molecular  levelthanks to their unique biotechnological procedure for producing  large quantities of pureallicin, garlic's main biologically active  component. One study, appearing in the October issue of the American Society forMicrobiology's Antimicrobial Agents and Chemotherapy, explains how allicin fights infection.This research supports the notion that garlic is an excellent, although smelly,natural antimicrobial drug that can disable an unusually wide variety of infectiousorganisms. The second study, soon to be reported in Biochimica Biophysica Acta, may helpclarify the role allicin plays in preventing heart disease and other disorders. In the studies, the scientists revealed and characterized a molecularmechanism by which allicin blocks certain groups of enzymes.  Allicin, created when garlic cloves are crushed, protects the plant from soil parasites and fungi and is also responsible for garlic's pungent smell. The studies were led by Profs. David Mirelman and Meir Wilchek of theWeizmann Institute's Biological Chemistry Department, who worked together withdepartmental colleagues Drs. Serge Ankri, Talia Miron and Aharon Rabinkov and with Prof. LevWeiner and Dr. Leonid Konstantinovski of the Organic Chemistry Department. A natural weapon against infection, the research reported in October's Antimicrobial Agents and Chemotherapyrevealed that allicin disables dysentery-causing amoebas by blocking two groups ofenzymes, cysteine proteinases and alcohol dehydrogenases. Cysteine proteinase enzymes are among the main culprits in infection,providing infectious organisms with the means to damage and invade tissues.Alcohol dehydrogenase enzymes play a major role in these harmful organisms'metabolism and survival. Because these groups of enzymes are found in a wide variety of infectiousorganisms such as bacteria, fungi and viruses, this research provides a scientific basis forthe notion that allicin is a broad-spectrum antimicrobial drug, capable of warding off different types of infections. "It has long been argued that garlic can fight a wide range of infections, andnow we have provided biochemical evidence for this claim," says Prof. Mirelman. The role of allicin in warding off infection may be particularly valuable inlight of the growing bacterial resistance to antibiotics. It is unlikely that bacteria woulddevelop resistance to allicin because this would require modifying the very enzymes thatmake their activity possible. Blocking mechanism explained in the study slated to appear in Biochimica Biophysica Acta, Institutescientists found that allicin blocks the enzymes by reacting with one of their important componentsknown as sulfhydryl (SH) groups, or thiols. This finding has important implications because sulfhydryl groups arealso crucial components of some enzymes that participate in the synthesis of cholesterol. Byreacting with and modifying the sulfhydryl groups in those enzymes, allicin mayprevent the production of arteryclogging cholesterol. "It has been suggested that garlic lowers the levels of harmfulcholesterol, and our study provides a possible explanation for how this may occur," saysProf. Wilchek. "However, more research is necessary to establish what role allicinmight play in preventing the clogging up of arteries." Complicating the issue is the concern that  blocking sulfhydryl groupsin proteins may sometimes be harmful because these groups are also present inenzymes involved in some of the body's vital processes. However, unlike most bacteria,human tissue cells contain detoxifying molecules of a substance called glutathione,which helps maintain appropriate sulfhydryl levels. These glutathione molecules canreverse the anti-sulfhydryl effects of small amounts of allicin. Measuring antioxidant activity while reaction with sulfhydryl groups appears to explain most of allicin'sactivity, it has also been suggested that allicin acts as an antioxidant. The study reported inBBA confirmed this antioxidant effect and for the first time provided its quantitative assessment. Antioxidants gobble up harmful free radicals believed to contribute to tumor growth,atherosclerosis, aging and other processes.  Producing pure allicin in large quantitiesin nature, allicin is created when garlic cloves are cut into or crushed. Thecutting or crushing causes two components of garlic, alliin and the enzyme alliinase, tointeract. The allicin produced at the Weizmann Institute is semi-synthetic; first,its precursor, alliin, is chemically synthesized, then a modified form of thenatural enzyme, alliinase, converts it into pure allicin. The pure semi-synthetic allicin can be stored for months without losingits effectiveness. In contrast, the natural compound loses its beneficial propertieswithin hours because it begins to react with garlic's other components as soon as theclove is crushed. A patent application for this production of pure allicin has been submitted byYeda Research and Development Co., the Weizmann Institute's technology transfer arm,and several companies have already expressed interest in scaling up the process forcommercial use and clinical testing. Prof. Mirelman, the Weizmann Institute's Vice President for TechnologyTransfer, holds the Besen-Brender Chair of Microbiology and Parasitology, andProf. Wilchek, Dean of the Biochemistry Faculty, holds the Marc R. GutwirthChair of Molecular Biology. Partial funding for this research was provided by the Center forMolecular Biology of Tropical Diseases at the Weizmann Institute and the Avicenne Programof the European Union. Drs. Rabinkov and  Konstantinovski were partly supported bythe Center for the Absorption of  Scientists of Israel's Ministry of Absorption. The Weizmann Institute of Science, in Rehovot, Israel, is one of theworld's foremost centers of scientific research and graduate study. Its 2,400 scientists,students, technicians, and engineers pursue basic research in the quest for knowledge andthe enhancement of the human condition. New ways of fighting disease and hunger,protecting the environment, and harnessing alternative sources of energy are highprioriti  A natural weapon against infection, the research reported in October's Antimicrobial Agents and Chemotherapyrevealed that allicin disables dysentery-causing amoebas by blocking two groups ofenzymes, cysteine proteinases and alcohol dehydrogenases. Cysteine proteinase enzymes are among the main culprits in infection,providing infectious organisms with the means to damage and invade tissues.Alcohol dehydrogenase enzymes play a major role in these harmful organisms'metabolism and survival. Because these groups of enzymes are found in a wide variety of infectiousorganisms such as bacteria, fungi and viruses, this research provides a scientific basis forthe notion that allicin is a broad-spectrum antimicrobial drug, capable of warding off different types of infections. "It has long been argued that garlic can fight a wide range of infections, andnow we have provided biochemical evidence for this claim," says Prof. Mirelman. The role of allicin in warding off infection may be particularly valuable inlight of the growing bacterial resistance to antibiotics. It is unlikely that bacteria woulddevelop resistance to allicin because this would require modifying the very enzymes thatmake their activity possible. Blocking mechanism explained in the study slated to appear in Biochimica Biophysica Acta, Institutescientists found that allicin blocks the enzymes by reacting with one of their important componentsknown as sulfhydryl (SH) groups, or thiols. This finding has important implications because sulfhydryl groups arealso crucial components of some enzymes that participate in the synthesis of cholesterol. Byreacting with and modifying the sulfhydryl groups in those enzymes, allicin mayprevent the production of arteryclogging cholesterol. "It has been suggested that garlic lowers the levels of harmfulcholesterol, and our study provides a possible explanation for how this may occur," saysProf. Wilchek. "However, more research is necessary to establish what role allicinmight play in preventing the clogging up of arteries." Complicating the issue is the concern that  blocking sulfhydryl groupsin proteins may sometimes be harmful because these groups are also present inenzymes involved in some of the body's vital processes. However, unlike most bacteria,human tissue cells contain detoxifying molecules of a substance called glutathione,which helps maintain appropriate sulfhydryl levels. These glutathione molecules canreverse the anti-sulfhydryl effects of small amounts of allicin. Measuring antioxidant activity while reaction with sulfhydryl groups appears to explain most of allicin'sactivity, it has also been suggested that allicin acts as an antioxidant. The study reported inBBA confirmed this antioxidant effect and for the first time provided its quantitative assessment. Antioxidants gobble up harmful free radicals believed to contribute to tumor growth,atherosclerosis, aging and other processes.  Producing pure allicin in large quantitiesin nature, allicin is created when garlic cloves are cut into or crushed. Thecutting or crushing causes two components of garlic, alliin and the enzyme alliinase, tointeract. The allicin produced at the Weizmann Institute is semi-synthetic; first,its precursor, alliin, is chemically synthesized, then a modified form of thenatural enzyme, alliinase, converts it into pure allicin. The pure semi-synthetic allicin can be stored for months without losingits effectiveness. In contrast, the natural compound loses its beneficial propertieswithin hours because it begins to react with garlic's other components as soon as theclove is crushed. A patent application for this production of pure allicin has been submitted byYeda Research and Development Co., the Weizmann Institute's technology transfer arm,and several companies have already expressed interest in scaling up the process forcommercial use and clinical testing. Prof. Mirelman, the Weizmann Institute's Vice President for TechnologyTransfer, holds the Besen-Brender Chair of Microbiology and Parasitology, andProf. Wilchek, Dean of the Biochemistry Faculty, holds the Marc R. GutwirthChair of Molecular Biology. Partial funding for this research was provided by the Center forMolecular Biology of Tropical Diseases at the Weizmann Institute and the Avicenne Programof the European Union. Drs. Rabinkov and  Konstantinovski were partly supported bythe Center for the Absorption of  Scientists of Israel's Ministry of Absorption. The Weizmann Institute of Science, in Rehovot, Israel, is one of theworld's foremost centers of scientific research and graduate study. Its 2,400 scientists,students, technicians, and engineers pursue basic research in the quest for knowledge andthe enhancement of the human condition. New ways of fighting disease and hunger,protecting the environment, and harnessing alternative sources of energy are highpriorities.
--------
266-> Researchers Locate Second Late-Onset Alzheimer's Disease Gene
CHICAGO -- The same research team that found the first gene forlate-onset Alzheimer's disease has reported locating another gene that probablyaccounts for the genetic component of the disorder in up to 15 percent of thosewith the late-onset form.  The gene appears to work independently of thepreviously discovered gene, which accounts for almost half of all patients withthe disease. While the scientists have not yet isolated the gene, they have narrowedits location to a tiny piece of human chromosome 12.  The researchers cannotdetermine the gene's purpose until it is pinpointed and more closely studied. "This finding is another tile in the complex genetic mosaic that helpsdefine who is at risk for Alzheimer's disease (AD)," said Margaret Pericak-Vanceof the Duke University Medical Center, lead author of the study. "Little bylittle, we are piecing together a picture of how environmental exposures combinewith genetic predisposition to trigger Alzheimer's disease." "Our understanding of the genetic component of AD is far fromcomplete," she emphasized in an interview. "Nearly half of the genetic basis isstill unexplained and these genes may hold the key to better treatments andeventually a cure." AD is the leading cause of dementia in the elderly, with about 4million people affected. People with AD accumulate abnormal clumps of nerves andtangled bundles of fibers in their brains. They lose nerve cells in areas of thebrain that are vital to memory and other mental abilities. The devastatingdisorder robs older adults of their ability to think clearly and to care forthemselves. The new research findings are reported in the Oct. 15 issue of theJournal of the American Medical Association. The research was funded by theNational Institute of Neurological Disorders and Stroke, the National Instituteon Aging, the Alzheimer's Association and the Joseph and Kathleen Bryan researchfund. "This is an exciting result that is the product of true collaborationbetween many scientists from different disciplines, including clinicians,genetic epidemiologists and molecular geneticists," said co-investigator andsenior author Jonathan Haines of the Vanderbilt University Medical Center,Nashville, Tenn. Other authors of the paper are Henry Terwedow of MassachusettsGeneral Hospital, Charlestown, Mass.; P. Michael Conneally of Indiana UniversityMedical Center, Indianapolis; Gary Small of the University of California at LosAngeles; Meredyth Bass, Larry Yamaoka, Pete Gaskell, William Scott, MarisaMenold, Dr. Jeffery Vance and Anne Saunders of Duke; and Dr. Allen Roses, vicepresident and worldwide director of genetics, Glaxo-Wellcome, London. The research team discovered the first major genetic risk factor for ADin 1993. They found that people who inherit a certain version of the gene calledapolipoprotein-E (ApoE) are at significantly increased risk for developing AD.The ApoE gene is the blueprint for a protein that helps deliver cholesterol, acritical building block of the membranes of newly forming cells. The ApoE gene comes in three versions, and people who inherit theversion called ApoE4 are much more likely to develop AD later in life.Researchers aren't sure why a protein that ferries cholesterol around the bodyleads to AD, but they do know the ApoE4 gene accounts for up to 50 percent ofall late-onset AD. The researchers sought other AD genes, knowing that a genetic basislikely exists for the unexplained portion of the disease. To find the gene, theyscanned the human genome seeking additional genetic segments shared among peoplewith AD. In an initial screen two years ago, the researchers studied 16 familiesin which several generations were affected by AD. They compared the DNA of 52family members who developed AD with 135 who did not. In this search -- the mostextensive ever conducted for new AD genes -- they identified several regions ofDNA that might be linked to AD, including the potential region on chromosome 12.  The researchers narrowed their quest for the new gene by studying anadditional 216 people in 38 families with a high incidence of AD. They foundthat regions on chromosomes 4, 6 and 20 might also harbor genes involved in AD,but the strongest link continued to be on chromosome 12. Based on theirfindings, the researchers say the chromosome 12 gene could account for up to 15percent of AD cases. Other genes associated with AD, including amyloid precursor protein(APP), and Presenilin 1 and 2 (PS1, PS2), account for only a tiny fraction ofAD, less than 5 percent, mostly in early onset cases. Now that the scientists say they are in the right neighborhood of thegene on chromosome 12, they will use a more detailed genetic map of the region,further narrowing down the possible gene location. Finally, the researchers willmethodically screen individual gene candidates. However, even before the gene itself is isolated, the chromosomallocation is valuable because it has narrowed the search for this new geneticfactor to less than 1 percent of the human genome. "The Alzheimer's Association is very pleased to support research thatgenerates new knowledge about susceptibility genes and other factors that mayhave an impact on the age of onset of Alzheimer's disease," said ZavenKhachaturian, director of the association's Ronald & Nancy Reagan ResearchInstitute. "As we learn more about these mechanisms, the possibility of delayingthe onset of Alzheimer's becomes more real," said Khachaturian.  "If we candelay the onset of the disease for five years, we can cut in half the number ofpeople who get the disease, add years of independence to people's lives and savethis country billions of dollars in health care costs."
--------
267-> UNC-CH Study Shows Tomato Sauce Might Protect Against Heart Attacks
CHAPEL HILL -- People looking for a good guilt-free reasonto eat pizza might relish results of a major study that took place in nineEuropean countries. The study involved analyzing fat samples taken from 1,379 men whosuffered heart attacks and comparing them with fat samples from healthy controlsubjects. Researchers found that an antioxidant compound called lycopeneappeared to have a protective effect against heart attacks. The chief source of lycopene in the average diet is tomato sauce, andthe food many Americans get most of their tomato sauce from is pizza. "Based on our findings, and other research showing lycopene can be anexcellent antioxidant, we recommend that people eat tomato-based cooked foods,"said Dr. Lenore Kohlmeier, professor of nutrition and epidemiology at theUniversity of North Carolina at Chapel Hill schools of public health andmedicine. "Tomato sauce on grains or pasta would be better than pizza, however,because cheese can carry a lot of fat." The apparent protective effect of lycopene -- or another unknownnutrient closely associated with it -- was greatest among non-smokers, the studyshowed. A report on the research appears in the Oct. 15 issue of the AmericanJournal of Epidemiology. Kohlmeier, a member of the UNC Lineberger ComprehensiveCancer Center, is chief author. Researchers found that men whose fat samples revealed high consumptionof lycopene had about half the risk of heart attack as men whose samples showedlow lycopene consumption. This effect exceeded any protective effect of eitheralpha- or beta-carotene -- dietary carotenoid compounds similar to lycopene. Other foods containing lycopene are watermelon, red grapefruit and, to alesser extent, shellfish, Kohlmeier said. People get more lycopene from cookedtomatoes than raw ones; apparently cooking releases the nutrient from the matrixthat binds it in raw tomatoes. The process appears to be similar to the waycooking releases beta-carotene from raw carrots. "Again we are seeing that consuming protective substances through foodis much better and safer than turning to a supplement," the scientist said. "Infact, supplements may actually compete with and inhibit uptake of otherimportant products in our diet." The study took place in Finland, Germany, Israel, the Netherlands,Norway, Russia, Scotland, Spain and Switzerland and was part of the EuropeanCommunity Multicenter Study on Antioxidants, Myocardial Infarction and BreastCancer (EURAMIC). It was financed by participating countries in part as aConcerted Action by the Commission of European Communities. Co-authors of the new report include Drs. Jeremy D. Kark, EnriqueGomez-Garcia, Blaise C. Martin, Susan E. Steck, Alwine F.M. Kardinaal, JetmundRingstad, Michael Thamm, Victor Masaev, Rudolf Riemersma, Jose M. Martin-Moreno,Jussi K. Huttunen and Frans J. Kok. Antioxidants are compounds that are believed to help protect the bodyagainst damage caused by charged particles of oxygen known as free radicals,Kohlmeier said. Such oxidative processes occur naturally, but external stressessuch as cigarette smoking and sun exposure add to them and can increase damageto cell membranes and body proteins. Many scientists around the world are tryingto identify antioxidants and understand how they work. Low density lipoproteins, a form of cholesterol that circulates inblood, are believed to be particularly dangerous in promoting heart diseasethrough oxidation, she said. Lycopene -- or an unknown, closely associatedcompound -- may prevent their formation in the blood. Another recent studysuggested lycopene-rich foods might protect against prostate canc  Other foods containing lycopene are watermelon, red grapefruit and, to alesser extent, shellfish, Kohlmeier said. People get more lycopene from cookedtomatoes than raw ones; apparently cooking releases the nutrient from the matrixthat binds it in raw tomatoes. The process appears to be similar to the waycooking releases beta-carotene from raw carrots. "Again we are seeing that consuming protective substances through foodis much better and safer than turning to a supplement," the scientist said. "Infact, supplements may actually compete with and inhibit uptake of otherimportant products in our diet." The study took place in Finland, Germany, Israel, the Netherlands,Norway, Russia, Scotland, Spain and Switzerland and was part of the EuropeanCommunity Multicenter Study on Antioxidants, Myocardial Infarction and BreastCancer (EURAMIC). It was financed by participating countries in part as aConcerted Action by the Commission of European Communities. Co-authors of the new report include Drs. Jeremy D. Kark, EnriqueGomez-Garcia, Blaise C. Martin, Susan E. Steck, Alwine F.M. Kardinaal, JetmundRingstad, Michael Thamm, Victor Masaev, Rudolf Riemersma, Jose M. Martin-Moreno,Jussi K. Huttunen and Frans J. Kok. Antioxidants are compounds that are believed to help protect the bodyagainst damage caused by charged particles of oxygen known as free radicals,Kohlmeier said. Such oxidative processes occur naturally, but external stressessuch as cigarette smoking and sun exposure add to them and can increase damageto cell membranes and body proteins. Many scientists around the world are tryingto identify antioxidants and understand how they work. Low density lipoproteins, a form of cholesterol that circulates inblood, are believed to be particularly dangerous in promoting heart diseasethrough oxidation, she said. Lycopene -- or an unknown, closely associatedcompound -- may prevent their formation in the blood. Another recent studysuggested lycopene-rich foods might protect against prostate cancer.
--------
268-> Colorado State Anthropologist Finds Fossil Treasures In Africa
 FORT COLLINS--A day's work for Colorado State anthropologistDiane Waddle can include encounters with deadly cobras,excavations on steep walls using rock-climbing equipment andtraveling to fossil sites on roads so rough a kidney belt isrequired. But the treacherous conditions are worth the bounty Waddleand two other anthropologists recently uncovered in a remotelimestone cave in Botswana, Africa: fossilized bones of thousandsof tiny bats, shrews, birds and frogs as well as a complete skullof an adult primate and the jawbone of a juvenile primatebelieved to be ancient ancestors of present-day baboons. The vast collection of fossils is one of the few uncoveredin Botswana and contains well-preserved specimens of smallmammals that may have roamed the earth sometime between 100,000and 3 million years ago. Most likely used by owls and othermammals to eat their prey, the cave is so rich with fossils it'scalled Bone Cave. Waddle and the other researchers believe the find can helpfill the gap in the fossil record of Botswana, an area that hasnot been a major focus for anthropologists or archaeologists inrecent years. Although there are numerous sites containing stonetools in Botswana, the only human or primate remains fromBotswana are less than 10,000 years old and are fully modern.Other fossils found in Botswana have been from the Middle StoneAge, roughly 100,000 years and earlier. "This is a great find because of the wealth of fossils inthe cave," Waddle said. "It's particularly important becauseBotswana has virtually no fossil sites of this kind and therereally is no fossil record of primates at all. Many fossil sitesmay only produce a few fossils. "This is really impressive because it's like a big pile ofbones glued together." Waddle said the main reason that not much is known about theevolutionary history of this region is the remote location of thecaves; about an 11-hour drive from the nearest town. To get toBone Cave, the research team must rely on tire tracks from theprevious year's expedition, which often proves difficult. Therainy season causes grasses to grow over the tracks and elephantsscar the road with footprints. Using a grant from the National Geographic Society, Waddlebegan making the trips to Bone Cave with anthropologists CallumRoss of SUNY Stoney Brook University and Blythe Williams of DukeUniversity in 1994. Colorado State anthropology students JodiLaumer and Lawrence Steumke traveled to Africa with the team onthe most recent trip. In the project's first two years, researchers took aninventory of the cave and learned how to better navigate itsnarrow passages, which serve as a link between two chambers wherethe fossils are located. To get to the main chamber--called theDrop Room--the research team must climb down a steep rubble slopeto a small opening measuring 4 feet across. The larger primatebones are embedded in the steep rock walls and ceilings of theDrop Room, making the fossils much more difficult to reach andremove. To access these fossils, the research team dangles inharnesses and other rock-climbing equipment as high as 15 feetabove the cave floor, carrying drills and other excavation tools. The main chamber below the Drop Room, known as the atrium,consists of spectacular stalactite formations. The atrium'sceiling is covered with a rock matrix containing the bones of small mammals. To access the second chamber, Waddle and the others mustpass through a gauntlet of bats, bugs and critters, includingsnakes. During their most recent trip, Waddle and the other membersof the research team encountered a 5-foot long cobra inside thecave. The team quickly crawled out of the cave to safety whileRoss drove to the nearest town six hours away to retrieve ashotgun. Because he was the best shot of all the researchers inthe party, Steumke was charged with entering the cave andshooting the snake. To celebrate restored peace, each member ofthe research team ate a piece of the cobra, cooked to perfectionon an open fire. "No one wanted to go back into that cave until we knew thatcobra was dead," Waddle joked. Waddle will spend the next several months in the safety ofher lab at Colorado State separating the hard breccia from theprimate skull and other large bones taken from the site. Thetechnique involves coating exposed bone with a preservative andsoaking the specimens for several weeks in vinegar or other weakacid to dissolve the calcium carbonates that hold the brecciatogether. Once the specimens are restored, Waddle will take themto the Smithsonian Institution in Washington, D.C., foridentification, using its inventory of primate fossils todetermine whether they represent a new or existing species. Portions of rock retrieved from the cave where the largestbones were found will be sent to laboratories at the Universityof Georgia for dating.
--------
269-> Overproduction Of Glutamate Can Lead To Brain Damage During Heart Surgery
Cooling the body for heart surgery causes an overproduction of the neurotransmitter glutamate, an excitatory amino acid, and can leave the nervous system vulnerable to damage from the start of the cooling process until up to eight hours after recovery, a Johns Hopkins animal study suggests.  This contradicts previous theories that brain damage occurred only during the initial recovery period. Results of the study, supported by the National Institutes of Health and the Nina Braunwald Research Fellowship from the Thoracic Surgery Foundation for Research and Education, will be presented Oct. 14 at the American College of Surgeons' annual meeting in Chicago. During the cooling process, called hypothermic circulatory arrest (HCA), the body temperature is lowered to reduce the need for oxygen, the heart is stopped and a heart-lung bypass machine takes over circulation in an effort to prevent brain damage.  Prolonged HCA, however, may increase the risk of brain damage, leading to problems in learning, memory and involuntary movements. The researchers measured brain levels of the potentially toxic amino acids glutamate, glycine and citrulline (a marker of nitric oxide) in a group of dogs during closed-chest cardiopulmonary bypass and two hours of HCA.  Significant increases in glutamate were observed throughout the cooling process, recovery period and up to eight hours post-recovery.  Glutamate overproduction led to increases in glycine and citrulline, which were observed during recovery and two to eight hours post-recovery. "These findings suggest that pharmacologic strategies to protect the brain from injury and cell death during HCA will require targeting the excitatory amino acid pathway throughout the cooling process," says Charles J. Lowenstein, M.D., assistant professor of medicine at Hopkins and an author of the paper. The study's other authors were lead author Elaine E. Tseng, M.D.; Malcolm V. Brock, M.D.; Christopher C. Kwon, M.S.; Jorge D. Salazar, M.D.; John R. Doty, M.D.; Michael V. Johnston, M.D.; and William A. Baumgartner, M.D.
--------
270-> Clues To Horse Extinctions Point To Gritty Grass, Climate Change
Johns Hopkins paleobiologist Steven Stanley has sleuthed outclues to the evolution of horses, coming up with a new solutionfor an enduring mystery: What caused the extinction of manyequine species and other mammals 6 million years ago? Like the protagonist in an evolutionary detective thriller,Stanley pursued a hunch that apparently had never occurred toother scientists. His long shot hit a bull's-eye, enablingStanley to learn how shifting climate and changing vegetationlikely altered the fate of horses in North America millions ofyears ago. Stanley, a professor in the Johns Hopkins Department of Earth andPlanetary Sciences, pieced together the findings of otherscientists and  connected those data in a way no otherresearchers had done previously. When taken together, the datapaint a picture of how Earth's changing climate and vegetationmay have been directly involved in the dramatic evolutionarytrends of horses and other animals. The time was marked by the largest extinction rate of NorthAmerican mammals in the last 30 million years; about 60 genera,containing numerous species, perished. Some scientists believe that changing atmospheric concentrations of carbondioxide could have helped bring about the climatic shifts that Stanleybelieves were directly linked to changes in the vegetation thriving in NorthAmerica. Because the extinctions apparently were brought about by thosechanges in vegetation, the lesson is that carbon dioxide-linked global warming-- if it is occuring again today as many scientists believe -- could have aprofound impact on future extinction rates. Stanley will touch on his theory during a 1:35 p.m. talk onSunday, Oct. 19, at the start of the annual meeting of theGeological Society of America. The talk will be in the SaltPalace Convention Center, in Salt Lake City, Utah. Contrary to the popular belief that horses were foreign to theNew World until they were brought here by the Spaniards, theanimals actually evolved in North America, spreading to Europe bycrossing the Bering land bridge that once connected Alaska andSiberia. But they later died out in North America near the end ofthe Ice Age. Well before their disappearance, however, their life history tookan abrupt turn that killed off all but those horses with thelongest teeth. In fact, numerous other mammals, including camelsand rhinos, suffered the same fate in North America. Scientists have known that the extinctions were somehow relatedto expanding grasslands and shrinking forests. Grasses possess agritty compound called silica, which is contained in sand and isused to make glass. As animals chew grass, the silica wears downtheir teeth. Therefore, animals with longer teeth live longerbecause their teeth don't wear down as fast, and they cancontinue to feed. For tens of millions of years, as the Earth's climate becamecooler and dryer, the trend toward expanding grasslands andreceding forests continued in North America. About 13 millionyears ago, the 15 or so species of horses in North America weresplit between those with long teeth and those with shorter teeth.Also at that time, a few new species emerged that had very longteeth. As grasslands expanded, the horses with long teeth lived longerbecause they were best adapted to eating grasses instead ofleaves. Living longer enabled them to produce enough offspring toguarantee survival of their species and the evolution of newspecies. By 11 million years ago, only the horses especially adapted toeating grasses -- those with the long and very long teeth -- wereliving in North America. "Then, there is this sudden event, 6 million years ago, more orless, and what you see is a big extinction pulse, a big drop intotal diversity, and the survivors are all the ones with verylong teeth," Stanley said. The conventional wisdom has suggested that the long-toothedhorses disappeared because of expanding grasses. But that justdidn't make sense, Stanley said, because the horses with longteeth were especially adapted to eating grasses. "So, why would more grass be a problem for them?" Stanley asked. Somehow, something about the grasses must have changed, hereasoned. Meanwhile, other scientists had discovered that, as the climatebecame dryer and cooler, a different type of grasses began todominate North America. Those grasses, known as C-4 grasses,which thrive in dryer climates, replaced many of the previouslydominant grasses, known as C-3 grasses. "I thought, well, this seems like a long shot, but I wonder ifthere are on average more silica bodies in the C-4 grasses thanC-3 grasses," Stanley said. His hunch proved correct. Stanley found that, on average, C-4grasses contain about three times as many of the silica particlesas do C-3 grasses. "Think about a species that was doing all right eating C-3grasses. Maybe it lived 10 years on average and produced enoughcolts to reproduce the species. Well, what happens if that horseis suddenly only living seven years, or six years? It may notproduce enough colts to perpetuate its species. "I think that's what happened. I think there was a big grinddown." The title of his talk is, "Geobiology: Studying the deep historyof the earth-life system."
--------
271-> New Forms Of Old Disease, Leptospirosis, Threaten Dogs In U.S. -- Humans Also Are Susceptible
ITHACA, N.Y. -- A potentially fatal bacterial disease that damages theliver and kidneys of dogs, humans and other animals -- leptospirosis -- isappearing in new forms in the United States.  Citing an alarming increasein leptospirosis cases, bacteriologists in the Cornell University Collegeof Veterinary Medicine's Diagnostic Laboratory are urging dog owners towatch for symptoms of the disease until improved vaccines are available. "We're especially concerned about some of the new types of lepto, such asgrippotyphosa, that we first documented in the New York City metropolitanarea in dogs, but which probably is not confined there.  We're findinggrippotyphosa in the Northeast and in other areas of the country," saidPatrick McDonough, a veterinary bacteriologist at the Cornell DiagnosticLaboratory. That laboratory is the official diagnostic center for animaldisease control in New York state and each year conducts more than 700,000diagnostic tests for animals of all species, including humans. While currently available vaccines do protect against some serovars(serological varieties) of leptospirosis, newer serovars, such asgrippotyphosa and pomona, are not included in that protection, McDonoughnoted, saying:  "There is room for improvement in the vaccinationprotocols."  Worldwide, there are more than 200 known serovars ofleptospirosis infecting many kinds of mammals, including rodents andcattle. Leptospirosis is spread by a spirochete (or spiral shaped) bacteria calledleptospires in the urine of rodents and other infected animals, as well asin water, such as pond water.  The leptospires enter the body throughmucous membranes or through abraded skin. For dog owners, the first signs of leptospirosis in a pet often are severaldays of anorexia, vomiting, lethargy, depression, muscle pain and sometimesdiarrhea or bloody urine.  Veterinarians examining dogs with leptospirosisfind depression, fever, dehydration, jaundice and abdominal pain.  Thedisease damages the animal's liver and kidneys, sometimes resulting inrenal failure and death. If the disease is caught in time, McDonough said, it can be successfullytreated with penicillin and -- when the kidneys have recovered -- with alengthy course of tetracycline drugs.  During their recovery, dehydratedanimals need intravenous fluids and "good, supportive nursing care," headded. "Until vaccines are upgraded to include these new types of lepto, we'readvising dog owners to watch for flulike illnesses in their pets,"McDonough said.  "If the dog has been exposed to the urine of anotherdomestic animal or a wild animal, either directly or in ponds or run-offwater that collect urine, and if you notice these flulike signs, the petshould be tested for lepto." Noting that leptospirosis is a zoonotic disease that can pass from animalsto humans, Cornell Diagnostic Laboratory Director Donald Lein said theinfection can be an occupational hazard for people who work with animals."This used to be called 'milkers' disease,' and there is real potential forits spread among dairy farm workers, as well as people handling otheranimals."  He said that personnel in large dairy farms, where hundreds ofcows are milked several times a day, must work in pits ateye-nose-and-mouth level to a continuous stream of cows -- and to anaerosol form of their urine that could contain leptospires. "Leptospirosis is a disease that's been around for a long time,"McDonough said.  "Now we're recognizing new types.  Certainly in differentareas of the country there are endemic types of lepto that aren't found inother areas, and each area might have its unique lepto problem." -30- Lepto Facts from the Diagnostic Laboratory College of Veterinary Medicine, Cornell University What causes leptospirosis? Leptospirosis is caused by spirochete (or spiral-shaped) bacteriacalled leptospires.  The leptospires live in fluids from infected animals,including urine, saliva, blood and milk.  The disease-causing organisms aretransmitted by direct contact with the fluids or with an infected animal,as well as by indirect contact, including contamination on vegetation, foodand water, soil and bedding materials.  Disease transmission is increasedin crowded conditions.  The disease may be carried for years in animalsthat serve as host reservoirs without the animals showing clinical signs ofthe disease.  The leptospires enter the body through mucous membranes orthrough breaks in the skin. Where are leptospires found? The leptospires cannot survive for long outside their idealenvironment: water or other fluids, moderate temperatures around 25 degreesCelsius (77 degrees Fahrenheit) and neutral or slightly alkaline pH.Stagnant water or slowly flowing streams may carry the leptospires;worldwide, leptospirosis infection increases with flooded conditions.  A1996 outbreak of leptospirosis among white-water rafters was traced by theU.S. Centers for Disease Control and Prevention to contaminated river waterin Costa Rica.  Leptospires are known to survive in urine-soaked soil forsix months.  Summer and early fall are the most likely times forleptospirosis transmission to dogs.  Milk from infected dairy cows maycarry leptospires, although heat from the pasteurization process shouldkill the microorganisms. What are the symptoms of leptospirosis? In general, the disease resembles the flu with fever, headache,chills and myalgia (muscle pain).  Dog owners may notice vomiting,lethargy, depression, muscle pain and sometimes diarrhea or bloody urine inthe pets.  The disease damages the liver and kidneys and, if untreated, maycause death. How is leptospirosis treated? Dogs are treated with a course of antibiotics and with intravenousfluid to overcome dehydration.  Diagnosis is based on clinical signs andlaboratory tests, including tests for the disease-causing organism,urinalysis and blood tests. Can vaccination prevent leptospirosis in dogs? Currently available vaccines for dogs cover only theicterohaemorrhagiae and canicola forms of leptospirosis but not certainemerging forms in dogs, such as grippotyphosa and pomona.  Vaccine makersare now attempting to include protection for emerging forms ofleptospirosis. Do humans catch leptospirosis? Leptospirosis is a so-called zoonotic disease that can betransmitted from animals to humans.  People can catch the disease fromwater that is contaminated by infected wild or domestic animals, as well asfrom more direct contact with animals, such as rodents, raccoons, skunksand cattle.  A well-known Hollywood actress is now recovering fromleptospirosis.  Public health authorities  suggest keeping dogs away fromchildren's play areas, including sandboxes and wading pools. Why are cats not affected by leptospirosis? Tests for antibodies show that some cats are exposed to thedisease, but cats almost never show clinical signs of leptospirosis.  Someexperts believe that cats have developed a kind of immunity toleptospirosis from their longtime association with rodents.
--------
272-> Tune In To This: Weizmann Institute Study Provides Evidence For A Radio-Like Mechanism In The Brain
REHOVOT, Israel, October 14, 1997...Research conducted at the Weizmann Instituteof Science may give a whole new meaning to the phrase "stay tuned." Institute scientistshave found evidence that when the brain interprets sensory input, it uses a mechanism remarkably similarto that of an FM radio. In a study reported in the October 14, 1997, issue of the Proceedings ofthe National Academy of Sciences (PNAS), the researchers describe how the brain uses this radio-likemechanism to "tune in" to a particular frequency, allowing information gathered through touch to betranslated into data about external objects.  This research provides a possible new explanation for the way the brainprocesses sensory information. "We hope that our study will contribute to the deciphering of the neuralcode, the way in which information is encoded by the sensory organs and decoded by the brain," saysresearch team leader Dr. Ehud Ahissar of the Weizmann Institute's Neurobiology Department. He conductedthe study with departmental colleague Dr. Sebastian Haidarliu and Dr. Miriam Zacksenhouse ofthe Technion-Israel Institute of Technology. "Cracking" the neural code would immensely advance brain research, justas the discovery of the genetic code revolutionized genetics and molecular biology. Like an FM receiver When we touch an object, the nerve endings in our skin send electric neuralsignals to the brain. Until now, scientists studying touch -- or, for that matter, other senses --have focused on  identifying the brain cells that receive these signals and on assessing the signals' intensity.  However, according to Weizmann Institute researchers, this is not thewhole story of how the brain actually knows what it's being told by the senses. In the new study, they arguethat the timing of the signals also plays a crucial role in this process. "We found that certain circuits in the brain work on the same principleas an FM radio," says Dr. Ahissar. In frequency modulation (FM) receivers, the radio is tuned to a particular frequency, or station. During the broadcast this frequency is being constantly altered, or modulated,and the receiver translates these modulations into different sounds. Similarly, the brain appears to be tuned to its own "radio stations." In the past decade, scientists discovered that the sensory cortical areas of the brain contain cells thatoscillate at regular frequencies due to intrinsic mechanisms that do not rely on external stimuli. In their study inPNAS, Ahissar and colleagues show that neural signals generated by touch modulate the oscillation frequencyof these cells. Because the cortex oscillations are regular and persistent, they providethe brain with a "yardstick" against which the timing of incoming signals can be compared. The comparisonprobably takes place in the thalamus, which receives input both from the cortical areas containing theoscillating cells and from the external sensory stimuli. It is this comparison that allows the brain to track the timing, orfrequency, of the incoming signals, enabling it to decode the information about the object being touched.  Imagine, for example, that you rub your finger against a ribbed surface,such as corduroy fabric. Nerve endings in the skin would send a signal to the brain every time they hitupon one of the fabric's ridges. The thinner and closer-spaced the ridges, the more frequent the signalswould be. Thus, the frequency of the signals encodes sensory information about the surface. In fact, this may be the reason we need to move the finger over asurface in order to better assess its texture: movement allows us to assess the distribution of sensory input overtime and better define the object being touched. "The timing of the sensory signals appears to be aninherent part of the neural code," says Ahissar. "In fact, this timing contains so much information about theexternal world that it would be surprising if the brain made no use of it." Clarifying the mechanism The researchers conducted their study on rats, that twitch their whiskers whenscouring for food. The rats' brains translate the input from their whiskers into data about thelocation of objects.  The whiskers twitch rapidly, at a rate of about eight motions per second. Thesemotions "notify" the oscillating neurons in the cortex to tune in to a "transmission frequency" ofabout 8 Hz. When the whiskers hit upon an object, they trigger additional neural signals to the brain, whichperturb, or modulate, the regular 8 Hz transmission. The timing of these perturbations is determined bythe object's location. Therefore, it allows the brain to create an internal representation of theobject's whereabouts. "The brains of primates contain similar oscillating cells, which are tuned tothe characteristic frequencies generated when the fingertips rub against an external object," saysAhissar. "Thus, the human brain could use similar FM-radio-like mechanisms to process information obtainedthrough touch and perhaps through other senses as well." In an extension of this research, Weizmann scientists are currentlyseeking to demonstrate that the same principle applies when the brain decodes information perceived throughother senses, particularly vision. This research was funded in part by the Minna-James-Heineman Foundation,Germany; the Israel Science Foundation; and the United States-Israel Binational Science Foundation,Israel.  The Weizmann Institute of Science, in Rehovot, Israel, is one ofthe world's foremost centers of scientific research and graduate study. Its 2,500 scientists, students,technicians, and engineers pursue basic research in the quest for knowledge and the enhancement of the human condition. New ways of fighting disease and hunger, protecting the environment, and harnessing alternativesources of energy are high prioriti  When we touch an object, the nerve endings in our skin send electric neuralsignals to the brain. Until now, scientists studying touch -- or, for that matter, other senses --have focused on  identifying the brain cells that receive these signals and on assessing the signals' intensity.  However, according to Weizmann Institute researchers, this is not thewhole story of how the brain actually knows what it's being told by the senses. In the new study, they arguethat the timing of the signals also plays a crucial role in this process. "We found that certain circuits in the brain work on the same principleas an FM radio," says Dr. Ahissar. In frequency modulation (FM) receivers, the radio is tuned to a particular frequency, or station. During the broadcast this frequency is being constantly altered, or modulated,and the receiver translates these modulations into different sounds. Similarly, the brain appears to be tuned to its own "radio stations." In the past decade, scientists discovered that the sensory cortical areas of the brain contain cells thatoscillate at regular frequencies due to intrinsic mechanisms that do not rely on external stimuli. In their study inPNAS, Ahissar and colleagues show that neural signals generated by touch modulate the oscillation frequencyof these cells. Because the cortex oscillations are regular and persistent, they providethe brain with a "yardstick" against which the timing of incoming signals can be compared. The comparisonprobably takes place in the thalamus, which receives input both from the cortical areas containing theoscillating cells and from the external sensory stimuli. It is this comparison that allows the brain to track the timing, orfrequency, of the incoming signals, enabling it to decode the information about the object being touched.  Imagine, for example, that you rub your finger against a ribbed surface,such as corduroy fabric. Nerve endings in the skin would send a signal to the brain every time they hitupon one of the fabric's ridges. The thinner and closer-spaced the ridges, the more frequent the signalswould be. Thus, the frequency of the signals encodes sensory information about the surface. In fact, this may be the reason we need to move the finger over asurface in order to better assess its texture: movement allows us to assess the distribution of sensory input overtime and better define the object being touched. "The timing of the sensory signals appears to be aninherent part of the neural code," says Ahissar. "In fact, this timing contains so much information about theexternal world that it would be surprising if the brain made no use of it." Clarifying the mechanism The researchers conducted their study on rats, that twitch their whiskers whenscouring for food. The rats' brains translate the input from their whiskers into data about thelocation of objects.  The whiskers twitch rapidly, at a rate of about eight motions per second. Thesemotions "notify" the oscillating neurons in the cortex to tune in to a "transmission frequency" ofabout 8 Hz. When the whiskers hit upon an object, they trigger additional neural signals to the brain, whichperturb, or modulate, the regular 8 Hz transmission. The timing of these perturbations is determined bythe object's location. Therefore, it allows the brain to create an internal representation of theobject's whereabouts. "The brains of primates contain similar oscillating cells, which are tuned tothe characteristic frequencies generated when the fingertips rub against an external object," saysAhissar. "Thus, the human brain could use similar FM-radio-like mechanisms to process information obtainedthrough touch and perhaps through other senses as well." In an extension of this research, Weizmann scientists are currentlyseeking to demonstrate that the same principle applies when the brain decodes information perceived throughother senses, particularly vision. This research was funded in part by the Minna-James-Heineman Foundation,Germany; the Israel Science Foundation; and the United States-Israel Binational Science Foundation,Israel.  The Weizmann Institute of Science, in Rehovot, Israel, is one ofthe world's foremost centers of scientific research and graduate study. Its 2,500 scientists, students,technicians, and engineers pursue basic research in the quest for knowledge and the enhancement of the human condition. New ways of fighting disease and hunger, protecting the environment, and harnessing alternativesources of energy are high priorities.
--------
273-> Wake Forest Scientists Find Way To Short-Circuit Initial HIV Invasion
WINSTON-SALEM -- Scientists at Wake Forest University Baptist MedicalCenter report today that they have found another way to shut down the doorwayfor HIV-1 to invade two types of white blood cells -- lymphocytes andmacrophages. In a report in the Oct 14 issue of the Proceedings of the NationalAcademy of Sciences, Si.-Yi Chen, M.D., Ph.D., assistant professor of cancerbiology, and his colleagues describe how they have inactivated the mostfrequently used co-receptor -- docking site --  for HIV-1 viruses on the surfaceof both macrophages and lymphocytes, resulting in immunity of those macrophagesand lymphocytes to HIV-1 infection. This co-receptor is called CCR5 and serves as the doorway or dockingsite for early-stage HIV-1 virus, known scientifically  as macrophage tropic (orM-tropic) virus. Two weeks ago, the same team reported in Nature Medicine that they hadfound a way to inactivate a different co-receptor --  CXCR4  -- which is thedocking site for late stage HIV-1 virus, known medically as T-cell tropic virus. Based upon HIV-1 infectivity, HIV-1 viruses are classified as M-tropicor T-cell tropic.  During the period soon after HIV-1 infection when mostpatients have no symptoms, most HIV-1 viruses are M-tropic, and use the CCR5co-receptor for entry into lymphocytes and macrophages. In the late stage of AIDS, HIV-1 viruses change their infectivity toT-cell tropic, and use the CXCR4 receptor to get into the lymphocytes. Soblocking entry of that type of virus into the cell blocks the late stages ofAIDS. The approach described in  Nature Medicine could be utilized to treatAIDS patients and late stage HIV-1-infected individuals, while the approachdescribed in Proceedings could be used to treat early-stage of HIV-infectedindividuals and may be some day be used to prevent HIV-1 infection. For both instances, Chen and his colleagues designed a novel approach,termed "intracellular chemokine" --  intrakine for short -- to geneticallyinactivate the chemokine co-receptor. In the report in Proceedings, Chen and his colleagues described how theyused an intrakine called RANTES-intrakine to successfully inactivate the CCR5co-receptor for the macrophage-tropic HIV-1 viruses.. The SDF-intrakine described in Nature Medicine genetically inactivatesthe  CXCR4 co-receptor.  The SDF-intrakine binds to the CXCR4 and traps themolecules inside the lymphocyte, leaving the T-cell tropic HIV-1 with no placeto dock. Chen said that the intrakine approach avoids technical problems facingmany current gene therapy approaches. "This intrakine approach is especially well suited to be translatedinto clinical practice," Chen said, noting that on a typical macrophage orlymphocytes, there are few CCR5 co-receptors, which means that the task ofinactivating the CCR5 can be achievable by current available gene therapytechnology.  Intrakines are human derivatives, and not foreign to human. In treating people with HIV infection, Chen envisions that in the nearfuture, human macrophages and lymphocytes from an infected patient's peripheralblood can be genetically modified with the appropriate intrakine, andperiodically reinfused back into patients to delay the disease progression. Ultimately, Chen said he hoped that stem cells, the mother cells of allimmune cells with an unlimited capability of proliferation, can be geneticallymodified with the intrakine, and reinfused back into patients to regenerate anew immune system that is resistant to HIV-1 infection. His group is now in the stage of pre-clinical study to further evaluatethe efficacy and safety of this intrakine approach, and clinical trials inhumans are a year or more away. The Proceedings article was edited by Anthony S. Fauci, M.D., directorof the National Institute of Allergy and Infectious Diseases of NIH, and and amember of the editorial board.  The research scientists in Chen's team includeAn-gang Yang, M.D., Ph.D. a post-doctoral fellow, Xuefai Bai, Ph.D., a  researchfellow, and Xue F. Huang, Ph.D. a research fellow.
--------
274-> University Of Florida Researchers Report Improvement In The Treatment Of Heart Bypass Patients With Recurrent Problems
By Melanie Fridl Ross GAINESVILLE, Fla---Although bypass surgery is keeping heart disease patients alive longer, the veins most often used to circumvent their obstructed coronary arteries are prone to developing fatty blockages years later. Now a national study shows a minuscule metallic device used to prop open the clogged vessels is better at restoring blood flow than traditional balloon angioplasty -- and does so more safely. Physicians have known for some time that the device, known as a stent, frequently is better suited for opening diseased arteries, but their use hadn't been put to the scientific test in vein bypass grafts, says cardiologist Carl Pepine, chief of cardiovascular medicine at the University of Florida College of Medicine. Pepine participated in the Saphenous Vein De Novo (SAVED) trial along with physicians from 11 other medical centers, led by Philadelphia's Thomas Jefferson University. The scaffold-like stents yielded three benefits: The procedure typically went more smoothly than angioplasty; the diameter of the vein grafts was wider at a six-month follow-up examination; and the risk of death or serious complications such as heart attack, repeat bypass surgery or repeat angioplasty dropped 36 percent, researchers wrote in the September issue of The New England Journal of Medicine. Each year, an estimated 500,000 Americans undergo coronary bypass surgery, said Dr. Michael P. Savage, the study's principal investigator and director of the cardiac catheterization laboratory at Thomas Jefferson University Hospital. Savage also is an associate professor of medicine in the division of cardiology at Jefferson Medical College. Researchers tracked 220 patients with obstructed bypass grafts who had chest pain and/or signs of impaired blood flow to the heart. Participants were randomly assigned to stent placement or standard balloon angioplasty. X-ray images were taken during the initial procedure and at a six-month follow-up visit. Both times, the images showed that individuals who received stents had a larger channel for blood to flow through, said UF cardiologist Richard Kerensky, director of the cardiac catheterization lab at Shands at UF. In addition, physicians were able to reduce the blockage without major complications 92 percent of the time with the stent, compared with only 69 percent in the angioplasty group, he said. Eight months after the procedure, 73 percent of patients in the stent group were still alive, had not had a heart attack and did not have to undergo repeated bypass surgery or angioplasty, compared with 58 percent of those in the angioplasty group. The most commonly used blood vessel to make the bypass is a vein removed from the leg at the time of the heart surgery. Yet within a decade, half of all so-called saphenous-vein bypass grafts are riddled with atherosclerosis. "This is an increasingly common problem as patients are surviving many years after bypass surgery," Savage said. "Once the bypasses become blocked, it can lead to problems like heart attacks or chest pain and may necessitate a second operation, which is obviously something everyone would like to avoid." Traditionally, physicians have performed conventional balloon angioplasty to treat the obstructed vein bypasses, but this has proven problematic because of frequent complications -- and because the veins often reclose within six months, he said. During angioplasty, cardiologists maneuver a thin guide wire through a small incision in a vessel in the leg up to the blockage. A balloon-tipped catheter is then threaded over the guide wire and inflated to compress the fatty build-up and enlarge the artery's interior diameter, improving blood flow. In contrast, the stent is mounted on a balloon, slid into the vein graft, and expanded when the balloon expands. The balloon is removed, and the stent is left behind to bolster the vein graft and keep it open. "This really gives new hope to patients who have had prior bypass surgery -- new hope for avoiding problems and new hope for possibly avoiding repeated operations," Savage said. ---------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
275-> UF-Developed Software Means Paperless Clinical Trials, Quicker Cures
Writer: Kristen Vecellio, vecellio@ufl.edu Source: Mike Conlon, (352)392-3900 GAINESVILLE, Fla. --- University of Florida researchers have designed an Internet-based electronic computer system to bring large scale clinical trials into the world of cyberspace, saving time, money and maybe even lives. The computer system will allow pharmaceutical companies to bring prescription drugs to the market faster, and successful trials can produce and deliver cures for patients more quickly. "It significantly reduces the amount of time and money that it takes to get research results from a clinical trial," said Mike Conlon, chief information officer for UF's Health Science Center and one of the system's designers. The system, which allows clinical research to be done electronically, can trim six to nine months off the five years needed to complete a typical clinical trial.  It eliminates the need to hand-check the data and shortens the lengthy process of finding and recruiting patients to serve as study subjects.  	Researchers using the Internet-based electronic data capture system need less time to complete a trial, mainly because data is correct as soon as it is entered and is available immediately for analysis and review. Past trial systems were strictly paper forms, which were time consuming and expensive. Extra time and manpower were essential to the process of checking all paperwork by hand.  Even more recent trials still had paper forms that were then entered into a computer. The new system is paperless. "Data is ready to be analyzed as it is entered," Conlon said. "Statisticians are involved in trial planning and final analysis of data, which can now begin as soon as the last patient is treated in the trial." The new system also will speed up the process of subject recruitment by identifying ineligible patients before they are entered into a study.  With direct Internet links, physicians can enter subject information into a database, and the system determines eligibility. The process omits possible patient errors written on eligibility forms. In addition, physicians and trial mangers can check the electronic database form around the world with access to up-to-the-minute information. There is now real-time participation with the Institutional Review Board, regulatory agencies and sponsors. All participants are online and can see the study as it develops. "That database is live and available to the study participants under appropriate security control," Conlon said. "Everyone has improved access to trial data." System designer Ron Marks said the system is unique because all of the research is done over the Internet. The initial run of the system began in early September with the International Verapamil SR-Trandolapril Study for UF cardiologists in the treatment of high blood pressure.   Patient treatment will last two years. Nearly 1,500 computers worldwide are collecting data on an estimated 27,000 patients. A patent for the system has been applied for, creating an opportunity for large-scale clinical research at UF.  Development of the system will give UF researchers a competitive advantage in applying for studies in the collection and management of human subject data. The UF Division of Biostatistics also has been involved in the creation of the primary data collection system, which has been ongoing at UF for the last 13 years.
--------
276-> Move Over El Nino, A Major New Climate Cycle Has Been Discovered, And It Lasts For Decades
Move over El Nino, a major new climate cycle has been discovered, and it lasts for decades It looks like El Nino, it feels like El Nino, and if you are watching fish stocks, reservoir levels or farm production, you would say it is El Nino. But it isn't. Researchers at the University of Washington are describing in two recent research papers what they call a decades-long climate shift in the Pacific Ocean that seems to explain many of the changing environmental patterns seen across North America, and particularly in the Pacific Northwest, since the late 1970s. The scientists are calling this climatic phenomenon the PDO, for Pacific decadal oscillation. And, they say, its current positive cycle helps to explain why U.S. West Coast ocean temperatures have been warmer than average, why winters have been wetter than usual in the South, and why Alaska salmon harvests have been at historic highs, while there have been record declines along the West Coast. El Nino, it appears, is only one small -- albeit exaggerated -- phase of this cycle, says David Battisti, UW atmospheric sciences associate professor, who was the first to show why El Nino recurs on an average of every four years. He describes this latest discovery as an index of sea-surface temperatures in the North Pacific, "which my guess also involves the tropics." Says Battisti: "This phenomenon explains much about what is happening in regional climate change. And if we could predict the PDO, we would have much more reliable forecasts." However, says Nate Mantua, a UW research associate, scientists probably will not have the ability to begin making accurate forecasts for at least another five years. A PDO prediction system, he says, would allow long-term planning in such areas as fisheries, water supplies, agriculture and energy production. "The science right now is more like our understanding of El Nino 15 to 20 years ago," says Mantua. But when a PDO forecast is developed, he says, it will become an important measure of climate across North America. The discovery of the PDO has been something of a scientific detective story. Using high-speed computers, researchers combed the past century's meteorological records to see if they could spot any recurring patterns of climate change. In more recent decades, El Nino quickly emerged as the dominant recurring pattern of year-to-year climate variability on the planet. But when records were studied back to 1900, with the focus on the region north of Hawaii in the Pacific basin, the PDO revealed itself with positive and negative phases lasting from 10 to 30 years With a few interruptions, researchers found that since 1977 the PDO has been in a positive phase with cool air in the Southeastern U.S., and a tendency to dry weather over the Columbia Basin and the Great Lakes. In the Northwest, winters have been largely warm and dry, water levels have been down because there have been fewer storms than normal, and snow packs have been low. In the previous negative phase of the PDO, lasting from 1947 to 1976, the Northwest's water supplies were an average of 20 percent higher than between the 1920s and the 1940s, with more precipitation and higher snow packs. Evidence also suggests that many populations of Pacific salmon are influenced by changes in marine climate. This could explain why in the last negative phase of the PDO, when coastal ocean temperatures were cooler, coho and chinook salmon were in abundance off the coasts of Washington, Oregon and California, but Alaska's stocks were greatly depleted. Since the 1970s, warmer coastal waters have reversed these conditions. However, the UW researchers say, the present positive phase of the PDO should be expected to reverse within a decade, at which time favorable ocean conditions should return for West Coast salmon. Many of these climate changes are felt across North America because of wave patterns -- like ripples in a stream -- in the atmosphere, which is directly affected by changes of temperature in Pacific Ocean currents. But the phenomenon is particularly evident in the Northwest because of a feature in the wind field called the Aleutian low, which directs atmospheric patterns across the region. One of the puzzles of the PDO, says Mantua, is whether it acts as a restraint on El Nino, or whether it is a long-term response to the phenomenon. Mantua says he prefers the argument that the PDO is a slower change in the climate system of the oceans and atmosphere over the entire Pacific basin which influences how El Nino develops. One frustrating aspect of attempting to forecast the PDO is that it develops over such a long period that a negative or a positive phase can have passed before researchers even discover it. "We can recognize the phenomenon, but we can't say what phase we're in at the time," says Battisti. "But that's only because we don't yet fully understand it. After all, it has only been in recent years that we've recognized it even exists." ### To find out what the PDO forecast could be for your region, call Battisti at (206) 543-2019, or at david@atmos.washington.edu, or call Mantua at (206) 616-5347, or at mantua@atmos.washington.edu. Battitsti's paper, whose authors include UW professor of atmospheric sciences John Wallace and graduate student Yuan Zhang, appeared in Journal of Climate Mantua's paper, whose authors include UW quantitive biologist Steven Hare, UW professor of fisheries Robert Francis, Wallace and Zhang, appeared in the Bulletin of the American Meteorological Society.
--------
277-> Testosterone Levels Early In Life May Determine Later Risk Of Prostate Cancer
DURHAM, N.C. -- Duke University Medical Center researchers have foundpreliminary evidence suggesting a man's lifetime risk of prostate cancer may belinked to the amount of male hormone testosterone circulating in his body asearly as puberty or even in utero, although direct evidence of this link remainsto be shown. The two possible risk factors they found -- high "free" testosteronelevels in adulthood and a small shoulder span in relation to body size -- appearto be unrelated to one another. However, they are both tied to hormone levels atvarious stages of development, said Wendy Demark-Wahnefried, associate professorof surgery at Duke and lead author of  two parts of a study that produced thefindings. While doctors won't be able to predict who will get the disease based onthese two factors  alone, the results suggest that "free" hormone levels andshoulder span could be benchmarks for determining who is at greater risk for thedisease, Demark-Wahnefried said. Free testosterone refers to a type of hormonethat is not bound to a protein and thus can freely enter cells throughout thebody. "We have to look at how hormone levels at different points in timeactually determine the risk of prostate cancer," she said. "It is hypothesizedthat hormone levels throughout life -- ranging from in utero to old age -- drivesuch events as skeletal and muscle formation, fat deposition, baldness, and thatthese events may provide the initial stimuli and promotion for prostate cancer. "By studying the tell-tale signs that hormones leave on the body, ourgoal was to clearly separate those men at risk for prostate cancer from thosewho are not." Demark-Wahnefried's research, funded by the National Cancer Instituteand the Cancer Research Foundation of America, set out to measure the linkbetween prostate cancer and factors such as height, weight, musculature andbaldness -- all of which are related to hormones. The two-year, blinded,case-controlled study compared a group of 159 men with prostate cancer to acontrol group of 156 men who had come to the urology clinic for prostatescreenings and other concerns such as kidney stones.  Subjects were aged 50 to70 years. In the first phase of the study, Demark-Wahnefried and her colleagues atthe Duke Comprehensive Cancer Center found nearly a two-fold increase in therisk of prostate cancer among men with high "free" testosterone levels, the formof testosterone that can readily be used by cells throughout the body. While the link between testosterone and prostate cancer has been madebefore, previous studies have measured "total" testosterone, a less active formof the hormone that is bound to specific protein and thus cannot enter thecells. The researchers also found a link between high testosterone levels andvertex or "top of head" baldness. However, baldness was not linked to prostatecancer in the study subjects, probably because baldness is as much related toage as it is to other factors like testosterone, she said. Demark-Wahnefried theorizes that baldness at a younger age, perhaps at40, could be used to predict  the later risk of prostate cancer, a theory thatshe plans to study next. The part of the study that looked at baldness, testosterone levels andprostate cancer is published in the September/October issue of the Journal ofAndrology. Co-authors of that study include Samuel M. Leski of Boston UniversitySchool of Medicine and Mark R. Conaway, Cary N. Robertson, Richard V. Clark,Bruce Lobaugh, Barbara J. Mathias, Tara Smith Strigo, and David F. Paulson ofDuke. In the next phase of the study, published in the September issue of theJournal of Nutrition and Cancer,  researchers found that men with prostatecancer were more likely to have a narrower shoulder span in proportion to theiroverall body size, a trait that earlier studies have shown to be determinedduring puberty. Demark-Wahnefried said those earlier studies, although quite limited intheir sample size, showed that men who go through puberty later have a broadershoulder span than men who go through puberty early. She said this findingsuggests that hormone levels have a direct influence on shoulder span. While the difference in shoulder span was less than a centimeter,Demark-Wahnefried said it was the only physical factor she studied that wassignificantly associated with prostate cancer. "Shoulder span may provide us with a benchmark of past hormonal and/ornutritional status and help elucidate the etiology of this disease," she said. While researchers have long believed that prostate cancer is linked tomale hormone levels, Demark-Wahnefried said the existing research has yieldedconflicting results, similar to the controversy surrounding estrogen as a riskfactor for breast cancer. The current studies provide strong evidence that risk of prostate canceris, in fact, influenced by hormonal events that occur much earlier in life, suchas the formation of skeletal frame, she said.  However, Demark-Wahnefried saidthese events may originate in utero and continue to manifest themselves atdevelopmental milestones throughout a man's life. In her next phase of research, Demark-Wahnefried and colleagues JoellenSchildkraut and Philip Walhter will study the link between baldness and prostatecancer in younger men as well as hormonal differences between younger men, aged18 to 35, who have a strong family history of prostate cancer versus those fromfamilies with no history of the disease.
--------
278-> Deep Space Mission Ion Engine Passes 8,000-Hour Endurance Test
Ion engine propulsion, a futuristic form of spacecraft propulsion referred to in science fiction novels and films for decades, is one step closer to becoming a reality. On September 25, JPL completed an 8,000-hour endurance test of a prototype xenon ion engine, providing a green light for the engine's first-ever application to a deep space mission next summer. Ion propulsion, also known as solar electric propulsion, is set to be used on Deep Space 1 (DS1), the first launch of the New Millennium program, a series of missions designed to test new technologies so that they can be confidently used on science missions of the 21st century. DS1, which will fly by Mars, an asteroid and a comet while validating a dozen technologies, is scheduled to launch on July 1. "This marks an exciting step in deep space exploration," explains Jack Stocky, manager of the NASA Solar Electric Propulsion Technology Application Readiness (NSTAR) program, which is developing ion propulsion for use on a variety of missions. "After years of speculation about the potential of this form of propulsion, we are finally nearing the day when we can validate solar electric propulsion as the propulsion system of choice for tomorrow's most distant missions." The most extensively instrumented endurance test of an ion engine ever performed, the test, which began on June 17, 1996, verified the engine's life expectancy, which has proven to be well beyond the needs of the DS1 mission, while demonstrating performance levels that exceeded all expectations. Conducted in the space-like environment of JPL's vacuum chamber, the test was designed to run full power for several days, then shut off and restarted, a stressing process repeated until 8,000 hours of operation were accumulated. Ion propulsion provides only the tiniest amount of thrust, roughly equivalent to the pressure of a single sheet of paper held in the palm of the hand. Its magic lies in its staying power, for this low thrust slowly changes the craft's velocity from low to high speed, making it ideal for long missions. Compared to traditional chemical propellants, solar electric propulsion provides tremendous savings for future deep space and Earth-orbiting missions with great velocity-change (delta v) requirements. Xenon, a heavy, inert gas used as fuel for the DS1 experiment, is converted into an eerie, blue haze visible from the back of the spacecraft as it catapults through space. DS1's xenon ion engine, which fires electrically charged atoms from its thrusters, is just 29.9 centimeters (11.8 inches) in diameter. It is powered by more than 2,000 watts from large solar arrays provided by the Ballistic Missile Defense Organization. The actual thrust comes from accelerating and expelling positively charged atoms, called ions, starting with only about 22.7 milligrams (20-thousandths of a pound) of thrust. While the charged atoms are fired in great numbers out the thruster at more than 112,654 kilometers (70,000 miles) per hour, their cumulative mass is so low that the spacecraft moves only millimeters per second in its early stages of flight. However, it can eventually build up to 112,976 kilometers (70,200 miles) per hour, compared to just 16,737 kilometers (10,400 miles) per hour for the fastest chemical propulsion engines. After DS1 is launched by an expendable rocket with sufficient power to escape Earth's gravity, it will orbit the Sun at the same speed as Earth. With the ion engine's power, the spacecraft's velocity will increase over time to more than 35,405 kilometers (22,000 miles) per hour, fast enough to rendezvous with a comet or asteroid. In addition to the engine itself, being assembled by the Hughes Electron Dynamics Division, Torrance, CA, NSTAR is also delivering a power processing unit, digital control interface unit, propellant storage and control system, and a diagnostics system. For further details about the DS1 mission, visit http://nmp.jpl.nasa.gov/ds1/ . Development of the xenon ion engine is supported by NASA's Offices of Space Science and Aeronautics, Washington, D.C. NASA's Jet Propulsion Laboratory is a division of the California Institute of Technology, Pasadena, CA.
--------
279-> Disease Takes Its Toll On Waterfowl Populations
If U.S. Fish and Wildlife Service predictions hold, this year 92 million ducks will migrate south from their northern breeding grounds.  Many factors will challenge the survival of these migrants, one of which is disease.  According to Dr. Lynn Creekmore, hundreds of  thousands of waterfowl are presently dying from avian botulism in flyway staging sites in southern Canada and the northern U.S. Dr. Creekmore is a wildlife disease biologist at the U.S. Geological Survey's National Wildlife Health Center in Madison, WI.  It is her job to monitor the occurrence of wildlife disease events in the U.S.  Dr. Creekmore points out that avian botulism is the most serious disease of waterfowl in North America and quite likely the world. The disease can produce massive annual mortality; during this year's fall migration,  Canadian biologists are estimating the losses at one southern Saskatchewan lake to be as high as 300,000 to 500,000 birds.  Also this year, at the Bear River Migratory Bird Refuge, along the shores of the Great Salt Lake, U.S. Fish and Wildlife Service biologists report waterfowl mortality from botulism has reached nearly 100,000 birds.  Most recently, approximately 5,600 birds are believed to have died from botulism at a National Wildlife Refuge in Illinois.  What is even more troubling is that the mortality is continuing and may not end until cold weather drives the birds further south. Avian botulism is a disease of birds resulting from the ingestion of a paralyzing toxin produced by the bacterium, Clostridium botulinum type C.  The toxin is closely related to botulism toxins A and B, which are responsible for a similar food-borne disease in humans.  Affected birds lose coordination and show signs of paralysis of the legs and wings and labored breathing.  In advanced stages of the disease, the birds cannot hold their heads up, and often drown or suffocate. Most outbreaks of type C botulism occur in ducks, and species such as pintails, shovelers, and mallards are among those that suffer the greatest losses.  However, almost all birds are susceptible to the disease, says Dr. Creekmore, and in recent years, losses in other species, including pelicans, herons, and egrets have been increasing. Dr. Tonie Rocke, a veteran scientist also at the USGS National Wildlife Health Center, who has spent years studying botulism explains,  "Often the disease will occur in one wetland and not occur in an adjacent wetland just a few yards away.   If we could determine the environmental factors that trigger the disease, we may be able to devise wetland management methods to lower the risk of outbreaks and reduce mortality." Dr. Rocke and her colleagues have made significant progress in determining the conditions that are associated with avian botulism outbreaks.  The organism is widely distributed in wetland sediments and factors such as acidity (pH), salinity, and temperature apparently play major roles in increasing or decreasing the risk of outbreaks.  The next step is to determine if management actions influence these key environmental conditions. The USGS National Wildlife Health Center is the foremost wildlife diagnostic and investigative facility of its type, devoted to identifying causes and possible management responses for episodes of death or debilitation among free-ranging wild creatures throughout the United States and, on a consulting basis, other nations. As the nation's largest earth and biological science and civilian mapping agency, the USGS works in cooperation with more than 1,200 organizations across the country to provide reliable, impartial, scientific information to resource managers, planners, and other customers. This information is gathered in every state by USGS scientists to minimize the loss of life and property from natural disasters, contribute to wise economic and physical development of the nation's natural resources, and enhance the quality of life by monitoring water, biological, energy, and mineral resources of the nation.
--------
280-> Captive Lemurs To Depart For Madagascar Oct. 17 For First Release Into The Wild
DURHAM, N.C. -- Five captive black-and-white ruffed lemurs -- Janus,Letitia, Praesepe, Sarph and Zuben'ubi -- will begin an historic journeyOct. 17 when they depart for Madagascar to become the first such animalsever to be returned to the wilds they never knew. The five lemurs, born in captivity at the Duke University Primate Center,will travel to Madagascar accompanied by veterinarian Graham Crawford ofthe San Francisco Zoo. Once in Madagascar, they will be acclimated in outdoor cages for abouta month in the Betampona Natural Reserve, after which they will be releasedto join a dwindling population of their wild cousins. The animals are allnamed after heavenly bodies such as asteroids, planets, moons and constellations. Madagascar Fauna Group (MFG), the project's international sponsor, plansto systematically repatriate as many as 20 of the adaptable lemurs to theirancestral island nation over the next three years. The first potential releasegroups of the long-tailed, tree-climbing primates now live in two U.S. researchand breeding habitats: the Duke Primate Center and a Wildlife ConservationSociety site on St. Catherine's Island off the coast of Georgia. "This is a beginning, but it is only a beginning," said AndreaKatz, Duke Primate Center's conservation coordinator and an MFG technicaladviser, who will serve as the project's field administrator in Madagascar."Lemurs remain highly endangered in Madagascar, as their habitats aredestroyed and they are hunted for food. Along with such restocking programsmust come major efforts at aiding the nation's economy and preserving remainingnatural habitats." Black-and-white ruffed lemurs, known for the fur that frames their facesand the lush coats of black and white fur, are among Madagascar's most endangered,Katz said. "They can only survive in primary tropical rainforests. They cannotadapt to cleared land or secondary forest. They are also among the mostwell-known lemurs, beautiful, striking, and vocal." The Betampona reserve especially needs new stocks of black-and-whiteruffed lemurs, said Katz and Charles Welch, the project's director. Theyestimate that only 30 to 35 of the animals live there now, a density atleast one-tenth that of any other research site in Madagascar. That numberis so low that diseases, storms or breeding problems could potentially exterminatethe animals at that location, they warned. A careful study of the reservehas shown that it contains sufficient food resources for additional lemursand is now secure enough that they will be relatively safe from poachers,they said. Past poaching activities may partially explain such a low census. Black-and-whiteruffed lemur meat is "reportedly the tastiest," they noted intheir restocking proposal. Another possible culprit is inbreeding. The five animals to be released are related to one another, but sincethey are unrelated to the sparse population in Betampona, their interbreedingwith that population will greatly enhance the gene pool of ruffed lemursin the reserve, said Katz and Welch. Praesepe and Zuben'ubi are brother and sister. Praesepe is the motherof Letitia and Sarph, and Zuben'ubi is the father of Sarph. Letitia is themother of Janus. The Betampona Reserve, a protected area of more than 5,000 acres, isamong the few remaining parts of a vast lowland rain forest that once dominatedmuch of eastern Madagascar. Most of that forest has now been cleared forfarming and local wood consumption, said Katz and Welch. Betampona, in fact,is itself surrounded by rice fields. Besides releasing lemurs, project organizers hope to stimulate a strongerconservation mindedness in Madagascar's own citizens. Toward that aim, Malagasyscientists and nearby villagers will be closely involved in project researchand activities. And the reintroduction efforts will also provide local Malagasywith jobs and educational opportunities. "As an example of education efforts, we plan environmental classesfor local school children to encourage their appreciation of their homeland'snatural riches -- including its unique plants and animals and their habitats-- and the conservation issues facing them today," Welch said. "Localresidents will be reminded that the Betampona refuge constitutes a vitalrepository for clean drinking water and plentiful water for their rice fields,and also protects their villages from flooding," he said. Madagascar is one of the world's poorest nations and a major priorityfor conservationists. Its once-rich array of wildlife has been decimatedby habitat destruction, and by its growing human population's need for usableland and forest products. The problem is critical for lemurs' futures becauseall lemur species are native only to Madagascar. The MFG, headquartered at the San Francisco Zoo, was formed in 1988 tocoordinate conservation efforts for Malagasy animals there and abroad. Itsactivities include training Malagasy students, researchers and technicians.It also assists the government of Madagascar in preserving lemurs and otherthreatened species through well-managed breeding programs. Those programs are underway in distant places like the Duke Primate Centerand other MFG institutions, as well as in Madagascar's own two zoos: TsimbazazaBotanical and Zoological Park and Ivoloina Zoological Park. "This project is an outstanding example of what zoos can do andmust do to preserve wildlife," said David Anderson, the MFG's chairmanand director of the San Francisco Zoo. "We have come full circle --from old fashioned menageries that only displayed animals, to centers forconservation that return wildlife to the wild and protect habitats aroundthe globe." -- (Additional background) The Duke center, located in an isolated off-campus forest, is now hometo 16 different endangered lemur species, as well as six other "prosimian"(pre-monkey) species such as lorises and bushbabies. It is a MFG member,as are 30 other zoological organizations in the United States, Europe andGreat Britain. Despite the species' severe decline in the wild, these lemurs have beenfound to breed very successfully in captivity, Katz and Welch said. More than 250 black and white ruffed lemurs now live in North Americaninstitutions, while others are prospering in British and European zoos.These facilities all share husbandry and health information on their charges,and they often exchange animals as well for outbreeding. In effect, thewidely distributed lemurs are being genetically managed as if they werea single large population. Besides the five to be released, other candidates are now being keptin fenced natural enclosures at the Duke Primate Center or on St. Catherine'sIsland. The animals are prepared for their future lives in Betampona by puttingthem through a kind of lemur "boot camp." For instance, whilethe Duke animals now descend to eat "unnatural" rations of monkeychow, their keepers are varying their feeding sites. That's to discouragedependency and encourage them to range widely. The lemurs at Duke and St. Catherine's Island also readily forage forwild plants as they will have to do in Madagascar. And they've been observedissuing the appropriate alarm calls when they spot local predators. In NorthCarolina, their enemies include hawks, foxes and owls. At Betampona, themain predator will be the fossa (pronounced "foosh"), a bobcat-sizedcousin of the mongoose. Despite their apparent ability to forage, the animals will undergo acareful acclimatization process before being released, said Welch. "They'll be fed a mixture of the local fruits and leaves that weknow lemurs eat there," he said. "At the end of the month, thedoor will be opened, but we may not immediately cut off the food. We'llcontinue to supplement their diet for as long as it takes for them to reliablylocate food trees in the area. As they do that, we'll reduce and eventuallyeliminate the food we give them." They will also be equipped with radio collars so that Welch and otherfield researchers can track their movements. Both he and Katz hope thiswell-monitored and well-documented first attempt will become a model forreintroducing many lemur species to their former home. Primary collaborators in the project include some of the MFG's key memberorganizations: the Duke Primate Center, Philadelphia Zoo and Roger WilliamsPark Zoo in the United States; and the Jersey Wildlife Preservation Trust,Marwell Preservation Trust and Zoological Society of London in Great Britain.The American Zoo and Aquarium Association also supports the project. Madagascar collaborators include the National Association for the Managementof Protected Areas, the Malagasy Department of Water and Forests, the Universityof Madagascar and Parc Ivoloina. The total budget for the first three year phase will be $300,000. Almosthalf that money is already in hand due to fund-raising efforts -- principallyby the Jersey-London-Marwell group, which has raised $120,000. In one notable example, actor-producer John Cleese donated the proceedsfrom the London premier of his comedy film Fierce Creatures , whichfeatured captive lemurs in addition to its human cast. Other MFG members include: Aktiengesellschaft Zoologischer in Koln, Germany;Baltimore Zoo; Brookfield (Ill.) Zoo; Cincinnati Zoo; Colchester Zoo inEssex, England; Columbus (Ohio) Zoo; Denver Zoo; Fort Worth (Tex.) Zoo;Institut d'Embryologie, Strasbourg, France; Institute for the Conservationof Tropical Environments in Stony Brook, N.Y.; Knoxville (Tenn.) Zoo; LosAngeles Zoo; Micke Grove Zoo in Lodi, Calif.; Oklahoma City Zoo; OrgrodZoologiczny Poznon in Poland; Parc Zoologique et Botanique Mulhouse in France;Point Defiance Zoo in Tacoma, Wash.; San Antonio Zoo; San Francisco Zoo;St. Louis Zoo; Transvaal Snake Park in South Africa; Wildlife ConservationSociety in Bronx, N.Y.; Zoo Atlanta; Zoological Garden Zurich in Switzerland);and Zoologischer Garten der Landes in Saarbrucken, Germany.< 
--------
281-> New "Wonder Peanut" Beats Olive Oil In Healthful Benefits
GAINESVILLE -- A new "wonder peanut" being harvested for the first time in the United States this month beats olive oil in healthful benefits, says a University of Florida peanut breeder. The SunOleic 97R peanut, developed by Daniel W. Gorbet, a UF Institute of Food and Agricultural Sciences agronomy professor, not only surpasses olive oil in cholesterol-lowering properties, it offers growers better yields than the industry standard, "Florunner" - 10 to 14 percent more peanuts per acre, he says. And if that isn't enough, it offers manufacturers and retailers a three- to 15-fold increase in product shelf life, Gorbet says. "That attribute alone translates into millions of dollars of savings on recalls due to outdated product," he said. "Longer shelf life also gives the new peanut an edge in taste. In industry meetings, where many varieties of peanuts are handed out and tested by growers and manufacturers, this is the peanut everyone's eating. Not only does it taste good, it holds its flavor longer." What gives the peanut its health-promoting qualities is its chemistry, Gorbet says. It has more than 80 percent oleic fatty acid - compared with about 50 percent in regular peanuts. Fatty acids are a major component in all oils, but it is the oleic form - found in largest quantities in oliveand canola oils - that scientists believe make them healthy. "This peanut has even more oleic acid than olive or canola oil. Its health benefits, therefore, could potentially be better," he said. Coronary heart disease is the leading cause of death for women over 40. Yet in a 1995 UF nutrition study, the new peanut's chemistry, in conjunction with a low-fat diet, was shown to help reduce coronary risk factors by lowering blood cholesterol levels in postmenopausal women. That study, conducted by UF/IFAS nutrition professor Rachel Shireman and graduate student Dawn O'Byrne, showed significant reductions in serum cholesterol and low density lipoprotein (LDL) cholesterol - the "bad" cholesterol. As reported in the July 1997 issue of the scientific journal Lipids, the study concluded that substituting high-oleic peanuts as the primary source of monounsaturated fatty acids as part of a low-fat diet may be more advantageous than use of typical vegetable oils. The SunOleic 97R peanut is the second in a series of health-giving peanuts released by UF/IFAS. The first, SunOleic 95R, released two years ago, had slightly lower oleic content and was more susceptible than SunOleic 97R to tomato spotted wilt virus. More importantly, it didn't have the yield growers wanted. "This one does," Gorbet said. This year's SunOleic 97R crop will go to commercial growers in 1998, he says. The peanut should appear in products on grocers' shelves next year. To provide enough seed for growers, this year's crop is being grown in five major peanut-producing states: Florida, Georgia, Alabama, South Carolina and Texas. Gorbet has spent 27 years working on peanut breeding. He says SunOleic 97R is a significant development - for both the peanut industry and the consumer - because of its chemistry. "It is the direction that breeders will go with peanuts in the future," he said.
--------
282-> University Of Florida Researchers Attempt To Find Diagnostic Tool For Fibromyalgia
By Melanie Fridl Ross Shands Public Relations GAINESVILLE, Fla.---Imagine having a disease that causes disabling body pain and fatigue. Doctors think you have a mysterious disorder known as fibromyalgia. But this diagnosis is based on unspecific signs and symptoms -- medical science cannot prove it. University of Florida researchers are embarking on a study of this puzzling ailment, which mainly afflicts women and is a leading cause of disability in Florida, says Dr. Roland Staud, an associate professor of medicine at UF's College of Medicine. Researchers working at the Clinical Research Center at Shands at UF aim to develop a diagnostic tool for fibromyalgia and at the same time glean insight into how the disease causes pain. Currently, standard tests or scans are unable to detect abnormalities that set these patients apart from the general population. "So far neither blood tests nor MRIs (magnetic resonance imaging), nor PET (positron emission tomography) scans have shown any differences in these patients," Staud said. "This lack of findings causes a lot of anxiety with fibromyalgia patients. We really need to find something tangible."               	About 10 percent of the U.S. population -- or 30 million people -- has fibromyalgia, Staud said, yet only a minority of these patients come to medical attention. Only about 1 percent actually see their doctor about it, he said. "The rest suffer and cope alone," he said. So far no single cause or defect has been found to explain the syndrome, which consists of generalized body pain, sleep abnormalities, memory problems and fatigue. Patients also experience tenderness in many so-called "tender points" in the body. "Fibromyalgia ranges from minimal interference to absolute disability," Staud said. "It's really a major health problem. Many patients can't work because of the incredible pain and fatigue they have, and they are not responsive to pain medications. Physical activity worsens their symptoms...they have more pain and they have worse sleep abnormalities. Rest usually improves this but only to some degree -- they never get completely symptom-free." Previous studies examined psychological abnormalities of fibromyalgia patients but found no difference between these patients and the general population. "These people are not crazy and their symptoms cannot be explained by depression," Staud said. Some patients describe battling infections or illnesses prior to the onset of fibromyalgia, but no specific incidents have been definitively linked to the disease. "Some patients just start to hurt," Staud said. "Others think they've just got the flu and it'll go away, but then it doesn't." Researchers will seek to detect an abnormality in the way men and women with fibromyalgia ages 18 to 60 respond to certain stimuli. They must meet the clinical criteria for fibromyalgia and must have had body pain for at least three months. "We are looking for abnormalities of 'wind-up'," Staud said. "Wind-up is a phenomenon of body sensation caused by repetitive stimulation of the skin. We will be testing these patients with a special apparatus and compare the changes they report with normal controls. "Our hypothesis is that patients with fibromyalgia have an abnormality in wind-up," he added. "They don't react to repetitive stimulation as the normal population does." Patients will undergo three sessions lasting 20 minutes each at Shands' Clinical Research Center. These sessions can be spaced out over the course of several days or weeks. "If we find our hypothesis to be true we are naturally very interested in testing medications for the treatment of this disease," Staud said. Staud, the study's principal investigator, is working with researchers in the department of neuroscience. Eventually they plan to seek funding from the National Institutes of Health for expanded studies of the disease. ------------------------------------ Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
283-> Photocatalytic Air Cleaning System Promises To Help Allergy Sufferers
Writer: Randolph Fillmore, rfill@nervm.nerdc.ufl.edu GAINESVILLE, Fla. --- Allergy and asthma sufferers soon may have a new weapon in their fight against airborne enemies: an indoor-air cleaning system that uses light and simple chemicals to destroy the dust mites and mold spores that cause many allergies. Developed at the University of Florida's Solar Energy and Energy Conversion Laboratory, the photocatalytic air filtration system has been tested in medical and industrial settings and already has proven successful at zapping odors and impurities caused by chemicals, viruses and bacteria. It soon will be available for home use, said Yogi Goswami, professor and director of the laboratory. "This technology will revolutionize our notions about the quality of indoor air," said Goswami. "With people spending more and more time indoors, it becomes increasingly important to provide clean air." The  system uses light, which reacts with a titanium dioxide-based chemical catalyst as air passes through. The result is oxidation, which attacks and destroys microbes by disintegrating their DNA. The reaction also kills dust mites and mold. Goswami said that the photocatalytic process is superior to conventional  techniques using filters, which must be changed and disposed of. "With this system, contaminants are destroyed rather than transferred. No toxic chemicals are employed," said Goswami. Allergy and asthma suffers may find great relief once dust mites and mold spores are eliminated from the air they breathe, he said. "Dust mites in the air cause allergic reactions in an estimated 15 to 20 percent of the population, and have been linked to the development of childhood asthma. The droppings of dust mites live in bedding and carpeting, but they also circulate in the air," said Goswami. "Inhaled mold spores are also responsible for many allergy symptoms and aggravate asthma. Mold seeds are microscopic and need to be 100 percent destroyed. Otherwise they lie dormant and grow back. Because mold spores also circulate in the air, cleaning an environmental surface is not an efficient way of eliminating molds. This system eliminates molds altogether." Goswami said the system has been tested successfully in medical research settings where the air in laboratories must be microbe-free. "We've tested the photocatalytic air cleaning system on a variety of indoor air problems, including toxic bacteria, such as those found to cause Legionnaire's disease," said Goswami. "Surgical suites and hospital nurseries are just two obvious places for this system. Sick building syndrome will be a thing of the past where this system is used. The photocatalytic system can quickly kill off 100 percent of bacteria in indoor air." The technology is being readied for the market by Universal Air Technology at the Sid Martin Phototechnology Development Institute, a biotechnical business incubator of the University of Florida.  The home units, Goswami said, may cost as little as $500. -30- Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-9092.
--------
284-> Penn Scientists Develop Novel Procedure To Make Cancer Vaccines
Researchers at the University of Pennsylvania Medical Center have devised aunique and rapid way to transform plentiful monocytes into battle-readydendritic cells in an effort to boost the immune system's cancer-fightingforces. In test-tube cultures, the modified cells have already shown theirability to activate T cells within one week. Penn investigators collaborated with a team from the National CancerInstitute in this ongoing research. The next step, the scientists say, will beto demonstrate that the dendritic cells can induce a clinically useful and saferesponse in the bodies of cancer patients. "Our procedure could be used to produce vaccines against cancers,including breast, colon, and melanoma," says Brian J. Czerniecki, MD, PhD,assistant professor of surgery in Penn's School of Medicine. Although vaccinesare typically thought of as a preventative treatment--administered to patientsbefore contracting a disease--most cancer vaccines are designed to spur theimmune system into attacking existing tumors. Czerniecki and colleagues reporttheir findings in the October 15 issue of the Journal of Immunology. Dendritic cells play a leading role in generating an immune response.After ingesting antigens (molecular tags, of sorts, found on all substances),dendritic cells attach pieces of  internalized antigens to their outer surfacesto attract the attention of T cells. The dendritic cells and their antigen flagstravel to the lymph nodes--where T cells reside--and display the antigens toactivate T cells. The T cells then trigger a complicated immune response toeliminate the antigens, including those on tumor cells. Until recently cancer vaccines have used additives called adjuvants tomobilize dendritic cells. Now, scientists have found ways to generate dendriticcells directly. This concept is working in animal models, but the problem in humans,says Czerniecki, is that there hasn't been an easy way to produce enoughdendritic cells, which make up only 1 percent of the peripheral blood. Tocompensate for such a minuscule pool, Czerniecki's team looked to monocytes astheir starting cell type because they account for 10 percent of human blood. This hypothesis--described by Cerzniecki and his NCI collaborator PeterCohen--proved golden because the researchers' method not only yielded dendriticcells from monocytes, but created them in surprisingly large quantities, andwith amazing speed and potency. "With this technique we can supply very largenumbers of activated dendritic cells, all directed at cancer antigens," saysCzerniecki. The scientists separate the monocytes from a donor's blood and treatthem with calcium, and now, in an as-yet unpublished step, they also addinflammatory molecules called cytokines to further activate the dendritic cells.The surface of these modified cells are tagged with a melanoma antigen. Theflagged dendritic cells are then grown with the donor's T cells, and after oneweek, even T cells from donors without melanoma can fight melanoma tumors. Using the modified dendritic cells, the team of Czerniecki and Cohenplans to conduct a human clinical trial with melanoma patients next spring. "Weplan to kick start the immune system of these patients by giving themmelanoma-antigen-labeled dendritic cells," he explains. "These cells will havethe instructions to activate T cells to find the melanoma tumor and work atshrinking it." Using a similar, but weaker vaccine, German colleagues ofCzerniecki's have detected shrinkage and disappearance of melanoma tumors in ahandful of patients. National Institutes of Health researchers Charles Carter and Steven A.Rosenberg also collaborated on the study, which was supported by the AmericanCancer Society, and the Arthur Pardee, Thomas B. McCabe, and HarringtonFoundations.
--------
285-> Chesapeake Bay Sediment : Home To Pfiesteria-Like Microbes
Analysis of Chesapeake Bay sediment cores collected by the U.S. Geological Survey and the University of Maryland Center for Environmental and Estuarine Studies (CEES) indicates that some of the sediment samples dating back hundreds or thousands of years contain Pfiesteria-like organisms and other microbes. Pfiesteria are microscopic, single-celled plants known as dinoflagellates that have complicated life cycles involving many different physical forms. Scientists are aware that the Pfiesteria living in the sediments of the Chesapeake Bay watershed can become toxic and attack fish under certain, but not well known, nutrient conditions. USGS scientists have collected nutrient (nitrogen and phosphorus) data in the Chesapeake Bay watershed for many years. This historical data can be used to make comparisons with present water conditions.  Since 1995, USGS scientists have also been studying factors such as precipitation,streamflow, salinity, and  dissolved oxygen and their effects on the plants and animals of the Bay.  Sediment cores taken from the bottom of the Bay and its tributaries allow scientists to "look into the past" by analyzingthe fossil pollen, algae, protists, molluscs, crustacea, and fish  from as long ago as 3,000 years. This data provides a baseline of former environmental conditions on which comparisons to the present can be made. The presence of Pfiesteria-like microbes and their effect on aquatic life is a complicated issue requiring knowledge of fish immunology, chemical reactions involving nutrients, stream dynamics, sediment loads, the life cycles of Pfiesteria-like microbes, water temperatures, and otherfactors. The USGS is working with other state and Federal agencies to establish the linkages between these factors and find the cause of the fish lesion/fish kill situation that occurred in the Chesapeake Bay during the summer. As the nation's largest earth and biological science and civilian mapping agency, the USGS works in cooperation with more than 1,200 organizations across the country to provide reliable, impartial, scientific information to resource managers, planners, and other customers. Thisinformation is gathered in every state by USGS scientists to minimize the loss of life and property from natural disasters, contribute to wise economic and physical development of the nation's natural resources, andenhance the quality of life by monitoring water, biological, energy, and mineral resources of the nation. (For more detailed  information on Pfiesteria and sediment cores in the Chesapeake Bay and its tributaries, contact Thomas M. Cronin, geologist, by phone at (703) 648-6363; or for general information about  USGS activities in the Chesapeake Bay Region, visit the Web site at: http://chesapeake.usgs.gov/chesbay )
--------
286-> Designer Antibodies: Cell Repair Mechanism Promises Immune System Control
Immune system B cells are an inventive little army.  When challenged by antigens- proteins produced by invaders such as bacteria - they proliferate and secreteother proteins called immunoglobulins or antibodies. The molecular structure ofthese antibodies is a perfect fit, a receptor that locks onto and disarms theenemy. Immunologists know there is genetic machinery that generates countlesskinds of antibodies in immature B cells developing in the bone marrow, but up tonow, they believed the design process was random and independent of antigen'spresence or influence.  And they thought that once B cells matured, they losttheir ability to recombine their genetic material and produce new and differentantibodies. Not so, says Dr. Garnett Kelsoe, professor of microbiology andimmunology at the University of Maryland School of Medicine.  Mature B cells canreactivate the molecular machinery that makes new genes, which in turn designnovel antibody molecules.  What's more, they can do it outside the bone marrow,in peripheral lymphoid tissues such as the spleen and lymph nodes.  Even more significant is the fact that their renewed recombination of the Bcells' genetic material is antigen-driven.  "The antigen in effect instructsfailing B cell to make a new, antigen-specific receptor," Kelsoe said.  In otherwords, the intruder itself hands the defending army a blueprint for repairingineffective weapons against it. "At least in theory, this means we could expand lymphocyte repertoires to meet apatient's needs," he said.  For example, it should be possible to reconstitutemore quickly the damaged immune system of a cancer patient whose bone marrow hasbeen irradiated. Kelsoe and colleagues report on their findings in the October 10 issueof the journal Science. The University of Maryland School of Medicine researchers, includingKelsoe, Shuhua Han, Biao Zheng, and Michiko Shimoda, and collaborators Stacey R.Dillon and Mark S. Schlissel at Johns Hopkins University School of Medicine,immunized mice with antigen, jumpstarting an  immune reaction. Lymphocytes beganproliferating in the spleen, growing into collections of active B and T cellsknown as germinal centers.  In the germinal centers, where rapid mutation produces many B cells destined tofail and die, the recombination enzymes were turned back on in failing B cells,enzymes were turned back on, causing the cells' genetic material to recombine,generating new antibodies that were a perfect fit for the antigen threateningthem. "We now know that the recombination enzymes are being expressed again inmature B cells; we know that the genes are being rearranged, and we know thatthis mechanism actually is responding to antigen exposure," Kelsoe said. "This appears to be a rescue mechanism for cells that have been damagedby mutation," he suggested.  "The germinal center is a Darwinian microcosm, andevery potential soldier is an investment worth protecting." Kelsoe and colleagues' research was funded in part by the NationalInstitutes of Health, the Leukemia Society of America, the Arthritis Society,the Jeanne M. and Joseph P. Sullivan Foundation and the Santa Fe Institute.
--------
287-> Yale Scientists Measure Current Across Single Organic Molecule
New Haven, CT --  Researchers at Yale have succeeded for the first timein measuring an electric current flowing through a single organic moleculesandwiched between metal electrodes.  The feat could pave the way for aradically new generation of transistors so small that a beaker full wouldcontain more transistors than exist in the world today, according to Yaleelectrical engineer Mark A. Reed, team leader. The accomplishment, announced in the Oct. 10 issue of the journalScience, is a fundamental step toward creating computers and sensors that aresmaller, faster and cheaper than today's silicon-based computers, Professor Reedsaid.  The next step is to design computer chips whose wires are made ofself-assembling strings of organic molecules that grow in a beaker, since thewires would be far too small to produce any other way.  The organic wires wouldadhere to metal electrodes, a revolutionary strategy for fabricating electronicdevices for which Professor Reed and Yale hold a joint patent. "Scientists have gone from one transistor on a single chip to tens ofmillions.  Now we are ready to go to billions of transistors on a single chip,"said Professor Reed, a nanotechnology expert who works with electricalcomponents only about one-billionth of a meter wide (one nanometer), or thewidth of about three atoms.  He and his colleagues have been studying quantummechanical effects that become crucial at such small scales. He warned, however, not to expect to see organic circuits next year at alocal electronics store.  "Just as it took a decade from the discovery of thefirst transistor until the first integrated circuit was made, it could take adecade for us to learn to make useful devices out of quantum components madefrom organic compounds," said Professor Reed, chairman of the electricalengineering department at Yale.  "But success would mean not just anevolutionary change but a revolutionary jump in computer technology." To capture the historic measurement of current across a single organicmolecule, the researchers made a mechanically controllable break junction bygluing a notched gold wire to a flexible substrate, then fracturing the wire tomake an adjustable gap.  Next, they sandwiched a single molecule of benzene (ahexagonal ring made up of six carbon and six hydrogen atoms) flanked by twosticky sulfur atoms between the two gold electrodes.  The process requiredself-assembly of benzene molecules onto the electrodes. Collaborators were graduate student Chong Wo-Zhou and formerpostdoctoral fellow C.J. Muller, both of Yale; and chemistry professor James M.Tour and graduate student Timothy P. Burgin of the University of South Carolina. Overcoming Cost of Miniaturization Organic transistors could replace today's silicon semiconductors, whichare rapidly reaching a point where further miniaturization is too costly. "Thousands of silicon transistors can be produced now for less than a penny, butthe dramatic decrease in cost per transistor that we've enjoyed over the lasttwo decades will start to slow down soon," Professor Reed said.  "Nanotechnologycould become the solution, if we can surmount the hurdles." Perhaps the greatest obstacle Professor Reed must overcome in order tofabricate useful quantum devices is to find better, faster ways to make largequantities.  Quantum devices are made individually by a process called electronbeam lithography, but making billions of transistors that way "would be likewhittling all the books in the Library of Congress from a single block of woodor carving a bridge from a block of steel," he said.  The answer is to find materials that will assemble themselves intoquantum components.  "When you cook a sauce, billions of butter and flourcomponents self-assemble," he said.  "Our goal is to find organic chemicals thatwill combine to form a substrate of conducting molecules -- a goal we have beenworking toward for the last five years." Among the imaginative uses scientists have suggested for quantum devicesare "intelligent" computers -- computers that can learn and reason like humans. They would be built from billions of quantum transistors linked together with reconfigurable interconnections so that each transistorfunctions like a neuron in the brain.  It might even be possible to blendelectronics with biological systems by forcing damaged nerves to regeneratethrough porous quantum computer chips so the human brain can be connected toartificial limbs. Quantum components also could be formed into materials capable ofabsorbing and emitting light at whatever wavelengths their designers specify and"could become the basis for semiconductor lasers more efficient and moreprecisely tuned than any now in existence," said Professor Reed, adding thatlaser diodes found in compact-disc players and sensitive microwave receivers insatellite dishes are relatively simple applications of quantum technologydeveloped 20 years ago. More like waves than particles "When working with quantum components, we must deal with special laws ofphysics that can be ignored when working with larger components.  For example,electrons behave more like waves than particles at quantum scales and can dounexpected things like tunnel through barriers," Professor Reed said.  "Thanksto powerful scanning tunneling microscopes, we have observed behavior thattremendously surprised us and made us realize how little we understand quantummechanics in extremely small electronic devices." Understanding quantum mechanics is crucial in Professor Reed's specialty-- "low-dimension" electronics.  His devices prevent electrons from moving insome or all of nature's three dimensions.  For example, electrons confined in aplane made of an extremely thin film are free to move in only two dimensions,since they can't move perpendicular to the plane.  Those confined in anextremely thin quantum wire are free to move in only one dimension whileelectrons trapped in a quantum "dot" can't move at all -- they are free to movein zero dimensions. Professor Reed, who invented the first quantum dot in 1988 by carving apillar in a semiconductor substrate using lithography, said the smallestconceivable transistors would be made up of quantum dots linked in a circuit,with each dot holding one electron. "More than 35 years ago, the Nobel Prize-winning American physicistRichard Feynman first described the fascinating possibilities that would         arise when we achieved the ability to manipulate matter at the atomic scale,"said Professor Reed, whose research is funded by a four-year grant from theDefense Advanced Research Projects Agency (DARPA).  "Feynman's talk was titled'There's Plenty of Room at the Bottom' -- room for more growth, morebreakthroughs.  In electronics, we are finally reaching the bottom Feynmanpredicted."
--------
288-> War Zone Could Promote Peace By Conserving Environment
University Park, Pa. --- The Demilitarized Zone (DMZ) once symbolized war andconflict, a 366-square-mile area rigidly separating North and South Koreatotally unhabited by humans.  Today, the DMZ may represent a major hope forpeace between the two Koreas. In the current issue of Science magazine (Oct. 10), Penn State scientistKe Chung Kim, professor of entomology, recommends the official conversion of theDMZ into a system of bioreserves that would offer havens for rare and endangeredspecies of animals and plants, as well as an economic boost for North and SouthKorea. "The preservation of DMZ ecosystems is basic to Korea's preservation andenvironmental restoration efforts," says Dr. Kim. "The Korean Peace BioreservesSystem that I proposed in 1994 provides a strategy to preserve the DMZ's richbiodiversity that is critical to conservation efforts in Korea. Jointdevelopment of the KPBRS will foster trust, understanding and respect betweenthe Democratic People's Republic Of Korea (DPRK)  in the north and the Republicof Korea (ROK) in the south." Korea's ecosystems and landscapes have been systematically compromisedby aggressive economic development and military buildup along with rapidurbanization, Dr. Kim notes. For example, in South Korea, most naturalecosystems, including large sections of the coastline and salt marshes, havebeen converted into industrial estates and urban centers. Such efforts resultedin severe pollution of waterways and farmlands and destruction of habitats foranimals and insects. In North Korea, rampant deforestation has caused severesoil erosion and flooding, he says. This massive environmental degradation in both Koreas has led to theloss of plant and animal species in areas outside of the DMZ, says the PennState researcher. "The 1994 biodiversity study showed that 14 percent of birds,23 percent of freshwater fishes and 60 percent of amphibians, for example, havebeen destroyed or endangered." Because of its isolated status, rare animal and plant species arecurrently found in the DMZ.  The ecosystems of the DMZ and a buffer zone, theCivilian Control Zone, provide wintering grounds for two of the world's mostendangered birds: the white-naped crane and the red-crowned crane. While the ROK government in South Korea has voiced support for thepreservation of the DMZ ecosystems, the Construction-Transportation Ministrythis month announced plans to seek legislation to drastically erase green beltregulations, the result of lobbying by land developers. Dr. Kim acknowledges the political and economic pressures, saying "TheKorean population of the whole peninsula may reach 100 million by the year 2025,and continued economic development activities will require additionalappropriation of lands and natural resources. But the lack of a commitment topreserving biodiversity in favor of short-term economic development will hurtKorea's economy in the long-term by destroying its natural resources." Creating a bioreserve system in the DMZ could result in economicopportunities such as international parks for resource conservation andecotourism, like the La Amistad International Park (Biosphere Reserve) betweenCosta Rica and Panama, says the Penn State scientist. Working together on a joint project to create and manage a Koreanbioreserve system could gradually eliminate the distrust between the twocountries and lead to further collaboration, Dr. Kim suggests. In late September, the preliminary round of the Korean peace talks hadbroken down. "Environmental issues may be the least provocative way of breakingthe ice," he says. Over the past two years, Dr. Kim has been talking with groups ofgovernment officials, scientists and other agencies to promote and build supportfor the concept of the Korean Peace Bioreserves Systems not only from bothKorean governments, but also in the United States and througout the world. "The processing of building Korean Peace Bioreserves System will notonly foster close relationships between the two Koreas, but it also willultimately improve environmental security and nurture cultural revival, thusbuilding human security on the Korean peninsula," he sa 
--------
289-> Computer Study Links Mouse Position To Muscle Tension
SAN FRANCISCO--People who use a mouse with their computer suffer more than twice as much muscle tension in their arms, necks and shoulders as those who don't use a mouse, according to research just published by a scientist at San Francisco State University. However, training sessions promoting greater awareness of muscle tension, coupled with frequent one-second breaks from keyboarding, can cut tension levels in half, the study also showed. The findings appear in the current issue of Ergonomics, and emphasize the apparent connection between greater muscle tension and keyboards that force mouse users to extend their arms for long periods. "Wide keyboards with numeric keypads on one end force the arm to extend farther to use the mouse, and that almost always puts you into trouble," said experimental psychologist Erik Peper, coauthor of the paper and a professor of holistic health at SFSU. "The new, raised ergonomic keyboards are even wider, increasing chronic shoulder tension even more when you use a mouse." In a separate, ongoing study, Peper and his colleagues have found that about 80 percent of computer stations are set up incorrectly for the user's body.  Chairs, keyboards and screens are often at the wrong height or angle, and the muscle tension that results can lead to long-term injuries and chronic pain that is difficult to remedy, according to studies by other researchers.  "By the time we are aware of it, it  is much harder to reverse," Peper said. Peper suggests that computer users can reduce muscle tension by switching to keyboards with a centrally located trackball or trackpad pointer instead of a mouse, or keyboards compact enough to allow the mouse to be used without extending the arm too much.  He finds that reducing the arm extension and taking quick "microbreaks" every minute during computer use minimize muscle tension. An alternative toswitching keyboards is to cover the 10-key section to the right with a pad that allowsa mouse position less likely to create arm and shoulder muscle tension. Although he found reduced muscle tension among users of trackball or trackpad pointing devices, Peper noted that there is a low base level of tension any time a computer user approaches the keyboard. People's breathing rates increase, their shoulders often rise, and other indicators of low-level tension appear. "But just because you tense up doesn't mean you'll get sick," he said. With greater awareness of muscle tension, computer users can learn to relieve their muscles and reduce the tension that can result in subsequent pain and injury. Peper used standard methods of recording tension in four muscle groups with test subjects in four keyboarding positions, and found the greatest reduction in muscle tension among trackball or trackpad pointing device users. Peper is the director of SFSU's Institute for Holistic Healing Studies, a center which focuses on natural approaches to health.  He coauthored the muscle tension awareness study with Richard Harvey, a former SFSU psychology graduate student who won a California State University research competition for this work. Their findings include the development of new ways to apply muscle tension measurements in the design of computer pointing devices and keyboards, and the recommendations for healthier computing practices. SFSU is a highly diverse community of 27,000 students and 3,500 faculty and staff.  It is the second largest of the nationally recognized 23-campus California State University System.  Founded in 1899, the University is approaching its 100th year of service to San Francisco, the Bay Area, California and beyond.
--------
290-> Purdue Study Finds Prehistoric Couch Potato
That's the finding of Purdue University researcher Richard Hengst, who studies the physiology of dinosaurs to determine the efficiency of their breathing systems. Hengst, a biologist at Purdue's North Central campus, found that while all early dinosaurs -- those dating back about 220 million years -- breathed inefficiently, dinosaurs that lived only 70 million to 65 million years ago had a much-improved system, resembling that of modern mammals. However, the rate of improvement in respiratory capabilities differed significantly between the South American and North American dinosaurs, with the southern dinosaurs lagging behind their northern relatives in aerobic fitness for tens of millions of years. "Whereas 140 million year ago, the Argentine dinosaurs breathed only slightly more efficiently than their more primitive ancestors, the North American dinosaurs of the same age had vastly improved their technique," he says. "The South Americans caught up with their northern relatives only in the later Cretaceous, or about 70 million years ago." He will present his findings Saturday (10/11) during the annual meeting of the Society of Vertebrate Paleontologists in Chicago. In his study, Hengst looked at how the ribs were attached to the vertebral column to determine the efficiency of the respiratory systems in a number of carnivorous theropods, a class of flesh-eating dinosaurs that walked mainly on their hind legs and included Tyrannosaurus rex. By analyzing how the ribs pivoted around two prominent points, and studying how the ribs that make up the chest were aligned on the vertebrae, Hengst was able to determine how the dinosaurs' ribs moved during breathing. "The more efficiently the chest expanded, the more air the animal could take in and therefore the more aerobic it could be," he says. Though all of the of the early dinosaurs had a similar lineup of ribs to vertebrae, Hengst found that by the middle of the Jurassic period, or about 140 million years ago, many of the northern dinosaurs had evolved a system so that each rib moved in a specialized direction, allowing the dinosaur to consume up to 40 percent more air per breath for the same effort. "This suggests that there was some kind of pressure on these dinosaurs to become more aerobically active over time," he says. Last fall, during a trip to Argentina, Hengst compared the anatomy of the northern dinosaurs to their southern cousins. To his surprise, the southern dinosaurs living during the same period had retained much of their primitive respiratory structures, indicating that they weren't as active as their northern cousins, he says. Though the reason for the difference in respiratory rates is not clear, Hengst says different hunting techniques may have played a role. "The North American theropods may have been pursuit hunters, like wolves, which would require the ability to run over a long period of time, while the South American dinosaurs perhaps employed a 'dash and dine,' approach, an activity that required only a short burst of activity," he says. Other possible explanations, says Hengst, are that the southern dinosaurs may have had more abundant food sources or a landscape that favored ambushing, factors that could have reduced the pressure to become more active. "Whatever the reason, the fact that they eventually did catch up with the northern dinosaurs suggests that there was an optimal level of respiratory efficiency for the dinosaurs, and that all the dinosaurs eventually got there," he says. Hengst also found similar differences in the respiratory systems of non-meat-eating dinosaurs in North America and South Ameri 
--------
291-> Team Begins Test Of Advanced Life Support System
The next phase of testing of regenerative life support systems has begun at NASA's Johnson Space Center, Houston, TX.  A crew of four is being maintained in an air-tight chamber environment for 90 days testing life support systems for future space exploration missions, such as a mission to Mars. Phase III of the Lunar-Mars Life Support Test Project began on Sept. 19, 1997.  It is the fourth in a series of tests being conducted at Johnson.  This phase uses a combination of physical, mechanical, and biological methods to recycle air and water.  The four-person  crew will spend more than 90 days investigating the use of biological, mechanical, and chemical means to recycle all their air and water and provide some of their food.  Regenerative life support is a critical enabling technology for future human deep-space missions, since astronauts cannot carry the supplies necessary to support a trip to Mars or a base on the Moon. The test crew members for Phase III are Crew Commander Dr. Nigel Packham (36, Lockheed-Martin Life Support System Scientist); Vickie Kloeris (41, NASA Shuttle Food System Manager), John Lewis (30, Lockheed-Martin Life Support System Engineer) and Laura Supra (28, Allied Signal Life Support System Engineer).  They plan to remain in the chamber until late December to evaluate the effectiveness of advanced  regenerative life support systems. The current test utilizes biological systems for the primary means of water recovery and employs a combination of mechanical and biological systems to revitalize the air.  A module containing wheat crops will be linked to the test chamber to provide up to 25 percent of the crew's oxygen from the carbon dioxide produced by the crew in the 20-foot chamber.  Water consumed by the crew willbe recycled using a unique biological and physical/chemical water recovery system designed at Johnson.  Solid waste from the crew will be incinerated to produce additional carbon dioxide to sustain plant growth for air revitalization and food production. The team members will provide daily status reports on the operation of the life support systems, as well as crew habitability criteria.  The prime and backup crews also will conduct fourteen demonstration projects during the test including both physiological and psychological medical investigations and evaluations of food systems and of astronaut training techniques. The current test continues investigations begun on three previous tests, conducted in  August 1995, June-July 1996, and January-March 1997.  In the first test, Packham spent fifteen days in a 10-foot chamber using a crop of wheat plants to recycle breathing air.  A 30-day test followed in 1996 with four volunteers in the 20-foot chamber evaluating the effectiveness of advanced mechanical and chemical systems to recycle air and water.  The third test employed mechanical and chemical systems functionally similar to those planned for use aboard the International Space Station to purify air and water supplies for 60 days. NOTE TO EDITORS:    The latest information about the chamber test, including daily updates from the crew, can be found at the Phase III web site at URL: http://pet.jsc.nasa.gov A press conference with the Advanced Life Support Management team and test chamber crew is scheduled on NASA TV for Oct. 9, 1997 at 1 p.m. EDT from the Johnson Space Center.  A tour of the Advanced Life Support Program facilities will be conducted immediately after the press conference for attending media.
--------
292-> UNC-CH Study Shows Carbon Nanotubes Display Remarkable Strength, Flexibility
CHAPEL HILL -- Carbon tubes so thin it would take several million lyingside by side to cover an inch show such remarkable flexibility, strength andresiliency that industry should be able to incorporate them into highperformance sports and aerospace materials, according to new experiments. Manyother products also could be made stronger and possibly safer, scientistsbelieve. The research, conducted at the University of North Carolina at ChapelHill, for the first time used a unique computer-linked microscope to bend andrecord properties of carbon nanotubes. Researchers create the materials -- a form of soot -- by arcingelectricity between two sticks of carbon. About six years ago, Japanesescientist Sumio Iijima discovered the tiny tubes, which are proving to bestiffer and stronger than any other known substance. "Carbon nanotubes are a new material that scientists around the worldhave been studying intensively," said Michael R. Falvo of UNC-CH. "What we havefound is that under large strains, they have the extraordinary property of beingone of the stiffest materials known, while also being able to bend withoutbreaking and then be bent back into their original shape. This is unique." Falvo is a doctoral student working under the direction of Dr. RichardSuperfine, assistant professor of physics and astronomy. A report on the research appears as the cover story in Thursday's issue(Oct 9) of the journal Nature. Besides Falvo and Superfine, authors of thereport are graduate student Gregory J. Clary;  Russell M. Taylor II, researchassistant professor of computer science; Vernon Chi, director of themicroelectronics systems laboratory; Dr. Frederick P. Brooks Jr., Kenanprofessor of computer science; and Dr. Sean Washburn, professor of physics andastronomy. The UNC-CH scientists used a device they invented and called thenanoManipulator to bend the nanotubes, which are extremely light, and thenmeasure the curvature of the bends. They also studied the tubes' bucklingbehavior -- whether or not they buckled under pressure like drinking straws in achild's hands and stayed bent and damaged. "We found that most of the bending was reversible, and that's excitingbecause it was not known before," Falvo said. "Even after repeated bending andstraightening of the nanotubes, they did not break. In fact, we have neverobserved a tube fail after repeated bending." The unique nanoManipulator combines a commercially available atomicforce microscope with a force-feedback virtual reality system. The formeremploys an atomically small probe capable of bending and otherwise manipulatingmolecule-sized particles. The latter allows the scientists to see and feel arepresentation of the surface a million times bigger than its actual size. Carbon fibers already are used in graphite composite tennis rackets andother products because of their strength and lightness, Falvo said. The UNC-CHexperiments indicate that carbon nanotubes are significantly stronger thancarbon fibers and hundreds of times stronger than steel.
--------
293-> Human Immune System Defenseless Against New Hong Kong Flu-Highly Unusual Infection Direct From Poultry
MEMPHIS, Tenn., October 9, 1997 -- A new influenza virus, first found in anow-deceased Hong Kong boy in May and against which the human immune system isdefenseless, passed directly and most unusually from poultry to the boy,reported Robert G. Webster, Ph.D., chairman of the St. Jude Children's ResearchHospital Department of Virology and Molecular Biology,  and other scientists inan article published today by Nature. "Typically, new influenza viruses pass through and are genetically modified inother mammals, like pigs, before reaching humans.  A unique feature of this newvirus of the H5 subtype found in Hong Kong, which we call HK97, is that itmanaged to cross the avian-human species barrier without prior adaptation inanother mammalian species," said Dr. Webster. Previously, only influenza viruses of the H1, H2 or currently circulating H3subtypes have been shown to cause influenza in humans.  It is not known how theHong Kong boy was infected with the H5 virus.  There was an avian flu epidemic amonth earlier. "Fortunately, there are no indications that more infections with HK97 have takenplace in humans or that the virus has spread amongst humans, so HK97 does notseem to be a direct pandemic, or world epidemic, threat at present.  However,its emergence illustrates the necessity for global influenza surveillance," saidDr. Webster. According to a U.S. Department of Agriculture report, more than 460 bloodsamples were taken from people exposed to the boy and another 1,900 samples weretaken from people showing flu symptoms, with none revealing new cases of HK97. The Center for Disease Control (CDC) in Atlanta is developing a lab test fordetecting the new virus, and the CDC Advisory Committee on ImmunizationPractices is scheduled to discuss HK97 when it meets on October 22-23. Note: Dr. Robert Webster will be available to answer questions from the media onOctober 8, 1997, 2:30 pm to 3:30 pm, CDT, via teleconference at 800.289.0730. The conference will be replayed for interested listeners beginning 5:30 pm, CDT,October 8, 1997, and continuing for one week until October 15, 1997, by calling888.566.0825. St. Jude Children's Research Hospital, in Memphis, Tenn., was founded by thelate entertainer Danny Thomas.  The hospital is an internationally recognizedbiomedical research center dedicated to finding cures for catastrophic diseasesof childhood.  The hospital's work is primarily supported through funds raisedby the American Lebanese Syrian Associated Charities (ALSAC).  All St. Judepatients are treated regardless of their ability to pay.  ALSAC covers all costsof treatment beyond those reimbursed by third party insurers, and total costsfor families who have no insurance.
--------
294-> Permissive Parenting May Be Hurting Kids' Sleep
Permissive parenting that doesn't set limits or consistently enforce rules when a child is awake is likely to mean the child isn't getting a good night's rest. When a research team compared 80 children from a sleep disorders clinic with 52 others at a primary care clinic for well children, they found that lax and permissive parenting was strongly associated with sleep disturbances among the children in the well group.  Lax parenting was described as parents giving in, allowing rules to go unenforced, or providing positive consequences for bad behaviors. Judith Owens-Stively, MD, and a research team from Rhode Island Hospital, Brown University School of Medicine (Providence, RI) and George Washington University (Washington, DC) publish their findings in the October Journal of Developmental and Behavioral Pediatrics . The children in the study averaged 5.7 years old. The researchers suggest that one reason the permissive-parenting link did not show up as well in the sleep-disorders pediatric group may be that children with more serious behavioral problems traceable to lax parenting probably are sent to a mental health clinic instead of a sleep disorders clinic. "It is also possible," they write, "that other parent-related variables not directly measured in this study, such as marital discord or maternal depression, are more important predictors of children's sleep problems...severe enough to result in referral to" a sleep-disorder clinic.  It has been estimated that between 15 and 35 percent of young children have problems sleeping.  These include refusal to go to bed, waking up at night, sleepwalking and nightmares. The researchers asked the parents of the children about sleep disturbances, child temperament, behavioral problems, and parenting styles. Intense and negative temperament characteristics in children was associated with clinically significant behavioral sleep disturbances.  As might be expected, highly emotional children - those with a high level of distress and low level of soothability - and those who have behavioral problems during the daytime are also more likely to have problems sleeping at night. The authors recommend that further studies be based on larger sample sizes and use independent observation instead of only parents' answers to questionnair 
--------
295-> Hubble Identifies What May Be The Most Luminous Star Known
Astronomers using NASA's Hubble Space Telescope have identified what may be the most luminous star known -- a celestial mammoth which releases up to 10 million times the power of the Sun and is big enough to fill the diameter of Earth's orbit.  The star unleashes as much energy in six seconds as our Sun does in one year. The image, taken by a University of California, Los Angeles (UCLA)-led team with the recently installed Near-Infrared Camera and Multi-Object Spectrometer (NICMOS) aboard Hubble, also reveals a bright nebula, created by extremely massive stellar eruptions.  The nebula is so big (four light-years) that it would nearly span the distance from the Sun to Alpha Centauri, the nearest star to Earth's solar system. The astronomers estimate that when the titanic star was formed one to three million years ago, it may have weighed up to 200 times the mass of the Sun before shedding much of its mass in violent eruptions. "This star may have been more massive than any other star, and now it is without question still among the most massive -- even at the low end of our estimates," says Don F. Figer of UCLA.  "Its formation and life stages will provide important tests for new theories about star birth and evolution." The UCLA astronomers estimate that the star, called the "Pistol Star" (for the pistol shaped nebula surrounding it), is approximately 25,000 light-years from Earth near the center of the Milky Way galaxy.  The Pistol Star is not visible to the eye, but is located in the direction of the constellation Sagittarius, hidden behind the great dust clouds along the Milky Way. The Pistol Star was first noted in the early 1990s, but its relationship to the nebula was not realized until 1995, when Figer proposed in his Ph.D. thesis that the "past eruptive stages of the star" might have created the nebula.  The Hubble spectrometer results confirm this conclusion. The astronomers believe that the Pistol nebula was created by eruptions in the outer layers of the star which ejected up to 10 solar masses of material in giant outbursts about 4,000 and 6,000 years ago.  The star will continue to lose more material, eventually revealing its bare hot core, sizzling at 100,000 degrees. Burning at such a dramatic rate, the Pistol Star is destined for certain death in a brilliant supernova in 1-3 million years.  "Massive stars are burning their candles at both ends; they are so luminous that they consume their fuel at an outrageous rate, burning out quickly and often creating dramatic events, such as exploding as supernovae," said Mark Morris, a UCLA professor of astronomy and co-investigator.  "As these stars evolve, they can eject substantial portions of their atmospheres -- in the case of the Pistol Star, producing the nebula and an extreme stellar wind (outflow of charged particles) that is 10 billion times stronger than our Sun's." The Pistol Star would be visible to the naked eye as a fourth magnitude star in the sky (which is quite impressive given its distance of 25,000 light-years) if it were not for interstellar dust clouds of tiny particles between the Earth and the center of the Milky Way that absorb the star's light.  The most powerful telescopes cannot see the Pistol Star in visible wavelengths.  However, ten percent of the infrared light leaving the Pistol Star reaches Earth, putting it within reach of infrared telescopes, which have seen rapid technological advances in recent years -- spurred by projects such as NICMOS. The Pistol Star was so massive when it was born that it brings into question current thinking about how stars are formed, say the UCLA astronomers.  In the current view, stars form within large dust clouds which contract under their own gravity, eventually forming hot clumps that ignite the hydrogen fusion process. The star may radiate enough energy to halt the inward fall of material, thus limiting its maximum mass.  The initial mass of the Pistol Star may have exceeded this theoretical upper limit.  "It is perhaps no accident that this extreme-mass star is found near the center of the galaxy," says Morris.  "Current evidence leads us to believe that the star formation process there may favor stars much more massive than our modest Sun." Over the coming year, the team will be using the new near-infrared spectrometer that Ian S. McLean's team is building at UCLA for the giant 10-meter Keck II telescope in Hawaii.  The new instrument will be used to measure the velocities of the expanding gas shells. In addition to Figer, Morris, and McLean, the team also includes Caltech physicist Gene Serabyn and Columbia University astronomer R. Michael Rich. The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc. (AURA), for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency. - end - EDITOR's NOTE:   A photo and caption are available via the World Wide Web at:http://oposite.stsci.edu/pubinfo/PR/97/33.html and via links inhttp://oposite.stsci.edu/pubinfo/Latest.html orhttp://oposite.stsci.edu/pubinfo/Pictures.html. Images are available via the World Wide Web at:http://oposite.stsci.edu/pubinfo/gif/pistol.gif (GIF),http://oposite.stsci.edu/pubinfo/jpeg/pistol.jpg (JPEG). Image files also may be accessed via anonymous ftp from:oposite.stsci.edu in /pubinfo:  gif/pistol.gif (GIF) and jpeg/pistol.jpg (JPEG). Higher resolution digital versions (300 dpi JPEG) of the release photograph are available in:/pubinfo/hrtemp: 97-33.jpg (color) and 97-33bw.jpg (black &white).  A full resolution TIFF image is available in:/pubinfo/tiff/1997/33.tif.
--------
296-> Deaths From Breast Cancer Decreasing
In the past few years, the number of women dying from breast cancer declined almost five per cent, the largest short-term decrease since 1950, according to a recent paper in Cancer Prevention & Control. "Physicians are now detecting smaller, localized tumors earlier," says Professor Judy-Anne Chapman, a biostatistician at U of T, the Henrietta Banting Breast Centre and Women's College Hospital, who oversaw the analytical review of 153 breast cancer studies. Reviewing papers for the National Cancer Institute of Canada, Chapman and her associates looked at studies examining breast cancer rates, screening and treatment conducted over the past 50 years. Data from U.S. studies revealed the incidence of breast cancer between 1940 and 1982 increased one per cent each year. Between 1982 and 1987, the increase was about four per cent each year. But while the incidence of breast cancer has increased, the number of women dying from breast cancer is decreasing. Between 1989 and 1992, the mortality rate declined 4.7 per cent. "Through screening methods, particularly mammography, breast cancer is being detected earlier," notes Chapman. "Earlier detection has improved the prognosis for survival.  "As more breast cancers are detected at an earlier stage, mortality rates should continue to decline," she says. "While mammography is recommended for Canadian women 50 to 69 years of age, public health decision-makers need to revisit the question of whether 40- to 49-year-old women would also benefit from breast cancer screening." Chapman notes that a review of data from the past 50 years needs to take into account the following cohort effects: women aged 40 to 49 more than 20 years ago have a relatively lower risk of breast cancer compared to current and future cohorts of 40- to 49-year-old women. This is due to that fact that fewer women 20 years ago were never pregnant, they tended to have their first pregnancy earlier and they had more pregnancies. In comparison, women currently 40 to 49 years of age may be at a higher risk of breast cancer because more of them have never been pregnant and there is a greater tendency to delay the first pregnancy and have fewer pregnancies. The data analysis also revealed physicians play a key role in mammography. "Ninety-three to 94 per cent of women will comply with a physician's request to have a mammogram," says Chapman. The paper's investigators were funded by the National Cancer Institute of Canada and the Canadian Cancer Society 
--------
297-> Northwestern University Medical School And Northwestern Memorial Hospital Join Baxter In Transgenic Liver National Research Trial
CHICAGO --- Researchers at Northwestern University Medical School andNorthwestern Memorial Hospital announced today that because of the chronicshortage of human donor organs for transplantation, they have joined with BaxterHealthcare Corporation in a nationwide clinical trial using genetically altered(transgenic) pig livers as a temporary "bridge" to help patients dying ofend-stage liver failure. With the aid of the transgenic livers, developed byBaxter's Nextran unit, it is hoped that more patients will be able to surviveuntil a human donor liver becomes available for transplantation. The phase I multicenter trial, cleared by the U. S. Food and DrugAdministration, uses transgenic pig livers as an ex vivo, or outside the body,support system to extend a patient's life until a human donor liver becomesavailable. Using a perfusion process similar to dialysis, transplant specialistsdivert the patient's blood outside the body through a catheter and pass itthrough the pig liver to remove toxins before returning the blood to thepatient's body. The patient's liver is left in place during the procedure. Whena human donor liver becomes available for transplantation, the ex vivo liverperfusion is terminated. Data from the trial will be presented in a scientific peer-reviewedforum at the conclusion of the research study in 1998. "As a leader in transplantation, Northwestern continues to apply scienceand technology to save patient lives. However, while we're hopeful this researchwill bring about new discoveries in the field of transplantation, there is stilla critical need for donor organs," said Jonathan Fryer, M.D., principalinvestigator for the study at Northwestern. Fryer is an assistant professor ofsurgery at Northwestern University Medical School and a transplant surgeon atNorthwestern Memorial Hospital. "The findings from the research will ultimately affect organavailability for all patients waiting for transplantation and give us criticalinsight into how to prevent rejection of all transplanted organs," he said. Each year, an estimated 3,000 Americans die waiting for a donor organ. An additional 100,000 die without even having qualified for the waiting list.Promising research has demonstrated the possibility of using transgenic pigorgans to alleviate the dramatic shortage of human donor organs. Baxter'sNextran unit has developed genetically engineered pigs designed to overcome oneof the major obstacles to successful organ transplantation -- rejection of thedonor organ by the recipient's immune system -- which helps to prolong the lifeof the patient until a human organ becomes available. Researchers at Nextran have genetically engineered pigs to express onthe surface of their organs human proteins that regulate the immune response. Byintroducing the genes for certain human regulatory proteins into a fertilizedpig egg, which is then allowed to develop normally, the researchers haveproduced pigs that possess the human proteins necessary to interrupt the immuneresponse before complement proteins can mark the organ as "foreign" and destroyit. "While this development program is still in its early stages, we alreadyhave gained valuable insight into the human immune response, and the rejectionprocess in particular," said John Logan, vice president of research anddevelopment at Nextran. "The knowledge we gain at Northwestern and other study sites isparamount to reaching our goal of transplanting these organs directly intopatients, supplementing the need for human donors and eventually savingthousands of lives each year," he said. This clinical research trial represents a continuation of a strongtransplant program at Northwestern, including the first kidney transplant inIllinois and, more recently, the first pancreatic islet cell transplant. Thehospital's first small bowel transplant was conducted in 1996, and bone marrowtransplant clinical trials are currently under way to alleviate such autoimmunediseases as lupus, multiple sclerosis and rheumatoid arthritis. Northwestern Memorial Hospital is the primary teaching hospital forNorthwestern University Medical School. It is a member of the NorthwesternHealthcare Network and is widely regarded as one of the nation's pre-eminentmedical centers. Nextran, Inc., based in Princeton, N.J., is a unit of Baxter HealthcareCorporation that develops organ transplant technologies to improve the successand increase the availability of organ transplantation. Baxter HealthcareCorporation is the principal U.S. operating subsidiary of Baxter InternationalInc.
--------
298-> Modified Catalyst Simplifies Manufacture Of Myriad Goods
By tweaking the structure of a class of increasingly popularchemical catalysts known as metallocenes, chemists at theUniversity of Rochester have uncovered a much simpler way to makethe material that forms the basis of a wide range of consumergoods, including soaps, detergents, oils, and plastics. If theprocedure can be scaled up for industrial use -- a question theresearch team is now investigating -- goods made out of billionsof tons of plastics and petroleum-based products should becomeless expensive and safer to produce. The findings are discussedin the October 1 issue of the Journal of the AmericanChemical Society . "This is a spectacularly interesting finding," says RickKemp, a senior research scientist at the Union CarbideCorporation and an expert in the class of materials known asalpha-olefins, which form the chemical backbone of many consumerproducts. "The new catalyst appears to yield products that arevirtually 100 percent pure, a trait that's increasingly desirablein industry." Scientists making alpha-olefins typically need temperaturesof 400 to 500 degrees Fahrenheit and pressures of 100 to 200atmospheres. That's because they use aluminum or nickelcatalysts, which require extreme pressures and temperatures towork. "It's costly to attain these conditions and build thereactors needed to make alpha-olefins with aluminum or nickelcatalysts," says Guillermo Bazan, associate professor ofchemistry and primary author of the JACS article. Bazan's modified metallocene catalyst,bis(ethoxyboratabenzene) zirconium dichloride (BEZD), is capableof churning out alpha-olefins at only one atmosphere of pressureand temperatures just slightly above room temperature. BEZDstrings ethylene molecules end-to-end to form alpha-olefins justas quickly as traditional aluminum and nickel catalysts, Bazansays. It also gives scientists precise control over just how longthe chains grow. Under varying pressure, BEZD can produce carbonchains ranging from ethylene dimers, with just four carbonsatoms, all the way up to full-fledged polymers containing manythousands. "There are a million and one uses for alpha-olefins," Kempsays. "In addition to serving as precursors for detergents,synthetic lubricants, and octane enhancers, they're used toproduce a significant fraction of the 150 billion pounds ofpolyethylene and polypropylene produced each year -- plasticsfound in products ranging from ice cube trays to textiles tobottle caps to trash bags." To make the new catalyst, Bazan put a new spin onmetallocenes, a class of catalysts currently taking the world ofplastics by storm. Scientists have known for more than 40 yearsthat these materials have potent catalytic properties, but it'sonly recently that the plastics industry has begun to takeadvantage of them to create polymers. The catalyst molecule Bazan created bears a strikingstructural and electronic resemblance to metallocenes, whichtypically include two five-carbon rings bracketing a single atomof the transition metal zirconium. Bazan's molecule features six-membered rings containing five carbons and an added boron atom toregulate zirconium's reactivity. But the molecules that grow inthe presence of the two catalysts are dramatically different.While traditional metallocenes yield long polymers of ethylene,BEZD leads to alpha-olefins, which are much shorter, versatile,and easily modified organic chains. While research by Shell inthe Netherlands has shown limited success making alpha-olefinsusing metallocene-like catalysts, Kemp believes Bazan's approachis more sophisticated and leads to far better products. By working with chemical companies, Bazan hopes to determinewithin the next year whether BEZD is an industrially feasiblemeans of producing alpha-olefins. Graduate students Jonathan Rogers and Caroline Sperry joinedBazan in the research, which was funded by the Alfred SloanFoundation and the Henry and Camille Dreyfus Foundation. Schematic of new molecule 
--------
299-> Revolutionary New Hobby-Eberly Telescope Opens Today
Mount Fowlkes near Fort Davis, Texas--The Hobby-Eberly Telescope represents a new era in the design and construction of telescopes. It is the first modern large optical telescope to use an innovative, cost-saving fixed-mirror design. It is also the first telescope ever designed and built to be optimized for spectroscopic surveys of the sky. The primary mirror of the Hobby-Eberly Telescope is composed of 91 separate one-meter (39.37 inch) hexagonal mirrors, aligned by small computer-controlled motors to act as a single 11-meter (433-inch) light-gathering surface. The light-gathering power of large telescopes is determined by the area of their primary mirrors. The Hobby-Eberly Telescope will be able to gather light from objects close to 100 million times fainter than the unaided human eye can see. Because of the way the Hobby-Eberly Telescope will be used, 9.2 meters (362 inches) of its surface will be accessible at any given time. Thus, the Hobby-Eberly Telescope is effectively the third-largest telescope in the world, after the twin 10-meter (393-inch) Keck I and Keck II telescopes in Hawaii. Based on a modification of the concept used in the large radio telescope at Arecibo in Puerto Rico, the Hobby-Eberly Telescope has a primary mirror that does not move up and down from the horizon to the zenith to track stars as they move across the sky, as the primary mirrors of most telescopes do. The Hobby-Eberly Telescope is set in place to point at a given area of the sky prior to an observation period. A much lighter tracker assembly, mounted at the top of the telescope above the primary mirror, then moves to track the astronomical object being observed. Exposure times on a given object of up to two-and-a-half hours are possible. The innovative design and the use of cost-effective, off-the-shelf technology made it possible to construct the Hobby-Eberly Telescope for a total price of $13.5 million. This is only a fraction of the cost of each of the only comparable telescopes in the world, the twin Keck I and Keck II telescopes in Hawaii. The fixed-mirror design of the Hobby-Eberly Telescope means that it cannot be pointed close to the horizon or the zenith, but scientists using it will be able to cover 70 percent of the sky available above McDonald Observatory over the course of a year, providing first-class scientific capability at a bargain price. The Hobby-Eberly Telescope is designed to make substantial contributions to many areas of astronomical research. For example, astronomers will measure the chemical compositions of stars that were too distant to study previously, search for planets in orbit around distant stars, identify and measure activity on the surfaces of stars, learn more about "dark matter" located around galaxies, monitor violent activity in the hearts of some galaxies, and refine theories about star formation and evolution. The Hobby-Eberly Telescope's primary mirror is curved in the shape of a partial sphere, so each of the Hobby-Eberly Telescope's mirror segments is identical in shape and curvature. They were produced by the same assembly-line method and any segment can be used to replace any other, a key cost-saving aspect of the telescope. Spherical mirrors do not produce images as sharp as those produced by the parabolic mirrors found in other telescopes. For this reason, the Hobby-Eberly Telescope uses a "spherical aberration corrector" that allows it to make sharp images over a small area. Light is transmitted from the spherical aberration corrector through fiber-optic cables to spectrographic instruments located in a temperature-controlled room beneath the telescope, where the spectra can be captured for later analysis by computer. The Hobby-Eberly Telescope stands on Mount Fowlkes at McDonald Observatory, adjacent to Mount Locke, the site of McDonald Observatory's other research telescopes. McDonald Observatory, in far West Texas, has the darkest skies of any major observatory in North America. A new gallery, which will allow visitors a close-up view of the new telescope, will open in December, 1997. Currently more than 120,000 visitors per year visit McDonald Observatory. That number is expected to double in the next five years. McDonald Observatory is expanding its visitors' center facilities to keep pace with growing public interest. Ground-breaking for the Hobby-Eberly Telescope occurred in March of 1994. "First light," the first engineering proof that the telescope works, was achieved in December 1996. "First Spectrum," the demonstration that the telescope and its commissioning instrumentation package work as planned, occurred in early September 1997, as did the initiation of limited regular scientific use of the telescope. The telescope is currently in its "commissioning" phase, similar to a "shake-down" cruise for a ship, in which its components are brought into optimal performance. The final instrumentation packages for the telescope are being constructed elsewhere and are expected to be installed throughout 1998.
--------
300-> Blood-Thinning Drug May Improve Clot-Busting Treatment, Save Lives
DALLAS, Oct. 7 -- For treating heart attacks, the blood thinner hirulogis better than heparin when added to a "clot-buster" to dissolve blood clots andreopen clogged arteries, according to a report in today's American HeartAssociation journal Circulation. New Zealand researchers found that individuals given hirulog were morelikely to have their arteries "open up" following the clot-busting orthrombolytic treatment.  Streptokinase was the thrombolytic used in this study. "At 48 hours, the artery has opened up in 35 percent of heparin and 48percent of high-dose hirulog patients," reports Harvey White, M.D., of thecardiology department at Green Lane Hospital.  The study included 412 patients:140 were given heparin, 136 were given low-dose hirulog and 136 were givenhigh-dose hirulog. Researchers point out that within the first 24 hours after clot-busingtreatment, about 5-15 percent of individuals may have new clots forming, aproblem that, in some cases, causes death. White says a large clinical trial will be conducted in 17,000 patientsto find out if hirulog given before streptokinase will improve survival.  Earlysuccessful reperfusion or reopening is normally associated with survival.
--------
301-> Common Drugs May Prevent Antibiotic-Induced Deafness
ANN ARBOR---University of Michigan scientists have found that ironchelators---medications used to "soak up" excess iron in the bloodstream---canprevent deafness in guinea pigs exposed to antibiotics that damage delicate haircells in the inner ear. If clinical trials show that iron chelators work as well in humans as they do inguinea pigs, the U-M research could lead to a safe and inexpensive way toeliminate the threat of deafness to individuals treated with a common class ofbroad-spectrum antibiotics called aminoglycosides. Discovered in the 1940s, these antibiotics---which include streptomycin,gentamicin, neomycin and others---are the most widely used antibiotics in theworld.  Because they are so effective and rarely produce allergic reactions,physicians continue to prescribe them, even though they are known to causehearing loss and kidney damage in a significant percentage of individuals whotake them. "In the United States, aminoglycosides are most often used for emergencytreatment of people with serious infections who have not responded to othertypes of antibiotics," said Jochen Schacht, a professor of biological chemistryand otolaryngology in the U-M Medical School.  "Increasing levels ofantibiotic-resistant infections associated with AIDS and a worldwide resurgenceof tuberculosis, however, make it likely that their use will increase in thefuture. "These drugs are a particularly serious problem in developing countries,especially China and Southeast Asia, where they are inexpensive and widelyavailable without a prescription," Schacht added.  "Mothers take children withupper respiratory infections to their local pharmacy for an injection.  As aresult, studies of deaf-mutism in southeastern China showed that two-thirds ofthe cases were caused by aminoglycosides." The fact that aminoglycosides have toxic side-effects has been well-known sincethe 1940s, but only recently---thanks to 20 years of research by Schacht andcolleagues at the U-M and other universities---have scientists figured out howthese drugs do their damage. In 1995, Schacht and his colleagues discovered that gentamicin is not toxicuntil it combines with iron in the bloodstream and becomes "activated."  Asthese gentamicin-iron molecules form, they trigger production of freeradicals---unstable molecules that rip apart and damage cells.  Thousands oftiny hair cells in the inner ear are especially vulnerable.  Without functionalhair cells, the inner ear is unable to detect sounds or transmit signals toauditory neurons leading to the brain.  The result is irreversible hearing loss. "The solution was to avoid the formation of free radicals by preventing thegentamicin from binding with iron in the first place," Schacht said.  "That'swhen we decided to try using iron chelators to absorb the iron and keep it fromcombining with gentamicin." In an article published in the July 1997 issue of the Journal of Pharmacologyand Experimental Therapeutics, Schacht published the results of experimentsshowing that iron chelators did protect guinea pigs from gentamicin's ototoxiceffects.  In this study, one group of guinea pigs received gentamicin byinjection.  In addition to gentamicin, another group of animals also receivedinjections of two iron chelators---deferoxamine (DFO) and 2,3-dihydroxybenzoate(DHB).  One group of animals also received the antioxidant mannitol.  Allanimals received hearing tests before, during and after treatment.  The quantityand physical condition of hair cells in the cochlea or inner ear of all animalswere examined in tests conducted at the experiment's conclusion. While the guinea pigs receiving gentamicin alone experienced significant hearingloss with complete loss of hair cells in certain areas of the cochlea, animalsreceiving some combination of iron chelators and antioxidant therapy did muchbetter.  "The most striking result was achieved with co-injection of gentamicinwith DHB and mannitol," Schacht reported.  "This regimen yielded completeprotection at all measured frequencies in all animals." Equally important, the treatment did not compromise the therapeutic effects ofgentamicin.  Schacht found that iron chelators and mannitol did not lower bloodserum levels of gentamicin nor affect its ability to kill E. coli bacteria. "We have the principle nailed down," Schacht said.  "Now we must work withpharmaceutical firms to identify the most effective iron chelators andantioxidants available, determine a safe human dosage regimen, and then see ifthey will prevent hearing loss in people." Since iron chelators and antioxidants are already approved for clinical use,Schacht said human clinical trials could start "tomorrow."  He added that healready has laboratories in China and Thailand, where the problem is mostprevalent, which have agreed to conduct the trials, if Schacht can obtainfunding. The research was funded by the National Institute on Deafness and OtherCommunication Disorders, National Institutes of Health.  Co-investigators on themost recent experiment include Ben-Bo Song, U-M research fellow, and David J.Anderson, U-M professor of electrical and computer engineering.  The experimentswere conducted at the U-M's Kresge Hearing Research Institute.
--------
302-> Yale Sonar Robot Modeled After Bat And Dolphin Echolocation Behavior
New Haven, CT --  A robot inspired by the ability of bats and dolphins touse echoes for locating prey is causing robotics experts to reevaluate therelative merits of sound waves versus camera vision for exploring newenvironments.  The sonar device, which was designed and created by YaleUniversity electrical engineering professor Roman Kuc, is so sensitive that itcan tell whether a tossed coin has come up heads or tails. "In the early days of robot design, primitive navigational sonars wereoften used to locate objects, but cameras were needed to identify them," saysProfessor Kuc, who has designed mobile robots and navigating wheelchairsequipped with ultrasound sensors during 10 years of robotics research.  "Inrecent years, scientists have virtually abandoned sonar detection in favor ofcamera vision for robots, but we decided to take a closer look at howecholocation is used in nature to see if we might be missing something." Advances in camera-vision research have reached a plateau becausescientists have encountered formidable obstacles in duplicating the incrediblepower and subtlety of human vision, Professor Kuc says.  Yale's design for sonardetection, on the other hand, could prove easier and less costly than cameravision for identifying an authorized customer at an automated teller machine,detecting production flaws on an assembly line, or helping someone who isparalyzed interact with a computer. Called Rodolph -- short for robotic dolphin -- Yale's robot is equippedwith three Polaroid electrostatic transducers that can act either astransmitters or receivers to serve as the robot's "mouth" and "ears."  Thetransducers are similar to those used in Polaroid autofocus cameras to gauge anobject's range, and in acoustic digital tape measures that use echoes to measuredistances. Attached to the end of a robotic arm, the transducer in the center emitssounds waves that bounce off objects, much like the high-pitched squeals of batsand the clicking sounds of dolphins.  The robot's mouth is flanked by tworotating transducer ears that act as receivers for detecting echoes.  The designis inspired by bats, whose ears react by rotating in the direction of an echosource, and by dolphins, who appear to move around in order to place an objectat a standard distance, Professor Kuc explains in the August issue of theJournal of the Acoustical Society of America in the cover article. The robot's bobbing head with its twitching ears has an eerie,animal-like quality as it scans the environment in Professor Kuc's laboratory,scrutinizing coins and distinguishing between various sizes of rubber 0-ringsand ball bearings.  A human hand inadvertently passing through its sonar fieldsets off scanning motions reminiscent of an inquisitive cat. "The robot exploits the important biological principle of sensormobility to place an object at a constant distance, thus reducing the complexityof object recognition," Professor Kuc says, adding that the rotating ears alsohelp pinpoint and amplify the sound.  "Then the robot can either learn a newobject by adding the echoes to its memory, or identify an old object already inits data base." Controlled by a Pentium 120 processor in a personal computer, the robotemits ultrasound pulses at 60 kilohertz as often as 10 times a second.  The earsrotate separately on the moving arm, helping to position the sonar 15centimeters from the object, plus or minus 0.1 millimeter. Previous sonar robots required a far larger number of sonar readingsfrom different angles and distances for object identification, but ProfessorKuc's robot requires only a single reading because it can move around and scanuntil it arrives at a predetermined distance from the object. The data the robot gathers during a learning process are logarithmicallycompressed to emphasize slight differences in structure and reduced to producevectors containing 32 different features.  Each object is represented byapproximately 50 vectors that form clusters, each cluster corresponding to aparticular view angle, says Professor Kuc, who uses C++ computer language forprocessing. The next step is to mount the stationary robotic arm on a mobile base toenable Rodolph to explore its environment, says Professor Kuc, whose research issupported by the National Science Foundation.
--------
303-> Improved Solar Cell Efficiency In The Works
BERKELEY, CA. -- Common manufacturing methods produce solar cells with anefficiency of 12 to 15 percent in converting sunlight to electricity; to make aprofit, 14 percent is the bare minimum. In work done at the Ernest OrlandoLawrence Berkeley National Laboratory, scientist Scott McHugo has discoveredimportant clues to the poor performance of solar cells manufactured frompolycrystalline silicon. The solar-cell market is potentially vast; because there's no need tobuild transmission lines or truck in generator fuel, lightweight solar panelsare ideal for bringing electrical power to remote locations in developingnations. Industrial nations faced with diminishing resources also have activeprograms aimed at producing better, cheaper solar cells. "In a solar cell there's a junction between p-type silicon and an n-typelayer such as diffused-in phosphorus. When sunlight is absorbed, it freeselectrons which start migrating in a random-walk fashion toward that junction,"explains McHugo; now with Berkeley Lab's Accelerator and Fusion ResearchDivision, McHugo became interested in solar cells when he was doing graduatework in materials science at UC Berkeley. "If the electrons make it to thejunction, they contribute to the cell's output of electric current. Often,however, before they reach the junction they recombine at specific sites in thecrystal," and thus can't contribute to current output.         McHugo looked at a map of a silicon wafer in which sites of highrecombination showed up as dark regions. Researchers before him had shown thatthese occurred not primarily at grain boundaries in the polycrystallinematerial, as might be expected, but more often at dislocations in the crystal --yet the dislocations themselves were not the problem. Using a unique heattreatment, McHugo performed electrical measurements to investigate the materialat the dislocations; he was the first to show that they were "decorated" withiron. "When I came to Berkeley Lab as a postdoc, I was able to employ atechnique using x-rays at the Advanced Light Source (ALS) which is orders ofmagnitude better than what can be done with standard techniques that use anelectron beam," says McHugo, who worked with the x-ray fluorescence microprobebeamline built and operated at the ALS by the Center for X-Ray Optics, part ofthe Lab's Materials Science Division. The one-micron spot of hard x-raysproduced by the beamline allowed McHugo to align the resulting x-rayfluorescence spectra with maps of the defects made with a scanning electronmicroscope, comparing defects and impurities directly. "That's when I found thatnot only iron but copper and nickel were also concentrated in thesehigh-recombination sites." Metal from valves, couplings, and other machinery can contaminate solarcells as they are grown from molten silicon, cut into wafers, and finished byadding dopants and attaching contacts. In an industry with a narrow profitmargin, where cheap polycrystalline silicon must be used instead ofeasy-to-purify but far more costly single-crystal silicon, rigorous cleanlinessat every step of the way would be too expensive. However, when it comes to purifying solar cells, cleanliness is not theonly variable. Doping with phosphorus, as well as sintering aluminum contactsonto the wafers (heating them almost to melting), both actually help in"gettering" the silicon -- getting out the contaminants chemically. By adjustingtime and temperature, these standard processes could be optimized to do a betterjob. McHugo has shown that briefly annealing the finished solar cell at hightemperatures is enough to remove copper and nickel precipitates of moderatesize, although dissolved copper and nickel or very small precipitates of thesemetals may remain.         McHugo is currently investigating what techniques are necessary toremove stubborn iron impurities from their hiding places in crystal defects."We're looking at a two-step process," he says, "first subjecting the wafer tovery high temperatures and then lowering the temperature to finish the properprocessing of the solar cell." "If a dirty manufacturing run produces solar cells of 12 percentefficiency, and a manufacturer can make money at 15 percent, think howprofitable cells of 18 percent would be," says McHugo, who has collaborated withAmerican and Japanese manufacturers and is now working with a consortium ofgovernment, university, and industry researchers in Germany. "Investigators have already achieved 18 percent in the lab with small samples; the challenge isto do it on the production line with full-sized solar cell wafers. It's a goalwe're close to reaching." Some of McHugo's findings were presented at the Materials ResearchSociety meeting held last spring in San Francisco and will appear in theOctober, 1997 issue of Applied Physics Letters. Berkeley Lab is a U.S. Department of Energy national laboratory locatedin Berkeley, California. It conducts unclassified scientific research and ismanaged by the University of California.
--------
304-> Accurate "Thermometers" In Space: The State Of Climate Measurement Science
Just how accurate are space-based measurements of the temperature of the Earth's atmosphere? In a recent edition of Nature, scientists Dr. John Christy of the University of Alabama in Huntsville, and Dr. Roy Spencer of NASA/Marshall describe in detail just how reliable these measurements are. Why is it important? The question is very important, as these temperature measurements from satellites in space are one of our most important windows into measuring and understanding the phenomenon of Global Warming. Over the past century, global measurementsof the temperature at the Earth's surface have indicated a warming trend of between 0.3 and 0.6 degrees C. But many - especially the early - computer-based global climate models (GCM's) predict that the rate should be even higher if it is due to the man-made "Greenhouse Effect". Furthermore, these computer models also predict that the Earth's lower atmosphere should behave in lock-step with the surface, but with temperature increases that are even more pronounced.                                      What is the "Controversy"? Unlike the surface-based temperatures, global temperature measurements of the Earth's lower atmosphere obtained from satellites reveal no definitive warming trend over the past two decades. The slight trend that is in the data actually appears to be downward. The largest fluctuations in the satellite temperature data are not from any man-made activity, but from natural phenomena such as large volcanic eruptions from Mt. Pinatubo, and from El Nino. So the programs which model global warming in a computer say the temperature of the Earth's lower atmosphere should be going up markedly, but actual measurements of the temperature of the lower atmosphere reveal no such pronounced activity. How do we know the Satellite Data are Correct? In theory, one could argue that the computer models are accurate, and that the real measurements have some problem. However this is not the case. An incredible amount of work has been done to make sure that the satellite data are the best quality possible. Recent claims to the contrary by Hurrell and Trenberth have been shown to be false for a number of reasons, and are laid to rest in the September 28th edition of Nature. Thetemperature measurements from space are verified by two direct and independentmethods. The first involves actual in-situ measurements of the lower atmosphere made by balloon-borne observations around the world. The second utilizes intercalibration and comparison amongidentical experiments on different orbiting platforms. The result is that the satellite temperature measurements are accurate to within three one-hundredths of a degree Centigrade (0.03 C) when compared to ground-launched balloons taking measurements of the same region of the atmosphere at the same time. So What is Going On? The atmosphere is extremely complex in its behavior. Because of this, finding the correct explanation for the behavior we observe is complex as well. Virtually all scientists will agree that a doubling of the amount of carbon dioxide in the Earth's atmosphere should have someeffect on the temperature of the Earth. But it is much less certain how or if we will recognize the effects of this increase. There are several reasons: * First, the influence of a man-made doubling of the amount of carbon dioxide in the atmosphere is small compared to the Earth's natural cooling rate, on the order of only a percent. * Second, there is a much more important greenhouse gas than carbon dioxide, namely water vapor. Water vapor over the Earth is extremely variable, both in space and in time. * Third, the ways in which clouds and water vapor feed back and ultimately influence the temperature of the Earth are, at best, poorly understood. * Fourth, while the whole Earth is indeed in a state that scientists describe as "radiative equilibrium," where the incoming sunlight equals the outgoing infrared radiation to provide a roughly constant overall temperature, the surface is far from this radiative balance condition. Evaporation and convectionprocesses in the atmosphere transport heat from the surface to the upper troposphere, where it can be much more efficiently radiated into space since it is above most of the greenhouse-trapping watervapor. So in short, it is this convective overturning of the atmosphere - poorly represented in computer models of global warming - that primarily determines the temperature distribution of the surface and upper troposphere, not radiation balance. The Answer Lies Partly in a Better Understanding of Water's Role A computer model is only as reliable as the physics that are built into the program. The physics that are currently inthese computer programs are still insufficient to have much confidence in the predicted magnitude of global warming,because we currently don't understand the detailed physical processes of clouds that will determine the extent and nature of water vapor's feedback into the Earth's temperature. And the Intergovernmental Panel on Climate Change (IPCC) agrees: ``Feedback from the redistribution of water vapour remains a substantialuncertainty in climate models...Much of the current debate has been addressingfeedback from the tropical upper troposphere, where the feedback appears likely to be positive. However, this is not yet convincingly established; muchfurther evaluation of climate models with regard to observed processes is needed." - Climate Change 1995, IPCC  Second Assessment More Complex Than We Had Thought Improving our understanding of the potential magnitude and extent of any man-made global warming will require a significant amount of critical scientific investigation, both in space and on Earth, using both observational and computational analysis techniques. It is clear that ifwe've learned anything in the past two decades, it's that the response and dynamics of the Earth as a complex, interconnected machine are far more detailed, intricate, and complicated than we first envisioned. Through NASA's Earth Observing System, researchers will continue to improve our ability to monitor the Earth system so that we may understand the subtleties of variations in the global atmosphere. NASA's continued direct observations of the Earth will help enable us to sort out the complicated issues of climate variability and change that affect the planet.
--------
305-> Space Research Provides Earthshaking Revelations
Research aboard the Space Shuttle is helping to provide away to protect structures from major vibrations such as those producedby severe earthquakes and high winds. Dr. Mark S. Whorton, an aerospace engineer at NASA's Marshall SpaceFlight Center, Huntsville, AL, has been working for several years onresolving vibration problems in a microgravity environment that can affectsensitive science experiments conducted aboard the Shuttle in orbit. "Movements of the Shuttle, such as attitude corrections and theactivities of the crew members aboard the vehicle, create vibrations thatcan affect delicate experiments being conducted on board," he said."Solutions to reducing these minor vibrations in space also can be appliedto reducing the effect of major vibrations produced by earthquakes and high winds on terrestrial structures such as buildings and bridges." Whorton has been conducting his research as part of his doctoralstudies program under Dr. Anthony J. Calise in the School of AerospaceEngineering at the Georgia Institute of Technology in Atlanta. The researchis part of a larger National Science Foundation effort to understand dynamicloads placed on structures by earthquakes and to identify ways of reducingtheir effect. The Georgia Tech research team for the past eight years hasbeen studying the benefits of using passive and active control strategies to reduce the effects of earthquakes on buildings. "Technologies we've developed here at Marshall to protect experimentssuch as those involving crystal growth aboard the Space Shuttle are directlyapplicable to buildings and bridges during seismic events. Right now we'reworking on developing technological 'tools' which architects and constructionengineers can use when designing more earthquake-tolerant structures and inenabling existing structures to better survive earthquakes," Whorton said. The National Science Foundation, under its program on EarthquakeHazards Mitigation in the Civil and Mechanical Systems Division, is funding amajor research program on structural control.  Under this effort, the GeorgiaInstitute of Technology and other universities are involved in various aspectsof earthquake engineering such as developing better building materials, passivedamping methods, and active vibration control. Research activities at Marshallare focused in the area of active vibration control. There are several ways to reduce the effect of structural vibrations.A direct approach is to stiffen the structure, which requires changing its massand therefore its vibration characteristics.  While this may be acceptable formany terrestrial applications, the need for strong but lightweight structuresin space renders this option infeasible for NASA. "Clearly, for applications in the space program, lightweight butequally effective vibration-mitigating alternatives were needed.  We foundthat these technologies had down-to-Earth applications as well.  One way ofcountering structural vibrations caused by a strong gust of wind or seismicground motion is to place sensors and force producing devices called actuatorsat specific locations on buildings.  As sensors in the system measure themotion of the structure, actuators apply forces to counteract the structure'svibrations," Whorton said. "One such force device would use hydraulic pistons moving counter-weights.  Another method involves placing adjustable tendons along the sidesof structures.  In fractions of a second, sensors in the systems can read thestructural vibration patterns caused by earthquakes or high winds and adjustthe tension on the appropriate tendons to reduce the excessive forces ormotions of the building," Whorton said. All the actively controlled buildings in operation today are in Japanwith the exception of one in Taiwan.  A TV tower in Nanjing, China, also is tobe retrofitted with active vibration control.  Other new construction willincorporate the technology, particularly in seismically active regions; and itmay be possible to retrofit the technology to other existing structures. "This technology -- in part derived from the nation's space program --is being adapted to meet the needs of the construction industry around theglobe," Whorton said.  "The active control technology for vibration isolationis mature and is fully capable of doing the job.  This is a technology readynow for commercial applications."
--------
306-> Two New Studies Suggest That Caloric Restriction In Monkeys May Extend Their Life And Health
Two recent animal studies offer a possible explanation for how caloricrestriction might possibly enhance human health and help extend life as well. One new study from the National Institute on Aging (NIA) and Dr. Roy Verdery atthe Arizona Center on Aging shows that a 30 percent reduction in calories in amonkey's diet leads to elevation in good cholesterol (HDL2B) levels with asubsequent reduction in risk for cardiovascular disease.  A second recent studyfrom the NIA has shown that caloric restriction slows the age-related decreasein amounts of a naturally occurring steroid hormone, DHEA.  Using natural DHEAlevels as a biomarker of aging may assist scientists in their search for a wayto slow down the aging process. Previous research in shorter-lived species such as fruit flies and rats hasdemonstrated that a 30 percent caloric restriction can lead to 30 percent longerlife in addition to enhanced markers of good health.          The first of the two studies (American Journal of Physiology, October,1997, Vol. 36, No. 4) demonstrates that, over a ten year period, a 30 percentreduction in caloric intake in rhesus monkeys leads to up to a 25 pointelevation in HDL2B levels as well as a 20 point decrease in triglyceride levels(as measured in milligrams per deciliter).  Increases in HDL2B and decreases intriglycerides of this magnitude in humans would be a great health benefit tomany, especially for those at risk for stroke or heart attack. Principal investigator, George Roth, Ph.D., Acting Chief of NIA's Laboratory ofCellular and Molecular Biology, says, "In addition to enhanced HDL2B and lowertriglyceride levels, we also see a small drop in blood pressure.  These HDL2Bresults, combined with previous findings from our lab showing better glucosetolerance and insulin sensitivity (which should predict lower incidence ofdiabetes), lower body temperature, and other such biomarkers suggesting thatcaloric restriction may exert beneficial effects in primates similar to those previously observed in rodents.  These results may someday serve as amodel for human studies." One interesting aspect of this particular study is that neither the controlmonkeys nor the calorically restricted monkeys eat much fat or cholesterol aspart of their diets.  Thus the study demonstrates that even in non-obese monkeys, a reduction in calorie intake can benefit cholesterol, triglyceridesand blood pressure.  This research presents an important contrast to studiesthat usually look at obesity and how weight loss from that level can benefithealth.                     It is demonstrated here for the first time that caloric restriction canlead to changes in HDLs and other lipid profiles that may be associated withhealth benefits for both those animals that are lean as well as those that areheavier. Recent research under the direction of Mark Lane, Ph.D., Senior Staff Fellow atthe NIH's Animal Center, has turned up an interesting added benefit to caloricrestriction.  In addition to boosting good cholesterol and reducingtriglycerides, monkeys on caloric restricted diets experience a favorableredistribution of fat away from their central regions thus reinforcing thecurrent finding about reduction in cardiovascular risk with caloric restriction. The second study from Drs. Roth, Lane, and Donald Ingram at NIA and Dr. SheldonBall at the University of San Francisco-Fresno, appeared in the July 1997 issueof the Journal of Clinical Endocrinology and Metabolism (Vol. 82, No. 7, pp. 2093-2096).  In this study, monkeys whose calorie intake was restricted by 30 percent showed a slower decline in DHEAS(dehydroepi-androsterone sulfate) and DHEA (the unsulfated form) levels thanthose observed in control monkeys. Dr. Lane, principal investigator of this study, says, "DHEA levels are of greatinterest to us, not because we believe that DHEA is the fountain of youth, butrather because it gives us a very good marker to measure the rates of aging incontrol versus calorically restricted monkeys.  It is important to distinguishbetween levels of DHEA that occur naturally in the body and decline with age andlevels that are seen in people who pop DHEA pills to pharmacologically raisetheir natural levels in hope of extending their lives.  These artificiallyhigher levels may or may not give them any benefit.  Controlled clinical trialsare needed before this question can be answered."  Dr. Ingram adds, "It isimportant to develop markers such as DHEAS which can be used to determine theeffects of various interventions, such as diet and exercise, on aging." According to Dr. Roth, "this study shows that monkeys eating a caloricallyrestricted diet which contains little fat maintain higher DHEA levels in theirbodies.  In this setting, DHEA is a marker of aging.  We do not yet know if DHEAplays a role in slowing the aging process." Until NIA initiated studies in rhesus monkeys in 1987, the phenomena of longerlife and better health and vigor through caloric restriction had never beeninvestigated in longer-lived primate species.  These studies will continue formany more years with the goal of eventually giving a more precise understandingof the mechanisms of how caloric restriction extends life. The National Institute on Aging, one of the 18 Institutes which make up theNational Institutes of Health, leads the Federal effort supporting basic,clinical, epidemiological and social research on aging and the special needs ofolder people.  A brochure, "Pills, Patches and Shots: Can Hormones PreventAging?" is available from the NIA by calling 1-800-222-2225 or by visiting theNIA's website at http://www.nih.gov/nia 
--------
307-> St. John's Wort Study Launched
Bethesda, MD--The National Institutes of Health (NIH) is launching the firstU.S. clinical trial of St. John's wort, an herb widely used in Europe to treatdepression. The three-year study, sponsored by NIH's Office of Alternative Medicine (OAM),the National Institute of Mental Health (NIMH) and the Office of DietarySupplements (ODS), will include 336 patients with major depression who will berandomly assigned to one of three treatment arms for an eight-week trial. One-third of the patients will receive a uniform dose of St. John's wort,another third will be given placebo, and the final third will take a selectiveserotonin reuptake inhibitor (SSRI), a type of antidepressant commonlyprescribed for depression. "This study will give us definitive answers about whether St. John's wort worksfor clinical depression," said NIMH Director Steven E. Hyman, M.D.  "The studywill be the first rigorous clinical trial of the herb that will be large enoughand long enough to fully assess whether it produces a therapeutic effect.""The compilation of research done thus far, although encouraging, still leavessome unanswered questions about exactly how the herb works," said Wayne B.Jonas, M.D., director of OAM, which is funding the study.  "The interest andcollaboration among these three NIH components in this clinical trial willprovide the scientific expertise and clinical guidance to rigorously investigatethis herb's benefit or risk in the treatment of depression." In Germany, where physicians routinely prescribe herbs for a variety of medicalillnesses, millions of doses of St. John's wort, known also by its botanicalname, Hypericum perforatum, are used daily.  However, no studies of long-termuse have been conducted and published studies have used several different doses. This study will use a standardized preparation containing a 900 mg daily doseof the herb.  In addition, study participants who respond positively will befollowed for another 18 weeks.  The goal of the followup is to determine ifpatients given St. John's wort have fewer relapses than patients given placebo. Depression, a brain disorder that affects more than 17 million adult Americanseach year, costs the nation up to $44 billion in treatment, disability, and lostproductivity-a figure comparable to the cost of heart disease.  Worldwide,depression is also a leading cause of disability.  The illness, often chronic orrecurrent, affects mood, thoughts, body and behavior.  Common symptoms includesadness, loss of interests, decreased energy, disturbed sleep and hopelessness. When severe, depression can lead to suicide. "Depression is a serious and sometimes fatal medical illness and we must be surethat the treatments people receive have been proven to be effective," said Dr.Hyman. An overview of 23 clinical studies in Europe, published August 3, 1996, in theBritish Medical Journal, found that the herb may be useful in cases of mild tomoderate depression.  The NIH study will examine patients with the moderate formof the disorder. NIH officials said the clinical trial will be coordinated by Jonathan Davidson,M.D., at Duke University Medical Center, which has received a three-yearcontract to conduct the $4.3 million study.  Patient enrollment is expected tostart next spring. .    .    .    .   . The National Institute of Mental Health's mission is to conduct and supportresearch on mental illnesses and mental health, including studies of the brain,behavior, and mental disorders.  For information, call NIMH (301) 443-4536 orvisit the NIMH Website at http://www.nimh.nih.gov . The Office of Alternative Medicine's mission is to identify and evaluateunconventional health care practices.  The Office supports, coordinates andconducts research and research training on these practices and disseminatesinformation.  For information, call OAM Clearinghouse 1-888-644-6226 or visitthe OAM website at http://altmed.od.nih.gov . The Office of Dietary Supplements's mission is to explore the potential role ofdietary supplements to improve health care.  The ODS promotes the scientificstudy of dietary supplements through conducting and coordinating scientificresearch and compiling and disseminating research results.  Watch for the newODS website in late Fall at http://dietary-supplements.info.nih.gov .  For moreinformation call ODS: 301-435-2920. The National Institutes of Health is an agency of the U.S. Department of Healthand Human Services.
--------
308-> $12 Million CU Instrument Package Headed For Saturn On Cassini Mission
A $12 million instrument package designed and built by theUniversity of Colorado at Boulder for the Cassini Mission to Saturn will beused to probe the planet's spectacular ring system, bizarre moons andatmospheric gases. Slated for launch Oct. 13 from Cape Canaveral, Fla., the spacecraftwill travel 2 billion miles during a roundabout, 6.7-year journey to theringed planet.  The $3.3 billion project, the most ambitious planetarymission ever mounted, is managed for NASA, the European Space Agency andthe Italian Space Agency by the Jet Propulsion Laboratory in Pasadena. Upon its arrival in 2004, the spacecraft will spend four yearsorbiting Saturn and many of its 18 known moons, providing a flood of newdata on what many view as a miniature solar system.  Professor LarryEsposito, chief scientist on CU's Ultraviolet Imaging Spectrograph, orUVIS, said it will be used to study the atmosphere of Saturn, the surfacesand atmospheres of its moons and the structure and dynamics of the fabulousring system. Cassini consists of an orbiter equipped with 12 scientificexperiments  and a probe carrying six instrument packages that willparachute into the thick atmosphere of Titan, Saturn's largest and mostintriguing moon. Two CU spectrometers on board the orbiter will take "chemicalfingerprints" of Saturn's atmospheric gases and measure their temperaturesand compositions, said Esposito, a researcher at CU's Laboratory forAtmospheric and Space Physics.  UVIS also will be used to analyze theatmosphere of Titan, which is 10 times denser than Earth's and is thoughtto contain nitrogen and a wealth of hydrocarbons, the building blocks oflife. "When Voyager flew by Titan in 1980, some thought there might be achance to detect evidence of life there," said Esposito, also a professorin CU's astrophysical and planetary sciences department.  Even thoughTitan's temperature was later measured at a frigid minus 290 F -- dashingmost hopes for life -- many scientists believe it may resemble a primordialEarth. Scientists also think Titan's surface may contain lakes of liquidmethane and ethane, and that organic molecules may constantly be rainingdown from the moon's thick clouds onto its surface.  "In many ways, Titanis like a little world," said Esposito.  "We should be able to look back intime and see what types of pre-biological chemistry are occurring.  Itcould be much like the pre-biotic chemistry present on early Earth, or itcould be vastly different." Esposito discovered Saturn's fourth known ring, dubbed the "F"ring, in 1979 while analyzing data from Pioneer 11 as it passed by Saturn.The F ring, a braided and kinked ring located far outside the E ring, isheld in place by two "shepherd" satellites and remains one of Saturn's mostexotic features. "Saturn's rings have a very violent history," he said.  "I thinkthey were created by the break-up of a small moon perhaps 100 million yearsago.  The fact that we can view Saturn's rings today may be due purely tochance.  I expect at some point all the ring material may reform itselfinto a moon or be ground into dust." The rings are "incredibly active, exhibiting waves, wakes, ripples,bends and kinks" that seem to wax and wane over time, he said.  The ring'swaves, which appear to be tied to gravitational tugs from Saturn's innersatellites, can spiral somewhat like the grooves in a phonograph record orripple like waves on a pond.  The researchers hope to resolve how gravity,magnetic energy and other forces hold the enigmatic rings together. Although a CU photopolarimeter aboard Voyager helped scientistsbetter understand the behavior of Saturn's rings, the UVIS photometer onCassini is 50 times more sensitive and will be able to resolve ringphenomena five times smaller than Voyager could.  Saturn's ring particlesare thought to consist of ice and rock and range in size from sugargranules to houses. To view the rings, the CU-Boulder team will use a process known asstellar occultation, focusing the photometer on a bright star behind therings.  As the spacecraft passes by the rings, the brightness of the starwill fluctuate as ringlets and ring gaps pass in front of it, allowingresearchers to determine very fine details in Saturn's ring structure anddynamics, Esposito said. In addition, the ring system "will provide a local lab of sorts tohelp us understand similar phenomenon in our larger astrophysical system,like spiral galaxies and accretion discs around black holes," he said. The LASP science team working on the Cassini project includesEsposito and co-investigators George Lawrence, Bill McClintock, CharlesBarth, Ian Stewart and Justin Maki, a 1996 graduate now at JPL.  Cassiniwill be launched on a Titan IV/Centaur rocket built by Denver's LockheedMartin. "CU has been building ultraviolet spectrometers for NASA since theMars missions in the early 1970s," said Esposito.  "The main thing we havelearned from our planetary exploration experience is that there will alwaysbe surprises and serendipitous discoveries." A fourth instrument on UVIS is a hydrogen-deuterium absorption celldesigned and built with the participation of the Max Plank Institute ofLindau, Germany.  Since all the universe's deuterium -- a heavy form ofhydrogen -- is thought to have formed during the big bang, the ratio of thetwo elements should shed light on the solar system's earliest history. The only other planetary investigations of Saturn -- Voyager 1,Voyager 2 and Pioneer 11 -- all have all been flybys, providing only briefglimpses of the riveting planetary system.  "But the Cassini effort is anintensive, four-year mission," said Esposito.  "We can investigate, ask newquestions and even reprogram our spacecraft orbits in order to answer them."The magnitude of discoveries on this mission should be tremendous." 
--------
309-> New Process Coats Computer Hard Drives With Diamond Armor
BERKELEY, CA -- With help from Ernest Orlando Lawrence BerkeleyNational Laboratory researchers, the storage capacity of your computer'shard drive is about to advance dramatically. Simone Anders of the Accelerator and Fusion Research Division atBerkeley Lab and her colleagues from IBM and UC Berkeley have found away to shield disks and sliders, or reader heads, with ultra-thin"overcoats" of diamond-like carbon that can survive repeated crashlandings at 3600 rpm.     IBM has already brought to market disks that store 2.64 gigabytes ofdata per square inch; densities almost twice that have beendemonstrated, and researchers are aiming for 10 gigabytes per squareinch and more. To read a disk where magnetic domains are packed only 25nanometers apart, disk surface and slider will have to move so close toeach other that it's almost a matter of semantics whether they willactually be touching.    Typical high-quality commercial overcoats now in use are made ofsputtered-on, hydrogenated carbon 12 to 15 nanometers thick. Higher datadensities require reduced magnetic spacing between heads and disks --thus disk coatings must be thinner and made of even harder material.Sputtering can't do the job. "For decades, tool manufacturers have put titanium nitride and otherhard coatings on the cutting edges of their tools using a techniquecalled cathodic arc deposition," says Anders. Unlike sputtering -- inwhich the coating material is knocked off the cathode of the plasmasource by ions, forming a plasma mixed with un-ionized (electricallyneutral) atoms -- cathodic arcs produce a fully ionized plasma ofwhatever material, including carbon, is used for the cathode. "Since the1970s it has been known that carbon deposited this way is almost as hardas diamond," Anders notes.    A fully ionized carbon plasma allows electrons and carbon nuclei toreassemble themselves as diamond, in a three-dimensional lattice inwhich each atom is bound to four others by electron pairs -- atetrahedral bond. By contrast, atoms in graphite are bound to only threeother atoms, forming a much less stable configuration. By tuning theenergy of the incoming carbon ions, the tetrahedral-bond content of thedeposited film can be optimized; thus films have been made that, whiletechnically amorphous, are 85 percent diamond. "Still, the method hasn't been practical for coating disks," saysAnders, "because micron-sized chunks of the cathode boil off andcontaminate the films." A micron-sized macroparticle in a nanometer-scale overcoat is like a mountain in a mud puddle, a thousand timesbigger. For cathodic arc deposition to be useful in coating disks andsliders, a way must be found to completely filter out themacroparticles. "What our team has done is to devise a filter so good that all ourgoals" -- of thin, flat, hard, macroparticle-free carbon -- "werefulfilled," Anders says. The secret is a magnetic coil that looks muchlike a Slinky toy, placed between the plasma source and the substrate tobe coated. The fully ionized plasma is easily bent through this S-shapedmagnetic field -- effectively two fields at right angles -- but themassive macroparticles of carbon can't turn easily; they fly rightthrough the sides of the coil or pile up on its walls. A coil that hasbeen used for some time is thickly coated with a dust of macroparticlesnear the plasma source, yet dust-free at the substrate end. After perfecting the filtering method, Anders and her colleaguesperformed a series of brutal endurance tests, pitting disks withcathodic arc-deposited carbon coatings against samples with sputtered,hydrogenated carbon coats. They found that disks coated with cathodic arc carbon had acoefficient of friction half that of those coated with hydrogenatedcarbon and caused 20 times less wear on the slider. In additionalstudies, when a silicon wafer coated with cathodic arc carbon wasexamined at nanometer scale after repeated loading, it showed virtuallyno scratches.       Slider tests were equally dramatic. Weighted sliders were repeatedlyset down on spinning disks coated with hydrogenated carbon. As could beexpected, uncoated sliders failed after only 7500 cycles -- they blew upand dug trenches in the disks -- but sliders coated with cathodic arccarbon were still going strong after 100,000 cycles, with no visiblewear on the disk.     The team announced these spectacular results in July, "and we'vereceived lots of requests for information," says Anders. "We are quitehopeful that cathodic arc-deposited carbon will find wide use inindustry." Details and results of the cathodic-arc carbon deposition andfiltering system will be published in the October edition of DataStorage magazine.     Berkeley Lab is a U.S. Department of Energy national laboratorylocated in Berkeley, California. It conducts unclassified scientificresearch and is managed by the University of California.
--------
310-> Pretending Not Just Child's Play: Parents Can Have Important Role, Too
CHAMPAIGN, Ill. -- Years of research on early childhood have been dominatedby thinking that children's pretending needs little help from adults.  "Weassumed it was pretty much a creation that came from within the child,"says Wendy Haight, a professor of social work at the University of Illinois. But from early in her studies of parent-child interaction, Haight observedthat many parents play an intentional role in encouraging their kids topretend, and obviously see that role as important.  "I was struck bythe extent to which caregivers were pretending with their very young children,even before the children were displaying independent pretend play,"she said. In one study with a group of middle-class, white Americans, "thevery consistent finding was that parents viewed pretending as importantto their children's development, viewed it as an enjoyable activity, andthought that their role was significant in helping their children learnhow to pretend." Through subsequent research, Haight concluded that these parents mightbe on to something.   "We've found that, in fact, when children pretendedwith their caregivers, it was more complex, more elaborated, and also moreextended than when they pretended by themselves," she said.  "Andthey used the ideas that the parents initiated in their subsequent pretending." A child playing by himself, for instance, might sit behind a toy steeringwheel and simply turn the wheel and make engine noises.  A parent joiningin can take the child on a pretend trip, teaching along the way. Among the things that parents begin to communicate very early throughpretending, whether consciously or unconsciously, is their culture, Haightnoted -- her observations based on a study involving both Chinese (in Taiwan)and white, middle-class Americans.  For the Americans, she found, pretendplay was often child-centered and revolved around a toy or object.  TheChinese parents more often than not initiated the play and used it to teachsocial customs or routines, like how to greet a guest or teacher. "It's fascinating to see how deeply ingrained cultural beliefs getincorporated into pretend play it's one of many everyday practices throughwhich children get socialized into their culture," Haight said.  Thelong-dominant thinking, that most pretending starts with the child, "wouldpredict that pretend play would look pretty much the same wherever, regardlessof the context -- but we're saying that doesn't appear to be the case." How individual parents pretend with their kids also depends a lot onhow they see their parental role, Haight said.  For most fathers, theirparticipation in pretend play seems "very related to how much theyenjoy it," she said.  For most mothers, it seems related to "howimportant they feel it is to children's development."
--------
311-> New Way To Drive Chemical Reactions: Collision Of Liquids At High Speed
CHAMPAIGN, Ill. -- When a liquid moves fast enough, gas bubbles willform and collapse.  This process -- called cavitation -- is responsiblefor the pleasant babbling sound of streams and rivers, and for the stealth-defyingsound of propellers on submarines.  Chemists at the University of Illinoishave discovered that in addition to making noise, high-velocity liquidsalso can drive chemical reactions. "By colliding two streams of liquids together at a combined speedof 450 mph, we can break some of the strongest chemical bonds," saidKenneth Suslick, a U. of I. professor of chemical sciences.  "Withwater, for example, the oxygen-hydrogen bond ruptures.  The fragments canrecombine to form hydrogen peroxide and other highly reactive intermediatesthat can destroy contaminants in the water." Some contaminants can be destroyed directly by the implosive collapseof the bubbles.  Other less volatile contaminants can be destroyed throughsecondary reactions with some of the fragments, such as free hydrogens andhydroxyl radicals -- both of which are extremely reactive.  "This raisesthe possibility of using turbulent liquid jets as a simple way of purifyingwater contaminated with low levels of chemical waste," Suslick said. The jets are made by pumping liquids at very high pressures through verysmall holes drilled in gemstones.  "Only gems are hard enough to takethe pressure without cracking or eroding," Suslick said.  Currently,liquid jets are used industrially for making emulsions (such as cosmeticlotions) and for cutting extremely hard materials. "The chemistry of turbulent liquids comes from 'hydrodynamic cavitation,'which causes the formation, growth and implosive collapse of small gas bubblesin the moving liquid," Suslick said.  "This is very similar tothe effects of high-intensity ultrasound in a liquid, where the collapseof sound-driven bubbles generates intense local heating, forming a hot spotin the cold liquid with a transient temperature of about 9,000 degrees Fahrenheit,the pressure of about 1,000 atmospheres and the duration of about a billionthof a second." Any turbulent flow can cause cavitation in liquids, Suslick said.  "Butgenerating bubbles doesn't necessarily generate chemistry.  The bubbleshave to collapse pretty intensively to create the required heat and pressure. By colliding two liquid jets, we can concentrate the collisional energyin the bubbles." There are only a few ways to force chemical reactions:  heat, light,radiation and ultrasound are the common ones, Suslick said.  "So, it'snot very often that we find a new way to drive chemistry, especially oneas simple as fast-moving liquids.  Although we can create very-high-energychemistry using these liquid jets, the reaction rates are pretty slow sofar." Suslick and graduate students Millan Mdleleni and Jeff Ries reportedtheir findings in the Oct. 1 issue of the Journal of the American ChemicalSociety. 
--------
312-> Bright Days, Cool Nights Help Create Autumnal Splendor, Says Cornell Plant Physiologist
ITHACA, N.Y. -- How leaves turn from green into colorful, autumnal splendoris known, but scientists have plenty of room to discuss how weathercontributes to the leaves' autumnal vibrancy. "Science agrees on the mechanism of fall color, but there is debate as towhat precedes it," said Peter J. Davies, Cornell University professor ofplant physiology.  "Is it a wet summer or a dry summer that increases thebrilliance?  Without a doubt, cool nights and bright days contribute quitea bit to fall color." Davies explained that fall color comes from two main sources: pigments,such as yellow and orange carotenoids, and red anthocyanins. Yellow and orange carotenoids are present in the leaves all the time butare masked by the green chlorophyll.  As the leaves become senescent (orage) at the end of the season, the green chlorophyll in certain treespecies degrades, allowing us to see the oranges and yellows of thecarotenoids, Davies said.  Senescence is triggered by the declining daylengths in the Northern Hemisphere at this time of year. During the warm days of fall, the leaves can still make sugars byphotosynthesis -- provided the leaves still possess chlorophyll, explainedDavies.  When the night temperatures fall, the transport of the sugars fromthe leaves is slowed and these sugars are converted into the redanthocyanins.  This process also is enhanced if the plants are understress, he said. Only certain species develop fall color, said Davies.  "The propensity todo so is genetic and it is associated particularly with the sugar and redmaples, as well as plants like sumac and white ash that are typical of thisregion," he explained.  In other areas, one or two species may show astrong yellow, but nothing like the trees in the Northeast. Undoubtedly, Davies said, the weather at the time of fall color has themost influence.  The most color will develop under warm sunny days withcool (but not freezing) nights.  Cool, rainy days cause the leaves to fallwithout developing much color, as the rain and wind knock the leaves offmore rapidly. "If you look at trees at the edge of a woodland area, the trees exposed tosun are always more colored than those that are more shaded.  There aremany opinions on the role of weather during the preceding summer.  I thinkmost are anecdotal and I don't know if anyone has done a long-term study onthe phenomenon," he added.  Even fertilizing a tree late in the season willdecrease the fall color of the leaves, he said. "It is my opinion that the more the tree is under (physiological) stress,the more color will be developed," Davies said.  "Thus a dry summer(leading to water stress or drought stress) will probably give more colorthe following fall than a moist, rainy one."
--------
313-> Scientists Find New Trigger For Nerve Cell Death
St. Louis, Oct. 3, 1997 -- A paper in today's Science challenges a well-established idea about why nerve cells self-destruct when the brain or spinal cord is injured or becomes diseased. It suggests that when potassium jumps ship, neurons commit suicide. "If our hypothesis proves correct, it will open up new possibilities for protecting nerve cells in patients who suffer stroke, head injury, spinal cord injury or neurodegenerative disorders such as Alzheimer's disease," says Dennis W. Choi, M.D., Ph.D., the Jones Professor and head of neurology at Washington University School of Medicine in St. Louis. Choi, who directs the Center for the Study of Nervous System Injury, was the senior investigator in the study. The novel idea was the brainchild of lead author Shan Ping Yu, M.D., Ph.D., research assistant professor of neurology. In the hours or days after the brain is injured, healthy cells surrounding the damaged region also die, killing themselves through a genetically controlled process called programmed cell death or apoptosis. Scientists previously have focused attention on changes in the amount of calcium contained within cells undergoing apoptosis. But Yu's experiments suggest that a mass exodus of potassium may be just as important as changes in calcium. Potassium ions cross the cell membrane through tunnels called potassium channels, which control the rate at which they flow. If these channels play a key role in apoptosis, it might be possible to use drugs called potassium channel blockers to stem potassium loss and prevent nerve cells from dying. This might restrict damage to the initially injured area of the brain or spinal cord, allowing patients to recover more fully. Yu got his idea by considering how apoptotic cells differ from those in the throes of necrosis -- sudden death at the focus of an injury. Whereas necrotic cells swell up and burst, apoptotic cells shrink into oblivion. "A shrinking cell must be losing ions and water," Yu says. Potassium seemed like the obvious ion to escape because there's so much of it in the cell. Yu therefore measured potassium movement through the membranes around cultured nerve cells after various events that cause apoptosis. Six hours after the neurons were deprived of serum, the current flowing out through one type of potassium channel had increased by 61 percent. By 9 hours, the amount of potassium inside the cells had dropped by 13 percent. The potassium currents in cells that were dying by necrosis didn't change, however. To determine whether potassium loss triggers apoptosis or is simply a side effect, Yu blocked potassium channels with a compound called TEA (tetraethylammonium). The potassium channel blocker reduced the number of cells that died after serum withdrawal, suggesting that potassium loss is indeed a trigger for apoptosis. Reducing potassium loss by increasing the amount of potassium in the solution bathing the cells also prevented apoptosis. This protective effect was seen even in the presence of a substance that prevents calcium from flowing into cells. "These experiments don't rule out a role for calcium in apoptosis," Yu says. "But they do suggest that potassium outflow is independently an important mechanism." Moreover, the potassium changes preceded apoptosis. "So potassium loss appears to play a critical early role, telling neurons to commit suicide," Yu says. The group now is looking to see whether TEA or other potassium channel blockers can reduce brain damage in rats that have suffered a stroke. Meanwhile, Yu and colleagues have found that TEA or elevated levels of extracellular potassium protect cultured neurons from beta-amyloid peptide, a substance that may kill brain cells in Alzheimer's disease. Again, these effects occur even in the presence of a calcium channel blocker. "These data suggest that manipulating potassium channels also may provide a new therapeutic strategy for slowing neuronal degeneration in Alzheimer's disease," Choi says.
--------
314-> Epilepsy Research Advance Reported At Jackson Laboratory
Bar Harbor -- Researchers at The Jackson Laboratory have identified the gene that is defective in a new mouse model known as "slow-wave epilepsy," or swe. This is the first genetic model to exhibit both petit mal (absence) and grand mal (convulsive) seizures, and promises to be the most authentic model yet for petit mal epilepsy in humans. Epilepsy is a neurological disorder of recurrent partial or generalized seizures estimated to affect one percent of the U.S. population, or three million people. Absence seizures primarily occur in children and are characterized by brief lapses in consciousness during which the person appears to be staring into space. The child does not fall and recovery is prompt. Convulsive seizures are more severe, typically lasting from 1 to 7 minutes, and involve loss of consciousness and motor control. The person falls and the body goes rigid, with jerking and twitching of extremities. Although the complex mechanisms of epilepsy are still a mystery, the seizures are known to result from the misfiring of neurons in the brain. Instead of transmitting electrical impulses in an orderly manner, epileptic neurons fire all at once, creating a "storm" that disrupts normal brain function. Half of all human epilepsies are estimated to have a genetic basis, but only a few genes are known at this time. The new development in epilepsy research is reported in the Oct. 3, 1997, issue of the journal Cell by a team led by Jackson Laboratory Staff Scientist Wayne Frankel and postdoctoral fellow Gregory Cox. They find that swe mice have a defect in Nhe1, a gene encoding a cell membrane ion transporter that has been studied extensively in many rodent and human cell types for its "housekeeping" role in regulating pH and cell volume. "Slow-wave epilepsy mice have a bad transporter, due to a mutation that occurred naturally in the Lab's large breeding colonies," says Dr. Frankel. "The gene is there, but it is dead." Nhe1 is unrelated to the first absence epilepsy gene discovered, which occurred in a Jackson Laboratory mouse called tottering as reported in Cell on Nov. 15,1996. That discovery was made jointly with a research team from the National Cancer Institute Frederick Cancer Research and Development Center in Maryland. The brain-specific abnormality of swe mice was a surprise because Nhe1 is expressed in so many different cell types. Dr. Frankel says the vulnerability of a few brain cells to changes in pH is likely to underlie the epilepsy. Co-author Dr. Jeffrey Noebels of Baylor College of Medicine, who has been analyzing brain waves in epileptic Jackson Lab mice for years, found that the electrical storm pattern in swe petit mal seizures is most similar to that of human absence epilepsy, and that the mice seem to outgrow it, also typical of humans. The swe mice also exhibit grand mal seizures and a stumbling gait, or ataxia, which is the characteristic that led to their identification by alert animal caretakers. "This is a unique mouse, with more essential elements of human absence epilepsy than any existing mouse model," says Dr. Frankel. "It will be exciting to see how much more we can learn about human absence epilepsy by studying swe mice." Co-authors with Drs. Frankel, Cox, and Noebels on the Cell paper are geneticists Cathleen Lutz and Audrey Fu of The Jackson Laboratory; pathologist Roderick Bronson of Tufts University School of Medicine; and Nhe experts Peter Aronson, Daniel Biemesderfer, and Chao-Ling Yang of Yale University School of Medicine.
--------
315-> Environmental Engineers Demonstrate Effective Method For Reducing Pollution From Highway Runoff
Cincinnati -- Researchers in the University of Cincinnati College of Engineering have shown that a modified filtration system along interstate highways can prevent heavy metals from polluting nearby water supplies. The system, known as a partial exfiltration trench (PET), was designed and built by research assistant professor John Sansalone as part of his doctoral research in the department of civil and environmental engineering at UC. The PET replaces the normal sand used in highway storm drainage systems with an iron oxide coated sand. That makes the sand signficantly more effective at trapping heavy metals such as cadmium, copper, lead and zinc. "Polluted water flows in, and clean water flows out," explained Steven Buchberger, associate professor of environmental engineering and Sansalone's thesis adviser. Sansalone presented data from a year-long field test during the recent World Congress of the International Association for Hydraulic Research (IAHR) in San Francisco. A prototype PET system was installed along a stretch of Interstate 75 near downtown Cincinnati. It is the second busiest stretch of interstate highway in the state of Ohio. The effectiveness of the PET system varied for each specific metal, but the overall trapping efficiencies ranged from 82 to 97 percent. The PET even holds up well during heavy rainstorms. The system can handle up to one inch of rain per hour. That's when Sansalone discovered a side benefit to his novel system. "The PET not only works as a water quality device, but it can act like a water quantity control device to reduce surface flooding," said Sansalone. That discovery was completely unexpected in the Cincinnati area where clay soils are common. Sansalone will continue his research by looking at ways to make the system more economical and efficient. It took ten tons of coated sand to treat 20 meters of highway during the field test, so Sansalone must find a consistent and simple method for producing huge quantities of coated sand. "When we made the prototype, we made more coated sand than has ever been artifically produced on Earth. It was a real undertaking," said Sansalone. He will also work on modifying the coating itself to increase its trapping efficiency and lifetime. The goal is to have a system which can last as long as the typical highway pavement about 15 years. Lab tests indicated Sansalone's coating could last approximately 40 years. The field tests indicated a much shorter life expectancy, but one very close to the final project goal. "Conditions in the field are always more severe than you can simulate in the lab," said Sansalone. "Based on the results we've seen so far, a 10 to 15 year life is reasonable." Even more important than lifespan is the ability to clean or recharge the PET system easily. In the next phase of the project, Sansalone will try to demonstrate that the trapped metals can be removed by a simple back-washing. That's important, because if you can't remove the toxic pollutants for disposal, you wind up with tons and tons of toxic waste. Lab-scale experiments indicate the back-washing process is feasible. However, field tests are required to test the procedures on a large-scale operation. Sansalone's research is funded by the Ohio Department of Transportation and the National Science Foundation. His presentation in San Francisco was recognized by the IAHR's John F. Kennedy Award for Hydraulic Research. The award is named for an engineering researcher who specialized in hydraulics.
--------
316-> Increase In Drug Resistance For Common Bacterium Termed "Rocket Ship" Based On National Study
TORONTO -- A national study has shown that by the year 2000, half of the infections caused by the bacterium responsible for 7 million cases of otitis media in children and 500,000 cases of pneumonia in children and adults each year in the U.S. will have some resistance to penicillin, an associate professor of pharmacy at the University at Buffalo warned this week. Already, according to a national study conducted by researchers at UB, Buffalo's Millard Fillmore Hospital and the University of Iowa College of Medicine, 32 percent of infections caused by Streptococcus pneumoniae are resistant to penicillin to some extent and about 10 percent are susceptible to few oral antibiotics. The former are termed highly resistant infections and the latter are described as showing intermediate resistance. And from 1994-97, the study showed, there was a 40 percent increase in intermediate-resistant Streptococcus pneumoniae infections and a 30 percent rise in those considered highly resistant. "This is a rocket ship," Charles Ballow, Pharm.D., reported here Sept. 30 at the InterScience Conference on Anti-Microbial Agents and Chemotherapy. Ballow, director of Anti-Infectives Research in the Clinical Pharmacokinetics Laboratory at Millard Fillmore Hospital, reported on a study that looked at regional trends of bacterial resistance based on more than 4,000 Streptococcus pneumoniae samples from hospital and community patients processed by 192 hospital laboratories from May 1996 to May 1997. The study, he noted, showed that resistance varies by geographic region of the U.S., and is found most often in the Southeast. Ballow said 40 percent of the Streptococcus pneumoniae samples from the Southeast were resistant to penicillin, while in the Midwest the rate was 36 percent, and in the Northeast and the West it was closer to 29 percent. The overall resistance rate in the U.S. for the bacterium was 32 percent. Identifying a cause for the higher rate of resistance in the Southeast is difficult, Ballow said. "It could be that one major hospital in the region has really poor infection-control standards," he said. "With this study, we have dissected the U.S. by region. Now we want to dissect it by hospital laboratory to see if there's one major metropolitan area in the Southeast that is skewing the results for the region." Ballow stressed that while the regional differences in bacterial resistance are important, the rate of increase that is being seen nationwide is especially alarming. Ballow characterized Streptococcus pneumoniae as a "community bug," explaining that while it is transmitted among patients in hospitals, it is transmitted more often outside of hospitals, particularly among children in daycare centers. He said that every year, the pathogen is one of the most prevalent causes of roughly 7 million cases of otitis media, a common ear infection in children, and 500,000 cases of pneumonia in adults and children. Sinusitis and bronchitis often are caused by it as well, he said. Ballow noted that the combination of the overuse of antibiotics and inadequate infection-control methods, both in hospitals and in daycare centers, account for the rapid rise of resistance for Streptococcus pneumoniae throughout the U.S. "Children in daycare centers share their germs," he said. "They share them on their toys, their clothes, their fingers." The problem is compounded, he explained, when a child who has a mild ear infection is treated with antibiotics. "Antibiotic use propagates the problem," Ballow said. "We're a society that thinks that for every ailment, there's a pill. You have a sick child, you expect to be able to go to the doctor and get medicine. We grew up in the antibiotic era and we have come to expect it. But very often, the cause of the ear infection is viral, not bacterial, and in that case, you don't need an antibiotic." For many ear infections, Ballow said, adequate treatment could include giving the child an over-the-counter pain-relief medicine, using cold compresses on the ear and keeping the child home, as well as following any instructions from the child's doctor. In most cases, he said, an antibiotic should be prescribed only if the symptoms change or persist. The study, funded by Rhone-Poulenc/Rorer, also demonstrated that sparfloxacin, a new drug developed by the company, shows excellent activity against resistant bacteria, including those that are highly resistant. Ballow cautioned, however, that due to the potential for cartilage toxicity, the drug cannot be administered to children or pregnant women.
--------
317-> Preventing Latex Allergies Before They Attack
Scientists at Columbia University have developed a new topical hand cream that may prevent the two most common latex allergy reactions-- sensitization to latex after prolonged exposure and contact dermatitis. Over 100,000 people in the United States are at risk for latex allergies, which causes itching and redness and in severe cases can lead to respiratory distress or even death. Study author, Shanta Modak, Ph.D., associate research scientist at Columbia-Presbyterian Medical Center and lead researcher in the discovery of the cream, will presented the findings today at the Interscience Conference on Antimicrobial Agents and Chemotherapy meeting. Researchers investigated topical creams containing a new gel composition for their efficacy in preventing irritant dermatitis when used before wearing latex gloves. Scientists discovered that when the zinc gel composition was formulated in a special base a gel matrix or a protective coating structure is formed on the skin's surface. The "matrix" appears to react with and bind soluble latex proteins and other irritants that are known to produce allergies and may actually prevent the allergic response altogether. Prevention of the initial onset of irritant dermatitis is critical, because these symptoms are prelude to more severe allergic reactions. And in the most severe cases, people left untreated with this condition--like those allergic to bee stings--risk respiratory distress or even death. "This cream can prevent latex glove allergies for up to four hours when applied before putting on the gloves," says Modak. "Use of the cream may reduce health care workers' risk of becoming sensitized to latex after continued exposure and may help the tens of thousands of health care workers who suffer daily with chronic irritant dermatitis," she says. The cream was developed for health care workers who are or who may become allergic to natural latex rubber in gloves and other common irritants. It is estimated that between eight and 17 percent of all health care workers risk developing latex allergies, both from wearing the powdered latex gloves and/or from inhaling cornstarch particles, coated with latex allergen, that drift from the gloves into the air. Preliminary clinical evaluation indicates the cream is safe for use by the general public and for those who are not allergic to latex. Columbia University licensed the anti-irritant cream called Allergy GuardR to Virasept Pharmaceuticals Inc. The study was funded by The Columbia-Presbyterian Medical Center surgery department and Virasept Pharmaceuticals.
--------
318-> Adolescent Psychiatric Disorders Linked To Teen Parenthood
Early Treatment Of Illness May Cost Less Than Dealing with Consequences Young people with early-onset mental illnesses-such as depression, anxiety disorders, and conduct disorders-are more likely to have children in their teenage years, according to a new study by a team of researchers at Harvard Medical School and other institutions. The rise in teenage parenthood, which occurs in both males and females, appears to be due to greater sexual activity and not a decrease in contraception. The findings are reported in the October issue of the American Journal of Psychiatry. As policymakers debate the costs and benefits of our health care system, the findings suggest that a move to expand mental health coverage may be an economical step to take. "For many of these psychiatric disorders, society pays a cost-all of us pay everyday when we get a percentage of our income taken out for taxes," says Ronald C. Kessler, professor of health care policy and lead author of the study. "It turns out the profile of consequences of psychiatric disorders-dropping out of school, having a baby early, not being married, not having good educational skills-is the profile of being a welfare mother." Kessler estimates that people on welfare have a very high incidence of psychiatric disease. He and his colleagues are currently looking at whether these people have a harder time getting off welfare than those without psychiatric disorders. "The common suggestion nowadays is to get these people to finish high school. But finishing is going to be difficult if they have depression or a drug problem," Kessler says. In a previous study, the researchers showed that people with early onset psychiatric disorders are significantly less likely than unaffected youths to finish high school and college. The new findings grow out of data from the National Comorbidity Survey, which Kessler began in 1990 to investigate the interaction between drug and alcohol use and early-onset mental illness. To assess the causes and consequences of psychiatric comorbidity, he and his colleagues conducted face- to-face interviews with 8,098 people between the ages of 15 and 54. Respondents were asked questions to assess whether they had ever suffered from anxiety, mood, conduct, or substance use disorders. A subsample of 5,877 respondents-including all those who screened positive for lifetime psychiatric disease, all others in the age range 15 to 24, and a random subsample of other respondents-were then asked a second set of questions to assess risk factors and social consequences of psychiatric disorders. Included were questions about parents' drug use, violence, mental illness, marital history, childbearing, and education and about their own educational attainment, marital status, parenting, employment, and income. Those with early-onset psychiatric disorders had a significantly higher chance of having a child before the age of 19 than the general population. "We also found young people in the sample were more likely to report they were sexually active if they had emotional problems. They were not less likely to use contraception," says Kessler. It is not clear why teens with psychiatric disorders are more likely to engage in sexual activity. "We don't really have any data on that," Kessler says, though he and his coauthors suggest that it might be due to the acting out and lack of inhibition associated with conduct disorders and substance use. In those suffering from affective disorders, it could be a product of low self- esteem - "needing to be needed, having a hard time saying no," says Kessler. He believes teens suffering from affective disorders are at greater risk of chronic psychiatric illness than those with conduct disorders, such as juvenile delinquents. "For juvenile delinquents, it's often a phase of life-they grow ponytails, do drugs. Then miraculously something happens-they graduate, get mortgages. They grow out of it somehow. But the ones who are using drugs because every time they get sad they have to take a drink, will have that problem for the rest of their life," says Kessler. Funding for outreach programs to children and teens with affective disorders could help reduce the adverse social consequences of psychiatric disorders, he says. Such programs could also help in the war on drugs. "It's clear a substantial part of the drug problem, and the more severe and prolonged drug problem, is in people starting out with emotional problems. And the drinking and drug problems are just a kind of manifestation of that," says Kessler. He and his colleagues have embarked on a pilot study with funding from the MacArthur Foundation to do school-based screening and interventions with young people at risk for affective and anxiety disorders. Kessler has a hunch that such programs may be more successful than the many that already exist for juvenile delinquents. "Delinquents don't want to hear they have a problem because they're too busy having fun. The anxious, depressed kids are not having fun," he says. Funding for this study came from the National Institute of Mental Health and the National Institute of Drug Abuse.
--------
319-> NEAR Spacecraft Gets Unexpected View Of Mysterious Gamma-Ray Bursts
A significant step toward revealing the mysteries of gamma-ray bursts was taken this week by The Johns Hopkins University Applied Physics Laboratory (APL), Laurel, Md., when NASA's Near Earth Asteroid Rendezvous (NEAR) spacecraft sent back unexpected data showing a major gamma-ray burst. APL manages the NEAR mission for NASA. The observation came after researchers reconfigured the gamma-ray spectrometer to make more frequent data returns as NEAR travels to a rendezvous with the asteroid Eros in February 1999. If they are as distant as new evidence suggests, gamma-ray bursts are the most violent explosions known, emitting in one second as much energy as the sun will emit in its lifetime. The gamma-ray spectrometer was not originally planned to begin its work until the spacecraft reached Eros. But while en route a simple software change was added that gave a new astrophysics capability to this planetary spectrometer, which resulted in detection of a gamma-ray burst on Sept. 15, that lasted for about 10 seconds. Since then six more bursts have been detected. Several of the bursts have been confirmed by the European Space Agency/NASA Ulysses spacecraft, now in a polar orbit around the sun and by two detectors on NASA's Wind spacecraft near the Earth. These three spacecraft, along with other Earth-orbiting spacecraft, form a 3-dimensional interplanetary network for observing gamma-ray bursts that has not been possible since the loss of the Mars Observer in 1993. "Seeing this burst validates that the NEAR detector can be a true working partner in the interplanetary network for gamma-ray burst detection," says APL's lead gamma-ray instrument engineer John Goldsten, who was the first to see the gamma-ray burst data. Jacob Trombka, NASA's Science Team Leader for the gamma-ray instrument, says, "NEAR's instrument is more sensitive than we believed it would be. It's seeing bursts that other spacecraft aren't seeing." The success of the instrument is the result of a good design, he says. "Originally we didn't have time to include a burst mode on the instrument, but the system was so well designed that we were able to upload such a system a few weeks ago." Gamma-ray bursts remain one of the great mysteries of astrophysics since their discovery more than 30 years ago. They tend to be randomly distributed over the sky and occur with a frequency of about one per day for the most sensitive detectors. If they are of cosmological origin, they represent the most powerful events that are known in the universe. The debate as to their local or cosmological origin will most likely be resolved by locating sources of gamma-ray bursts and then identifying them with optical and radio telescopes. NASA's Hubble Space Telescope made the first observation of a fuzzy object associated with a burst that was detected last Feb. 28 by the Italian BeppoSAX satellite. The sources of gamma-ray bursts can be located in the sky by timing the arrival of the gamma rays at three well-separated spacecraft. Since 1993, the spacecraft instrumented to observe such bursts have been the Ulysses spacecraft plus several spacecraft near the Earth: The BeppoSAX and Wind as well as NASA's Compton Gamma-Ray Observatory (CGRO) and Rossi X-ray Timing Explorer. The near-Earth spacecraft are too close to each other to allow a unique determination of the location of the bursts. The addition of the Near Earth Asteroid Rendezvous Spacecraft to the interplanetary network will provide 3-dimensional triangulation of source locations and should greatly increase the probability of associating a gamma-ray source with a particular source from optical and radio telescopes. The new capability on NEAR will expand the network and enable it to obtain the locations of moderate and stronger bursts, which occur at least several times per month, to a position in the sky accurate to about a minute of arc (about a thirtieth of the size of the moon). NEAR, the first mission of NASA's Discovery Program for "faster, better, cheaper" planetary exploration, will be the first spacecraft to orbit an asteroid. On June 27, NEAR sent back spectacular images of 253 Mathilde as it flew past the asteroid. In February 1999, NEAR will reach Eros and begin the first long-term, close-up look at an asteroid's surface composition and physical properties. NEAR was designed and built by The Johns Hopkins University Applied Physics Laboratory. __________ For more information contact Helen Worth, JHU/APL Office of Public Affairs. Phone: (301) 953-5113; e-mail: Helen.Worth@jhuapl.edu; or fax: (301) 953-6123; or Donald Savage, NASA Headquarters Office of Space Science. Phone: (202) 358-1547; e-mail: dsavage@hq.nasa.gov; or fax: (202) 358-3093. Information on the NEAR mission can be obtained on APL's NEAR homepage at: http://sd-www.jhuapl.edu/NEAR/.
--------
320-> Seamless, Porous Coating Developed To Help Analyze Dangerous Materials
ALBUQUERQUE, N.M. -- A coating that allows miniature sensors to detect dangerous, even lethal, air- or water-borne molecules much more quickly has been created in a joint project of Sandia National Laboratories and the University of New Mexico. The achievement is reported in the current issue of the journal Nature. The film-like coating -- less than one micron thick -- barely increases the size of the sensor. But the material's extreme porosity increases the sensor's surface area, and therefore sensitivity, by a factor of about 500, says Sandia principal investigator Jeff Brinker. "Imagine tasting something sour, and then 500 times more so," says Brinker. The film's sensitivity could help combat terrorism, lead to smaller yet more accurate sensors for environmental monitoring, and benefit oil and pharmaceutical companies, which use molecular separations to produce grades of gasoline and a variety of drugs, says Brinker. Funding was received through the Department of Energy's (DOE) Basic Energy Sciences program, and the UNM/National Science Foundation Center for Microengineered Materials. Sandia is a DOE multi-program national security laboratory. The extremely high surface area of the film can be modified to detect chemical weapons like Sarin, used in the terrorist attack in the Tokyo subway. Under laboratory conditions, the film applied to a sensor detected 200 parts per billion of a Sarin simulant. A human being can survive approximately 50 minutes at those concentrations, says Brinker. How does it do that? The material, honeycombed by tiny tunnels of precise size, acts as a membrane to separate molecules of differing dimensions. The film functions similarly to zeolites -- porous crystalline pebbles used by the oil industry to separate out molecules of different sizes. Honeycombed by tiny tunnels, zeolites filter out molecules too big to pass through them, trap mid-sized ones, and allow passage to smaller ones. Unlike some zeolites, the Sandia coating -- a lightweight gel -- must be created artificially. However, because the gel's molecules self-arrange themselves into a kind of molecular rug, no machinery of assemblage is necessary. Also, while a zeolite's pores never exceed a dimension of 13 angstroms, the pore sizes of the Sandia coating are controllable by scientists and can be made as large as 100 angstrom to accommodate a variety of molecules. While such artificial coatings long have been desired, scientists could not produce an interior network of tiny tunnels that allowed large numbers of molecules to enter the surface and exit the base of the film, rather than be halted at dead ends. Another problem -- not solved until development of the coating -- was making it seamless, so that molecules intended for inspection could not evade the sieve by flowing through cracks in it. More flawless than grandma's knitted blanket In the Sandia method, the gel is made seamless by continually removing a substrate from a liquid bath. The gel -- a nanocomposite -- forms seamlessly as water and alcohol evaporate. Earlier methods, which allowed the gel to dry on sections of substrates, formed fractured borders that made the gel useless as a sieve. Seen by transmission electron microscope, the coating's molecular structure resembles a grandma's endless knitted blanket with never a stitch missed. The continuous formation of a kind of cubic arrangement of molecules guarantees that a sizable number of pores accessible at the film's surface will pass completely through it. "Everything depends on the initial surfactant [surface-acting molecular] concentration we choose," says Brinker. Circling the wagons The materials of the gel self-assemble due to the two-sided organic surfactant molecules. One side is hydrophobic (hates water) and the other hydrophilic (loves it). In a solution of water and silica, small groups of organic molecules perform tiny versions of circling the wagon trains, arranging their water-loving ends to face outward in wheel-like shapes. The circles form an ordered array. The water-phobic ends remain within the circles, somewhat like spokes and hub. Silica in solution, attracted by the circular rims, surrounds them like tires encircling wheels. After this self-assembly process, the organics are removed by heating (pyrolysis), leaving an inorganic silica fossil with a periodic arrangement of pores where the organics used to be. The work is a collaboration between Brinker, Sandia researcher Celeste Drewien, Mark Anderson (formerly at Sandia, now at 3M), UNM students Yungfeng Lu and Rahul Ganguli, with Professors Bruce Dunn and Jeff Zink at the University of California at Los Angeles. Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national security, energy, and environmental technologies and economic competitiveness.
--------
321-> New Advance May Aid Alzheimer's: Early Study Shows Protein Shares Link With Disease And Reverses Memory Deficits In Mice
WASHINGTON, D.C. October 1 - For the first time, scientists have shown through genetic studies in adult mice that depletion of the protein nerve growth factor (NGF) causes a decline in learning and memory, mimicking a major characteristic of Alzheimer's disease. An estimated 4 million Americans are affected by the degenerative ailment. "We also have found that NGF can bring learning and memory back to normal levels in spite of the loss of about one-third of a population of cells that are important for learning and memory," says Heidi Phillips of Genentech, Inc. in San Francisco. "The finding is intriguing and adds encouragement for therapeutic approaches for Alzheimer's disease based on the principle of increasing the function of remaining brain cells." Her study is published in the October 1 issue of The Journal of Neuroscience. "This is an important advance and brings us one step closer to clinical relevance," says Ira Black, an expert on NGF at Robert Wood Johnson Medical School in New Jersey. "For the first time it demonstrates that memory deficits in a genetic model possibly can be treated with prolonged infusion of NGF into the brain." In the past, researchers suspected that NGF was important for the function and survival of a population of cells that are crucial for learning and memory - basal forebrain cholinergic neurons. "These cells undergo degeneration in Alzheimer1s disease and their loss is believed to contribute to the memory loss observed in the disease," says Phillips. In previous work, scientists found that the administration of NGF to injured basal forebrain cholinergic neurons could improve cognitive function in elderly rats. "Technical difficulties have been an obstacle to determine if NGF is necessary for normal brain function," says Phillips. Phillips and her co-workers overcame this challenge with genetic techniques. In the research, they studied mice bred to carry one dysfunctional copy and one normal copy of the NGF gene. (For each inherited characteristic, an organism has two genes, one inherited from each parent). Mice that lack both copies of the gene do not live long enough to study. The mice Phillips studied have learning and memory losses similar to Alzheimer1s. "The mice bearing one dysfunctional NGF gene have reduced levels of NGF in the brain, show a loss of about one-third of their basal forebrain cholinergic neurons, and display a mild, but significant impairment of performance in a learning and memory task," says Phillips. "The remaining basal forebrain cholinergic neurons are shrunken in size, indicating that they are not functioning optimally." These results show that NGF is critical for the development, survival and function of this cell population. "In the second step of the study, administering NGF not only reverses the cell shrinkage, but also completely reverses the learning and memory deficits in these mice," says Phillips. The scientists are optimistic that these findings could lead to further research that may result in ways to successfully treat Alzheimer1s disease and other memory disorders. NGF is now being studied for the treatment of diseases that involve defects in another type of neuron. These neurons, known as sensory neurons, convey pain and temperature information. Currently, NGF is in human clinical trials for the treatment of diabetic peripheral neuropathy and HIV-related neuropathy. Phillips' co-authors were Karen Chen, Merry Nishimura, Mark Armanini, Craig Crowley, and Susan Spencer, also of Genentech, Inc. Phillips, Chen, Nishimura, and Armanini are members of the Society for Neuroscience, an organization of more than 27,000 basic scientists and clinicians who study the brain and nervous system. The Journal of Neuroscience is published by the Society for Neuroscience.
--------
322-> "Male-Stuffing" Conserves Food In Wasp Nests
ITHACA, N.Y. -- When female wasps return to the colony after foraging, some females initiate aggressive encounters with males and stuff them -- head first -- into empty nest cells, according to Cornell University research reported in the Oct. 2 issue of the scientific journal Nature. Researchers call this newly discovered insect behavior "male-stuffing." "It's a strikingly aggressive behavior," said Philip T. Starks, Cornell doctoral candidate in neurobiology and behavior. "In a wasp colony, the behavior is normally somewhat aggressive, but no one has reported this level of aggression between male and female nestmates before. We observed sting threats, mauling, lots of antagonism. Perhaps it has not been reported because 'male-stuffing' lasts only a few seconds and is thus easy to miss." The article, "Male-stuffing in wasp societies," researched and written by Starks, from Andover, Mass., and Emily S. Poe, a Cornell senior from Endicott, N.Y., appears in the Scientific Correspondence section of Nature. Starks is working on his doctorate with H. Kern Reeve, Cornell assistant professor of biology. Poe and Starks observed and reported on two categories of the aggressive interaction of the paper wasp, Polistes dominulus. Once food arrives for the colony, the "initial stuffing" begins with antenna-to-antenna contact, followed by grappling, biting and sting threats from the females. (Males do not have stingers.) The female then forces the male into a nest cell, head first. The second category of interaction the researchers observed was labeled "repeated stuffing," which is characterized by the female biting and pushing on the abdomen of the male, whose head and thorax already are in the cell. The researchers discovered this behavior while watching and transcribing video recordings of interactions within a colony. Starks explained that this behavior, if not seen on videotape, is difficult to spot because ":male-stuffing" happens so fast and since colonies typically have over 30 individuals, a single interaction can easily go unnoticed." Sixty-six stuffing events were observed during a total of 24 hours of videotape recorded from multiple colonies. The researchers reported that none of the colony's queens stuffed males. Instead, all stuffing was done by worker wasps. While this behavior may seem strange to humans, the biological logic is sound, according to the researchers. Worker wasps bring food back to the colony and feed the needy reproductive destined larvae -- the colony's next reproducing generation. "Limiting food consumption by males may maximize the worker's inclusive fitness," Poe said. "If you look at their behavior, it gets the males out of the way. This contributes to the colony's fitness."
--------
323-> Satellite Tag Keeps Tabs On Young Bald Eagle's Migration Into Canada
Santa Cruz Predatory Bird Research Group gets first look at bird's rapid northward quest for salmon SANTA CRUZ, CA--Along the wild rivers of Alaska and British Columbia, immature bald eagles forage for dead salmon and learn to hunt for live ones in the late summer and fall. The eagles fly north on fast migrations from their birthplaces in California and elsewhere, stunning first journeys from the nest honed by thousands of years of instinct. At least, that's what wildlife biologists thought. Now, an information-age eagle has made that picture much more believable. Scientists from the Santa Cruz Predatory Bird Research Group (SCPBRG) at UC Santa Cruz have tracked, for the first time, a juvenile bald eagle's remarkable coming-of-age quest for food and independence. The eagle wears a tiny backpack fitted with a lightweight satellite transmitter that beeps every 10 days. Signals from the satellite, sent via e-mail to SCPBRG researchers, show that the bird flew some 900 miles in August from its nest at Lake Shasta, in northern California, to the vicinity of the Dean River in central British Columbia. The journey took less than three weeks. Subsequent signals reveal that the bird is staying at the Dean River, apparently having found a rich source of food. Biologists think other young eagles venture even further north, into northern British Columbia and southeastern Alaska's spectacular fjords. "Instinct drives these migrations," said SCPBRG researcher Grainger Hunt, Ph.D. "These young birds have never hunted before and have never caught anything. Yet they leave their parents behind and suddenly, they fly a thousand miles north at the end of the summer. It's very surprising." Hunt and SCPBRG wildlife biologist Ron Jackman tagged the eagle in its nest at Lake Shasta after the bird had reached its full body size. Their work, done in collaboration with Steve Zack of the Point Reyes Bird Observatory, is part of a long-term study of bald eagles by the U.S. Forest Service, Shasta Lake Ranger District. Over the next two years, if both eagle and satellite tag survive, the biologists will learn how long the bird remains in Canada and whether it returns to its home range for breeding. The research also paves the way for satellite tagging of more eagles, as well as falcons, seabirds, and other species of interest. Further, Hunt said, bald eagles offer a glimpse into cycles of nature that, for the most part, remain hidden from view. "Bald eagles are indicators of the health of the global ecosystem," Hunt said. "These telemetry studies will teach us about the eagles' food web. We may learn that the ecology of California bald eagles is tied to the health of the northern salmon runs, and thus to the abundance of plankton in the Pacific Ocean." Hunt speculates that juvenile bald eagles start by eating carrion along the mouths and inland stretches of big rivers with huge salmon die-offs. Later, they learn how to catch live fish--a necessity before they reach breeding age. The satellite technology is a leap forward from SCPBRG's previous method of choice, radio telemetry. For instance, Hunt attempted to follow several young bald eagles northward by plane in the mid-1980s, tracking them on signals emitted by radio transmitters. He saw how quickly they flew, crossing the Canadian border from Lake Shasta in less than a week. Hunt managed to keep up with one bird as far north as Lake George, British Columbia--inland and farther north than the Dean River. But in all cases, poor weather forced him back before he learned the birds' destinations. "This is a completely different kind of wildlife biology, like going from a typewriter to a word processor," said Brian Walton, longtime SCPBRG coordinator. "This technology will be important for tracking seabirds, which we can't follow by plane." Such birds, Walton noted, could include birds injured in oil spills, then cleaned and released. Satellite tags present a new way to gauge the effectiveness of those techniques. If the eagle's transmitter works properly, the researchers will get a report on its location every 10 days for the next two years. The backpack's straps are designed to fail after that time. Hunt and Walton hope to retrieve the $3,000 transmitter after it falls off for possible future use. SCPBRG researchers use Geographic Information Systems technology to map the bird's movements. The project is part of the group's overall management efforts for birds of prey, including the peregrine falcon in California. SCPBRG is credited with restoring the peregrine falcon to healthy breeding levels in the state throughout the 1970s and 1980s. ##### Editor's notes: You may reach the scientists as follows:Grainger Hunt: (408) 462-6229Brian Walton: (408) 459-2466 or walton@cats.ucsc.edu A map of the eagle's migration and color slides of adult and juvenile bald eagles are available.
--------
324-> World's Nobel Laureates And Preeminent Scientists Call On Government Leaders To Halt Global Warming
(Washington, DC - September 30) More than 1,500 of the world's most distinguished senior scientists, including the majority of Nobel laureates in science, have signed a landmark consensus declaration urging leaders worldwide to act immediately to prevent the potentially devastating consequences of human-induced global warming. The "World Scientists' Call for Action at Kyoto" was presented to the Clinton Administration today at a Science Summit on Climate Change in Washington, DC. "Let there be no doubt about the conclusions of the scientific community: the threat of global warming is very real and action is needed immediately," said Nobel laureate Henry Kendall, Chairman of the Union of Concerned Scientists and author of the scientists' statement. "It is a grave error to believe that we can continue to procrastinate. Scientists do not believe this and no one else should either." Leading scientists came to the Science Summit to ensure that government leaders base their global warming policies on climate science, not politics. In December, world leaders will gather in Kyoto, Japan, to negotiate final agreement on a treaty to reduce emissions of carbon dioxide and other heat-trapping gases that are altering the climate. The White House has yet to announce its concrete proposals to limit global warming and has scheduled a conference on the subject for October 6. The scientists' declaration urges all government leaders to demonstrate a new commitment to protecting the global environment for future generations. According to the scientists, a strong treaty will be the "first step to protect future generations from dire prospects that would result from failure to meet our responsibilities toward them. The stark facts carry a clear signal: There is only one responsible choice to act now." "This is a wake-up call for world leaders. Never before has the senior scientific community spoken so boldly on the urgent need to prevent disruption to our climate," said Nobel laureate Dudley Herschbach, Professor of Chemistry at Harvard University. "Scientists and citizens around the world will hold leaders accountable if a strong climate treaty is not reached." The "Call for Action" is notable in both the pedigree and cautious nature of its backers. The signers come from 63 countries and include leaders and senior members of national science academies from around the world, chief authors and the former head of the Intergovernmental Panel on Climate Change, National Medal of Science recipients, and winners of the Craaford Prize. A majority of the world's Nobel winners in science - 98 out of 171 - signed the statement. The declaration points out that a strong climate treaty in Kyoto would address one of the most serious threats to the planet and future generations. The declaration states that: * Global warming is underway and our overuse of fossil fuels is partly to blame. * Climate change is projected to raise sea levels; increase the likelihood of more intense rainfall, floods, and droughts; and endanger human health by greater exposure to heat waves and encroachment of tropical diseases to higher latitudes. * Climate change is likely to exacerbate food shortages and spread undernutrition by adversely affecting water supplies, soil conditions, temperature tolerances, and growing seasons. * Climate change will accelerate the appalling pace at which species are now disappearing, especially in vulnerable ecosystems. Possibly one-third of all species may be lost before the end of the next century. * Continued destruction of forests will undermine the environment's natural ability to store carbon, thereby enhancing global warming. The scientists note that leading economists have identified viable policies for reducing global warming and urge government leaders to enact sound energy policies that promote energy efficiency and renewable energy, like solar and wind power. "We need to speed the transition away from oil and coal while developing cutting-edge technologies involving wind, biomass, and solar power," said Kendall. "A move to clean energy and energy efficiency will bring major benefits to both industrial and developing nations." The world's scientists believe that completion of a strong Climate Treaty would set a "landmark precedent for addressing other grave environmental threats, many linked to climate change. It would demonstrate that the world's leaders have now recognized, in deeds and words, their responsibility for stewardship of the earth." The Union of Concerned Scientists organized the scientists' statement and summit. Established in 1969, UCS is a national non-profit organization dedicated to advancing responsible public policies in areas where science and technology play a critical role.
--------
325-> Bowman Gray Scientists Find Novel Way To Block AIDS Virus
WINSTON-SALEM -- In what could be the most exciting advance in the treatment of AIDS to date, Bowman Gray School of Medicine scientists today reported a novel way to block the deadly HIV virus from ever invading white blood cells. This new strategy, described in the Oct. 1 issue of the journal Nature Medicine, points to a fundamental new way to treat patients with HIV-1 infection or patients with Acquired Immune Deficiency Syndrome (AIDS). This study, by Si.-Yi Chen, M.D., Ph.D., assistant professor of cancer biology, and his colleagues at Bowman Gray School of Medicine, describes how a critical co-receptor on the surface of particular white blood cells called lymphocytes is blocked, making the cells immune to infection by HIV-1. HIV-1 virus causes AIDS by invading and destroying the white blood cells whose functions are essential to maintain the human immune system. Chen's advance is based on the recent discovery of the critical role of chemokine receptors on the surface of the lymphocyte, as the doorway B or co-receptor B for the HIV invasion into lymphocytes. After virus invasion, the now familiar steps in the development of AIDS follow: multiplication of the virus in the infected cells and the killing of the infected cells, progeny virus spreading to other normal lymphocytes, the decline of the disease-fighting CD4 lymphocytes and the progression to AIDS, and its ultimate downward spiral. Last year, in another dramatic discovery, a genetic defect in a chemokine coreceptor was found to protect individuals with this defect from HIV-1 infection. These genetically defective individuals remain healthy, because the usual functions of a defective chemokine receptor can be taken over by other receptors because of redundancies in the chemokine family. So, Chen reasoned, "genetic inactivation of the chemokine co-receptors should protect lymphocytes from HIV-1 infection and have therapeutic implications." Chen and his colleagues set out to mimic the natural resistance of the genetically defective individuals. They designed a novel approach, termed "intracellular chemokine" -- intrakine for short -- to genetically inactivate a CXC-chemokine coreceptor, or CXCR4 for short. This CXCR4 co-receptor plays a critical role in HIV-1 fusion and entry into permissive cells, especially for T-cell line tropic HIV-1 viruses that are frequently isolated in late stages of HIV-1 infection and AIDS. In their studies, Chen and his colleagues were able to inactivate CXCR4 through a series of steps B steps that prevent newly-produced CXCR4 deep within the lymphocyte from ever reaching the cell surface. The key is the alteration of what is known as the SDF-intrakine, which binds to the CXCR4 and traps the molecules inside the lymphocyte. Hence there is no place on which the HIV-1 virus can land to infect the cell. "The genetically modified lymphocytes are immune to T-tropic virus infection but appear to maintain normal biological activities," he said. Chen said that in treating people with AIDS or HIV infection, if the process proves out, human lymphocytes would be removed from an infected patient, genetically modified with intrakine, and periodically reinfused back into patients to delay or prevent the disease progression. "This intrakine strategy likely is superior to currently described anti-HIV approaches," said Chen, for two main reasons: * The intrakine approach is aimed at preventing virus entry into the cell, rather than interfering with virus multiplication. Therefore, the lymphocytes protected by this approach would be truly virus-free. In contrast, all other currently described genetically based anti-HIV-1 approaches can only inhibit virus multiplication after virus infection. * This anti-HIV-1 intrakine targets a cellular chemokine receptor, rather than HIV-1 viral components. "This approach may provide a new paradigm for the treatment of HIV-1 infection, that is, to protect cells from HIV-1 infection, rather than to inhibit HIV-1 replication," Chen said. "As long as this approach can protect sufficient amounts of lymphocytes to maintain immune functions, the HIV-1-infected individuals would be healthy, even if HIV-1 viruses still replicate in the individuals." He said that since genetically modified lymphocytes can live for many months or years, "this gene-based intrakine therapy should have a potent and long-lasting anti-HIV effect." In contrast to Chen's approach, the best current HIV treatment is with combinations or "cocktails" of drugs. While these combinations of medications shows promise of extending the lives of patients with HIV-1, Chen said, "such an approach induces toxic side effects, selects for resistant mutants, and is unlikely to completely eliminate HIV-1 from infected individuals." Chen said, "A strategy of genetic modification of host cells, the lymphocytes or stem cells, for resistance to HIV-1 infection, together with drug therapy, may hold the ultimate hope for HIV treatment." His group is now in the stage of pre-clinical study to further evaluate the efficacy and safety of this intrakine approach. But he said clinical trials in people are a year or more away. The research scientists in Chen's team include Jidai Chen, M.D., Ph.D. and An-gang Yang, M.D., Ph.D. both post-doctoral fellows, and Xuefai Bai, Ph.D., a research fellow.
--------
326-> Tobacco And Drug Companies Compete For Consumers
ANN ARBOR---The billowing smoke from the national tobacco wars is obscuring an ironic, new economic development---the emerging, multi-billion dollar market for long-term nicotine maintenance. Tobacco companies are likely to find themselves competing with pharmaceutical companies to develop new products that will deliver nicotine to nicotine-dependent consumers on a long-term basis without smoking cigarettes, according to Kenneth E. Warner, professor of health management and policy at the University of Michigan. "At present, these two industries have diametrically opposed objectives---the tobacco industry striving to sustain nicotine addictions and the pharmaceutical industry striving to end them," Warner said. But both industries are competing for the same consumer, and as the new market shapes up, it is becoming clear that "current regulatory policy favors the tobacco companies, which encounter little regulation to speak of and can introduce new, nicotine maintenance products quickly and easily." In contrast, safer pharmaceutical products, such as the nicotine patch or inhaler, must go through long, expensive trials to be approved by the Food and Drug Administration (FDA). The upshot is that they take longer to come to market than tobacco industry products and cost more when they arrive. Writing in the Oct. 1 issue of the Journal of the American Medical Association, Warner and his co-authors argue that policy-makers must be open to the concept of encouraging the pharmaceutical companies to develop nicotine delivery systems that will be sufficiently attractive to current smokers to serve as long-term, possibly permanent, substitutes for cigarettes. "For smokers who cannot or will not end their nicotine dependence, new, nicotine-only products could greatly reduce their risk of disease," Warner explained. "The primary goal of a new nicotine policy should remain helping everyone who wishes to be free from nicotine and tobacco to avoid addiction or achieve abstinence. However, some health professionals, concerned that some smokers cannot free themselves from addiction to nicotine, are cautiously considering a harm-reduction strategy that envisions a role for long-term nicotine maintenance using products that deliver nicotine without the other toxic substances in tobacco products." A policy that makes "minimally harmful" nicotine products available to adults, in a "deglamorizing" social and policy environment "seems worthy of open-minded consideration," Warner said. "For many health professionals, contemplating competition between the tobacco and pharmaceutical industries for long-term nicotine users will generate a sense of moral repugnance. Like it or not, however, this competition will continue to develop, barring extraordinary measures." Nicotine replacement therapy products, which aim to reduce or eliminate reliance on nicotine over time, include the familiar nicotine gum and the nicotine patch, and the new nicotine spray and nicotine inhaler, both recently approved by the FDA. Meanwhile, the tobacco industry has developed a cigarette-like device called Eclipse that does not burn tobacco and delivers nicotine in an aerosol consisting largely of water, glycerin, nicotine and carbon monoxide. Unlike the pharmaceutical company nicotine replacement products, however, Eclipse seems to be dedicated to the perpetuation of nicotine dependence. Historically, the tobacco companies' so-called new and "safer" products, such as "low tar and nicotine" and filtered cigarettes, have done little to protect the consumer because they simply encourage smokers to smoke more often or inhale more deeply to satisfy their cravings for nicotine, Warner noted. "The introduction of Eclipse thus follows a decades-old tradition, with the industry's apparent intent being to reduce public concern and thereby maintain or expand sales." Many smokers who would have quit if they had had no alternative are likely to continue, "increasing their exposure to nicotine and carbon monoxide, which, on balance, may increase the aggregate disease toll, since quitting is obviously far better for health than continuing to inhale carbon monoxide and nicotine." Warner and his colleagues suggest that policy-makers consider some or all of the following regulatory measures in order to level the playing field: --Allow all nicotine delivery devices currently available to continue in the marketplace, but make the least toxic products the most easily available and attractive. For instance, improve the flavor of nicotine gum, and make the new spray or inhaler, which offer rapid delivery of nicotine to the brain, more accessible to consumers. --Require reduction of nicotine content in cigarettes and chewing tobacco over several years to levels unlikely to cause or sustain addiction. "This would afford current users ample opportunity to wean themselves from tobacco products while reducing the ability of tobacco products to addict future generations of children," Warner explained. --Require that all nicotine delivery devices, regardless of industry of origin, be evaluated as drug-delivery devices by the FDA and allow advertising only for products that the FDA finds minimally dangerous. If permitted at all, limit cigarette advertisements to black-and-white letter factual text and require that cigarette packages carry warning labels that cover a third of the package. Warner's co-authors are Dr. John Slade of the University of Medicine and Dentistry of New Jersey, and St. Peter's Medical Center, New Brunswick, N.J., and David T. Sweanor, Non-Smokers' Rights Association, Ottawa, Ont.
--------
327-> Radarsat Begins First Complete Detailed Map Of Antarctica
Initial images from the first complete radar survey of Antarctica, using the Canadian Space Agency's Radarsat mission, show better-than-expected details of its massive ice streams and crevices, as well as old, buried features of the international South Pole research station established in the late 1950s. "The quality of these first images is quite stunning," said Dr. Robert Thomas, program manager for polar research in NASA's Office of Mission to Planet Earth, Washington, DC.  "Antarctica is the only continent on Earth that has not been properly mapped.  Despite many years of research, we still do not know whether this massive ice sheet is growing larger or smaller.  Radarsat's Antarctic Mapping Mission should help us answer this question, and many related questions about its potential for affecting global sea levels." Nearly 70 percent of the Earth's fresh water is contained in the Antarctic region, and changes in this enormous reservoir directly influence world sea levels and climate.  As a reference point, if fully melted, this ice would raise the global sea level by about 230 feet (70 meters). Previous research has revealed that about 90 percent of Antarctic ice flows into the sea via large "ice streams."   These rivers of ice are tens of miles wide and about a half-mile thick, and can flow rapidly within the predominantly slow-moving ice sheet.  "We know little about why these ice streams form where they do, or what determines their speed," Thomas said.  "Most Antarctic ice streams flow into 'ice shelves,' large, floating slabs of ice the size of Texas that rest on the ocean and occupy most of the Antarctic coastline.  They move seaward at about a half-mile per year, occasionally 'calving' to form huge icebergs." Where the seabed beneath an ice shelf becomes sufficiently shallow, the ice shelf runs aground, slows down and thickens to form an "ice rise" which tends to slow the seaward progress of the ice shelf, and ultimately to hinder ice discharge down the ice streams.  However, if the ice shelf were to become sufficiently thin, for instance, by increased melting from beneath, the speed of ice discharge would increase, allowing more ice to flow into the ocean, and thus raising the sea level.   "Just how quickly this could happen if climate were to change is not known, and would depend heavily on whether the ice sheet is already thinning or, as some evidence suggests, actually thickening," Thomas said.   "These unknowns are the prime reasons for this research effort." The first radar image of Earth's geographic South Pole from the Radarsat Antarctic campaign clearly shows the infrastructure of the Amunsden-Scott Station operated by the U.S. National Science Foundation. The image reveals the modern infrastructure that supports a host of international science programs, but also shows an abandoned aircraft runway and other remains of the old South Pole station, now buried under about 30 feet of snow and ice. This image and several others, as well as further information on the Radarsat mission, are available on the Internet at the following URL, under the link to the Antarctic Mapping Mission: http://radarsat.space.gc.ca The Antarctic Mapping Mission was made possible by rotating the satellite 180 degrees from its normal field of view, which was completed on Sept. 11.  Full mapping will require the collection of over 5,000 images. "Following the successful rotation, 30 percent of the mission's objectives have now been achieved," said Rolf Mamen, Director General of Space Operations at the Canadian Space Agency.  "We are extremely pleased with the quality of the radar images being obtained of this unmapped region of our planet, and of the contribution we are making to the scientific community." The high-resolution digital image mosaic of the ice sheet and exposed portions of the continent to be taken by the Antarctic Mapping Mission will serve as a benchmark for testing the predicted effects of global warming on the interior ice sheet and its bounding ice shelves.  This unique data set also will support the development of policies to help preserve Antarctica in its relatively pristine state, through the goals subscribed under the international Antarctic Treaty System. U.S. partners in the Antarctic portion of the Radarsat mission include the Byrd Polar Research Center of Ohio State University, Columbus, OH; NASA's Alaska Synthetic Aperture Radar Facility in Fairbanks; the Jet Propulsion Laboratory, Pasadena, CA, and the Goddard Space Flight Center, Greenbelt, MD. "The job of mapping one of the last largely unexplored regions of the Earth is truly a mission of international cooperation, with collaboration that includes scientists from Great Britain, Germany, Japan, and Australia in addition to the United States and Canada," said Dr. Kenneth Jezek, a professor of geological science and director of the Byrd Polar Research Center at Ohio State University.  "In that way, the Antarctic Mapping Mission is in keeping with the spirit and intent of the Antarctic treaty, which serves to preserve the continent for peaceful scientific research by any nation." In exchange for the launch of the Radarsat satellite by NASA in November 1995, Canada agreed to provide access to a proportionate amount of its operational data and to execute the yaw maneuver of the spacecraft twice during the mission to allow the mapping of the Antarctic continental ice sheet. Operated by the Canadian Space Agency from St. Hubert, Quebec, Radarsat utilizes a sophisticated microwave radar system able to produce images through cloud cover, smog, haze, smoke and darkness.  The satellite can be programmed to capture images of an area as wide as 320 miles (500 kilometers), and can detect objects as small as 26 feet (eight meters.) NASA's involvement in Radarsat is part of the agency's Mission to Planet Earth enterprise, a long-term coordinated research program to study the Earth's land, oceans, air, ice and life as a total system.
--------
328-> UF Researchers: Nuclear Power Will Make Mars Trip Shorter, Safer
Writer: Randolph Fillmore, rfill@nervm.nerdc.ufl.edu Source: Samim Anghaie, (352) 392-1421 GAINESVILLE -- As the world marks the 40th anniversary Saturday of the first Sputnik launch and the dawn of the Space Age, scientists at the University of Florida are working on a nuclear propulsion system they say could shorten a 600-day manned trip to Mars by more than a year. "Two years is too long for astronauts to be in space," said Samim Anghaie, professor of nuclear engineering and director of UF's Innnovative Nuclear Space Power and Propulsion Institute. "Our goal is to shorten the transit time necessary to complete a manned mission to Mars, reducing the time the crew is exposed to cosmic radiation." When the Soviet-built Sputnik, the first man-made satellite, left earth Oct. 4, 1957, it opened the door for space exploration. Sputnik's historic, short trip into Earth orbit was a small step compared with the giant leap of a manned flight to Mars, a round-trip that could take 600 days aboard a chemical-fueled rocket. Anghaie is developing fuels for a nuclear thermal propulsion rocket to carry a manned mission more quickly into Mars orbit. "The key to getting astronauts to Mars and back as soon as possible lies in nuclear propulsion," said Anghaie. "Using nuclear fuel rather than chemical fuel can shorten the round-trip to Mars from more than 600 days to about 200 days," he said. A small reactor about the size of a 55-gallon barrel can provide enormous power for propulsion and carry a spacecraft at much higher speeds than can an equivalent chemical system. "The spacecraft would leave earth aboard a standard chemically fueled rocket," said Anghaie, "but once it was away from the earth, it would switch to nuclear propulsion for the trip to Mars. Nuclear power can more than double the spacecraft's speed." The compact, lightweight system for which Anghaie has developed a conceptual model produces heat at more than 5,000 degrees Fahrenheit. Hydrogen is heated in the nuclear reactor and then exits the rocket nozzle to provide thrust. How soon will a manned mission to Mars be feasible? Anghaie said that the groundwork for such a mission has been well-laid by unmanned probes of Mars.  Too, an astronaut's ‘giant leap for mankind' onto Martian soil will borrow some well-rehearsed procedures from the Apollo moon missions. "The manned mission to Mars will use the same landing concept that Apollo moon missions used," said Anghaie. "The craft will go into orbit around Mars, and then a landing module will depart. When descending to Mars, the craft will be able to use ‘air braking.' It will slow down using the friction created by the Martian atmosphere, which is composed of almost entirely carbon dioxide." While nuclear-powered submarines have been around for a generation, using nuclear power for spacecraft is a promising frontier, said Anghaie, but one not without critics. "We have ground-tested nuclear-powered rockets since the 1970s and have learned a great deal about high-temperature nuclear fuels," said Anghaie. Anghaie dismisses critics of Cassini, an unmanned Saturn probe mission scheduled to lift off in January with an on-board plutonium radio-thermal generating (RTG) system. "We have significant expertise in the use of RTGs to power satellites in space. There have been many space probes, such as Sojourner and Galileo, that have used nuclear material to keep equipment warm and working under the cold Martian atmosphere," said Anghaie. "The plutonium isotopes used in these satellites do not undergo fission, the reaction that produces power in conventional nuclear power plants. Instead, they use the alpha particles these isotopes emit. These particles have a very short range, so short a piece of paper could stop them. They deposit all their energy locally as heat, which is converted to electricity." With the success of the unmanned Mars probes and the public interest they've generated, Anghaie said he expects a mandate for a manned Mars trip will crystallize soon.
--------
329-> New Discovery May Offer Protection Against Stroke
By further tracking nitric oxide's actions in the brain, Johns     Hopkins scientists report they have figured out what may be a     universal sequence of biochemical events from stroke to brain cell     death. Cell death appears to result from the overactivation of an enzyme     called poly (ADP-ribose) polymerase, or PARP, which lethally     depletes energy sources from the cells, according to Valina     Dawson, Ph.D., associate professor of neurology. When she and     her colleagues induced strokes in mice genetically engineered     without a PARP gene, brain damage was dramatically reduced in     comparison to a group of unaltered mice. "Nitric oxide has long been known to play a role in neuronal     damage after stroke, and now it seems that a candidate pathway     for that injury is DNA damage leading to unusual PARP     activation," Dawson reports in the October issue of Nature     Medicine. Nitric oxide does its damage by sabotaging the DNA of     nerve cells. The DNA nicks and breaks activate PARP, which is     normally, for the most part, dormant, she says. "Clinically, our work suggests that inhibiting PARP may spare     nerve cells from energy loss, thus preventing irreversible damage     and providing protection," says Solomon Snyder, M.D.,     distinguished service professor and director of the Department of     Neuroscience and an author of the paper. "The reduction in brain     damage from stroke we observed among the mice without PARP     exceeds the protection reported with any known stroke     treatment." Paradoxically, in cases of minor damage, PARP acts as a relief     squad, activated to make repairs. But with more substantial     damage, such as severe loss of blood during stroke, PARP can be     overactivated. When this happens, it uses up NAD, the substance     PARP acts on, and ATP, the major energy source of all cells,     causing the cell to die of energy depletion. In the study, researchers first compared brain tissue from the     so-called "knockout" mice, bred in Austria without a PARP gene,     to unaltered mice to measure toxicity caused by interaction with     other brain chemicals released in cases of neurological damage.     The tissue from the knockouts were completely resistant to     neurotoxicity. In tissues from the unaltered mice, however,     approximately 65 percent of the cells were destroyed. They then induced experimental strokes in the mice to evaluate the     extent of resulting brain injury. Tissue damage in the genetically     altered mice was 80 percent less than in the unaltered mice. "The reduction in stroke damage in PARP knockout animals     suggests that PARP inhibitor medications will be useful for treating     strokes," Snyder says. Stroke is the third leading cause of death and disability, affecting 3     million people each year. It occurs when a blood vessel bringing     oxygen and nutrients to the brain bursts or is clogged by a blood     clot or some other particle. Because of this rupture or blockage,     part of the brain doesn't get the flow of blood it needs, and the     nerve cells in that section start to die within minutes. Brain damage     from a stroke can diminish the senses, speech and the ability to     understand speech, behavioral patterns, thought patterns, and     memory. Paralysis on one side of the body is common. Michael Muskowitz and colleagues at the Massachusetts General     Hospital have independently replicated these findings, Snyder     says, and will be publishing their results in the near future. The study's other authors were Mikael J.L. Eliasson; Kenji     Sampei, M.D.; Allen S. Mandir, M.D.; Patricia D. Hurn, Ph.D.;     Richard J. Traystman, Ph.D.; Jun Bao, Ph.D.; Andrew Pieper;     Zhao-Qi Wang, Ph.D.; and Ted M. Dawson, M.D., Ph.D.. Johns Hopkins has previously licensed the rights for PARP     inhibitors to Guilford Pharmaceuticals in Baltimore. Under the     terms of the previous license agreement between the Johns     Hopkins University and Guilford, Snyder, Valina Dawson and Ted     Dawson are entitled to a share of sales royalties received by the     University from Guilford. The University owns stock in Guilford, with Snyder and Ted     Dawson having an interest in the University share under University     policy. The University's stock is subject to certain restrictions     under University policy. Snyder also serves on the Board of     Directors and the Scientific Advisory Board of Guilford, he is a     consultant to the company, and he owns additional equity in     Guilford. This arrangement is being managed by the Johns     Hopkins University in accordance with its conflict-of-interest     policies.
--------
330-> Researchers Discover Probable Molecular Site Of Alcohol And Anesthetic Actions
After 155 years of searching, researchers have identified a small     region on the surface of nerve cells that may be essential for the     actions of inhaled anesthetics, opening a door to rational design of     new pain medications. The same site may be responsible for some of the depressive     effects of alcohol and could provide crucial insights into the     genetics of alcohol addiction. The finding is reported by scientists from the University of Chicago     Medical Center, the University of Colorado at Denver, and the     University of Pennsylvania in the September 25 issue of Nature. "For the first time, this allows us to begin the process of designing     and synthesizing new anesthetics based on where and how they     work rather than on serendipity and sheer dumb luck," said Neil     Harrison, Ph.D., associate professor of anesthesia and critical care     at the University of Chicago and director of the study, which was     carried out in collaboration with Adron Harris (UC Denver) and     colleagues Eric Greenblatt at Pennsylvania and John Mihic, now at     Wake Forest University. "In the long term," adds Harrison, "it should result in safer, more     potent medications with far fewer side effects." "Although one cannot be 100-percent certain that the binding sites     themselves have been identified, this work represents an     impressive and important step forward in understanding how these     remarkable drugs work," said Nick Franks, Ph.D., head of the     biophysics section at Imperial College of Science, Technology and     Medicine, London, and a leader in the field. Franks and colleague     William R. Lieb authored a News and Views in the same issue,     putting the finding in perspective. Knowing where anesthetics act would also speed the development     of "antagonists," drugs that could rapidly reverse the effects of an     anesthetic. Such antagonists, for example, could render a patient     immediately wide awake and alert after surgery. "This is a very important finding," said Alison Cole, Ph.D.,     Program Director at the National Institute of General Medical     Sciences. "It provides the first structural basis for the sensitivity of     anesthetics, a crucial tool for understanding how these drugs work     and ultimately designing better ones." Despite more than a century and a half of use--since January,     1842, when William Clarke first administered ether to help dentist     Elijah Pope remove a tooth--no one has been able to demonstrate     exactly how general anesthesia produces its effects. The traditional     view was that anesthetics acted in a very nonspecific way, oozing     into cell membranes to deactivate nerve cells. More recently,     scientists have searched for more explicit targets, proteins on the     surface of selected nerve cells. A few years ago, the two labs in Chicago and Denver     demonstrated that clinically relevant concentrations of inhaled     anesthetics and alcohol enhanced the effects of a neurotransmitter     called GABA (gamma-aminobutyric acid) and its close relative     glycine. Unlike "excitatory" neurotransmitters such as glutamate or     acetylcholine, which convey signals from nerve to nerve, GABA is     an "inhibitory" neurotransmitter. It blocks signals by preventing     nerve cells from sending messages upstream to the brain. GABA     is the most important inhibitory neurotransmitter in the brain;     glycine plays a major role in the lower brain stem and spinal cord. "GABA makes sense as a target because it does the right job in     the brain," said Harrison. "It depresses the central nervous system.     By enhancing GABA, these drugs interrupt the processing of     sensory information, resulting in the unconsciousness and amnesia     we get with anesthetics." In order to find the crucial contact regions, the researchers     substituted small pieces of a different receptor into the GABA and     glycine receptors to see which parts could be replaced without     altering the receptor's response to alcohols or anesthetics. They     found a small region of 45 amino-acids that was necessary for     these drugs to enhance the receptor's effects. Within this crucial region, two specific mutations, made by     molecular biologist Qing Ye, rendered the receptors completely     unresponsive to alcohol or anesthetics, presumably by changing     the way the proteins folded. The researchers suspect that the     proteins fold up to form a pocket that serves as the binding site for     the drugs and have built a model of its possible configuration. They     have also begun to develop transgenic mice with mutations in the     GABA receptor to verify that alterations in the protein will alter     the response to anesthesia or alcohol. "We can't be absolutely certain that we have found the binding site     for anesthetics or alcohol until we can crystallize the protein and     determine its structure," cautioned Harrison, "but this does tell us     that this region is crucial for the drugs' effects." The findings may also help unravel the complex genetics of     alcoholism. "Alcohol clearly affects other receptors too," admits     co-author R. Adron Harris, Ph.D., of the University of Colorado     Health Sciences Center. The rewarding aspects of alcohol are     generally attributed to its effects on the neurotransmitter dopamine,     "but our guess is that the less pleasant, depressive or sedative     effects of alcohol involve its effects on GABA," said Harris.     "People with mutations in the GABA receptor, who don't     experience the same downsides from alcohol, may have fewer     incentives to restrict their drinking." A pilot study, looking for mutations within the critical region in     about a human population including alcoholics, is already     underway. Harrison and geneticist Edwin Cook, M.D., of the     University of Chicago, are working with alcoholism specialist John     Crayton, M.D., now at Loyola University Medical Center. The research published in Nature was supported by grants from     the National Institute of General Medical Sciences, the National     Institute on Alcohol Abuse and Alcoholism, the Foundation for     Anesthesia Education and Research, and the Brain Research     Foundation.
--------
331-> Stiffening The Spines Of Large Space Structures
So far, manned spacecraft have been small, cramped capsules. Much larger orbital structures, like the international space station, are now onthe drawing boards. As these larger space habitats are constructed, a newproblem will become increasingly important: stability. If two sections of a space structure begin moving to the beats of differentdrummers, the structure could easily be severely damaged. One solution to the problem is to design in added rigidity, but that adds weight,which can significantly increase cost. An alternate, and potentially more cost-effective, approach is to build in adynamic control system that actively controls errant oscillations. E. HarrisonTeague, a Stanford doctoral student in aeronautics and astronautics, hasdeveloped such a system, which employs signals from the Global PositioningSystem, the Department of Defense's satellite navigation system. Using inexpensive GPS receivers attached to different portions of a spacestructure, the method can detect wayward motions with centimeter-levelprecision and then automatically fire thrusters to compensate for them. Thesystem also can be used to change the orientation of a flexible structure withsuch accuracy that it moves almost as if it were rigid. Teague developed the GPS system as part of his doctoral thesis, which hecompleted in June. An article describing the work will appear in the summerissue of the Navigation Journal, which is still in press. His thesis advisers wereaeronautics and astronautics professors Jonathan How and BradfordParkinson. Previous methods that provided centimeter-level measurements of position andattitude using GPS relied on the object in question being a rigid body. Teagueadapted these techniques to provide the same level of precision with a flexiblestructure. Next he had to identify the shapes and frequencies of the various modes ofoscillation that could develop in such a structure. Although researchers hadsome general ideas of what such modes should be, they were not known withenough precision for effective control. Finally, the student came up with procedures that could control such motionswhile automatically accommodating processes such as docking and undockingof capsules and the addition and consumption of consumables, processes thatcan cause major changes in the dynamic properties of space structures. To try his system, Teague built an ungainly-looking test bed that allows him tosimulate the movement of a light structure in weightlessness. The test bedconsists of three 100-pound blocks of aluminum connected by two 15-footlong rods. Each block has two arms that are about five feet long extendingperpendicular to the rods. On the end of each arm is a small GPS receiver anda cluster of four compressed-air thrusters. The entire assembly is hung by extremely strong thread. The top of eachaluminum block is milled out in a cone shape so that the thread can be attachedat its center of mass and the block can rock without contacting the thread.Threads from each of the three blocks extend upward where they are attachedto a 30-foot length of heavy steel pipe. Straps from each end of the pipe aretied onto a thrust bearing that allows the entire assembly to rotate. The bearing,in turn, is supported by a heavy, overhead crane. Because the rods connecting the three blocks are extremely flexible, the testbedcan simulate a wide variety of motions. Each of the blocks can be set rockingvertically and horizontally. The rods transmit some of this motion to the otherblocks. So waves of motion can travel from one end of the assembly to theother. When the blocks are set rocking in different directions, the waves cancombine and cancel in unexpected ways. Teague's test area is indoors, so he had to use pseudo-satellites, antennas thatproduce imitation GPS satellite signals. The receivers use these signals to keeptrack of their precise position. All the positions are sent to a desktop computerthat contains a model of the assembly. The computer identifies the oscillationmodes when they are still very small and calculates the timing and duration ofthe air blasts necessary to dampen them out. The most dramatic demonstration of the system's capabilities comes whenTeague vigorously sets the assembly rocking and rolling. When he activates thecontrol system, the thrusters begin hissing, the motions get smaller and smallerand the assembly returns to rest within 5 seconds. A less dramatic, but more realistic test cares when Teague turns the controlsystem on and then manually moves one of the arms. Thrusters begin hissingimmediately and the arm rapidly returns to its proper position when he lets go. Teague also can use the system to rotate the flimsy assembly as if it were rigid.When he enters the proper command, the thrusters begin to hiss and theassembly begins to turn like a rigid body, with very little shuddering or deviationfrom its base configuration. The research was funded by the National Aeronautics and SpaceAdministration.
--------
332-> Genetic Engineering Offers Painless "Shots" For Cattle
MANHATTAN -- For Kansas cattle, getting vaccinated may become as simpleas eating fodder. Researchers at Kansas State University are developing avaccine for calf enteric disease that will not be delivered as a shot. Itwill instead immunize cattle through the alfalfa they eat. Sanjay Kapil, assistant professor of diagnostic medicine, heads theeffort to genetically express proteins for the bovine corona and bovinerota viruses in plants. With traditional vaccinations, farmers directlyinject cattle with non-infective virus protein. This produces antibodiesthat help fight disease. However, Kapil explains that this process is ahassle for ranchers. "If you inject too much of the virus, the cattle will get sick. But bydelivering vaccines with plants, the cattle will never get sick." This isbecause the plant vaccines do not have concentrations of infectiousvirus. Anyone who has struggled with capturing and injecting a calf witha needle will recognize the convenience the new vaccines will provide. Researchers must first insert the genes of the virus into the plantchromosomes so that it will become a permanent part of the plant'sgenetic code. The ultimate goal is expressing the new vaccination gene insuccessive generations of plants, which can then be fed to animals. Kapil explains that smaller trials represent the first step in theoverall process. "Before we go into large scale animal trials, we need todo it in a lab system. So we chose tobacco plants and the mouse, whichare easier to work with in the lab." The team has successfully integratedthe vaccine in tobacco plants and fed those plants to mice. Now, they aresimply waiting for the results. Though the Kansas State team moved first in bovine vaccinations,researchers had already begun expressing vaccination genes in plants forhuman consumption. Knowing the results of their trials, Kapil expects thesame positive results for cattle. The next step will be actual fieldtrials, taking vaccines into fodder crops, like alfalfa, and giving it tocattle. Field trials could be as little as five years away. Plant vaccines will help Kansas farmers and ranchers, but thesignificance of this research stretches far beyond its cattle ranches.Enteric diseases like corona and rota cost more than $3 billionworldwide, infecting and killing young cattle with diarrhea. Ranchers inthe United States lose $250 million annually to the viruses. Kapil expects this research to help many related projects. "We have crossed the boundaries of just the animal group." He explainsthat a similar rota virus invades human babies, as well as cattle,leading to infection in 750 million children each year. If the bovinevaccination proves effective, a similar technique may be developed forchildren. Because of this exciting potential, the K-State team is applying for apatent. While similar procedures have been patented, Kapil feels this histeam's genetic engineering is unique. "Every system is different: whichgene to go after, how to deliver it, which crop, how to deliver it in thecrop. We're very lucky. The initial results are very promising." Kapil says his team's research is "a storybook of daydreams." For cattleand farmer alike, gene vaccines would be a dream come true.
--------
333-> Meeting On Viral Origins Of Psychiatric Conditions
The Stanley Neurovirology Laboratory at the Johns Hopkins School of Medicine will host the Third Annual Symposium on the Neurovirology and Neuroimmunology of Schizophrenia and Bipolar Disorder on October 23-25 in Bethesda, Md. The meeting brings together researchers from many fields who are interested in the role that viruses may play in the development of these disorders.  Last year's meeting included researchers from the U.S., Canada, Finland, Japan, Sweden, Italy, Poland, Israel, Russia, and Jamaica. "There have been questions about the viral origins of these conditions for nearly a century," says Robert Yolken, M.D., who heads the laboratory and is the director of the Division of Infectious Diseases at the Johns Hopkins Children's Center.  "After the influenza epidemic in 1918, doctors noticed symptoms of schizophrenia and bipolar disorder in some of the patients recovering from the flu.  But so far we don't have a clear handle on how a virus could lead to these types of neuropsychiatric disorders." Subjects at this year's meeting include the epidemiology of schizophrenia and bipolar disorder; viruses as triggers for immune dysfunction; antiviral properties of antipsychotic drugs; the effects of viruses on neurotransmitters; molecular virology, and viral models for central nervous system function and pathology. 	The meeting will be held at the Bethesda Marriott, 5151 Pooks Hill Rd., from 8 a.m. to 5 p.m.  There is no registration fee.  Press can pre-register or get more information by calling Nancy Volkers at (410) 223-1747 or e-mailing nvolkers@welchlink.welch.jhu.edu. 	The Stanley Laboratory is funded by the Theodore and Vada Stanley Foundation.  The lab is online at www.stanleylab.org. 
--------
334-> University Of Florida Researchers Develop Computer Program To Accurately Stage Prostate Cancer
By Melanie Fridl Ross GAINESVILLE, Fla.---University of Florida researchers have developed a novel computer program, a silicon soothsayer that predicts the likelihood prostate cancer has spread. The patent-pending artificial intelligence system is notable because studies have shown surgery is not always worthwhile when cancer has progressed outside the gland or infiltrated nearby lymph nodes. More than 300,000 men are diagnosed with prostate cancer annually in the United States; nearly half have cancer extending beyond the gland. By accurately staging prostate cancer, practitioners can help patients with potentially incurable cancer avoid radical interventions, said Dr. Ashutosh Tewari, a urology fellow at UF's College of Medicine. Treatment options include surgery, radiation therapy, cryotherapy, watchful waiting or even hormonal therapy. Traditional tests -- such as digital rectal examination, prostate specific antigen screening, body-imaging CT or MRI scans and lymph node dissection -- are expensive and invasive and are correct only half the time, says Tewari. Tewari and Dr. Perinchery Narayan, professor and chief of urology at UF, collaborated on a pilot study to assess the computer program's accuracy. The program, which Tewari said could save practitioners and patients $150 million in annual health-care costs, simulates the functioning of the human mind using computer processing units to assimilate information and predict outcome. "For example, if you're crossing the street and see a car coming, you make a decision whether to cross the street or not, and if so whether you want to run or walk, based on multiple inputs," Narayan said. "They include information from your eyes, which see and assess how fast the car is coming; your muscles, which know how fast you can run or not run; and a certain portion of your brain that assesses how far you have to get before the car will or will not hit you -- what we call a past memory based on your prior experience. "The computer uses a similar process of back-and-forth questioning that combines past memory and present data to make a determination about the cancer's severity," he said. The computer recognizes subtle relationships among various data, then assigns a number depending on whether the patient's cancer is likely to be confined to the organ -- or 'curable' -- or whether it has spread to one or both sides of the prostate. UF researchers spent the past four years gathering data from 1,000 prostate cancer patients at Shands at UF and the Gainesville Veterans Affairs Medical Center, including age, race and prostate specific antigen information, and entered those findings into the computer. The system then predicted whether the disease was confined to the prostate and staged it. Researchers compared the computer's results with information obtained after radical prostatectomy -- surgery to remove the prostate. The system's so-called "negative predictive power" was very good, accurately determining cancer was confined to the prostate nine times out of 10. UF researchers currently are working on a new network to predict the possibility of prostate cancer recurrence and life expectancy in patients who undergo treatment. "This program will also help assess the value of newer tests," Narayan said. "By adding them to the current algorithm, we will find out whether they have additional value in terms of staging the cancer and determining prognosis, or whether traditional tests already give us the same information." -------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
335-> Scientists Develop Powerful Tool For Studying TB
Scientists supported by the National Institute of Allergy and Infectious Diseases (NIAID) have developed a technique that theoretically will allow researchers to study the function of every gene in the bacterium that causes tuberculosis (TB). The finding, reported in the Sept. 30, 1997 issue of the Proceedings of the National Academy of Sciences (PNAS), has significant implications for the development of new TB drugs and vaccines and for advancing our understanding of how TB bacteria cause disease. "This is a major advance for the TB research community and it represents an important step in NIAID's efforts to develop research-based solutions to one of our foremost global health problems," says NIAID Director Anthony S. Fauci, M.D. "One-third of the world's population is infected with Mycobacterium tuberculosis (M.tb), the organism that causes TB. Each year, an estimated 3 million people die from TB, more than from any other infectious disease." TB bacteria are notoriously difficult organisms to study in the laboratory. Many of the molecular techniques that scientists use routinely to analyze other microorganisms have until recently been of little use in TB research. Consequently, systematic methods for creating mutations in M.tb genes have eluded scientists. Such methods are extremely valuable in the study of disease pathogens, as they allow scientists to examine the effect of individual gene mutations on an organism's ability to grow or cause disease. These studies can reveal new drug targets or identify potential vaccine candidates. "Analyses of M.tb have been hampered by the lack of efficient systems for transferring new genetic material into this pathogen," explains William R. Jacobs, Jr., Ph.D., senior author of the study. "Furthermore, because M.tb is such a slow-growing bacterium, methods of creating and analyzing mutations that involve exposing cells to DNA-damaging agents, and then characterizing colonies arising from single cells, are of limited value." Dr. Jacobs, an NIAID grantee at the Howard Hughes Medical Institute (HHMI) at Albert Einstein College of Medicine in the Bronx, N.Y., led a research team that found an efficient way to create mutations in TB genes using fragments of DNA known as transposons. Transposons insert themselves at random into bacterial DNA, inactivating any gene in which they take up residence. Scientists have used transposon mutagenesis, as this process is called, to generate vast numbers of mutations in many other kinds of bacteria. These so-called mutation libraries allow scientists to study the function of individual bacterial genes. Until now, transposon mutagenesis has not been feasible in TB bacteria. Dr. Jacobs, NIAID grantees Barry R. Bloom, Ph.D., also of HHMI at Albert Einstein College of Medicine, and Graham F. Hatfull, Ph.D., of the University of Pittsburgh, and their colleagues constructed special delivery vectors to carry transposons inside TB cells. Known as conditionally replicating shuttle phasmids, these vectors essentially are genetically engineered mycobacteriophages -- viruses that infect M.tb and related bacteria. For this study, the researchers developed phasmids with mutations that prevented them from replicating at a temperature of 37 degrees Celsius (C). The transposons carried by these shuttle phasmids contained a gene conferring resistance to the antibiotic kanamycin. The researchers mixed M.tb cells with the transposon-bearing shuttle phasmids and incubated them at 37 C. Instead of replicating repeatedly and destroying the M.tb cells, at this "non-permissive" temperature the phasmids simply stuck to and entered the bacterial cells, providing an opportunity for the transposons to insert themselves into the bacterial DNA. To determine the success of their efforts, the researchers transferred the TB-phasmid mixture to culture media containing kanamycin. Only those TB bacteria carrying the kanamycin resistance gene, by virtue of having undergone transposon mutagenesis, will grow on this media. Dr. Jacobs and his colleagues recovered thousands of kanamycin-resistant M.tb mutants in three separate experiments. "Analyses of DNA from randomly selected kanamycin-resistant M.tb colonies revealed a random distribution of the transposon insertions," says Dr. Jacobs, "suggesting that the mutants obtained in our experiments represent libraries of independent mutants of M.tb." In the same issue of PNAS, researchers from France's Pasteur Institute describe an alternative method for performing transposon mutagenesis in M.tb, which also results in the production of thousands of mutants. Dr. Jacobs also is a co-author of that study. "With these techniques, researchers theoretically should be able to create mutations in virtually every gene of Mycobacterium tuberculosis," adds Ann Ginsberg, M.D., Ph.D., NIAID's TB program officer. "This should provide an unprecedented opportunity to make rapid and substantial progress in the understanding of pathogenesis and development of novel therapeutics and vaccines for TB." In addition to Drs. Jacobs, Bloom and Hatfull, collaborators on the NIAID-funded study include Stoyan Bardarov, M.D., Ph.D., Jordan Kriakov, M.D., Ph.D., Christian Carriere, M.D., Ph.D., Shengwei Yu, and Carlos Vaamonde, M.D., of Albert Einstein College of Medicine; and Ruth A. McAdam, Ph.D., of the Central Veterinary Laboratory in Surrey, Great Britain. NIAID, a component of the National Institutes of Health (NIH), supports research on AIDS and other sexually transmitted diseases, tuberculosis and malaria, as well as allergies and asthma. NIH is an agency of the U.S. Department of Health and Human Services.
--------
336-> Notre Dame Paleontologist Finds Damage Done To T. Rex Skull
GLASGOW, Mont. -- The skull of what is believed to be the largest Tyrannosaur on record has been seriously damaged by poachers on the northeastern Montana cattle ranch where the fossilized dinosaur skeleton was found, according to University of Notre Dame paleontologist J. Keith Rigby. The damage was discovered today when Rigby and his field crew, including Notre Dame students, returned to the site and found that two-thirds of the left side of the skull was missing. Both of the lower jaws also were missing. The FBI in Great Falls took possession last Friday of two fossilized jaws that are believed to belong to the Tyrannosaur discovered by Rigby. The bones were turned over to the FBI by two unidentified people, according to news media reports. The federal Antiquity Act protects fossils on federal land. No arrests have been announced. "This is about as bad as I could have imagined," Rigby said today. "We had a virtually complete skull and now I'm wondering what I can do to repair the damage." Rigby and a crew of volunteers from the Earthwatch Institute discovered the skeleton this summer in a vast dinosaur graveyard near the Fort Peck Reservoir. The fossil, which was nearly complete, is either a Tyrannosaurus rex or something very much like it. Certain aspects of the anatomy are different than the 15 or so known skeletons of T. rex, according to Rigby, and it appears to exceed all measured skeletons of the dinosaur. "What we do know," he said, "is that this is the largest carnivore on the planet." Unable to complete the excavation this summer, Rigby and his assistants covered the site for the winter. However, former owners of the cattle ranch on which the fossils were found entered the site two weeks ago and began digging up the bones that remained in the ground. The ranchers contend they still own the land, although a title search indicates it now belongs to the U.S. Department of Agriculture's Farm Service Agency. Federal law enforcement officers descended on the site Sept. 14 and forced the former owners to vacate the premises. Situated in the picturesque badlands of eastern Montana, the site lies in the Hell Creek, a geological formation famous for preserving dinosaur bones. The bones date from the end of the Cretaceous period 66 million years ago. In the Late Cretaceous, the now bond-dry site appears to have been a river channel. When the dinosaurs died, their bones washed into the channel and collected together there. Sediments covered and preserved the bones until they were discovered in July by the Notre Dame/Earthwatch team. Judging from the position of both surface bones and the bones so far unearth, Rigby believes the bone bed might cover 15 acres, making it one of the largest dinosaur graveyards of the Late Cretaceous ever found.
--------
337-> Imaging Studies Illuminate Brain's Response To Cocaine
Using a state-of-the art imaging technique, researchers at the Massachusetts General Hospital (MGH) have shown, in greater detail than before, how specific areas of the human brain react to cocaine, distinguishing patterns of activation associated with feelings of euphoria and craving among addicts. Their report, appearing in the September issue of Neuron, reveals that a much broader range of brain structures is involved in the cocaine "rush" than previously suspected and that the role of brain areas long thought to be involved in making cocaine rewarding and addictive is more complex than previously believed. "This study gives us a detailed picture of cocaine's effects on brain circuits involved in both aspects of the reward system: reinforcement, which refers to an immediate positive or pleasurable reaction, and incentive, which in this context means motivation to repeat an activity,"says Hans Breiter, MD, a member of the MGH Radiology and Psychiatry Services and first author of the study. Much current understanding of how drugs like cocaine affect the brain has come from animal studies that correlated brain activity with observed behaviors, like pressing a lever to receive additional doses of drugs. But animals cannot report the kinds of subjective, emotional reactions humans experience and describe by terms such as "rush," "high," "low" and "craving." The current study supports previous animal observations of how the brain responds to cocaine and provides much greater detail regarding reactions of specific, tiny structures and how they relate to the feelings of the cocaine user. "Understanding how different circuits are activated during the different stages of drug use and withdrawal can help us design and monitor novel treatments," says Steven E. Hyman, MD, director of the National Institute of Mental Health. Previously a member of the MGH Psychiatry Service, Hyman also is senior author of the Neuron paper. In studying the reaction of the brain to cocaine, the reseachers used functional magnetic resonance imaging (fMRI), a technique largely developed at the MGH. Using fMRI, areas of increased brain activity, characterized by increased levels of oxygen in the blood, can be superimposed on detailed images of brain structures. Functional MRI scans were made of 10 volunteer participants - all of whom were carefully selected cocaine addicts - as they received cocaine injections and for 13 minutes following the injection. At 15-second intervals throughout the testing period - starting 5 minutes before the injection - participants reported the extent to which they experienced feelings of rush, high, low or craving. Results indicated that more than 90 areas of the brain showed increased activity in response to cocaine. Many areas associated with thought and emotion showed an immediate although brief response of increased activity, which was associated with reported feelings of "rush" and euphoria. Other areas showing an immediate response remained activated longer, extending into periods when participants reported feelings of craving. One of the most significant among these is the nucleus accumbens, believed to be associated with reward reinforcement. In addition, the area called the amygdala, also associated with the reward system, showed lower-than-normal activity, particularly during periods of reported craving. The results suggest, the researchers believe, that while there are distinct areas involved in the various experiences of cocaine use, it is not simply a matter of turning certain structures on to produce a particular response. Instead the patterns of which areas are activated in what sequence and for how long seem to determine the feelings generated, particularly in the case of craving. "Our observations regarding the nucleus accumbens were probably the most unexpected," says Breiter. "That area has been thought to be involved in reinforcement, so we expected it would be activated as part of the pleasurable rush/high experience. But its continuing high level of activation into the craving phase suggests that it also plays a role in incentive, the motivation leading to a change in behavior, which is key to the development of addiction." Alan Leshner, PhD, director of the National Institute on Drug Abuse, a primary funder of this research, says, "These studies suggest specific brain areas that might be targeted in developing new medications to either block individual aspects of cocaine's effects - like the rush versus the craving experience - or as broader treatments for cocaine abuse and addiction." Additional funding for this study was provided by the National Heart, Lung, and Blood Institute and the National Alliance for Research on Schizophrenia and Depression.
--------
338-> Will Your Child Become An Overweight Adult? Step On The Scale
Doctors frequently encounter overweight children in their medical practices. But without hard data to help predict whether a particular child will remain overweight, it's difficult for doctors to know whether they should label a child as overweight and intervene with advice on nutrition and activity. Now, intuition has been bolstered by numbers from a study in last week's New England Journal of Medicine. The research shows a child's chance of obesity in adulthood is greatly increased if he or she has at least one obese parent. The study examined the health records of more than 800 young adults aged 23-29, taking their height and weight measurements starting at birth. Height and weight measurements were also taken from their parents' medical records. All were members of Group Health Cooperative of Puget Sound, a large Seattle-based health maintenance organization. "This study quantifies the conventional wisdom that obesity is a familial trait," said Dr. Robert C. Whitaker, who led the study while on the University of Washington School of Medicine faculty and who is now an assistant professor of pediatrics at Children's Hospital Medical Center in Cincinnati. "It is well-known that being obese as a child increases the risk of becoming an obese adult, but our study shows that having an obese parent dramatically increases that risk." "There's also a flip side to these results," said co-author Dr. Jeffrey A. Wright, UW associate professor of pediatrics and chief of the General Pediatric Service at Children's Hospital and Medical Center in Seattle. "Children who are overweight in the first three years of life but have normal-weight parents aren't likely to become obese adults. We shouldn't label them as being at risk." For a child under age 10 -- whether obese or not -- having an obese parent more than doubled the risk of being obese as an adult: an obese 3- to 5-year-old with normal-weight parents had about a 25 percent chance of being obese as an adult; a similar child with an obese parent had more than a 60 percent chance of being an obese adult. The researchers found that obese and non-obese children under age 3 have almost equally low chances (about 1 in 10) of becoming obese adults if they have normal-weight parents. However, if a parent is obese, the risk of being obese as an adult almost triples for the non-obese toddler, and quadruples for the obese one. "Early childhood is probably a critical time for intervening," said Wright. "You have to treat the whole family. You can't treat the child out of the family context." By the time children reach their teens, the likelihood of obesity is less dependent on the parents' weight status. The normal-weight 15- to 17-year-old with normal-weight parents has only a 5 percent chance of being obese 10 years later, and this chance increases to only 14 percent if a parent is obese. Obese teens have a better than 50 percent chance of becoming obese adults, even if neither parent is obese. The chances increase to 70 to 80 percent if a parent is obese. The study did not address the question of whether nature or nurture causes obesity. "The risk is transmitted from parent to child by both the genes and the family environment, but whatever is passed on to the child is often expressed by adolescence," said Whitaker. "This study is not meant to suggest that the children of obese adults will inevitably grow into obese adults," he cautioned. "It suggests, instead, that early and ongoing efforts should be made with these children and their families to prevent obesity from ever developing." The researchers were conservative in their definition of obesity, using a body-mass index (BMI) of 27 as the threshold. By this standard, 16 percent of the young adults in the study were obese. BMI is calculated by dividing the weight in kilograms by the square of the height in meters. A 5-foot 6-inch woman weighing about 165 pounds has a BMI of 27, as does a 6-foot man of about 200 pounds. Health problems like diabetes and high blood pressure become more common at a BMI of 27 and above. The long-term Group Health members in this study came largely from white, well-educated families. "From this study, we can't draw conclusions about other groups," Whitaker said. "However, we found that when the young adults in this study were teens, 30 percent of their middle-aged parents were obese. This is consistent with current rates of adult obesity in the United States." In addition to Wright, co-authors are Dr. Margaret S. Pepe and Kristy D. Seidel of the Fred Hutchinson Cancer Research Center and Dr. William H. Dietz of the New England Medical Center. The research was supported by a Robert Wood Johnson Foundation Generalist Physician Faculty Scholars Award to Whitaker and a grant to Dietz from the National Institutes of Health.
--------
339-> Shuttle-Mir Mission -- Measuring A Microverse With A Universal Yardstick
A device that helped show how the universe is put together is being pressed into service to help us understand how molecules assemble themselves into crystals. Lessons from the Interferometer Protein Crystal Growth (IPCG) apparatus, carried to Russia's Mir space station by the U.S. space shuttle Atlantis last week, will help scientists determine the best ways to grow protein crystals to fight disease. While scientists have been growing protein crystals in space since the mid-1980s, and great progress has been made in understanding the makeup of many crystals, their knowledge of how crystal growth works has serious gaps. "Ultimately, what everybody wants to know is how and why," explained William Witherow, an IPCG co-investigator at Marshall Space Flight Center; Dr. Marc Pusey of Marshall also is a co-investigator. The principal investigator is Dr. Alex McPherson of the University of California at Riverside. "A lot of the research effort to date is going into the shotgun approach." Analyzing crystals of proteins is the best way to understand their structure. From this, scientists can determine how bacteria, viruses, and our own bodies work, and how best to design drugs to cure disease. Space often proves to be the best place to grow protein crystals without the defects that often affect crystals grown on Earth. Scientists usually devise experiments involving different initial mixtures designed to promote crystal growth. With experience, they learned which blends work best - but not always why they work best. "All they got back are the protein crystals themselves," Witherow said, "but the investigators still don't know how the crystals grew or why." The IPCG experiment will look at that how and why. Crystals grow as molecules move through a fluid, bump into one another, and latch into position to build a repeating pattern, like a child's building blocks. The process involves diffusion as molecules migrate from an area of high concentration to an area of low concentration (the depleted area just next to the crystal). Many factors influence the growth rate, including contaminants (which may move faster - or slower - than the proteins you want to grow), how much salt is in the solution (salt collects water and raises the protein concentration to force crystallization), the acid-base balance (pH), temperature, and so on. These also affect the liquid's density and thus its index of refraction, how it will bend light. This is where Michelson is brought back into service. In the mid-1880s, Michelson and Edward Morley were trying to prove that light was carried through the universe by a mysterious substance called "the luminiferous ether" (nothing to do with laughing gas). They reasoned that if this was true, then light would be slowed as it traveled "upwind," while light traveling "crosswind" would not be affected. (The "wind-speed" would be due to the Earth's motion around the Sun and through space). Michelson developed an interferometer, a device which splits a beam of light, sends it in two different directions, then recombines the two beams. If the light has been changed in any way, the beam will paint a series of light circles where peaks combine with peaks to make the light more intense, and dark circles where peaks combine with valleys to zero the light out. Michelson and Morley wound up proving that the luminiferous ether does not exist (and Michelson won the Nobel Prize in physics in 1907). Meanwhile, they had invented an exceptionally powerful tool that could also be used to measure effects on scales much smaller than the cosmos. In the IPCG, it is combined with tools that Michelson could not have envisioned. The heart of the device is a Michelson interferometer comprising a beam-splitter prism to split, then recombine the light beams, a laser as the light source, and a microscope to enlarge the view. The target is a wafer-thin crystal growth chamber about the size and shape of a throat lozenge. It will be filled with a solution of lysozyme, a common protein found in eggs. "They use it as a benchmark because it's so well known and characterized," Witherow said. The backside of the cell is silvered to serve as one mirror in the interferometer. The other leg is a reference mirror. Light is split, directed onto the two mirrors and back again, recombined, enlarged by a 20-power microscope, and projected onto a video camera. The interference fringes will be enhanced by a liquid crystal phase modulator and a polarizing filter. A laptop computer will record about 4,050 images for study on Earth after the mission. Part of the challenge of designing the system was fitting it all into a box about the size of an overhead bin on an airplane (the approximate size of the Shuttle middeck locker) for use inside the glovebox in Mir's Priroda science module. Six fluid systems will be carried, each with different blends of lysozyme and other chemicals. The system is scheduled to return to Earth on STS-89 in early 1998.
--------
340-> Nutrients, Ground Water, And The Chesapeake Bay -- A Link With Pfiesteria?
Scientists from the U.S. Geological Survey (USGS) and other federal and state agencies involved in Chesapeake Bay studies are working together to understand the delivery of nutrients from the land into the Bay and the relationship of nutrients to Pfiesteria-like organisms and ultimately fish health. Scientists suspect a link between high nutrient levels in water and the occurrence of algal blooms and the occurrence of Pfiesteria-like organisms. Nutrients enter the waters of the Chesapeake Bay from ‘point' and ‘non-point' sources. Point sources of nutrients (phosphorus and nitrogen)are from wastewater treatment plants or industrial locations. Non-point sources of nutrients are more difficult to identify; they originate from agricultural, urban, suburban, or atmospheric sources. Nutrients enter the Chesapeake Bay from water that is washed off the land surface, chiefly in the aftermath of storms. Nutrients also seep into the ground water from the land surface and make their way into the rivers and streams that flow into the Bay, or directly into the Bay itself. Ground water is an important source of surface water and nutrients. The USGS has determined that about 50 percent of the water in streams comes from ground water, but the amount can be as low as 27 percent or as high as 85 percent. The amount of ground water varies according to the type of rock and sediment beneath the land surface. Up to one-half of the nitrogen entering the Bay travels through ground water. It is possible that about 10 to 20 percent of the phosphorus entering the Chesapeake Bay also travels through ground water. (A key factor in understanding Chesapeake Bay nutrients is that half of the Bay's water comes from freshwater sources and the other half comes from the ocean.) Travel time of the ground water can be as short as one year or as long as 60 years. The average travel time is between 10 and 20 years. For this reason alone, nutrient levels in the Bay and any connection with fish health will continue to be a source of concern well into the future. For more information on the Chesapeake Bay and fish lesions, check the following World Wide Web pages on the Internet: http://chesapeake.usgs.gov/chesbay and http://www.usgs.gov
--------
341-> 'Radar Flashlight' Would Help Police Or Corrections Personnel Detect Human Presence Through Walls & Doors
A prototype RADAR flashlight that can detect a human's presence through walls and doors could one day be used by police officers, prison guards and others to make their jobs safer. The device, for which a patent application has been filed, uses a radar and a specialized signal processor to detect movement. The RADAR flashlight discerns respiration from up to three meters away, with no physical connection between subject and radar. photo copyright information Part of a Family of Technologies The development is part of a family of technologies that also detects heartbeat, explained Gene Greneker, a principal research scientist at the Georgia Tech Research Institute (GTRI). "Based on respiration signature alone, the RADAR flashlight allows us to detect a stationary individual behind a solid wooden door, or standing four feet behind an eight-inch block wall," said Greneker. "These qualities make the flashlight potentially useful to police officers in ambush situations, and to prison guards doing bed checks." The Georgia Tech-funded project uses a rather narrow radar beam of about 15 to 20 degrees to detect body movement generated by breathing. Additional potential applications include: Locating people in a room during a hostage situation, based on their movement or radar respiration signature; immobilized people could be located via respiration signature alone. Finding survivors in the rubble of earthquakes or accidents. The amount of electromagnetic radiation exposure from the flashlight is very small -- 10 times less than the voluntary exposure leakage level for microwave ovens in the United States. That's about the same amount of exposure a person receives when walking under a microwave door opener, the box over an automatic door that senses your presence and opens the door for you. For now, the signal processor is outside the flashlight-sized casing, and the respiration signature is displayed on a monitor driven by a computer-based radar signal processor. Greneker plans to make everything small enough to fit inside the flashlight housing by incorporating high-speed signal processing technology. The RADAR flashlight has some advantages over other technologies. "The signal from the RADAR flashlight will penetrate clothes and detect respiration through a heavy jacket," Greneker explained. "In fact, the RADAR flashlight requires a body movement of only a few millimeters to detect human presence." Flashlight Has Origins in Battlefield Device Research that evolved into the RADAR flashlight began in the mid-1980s, with the patenting of a frequency modulated radar for remotely checking vital signs of battlefield wounded before risking medics' lives. This early technology also was tested for its ability to monitor vital signs of soldiers clothed in chemical or biological warfare suits, without requiring them to risk contamination by removing the protective gear. Most recently, Greneker developed a prototype vital signs monitor in hopes of displaying the heartbeats of archers and rifle competitors during television coverage of the 1996 Centennial Olympic Games. Such athletes are believed to sense their heartbeats and shoot between them to avoid the slight body movement -- and potential shooting inaccuracy -- created by each pulse. This application ascertains heartbeat signals 30 meters from the subject. The heartbeat channel is processed by a signal processor to remove the signal created by respiration. The system also includes a sensitive, charge-coupled device camera that allows the operator to view the area on the subject's thorax that is monitored by the radar. The heartbeat monitor was never used for the Olympics, in part because the archery and rifle competitions were not broadcast during prime time television viewing hours. Technology May Have Other Applications The technology's potential to monitor heartbeat raises some interesting possibilities, Greneker notes. "This version of the system might be used as a biometric identification tool," he said. "For example, if it could be shown that an individual's radar heartbeat signature is stable over long periods of time and is unique to an individual, the remotely sensed heartbeat could serve as a 'fingerprint' of sorts." Challenge is to Reduce Clutter Greneker also wants to explore ways to even further reduce clutter -- undesired and uncontrolled signals originating from something other than the target. Clutter may be many times stronger than the desired target's signal, requiring radar signal processing to reduce or eliminate it. "This is a challenge," he noted. "The amount of signal returned from the chest area of a moving person due to body motion alone is approximately 1,000 to 10,000 times the heartbeat signature. We are working on clutter suppression algorithms to use in the RADAR flashlight's signal processor circuit." Greneker has presented papers on the heartbeat monitor developed for potential Olympics use at several national and international conferences over the past year. GTRI is now seeking a partner to help commercialize this family of technologies.
--------
342-> Research Indicates Earth's Moon May Have Formed In Year Or Less
New computer simulations by a team of scientists working at the University of Colorado at Boulder indicate a disk of debris orbiting Earth early in its history may have taken less than a year to coalesce into the moon we see today. The researchers modeled a variety of conditions leading to the formation of the moon based on the widely held scientific assumption that a rogue "protoplanet" sideswiped Earth 4.5 billion years ago, vaporizing much of its crust and mantle into a swirling disk around the planet. The so-called "giant impactor theory" was first proposed in the 1970s following extensive research by NASA Apollo scientists. Although "giant impactor" models created by a Harvard University group in the 1980s and early 1990s indicated the protoplanet was about the size of Mars, research presented at a July 1997 planetary science meeting in Cambridge, Mass., by CU-Boulder research associate Robin Canup indicated the object must have been at least three times more massive than Mars to create enough debris to form our moon. The newest modeling results, which estimate the year-long time frame for the moon's formation, were published in the Sept. 25 issue of Nature. Calculations by the research team also indicate less than half the orbiting debris coalesced into the moon, while the rest eventually fell back to Earth. The Nature paper was authored by Shigeru Ida of the Tokyo Institute of Technology and research associates Robin Canup and Glen Stewart of CU-Boulder's Laboratory for Atmospheric and Space Physics. Ida spent the 1996-97 academic year on sabbatical at CU collaborating with Canup and Stewart on the project. A "ballpark figure" for the cooling of material blown off Earth by the violent collision with the impactor and its accretion into swarms of large, orbiting debris particles is thought to be somewhere between one and 100 years, speculated Canup. At this point in the process the team began modeling a variety of scenarios that may have taken place, including the numbers of large debris particles in orbit and their distances from Earth. Twenty-seven different computer models produced by the team varied the number of particles from 1,000 to 2,700 and assumed sizes of up to 60 miles across for some of the larger debris particles, said Canup. In each of the simulations, the particles invariably clumped together to form the moon in a year or less, always at a distance roughly 14,000 miles from Earth, she said. This is the equivalent to about 3.5 to 4 Earth radiuses from the planet. In the outer regions of the disk, the debris particles apparently clumped together quite easily, she said. But in the inner regions of the disk "they probably bounced off each other" due to the effects of Earth's gravity. The reason the particles in the inner portion of the disk failed to coalesce is due to their proximity to the "Roche limit," said Canup. The Roche limit is the distance from any planet or star inside of which tidal forces from the object pull orbiting particles apart rather than allowing gravity to hold them together. For Earth, the Roche limit is about three Earth radiuses from the planet. "That's why the moon always forms just outside that region in our models," she said. "Once the particles in the outer disk accreted to form the moon, its gravitational forces likely scattered the inner disk material back onto Earth," said Canup. In each of the computer simulations, only about 15 percent to 40 percent of the material from the initial debris disk wound up being incorporated into the moon. "This was a result we did not anticipate," Canup said. The researchers calculated the debris particles were orbiting Earth every nine to 10 hours, and that it would have required about 1,000 orbits -- the equivalent of about one year -- for the large particles to coalesce into our single moon. Interestingly, about one-third of the simulations formed two similarly-sized moons rather than one larger moon. "If this were the case, a two-moon system may have persisted for some time," she said. "That would have been quite a sight."
--------
343-> Mars Pathfinder Rover Exits Rock Garden To Begin Long Trek
After 83 days of atmospheric, soil and rock studies, NASA's Mars Pathfinder is moving into extended mission activities that will take the rover on its longest trek yet, while the lander camera completes its biggest and best landscape panorama. "The lander and rover performance continues to be nothing short of extraordinary," said Brian Muirhead, Mars Pathfinder project manager at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA.  "We have proven that we know how to design robust robots to operate in the hostile environment of Mars." The rover has just completed its last alpha proton X-ray spectrometer study for a while, taking compositional measurements of a rock nicknamed Chimp, located just behind and to the left of an area scientists call the Rock Garden.  Once data from the spectrometer have been retrieved, Sojourner will begin a 164-foot (50-meter) clockwise stroll around the lander to perform a series of technology experiments and hazard avoidance exercises. Meanwhile, the Pathfinder lander camera is continuing to image the Martian landscape in full-resolution color as part of its goal to provide a "super panorama" image of the Ares Vallis landing site.  Each frame of this panorama is imaged using 12 color filters plus stereo. "The super pan will be our biggest and best imaging data product," Muirhead said. "It is made up of 1 gigabit (1 billion bits) of data, of which we've received more than 80 percent. Given our limited downlink opportunities, we should have the full image by the end of October." The 22-pound (10.5-kilogram) rover has survived 10 times longer than its primary mission design of seven days, while the lander has now been operating 2.5 times longer than it was originally expected to operate, according to Richard Cook, Mars Pathfinder mission manager. Both vehicles are solar-powered, but carried batteries to conduct night-time science experiments and keep the lander warm during the sub-freezing nights on Mars. Normal usage has fully depleted the rover's non-rechargeable batteries, limiting it to daylight activities only.  The lander battery, which packed more than 40 amp-hours of energy on landing day, performed perfectly during the 30-day primary mission, but is now down to less than 30 percent of its original capacity. "We expected to begin seeing this type of degradation on both vehicles and, of course, designed both the lander and rover to operate without batteries altogether," Cook said.  "If everything else continues to operate properly, we could continue conducting surface experiments for months." About once every two weeks, the lander battery is used to perform some night-time science experiments, he added.  The primary activity is acquiring meteorological data and images of morning clouds, as well as images of Mars' two small moons, Phobos and Deimos. Despite the lack of battery power, the rover has continued taking successful spectrometer readings during the day.  In the next two weeks, engineers will drive the vehicle back to a magnetic target on the ramp from which Sojourner first touched Martian soil. "This analysis of the dust on the ramp magnet is a very important science measurement," noted Dr. Matthew Golombek, Mars Pathfinder project scientist. "The results should give us a clue about how all this magnetic dust was formed." Recent images and movies from Mars Pathfinder activities continue to be posted to the Internet at the following URL: http://marsweb.jpl.nasa.gov The next media briefing  on science results from Mars Pathfinder is tentatively scheduled for Wednesday, October 8, at 1 p.m. ET at JPL. The Mars Pathfinder mission is managed by the JPL for NASAÕs Office of Space Science, Washington, DC.  The mission is the second in the Discovery Program of fast track, low-cost spacecraft with highly focused science goals. JPL is a division of the California Institute of Technology, Pasadena, CA.
--------
344-> Report Notes Difficulties In Eliminating E. Coli O157:H7 From Food Supply
CHICAGO-The unusual and hardy characteristics of the pathogen Escherichia coli O157:H7 "have prompted food microbiologists to rewrite the rule book on food safety," according to the Institute of Food Technologists' (IFT's) October 1997 Scientific Status Summary "Foodborne Disease Significance of Escherichia coli O157:H7 and Other Enterohemorrhagic E. coli." "E. coli O157:H7 is more significant than other well-recognized foodborne pathogens for reasons including the severe consequences of infection that affect all age groups, its low infectious dose, its unusual acid tolerance, and its apparent special but inexplicable association with ruminants [cattle, deer, and sheep] that are used for food," wrote Robert L. Buchanan, Ph.D., and Michael P. Doyle, Ph.D., the document's authors. Less than ten E. coli O157:H7 cells may cause foodborne illness in people. Infectious doses associated with this pathogen in outbreaks have been consistently low?a characteristic associated with the organism's acid tolerance, according to Buchanan and Doyle. Unlike most other pathogens, E. coli O157:H7 has been known to survive for several weeks to months in acidic foods such as fermented sausage and apple cider, and experimentally, in foods like mayonnaise and cheddar cheese. The survival time in these foods is greatly extended at refrigeration temperatures (32 F-40 F) as opposed to room temperature. Recent studies have also indicated that acid tolerance may increase the pathogen's resistance to other stresses such as heat, radiation, and antimicrobials. "[E. coli O157:H7's] low infectious dose in combination with the disease severity means that successful prevention strategies must focus on reducing or eliminating the presence of the microorganism, rather than on preventing pathogen growth as is done in more traditional approaches," Buchanan and Doyle wrote. The Hazard Analysis and Critical Control Point (HACCP) system can reduce the risk of E. coli O157:H7 infections, but it is not infallible, especially due to the pathogen's nature. "For example, the low incidence of E. coli O157:H7 in foods makes direct microbiological testing for the pathogen as a means of verifying the effectiveness of a HACCP program of limited benefit," Doyle and Buchanan wrote. "Most desirable is a process that includes a step lethal to the pathogen." Current effective lethal steps include heat pasteurization for milk and juices and ionizing radiation for meat (if approved) and fresh fruits and vegetables. Ionizing radiation is a promising technology because it can eliminate E. coli O157:H7 while maintaining the raw character of foods. Though approved for use with poultry, pork, and fresh produce in the United States to control various pathogens, this technology is extremely underutilized. Approval for its use with beef and seafood is pending. The use of steam to briefly heat carcass surfaces to temperatures that will kill E. coli O157:H7 without cooking the meat is a new, promising food safety method. Steam pasteurization has been reported to achieve up to a 1000-fold reduction of E. coli O157:H7 on treated carcasses. Beyond these processing measures, the only way to eliminate E. coli O157:H7 is by cooking ground beef and venison to at least 160 F at home and in foodservice kitchens. Unpasteurized juices, if consumed at all, should be also heated to 160 F. Growers of produce should not fertilize plants with fresh manure. In an editorial accompanying IFT's Scientific Status Summary, I. Kaye Wachsmuth, Ph.D., wrote, "The tradition of recycling manure for vegetable gardening has caused E. coli O157:H7 illness; the pathogen can survive longer than the traditional 60-day holding period." Though potentially deadly to humans, E. coli O157:H7 is not pathogenic to cattle. Despite this, the bacteria have the ability to persist in and reinfect cattle, even those that have a strong immune response to it, Buchanan and Doyle wrote. Results of two major U.S. surveys indicated that about 3 percent of dairy calves and 2 percent of feedlot cattle had E. coli O157:H7. Young animals tend to carry the pathogen more frequently than adults. Though ground beef has been most often associated with E. coli O157:H7 outbreaks in the United States, other implicated foods include raw milk, apple cider, dry-cured salami, lettuce, produce from manure-fertilized gardens, potatoes, radish and alfalfa sprouts, yogurt, sandwiches, and water.
--------
345-> New Mechanism To Explain Carbon Monoxide Poisoning Identified
Researchers at the University of Pennsylvania Medical Center have discovered a novel biochemical mechanism for carbon monoxide (CO) poisoning that may someday lead to new clinical approaches for dealing with exposure to this deadly gas. The scientists report their findings, which challenge the textbook definition of CO toxicity, in the September issue of Chemical Research in Toxicology. Each year, carbon monoxide leads the list of causes of poison-related deaths in the United States. Thousands of people die annually from accidentally inhaling the tasteless and odorless gas. Major exposures to deadly levels of CO are associated with house fires and faulty furnaces and water heaters. However, CO is ubiquitous: Auto emissions and tobacco smoke account for much of the low-level exposures to which people are bombarded everyday. The physiological consequences of these sustained levels of CO exposure are virtually unknown. The classic explanation for CO's poisonous action is that it binds to hemoglobin molecules in the blood, impairing oxygen delivery to the body's cells. Eventually cells essentially suffocate and die. "This traditional view explains the mechanism of carbon-monoxide toxicity in only a small fraction of all people exposed to it," says senior author Stephen R. Thom, MD, PhD, Associate Professor of Emergency Medicine, and chief of hyperbaric medicine at Penn's Institute for Environmental Medicine. "The vast number of patients we see clearly don't fit this traditional explanation. Science falls down in terms of what we see in day-to-day practice." Interaction of Deadly Gases Now, Thom and Penn colleagues Harry Ischiropoulos, PhD, Research Assistant Professor of Biochemistry and Biophysics, and Y. Anne Xu, Research Specialist in Environmental Medicine, have identified a mechanism that provides an alternate explanation for CO toxicity. "We found that carbon dioxide binds to the same sites on heme proteins as nitric oxide," notes Thom. Nitric oxide (NO) is a much-studied, naturally occurring vasodilator and gaseous signaling molecule. An excess of NO, however, is deleterious to brain cells and other tissues. "The amount of nitric oxide in the cell interior rises because carbon monoxide usurps the spot of nitric oxide on the heme proteins," says Thom. This imbalance makes NO available for biochemical reactions that would not normally occur within the cell, namely ones that produce tissue-damaging oxidants and free radicals. The team's experiments showed more NO being released by cells with exposure to greater and greater concentrations of CO. The cells eventually died. "This is the first time this mechanism of carbon- monoxide toxicity has been demonstrated," states Thom. Everyday Exposures In earlier studies, Thom found that blood vessels are a major site of damage in the brain due to CO exposure, especially the cells that line the inner wall of the vessels, called the endothelium. This damage occurs relatively early during exposure to CO. Thom argued that if damage occurs early on, it could also be happening with lower concentrations of CO over longer periods of time. "A lower dose of carbon monoxide showed a lower magnitude of cell death, but the important thing is that we still saw cell death," says Thom. He measured toxicity at levels lower than what typical smokers would have in their bodies and lower than in the air next to busy streets at rush hour. "The big picture is that we have identified a mechanism of how carbon monoxide can damage cells at levels that are relevant to real-world situations, and a mechanism that has nothing to do with classic hypoxia," Thom concludes. On a more practical side, he hopes that the study's findings will "convince the large number of physicians who tenaciously hold onto the classic explanation for carbon-monoxide toxicity that there is more than one way to explain this type of poisoning. Hopefully this will improve our general understanding of what's going on in patients, and with that a greater sensitivity to the need to be more aggressive about prevention and treatment of carbon-monoxide exposure." This study was supported by a grant from the National Institute of Environmental Health Sciences and a contract from the Health Effects Institute.
--------
346-> Existence Of "Less-Than-Whole" Electronic Charges Confirmed At The Weizmann Institute Of Science
REHOVOT, Israel - September 22, 1997 - Researchers at the Weizmann Institute of Science have provided the first unambiguous evidence that electrons can behave in an intriguing way that seems to defy common sense. An electron is a tiny particle that carries the smallest negative charge in nature. Yet a daring theory of physics developed 15 years ago argues that under certain conditions, an electric current behaves as if it were made up of fractions of electronic charges. In an experiment described in the September 11 issue of Nature, Weizmann Institute physicists measured fractional charges one-third that of an electron. "Mind-boggling as this may seem, this phenomenon is real," says study author Rafael de-Picciotto. "Of course, electrons don't split into fragments in an electric current, but under certain conditions it is indeed possible to measure a charge smaller than that of an electron." The research team that conducted this experiment included de-Picciotto, Dr. Mikhail Reznikov, Prof. Mordehai Heiblum, Dr. Vladimir Umansky, Gregori Bunin and Dr. Diana Mahalu. Intuition vs. Reality Ever since American physicist Robert Millikan first measured the charge of an electron 80 years ago, this value has been widely regarded as a basic unit of electric charge. Scientists have consequently come to view electrons that make up an electric current as a flow of negatively charged, indivisible "balls." A current made up of fractions of an electronic charge, therefore, would seem a counter-intuitive idea, just as it would be absurd to describe a crowd made up of "less-than-whole" people or street traffic made up of "less-than-whole" cars. However, if electrons are always regarded as "whole," it is extremely difficult to understand and describe their behavior under certain conditions. For example, some particular instances of this behavior, as in a phenomenon known as the fractional quantum Hall effect, observed in a strong magnetic field, remain unexplained. In 1982, physicist Robert Laughlin of the United States proposed a theory that explained this effect and provided a very simple way of describing highly complex interactions between electrons. However, this explanation came at a "cost": the theory made the bizarre assumption that an electric current can be made up of odd-denominator fractions of electronic charges - one-third, one-fifth, one-seventh, etc. - of an electron. In the new experiment, Weizmann Institute scientists designed a sophisticated system to measure such fractional electric charges, should they exist. The system makes it possible to measure so-called "shot noise." In day-to-day environment, this noise results from random variations in the number and velocity of electrons and causes popping sounds in radio receivers and snow effects in television pictures. Under special laboratory conditions, "shot noise" can be analyzed to reveal the make-up of the electric current. This is possible because the noise has "ripples" left by the flow of electrons in a conductor. The size of each "ripple" is proportional to the unit of electric charge: the smaller the ripple, the smaller the charge, and vice versa. The scientists passed an electric current through a semiconductor immersed in a high magnetic field, under conditions in which the fractional quantum Hall phenomenon is observed. They used sophisticated equipment to eliminate all extraneous sources of noise. The "shot noise" made by the current was then amplified and measured. It turned out to be made of charges one-third that of an electron. "This is a beautiful manifestation of the strength of the theoretical methods used to predict such a counter-intuitive phenomenon," says Prof. Heiblum. The scientists' next challenge is to create conditions for the emergence of even smaller charges, one-fifth of an electron, and to measure these charges. This will require even greater refinement of the system because these tiny charges make smaller ripples that are consequently more difficult to measure. This work was partly supported by the Israel Science Foundation and Austria's Ministry of Science, Research and Art. The scientists are members of the Weizmann Institute's Condensed Matter Physics Department. They conducted the research at the Institute's Joseph H. and Belle Braun Center for Submicron Research. The Weizmann Institute of Science is a major center of scientific research and graduate study located in Rehovot, Israel. Its 2,400 scientists, students and support staff are engaged in more than 850 research projects across the spectrum of contemporary science.
--------
347-> Testosterone Linked To Violence In Female Inmates
Higher testosterone levels are related to criminal violence and aggressive dominance among women in prison, says a Georgia State University study released Sept. 23. The study, published in the September-October issue of Psychosomatic Medicine, measured testosterone in 87 female inmates at a maximum security prison. Their criminal behavior was scored from court records, and their prison behavior was assessed from prison records and staff interviews. Testosterone was found related both to the violence of the women's crimes and to the aggressive dominance of their behavior in prison. This finding was further supported by assessing how an inmate's age corresponded to her behavior and testosterone levels. As the amount of the hormone measured decreased in older prisoners -- testosterone declines with age -- so did the aggressive dominance. But the study concluded that testosterone, not age alone, was the significant factor; older inmates who had high hormone levels were not less aggressive or dominant. "The key to this study is it shows testosterone is linked to dominance in both criminal behavior and behavior in prison," says Dr. James Dabbs, a professor of psychology at Georgia State University and lead researcher on the project. The findings, by Dabbs and Marian Hargrove, are similar to those in studies of male prisoners. This indicates testosterone's effects on behavior are the same in women as in men, says Dabbs. Testosterone levels were highest among male inmates convicted of violent crimes such as rape, homicide and assault. These men also violated more prison rules. An intriguing observation from the study on women was discovered when prison staff members were asked to describe the five inmates who were lowest in testosterone. The three staff members used phrases like "very manipulative" and "sneaky," but all agreed the word "treacherous" best described the women. This doesn't mean having low testosterone is trouble, says Dabbs. But in a specific population, such as prisoners, this type of negative, underhanded behavior might be expected from those who lack other elements of power such as the aggressive dominance seen in those with high testosterone, he says. The study's findings indicate testosterone plays an important role in the female criminal population, but variables such as age, social factors, and other hormones must also be considered, says Dabbs. The study was supported by grants from the National Institute of Mental Health and the National Science Foundation.
--------
348-> Hubble Gives Scientists Their First Direct Visible-Light Glimpse Of A Neutron Star Alone In Space
Astronomers using  NASA's Hubble Space Telescope have taken their first direct look, in visible light, at a lone neutron star. This offers a unique opportunity to pinpoint its size and to narrow theories about the composition and structure of this bizarre class of gravitationally collapsed, burned-out stars. By successfully characterizing the properties of an isolated neutron star, astrophysicists have an opportunity to better understand the transitions matter undergoes when subjected to the extraordinary pressures and temperature found in the intense gravitational field of a neutron star. The Hubble results show the star is very hot, and can be no largerthan 16.8 miles (28 kilometers) across. These results prove that the objectmust be a neutron star, for no other known type of object can be this hot and small. "This puts the neutron star uncomfortably close to the theoretical limit of how small a neutron star should be," says Fred Walter of the State University of New York (SUNY) at Stony Brook. "With this observation we can begin to rule out some of the many models of the internal structure of neutron stars."  The observation results, made by Walter and Lynn Matthews (also of SUNY), are reported in the Sept. 25 issue of Nature magazine. Neutron stars, which are created in some supernovae, are so dense because the electrons and protons that form normal matter have been squeezed into neutrons and other exotic subatomic particles. Neutron star matter is the densest form of matter known to exist. (Theoretically, a piece of neutron star surface weighing as much as a fleet of battleships would be small enough to be held in the  palm of your hand.) The Hubble observations, combined with earlier data, promise to help astronomers refine the mathematical description -- called the equation of state -- of  the complex transformations matter undergoes at extraordinary densities not found on Earth.   Equations of state are well understood for "everyday" matter such as water, which can transition between gaseous, liquid and solid states.  But the behavior of matter under extreme temperature and pressure found on a neutron star is not well understood. Several hundred million neutron stars should exist in our galaxy.  However, all neutron stars now known have either been found orbiting other stars in X-ray binary systems or emitting machine-gun blasts of radio energy as pulsars (a class of neutron star).  The neutron star seen by Hubble is not a member of a binary system, and is not known to pulse at X-ray or radio wavelengths (it has not been detected as a radio source). Pulsars are young neutron stars born with strong magnetic fields; non-pulsing neutron stars may be old, dead pulsars, with ages of more than a million years, or they may never have been pulsars. Only a few lone neutron star candidates have been pinpointed through X-ray observations, and this is the first optical counterpart to be identified. The first clue that there was a neutron star at this location came in 1992, when the ROSAT (the Roentgen Satellite) found a bright X-ray source without any optical counterpart in optical sky surveys.  It drew the attention of astronomers because objects this hot and bright, without counterparts at other wavelengths, are extremely rare. Hubble's Wide Field Planetary Camera 2 was used in October 1996 to undertake a sensitive search for the optical object, and found a stellar pinpoint of light within only 2 arc seconds (1/900th the diameter of the Moon) of the X-ray position. Astronomers haven't directly measured the neutron star's distance but fortunately the neutron star lies in front of a molecular cloud known to be about 400 light-years away in the southern constellation Coronae Australis. Using the distance to the cloud as an upper limit, the astronomers calculated a diameter by next comparing the neutron star's brightness and color as measured by Hubble, along with X-ray brightness from the ROSAT and EUVE (Extreme Ultraviolet Explorer) satellites. The object is brightest at X-ray wavelengths.  In the two Hubble images, the object is brighter at ultraviolet wavelengths than at visible wavelengths. They concluded they are directly seeing an ultracompact surface sizzling at about 1.2 million degrees Fahrenheit. To be so hot, yet so dim (below 25th magnitude in visual light) and relatively close to Earth, the object must be extremely small -- below the size of a white dwarf, a more common stellar cinder. A hot white dwarf at this magnitude would lie 150,000 light-years away (outside our galaxy), and have 1/70,000 as much X-ray emission. The 16.8-mile diameter estimate comes from assuming the neutron star is at the farthest it can be, just in front of the obscuring "wall" of the molecular cloud. If instead the neutron star is significantly closer to us,  say midway to the molecular cloud, it would be smaller still, and present an even bigger challenge to the theories of the equation of state of nuclear matter. Although neutron stars in binary systems allow astronomers to measure their mass, which turn out to be consistent with theory, it's much harder for astronomers to estimate the diameter of the neutron stars.  Since the neutron stars "feed" on their companion stars in these systems, the light does not come exclusively from the surface but from jets, disks and other phenomenon that occur around the star.  This can lead to inaccurate size estimates. Over the next year, planned observation with the Hubble will be used in an attempt to determine exactly how far away and how large the star is. - end - A photo and caption are available via the World Wide Web at URLs: http://oposite.stsci.edu/pubinfo/PR/97/32.html and via links in http://oposite.stsci.edu/pubinfo/Latest.html or http://oposite.stsci.edu/pubinfo/Pictures.html.  Images are available via the World Wide Web at http://oposite.stsci.edu/pubinfo/gif/nscra.gif (GIF), http://oposite.stsci.edu/pubinfo/jpeg/nscra.jpg (JPEG). Image files also may be accessed via anonymous ftp from oposite.stsci.edu in /pubinfo:  gif/nscra.gif (GIF) and jpeg/nscra.jpg (JPEG).  Higher resolution digital versions (300 dpi JPEG) of the release photograph are available in /pubinfo/hrtemp: 97-32.jpg (color) and 97-32bw.jpg (black & white).  Full resolution TIFF image is available in /pubinfo/tiff/1997/32.tif.
--------
349-> Smoking Mice Lead To Emphysema Breakthrough
St. Louis, Sept. 26, 1997 -- With the help of some heavy-smoking mice, researchers at Washington University School of Medicine in St. Louis have discovered that lungs lacking a certain enzyme are apparently immune to emphysema. The discovery, described in the Sept. 26, 1997, issue of Science, throws serious doubt on conventional theories of the disease, and researchers are already using the finding to search for potential new drugs. Steven D. Shapiro, M.D., associate professor of medicine and of cell biology and physiology at the School of Medicine, and colleagues found that mice genetically engineered to lack an enzyme called macrophage elastase showed no signs of emphysema even after inhaling the smoke of two unfiltered cigarettes a day, six days a week for six months. Such heavy smoking invariably causes emphysema-like symptoms in normal mice. "There hasn't been a new drug for emphysema in 20 years, and that was oxygen," Shapiro says. "Blocking this enzyme or related enzymes might give us a way to halt the disease." Emphysema, almost always caused by smoking, robs lungs of their elasticity and leaves patients gasping for air. The lungs actually become overinflated, leaving no room for deep breaths. About 2 million Americans suffer from the disease. Before this study, most researchers assumed that emphysema was caused by neutrophils, white blood cells that destroy foreign invaders and, occasionally, cause inflammation. According to the most widely-accepted scenario, neutrophils mount a counter-attack against smoke by congregating in the lungs and releasing inflammatory enzymes. The enzymes eventually break down elastic fibers in the lungs, causing a new case of emphysema. But the prevailing theory had a shortcoming: lungs with emphysema don't have many neutrophils. Instead, they are full of macrophages, immune-system cells that eat bacteria and other intruders. Few thought macrophages played a role in emphysema because the cells seemed incapable of destroying sturdy lung tissue. But recent experiments by Shapiro and others showed that macrophages did indeed produce an enzyme -- macrophage elastase -- that could be up to the task. To find out if macrophage elastase causes emphysema, Shapiro and others created a strain of mice that lacked the enzyme. He calls them "mighty mice" and estimates their value at tens of thousands of dollars apiece. "We could speculate for years about the function of this enzyme," he says. "These mice helped us pin it down." Researchers put both the mighty mice and normal mice into smoking chambers twice a day, six days a week. The mice didn't actually have cigarettes in their mouths, but they got enough passive smoke to become quite fond of their routine. "After a while, they just started running into the chambers," Shapiro says. "They loved it." To Shapiro's knowledge, his is the first smoking chamber ever designed for mice. Six months later, all of the normal mice had inflamed, over-inflated lungs ? the hallmarks of emphysema. The mighty mice, however, appeared completely healthy. "This enzyme clearly plays a primary role in the development of the disease in mice and probably in humans," Shapiro says. Macrophage elastase is a member of a family of enzymes that is currently attracting intense scientific interest. Many researchers believe that members of this family, called metalloproteinases, play a major role in a host of disorders including tooth decay, atherosclerosis, arthritis ? and, now, emphysema. Pharmaceutical companies are now trying to develop metalloproteinase inhibitors that may be able to effectively prevent many of these disorders. Shapiro is currently determining whether a metalloproteinase inhibitor can block emphysema in normal, heavy-smoking mice. Shapiro notes that a drug that blocks macrophage elastase would, at best, only prevent damage caused by emphysema. Such a drug could not repair already-damaged lungs. There is still no "cure" for emphysema on the horizon, and the best way to avoid the disease is to not smoke, he says. One important question remains largely unanswered: What are metalloproteinases good for? They apparently help remodel tissues during growth and wound healing, but their role in healthy adults is unclear, Shapiro says. "Before we give people drugs to block these enzymes, we really need to know what the enzymes do," he explains. Other strains of "mighty mice" will undoubtedly be the stars of future experiments to answer these questions, he says. 
--------
350-> Searching For Pharmaceutical Proteins, Insect Researchers Just Say 'Grow'
ITHACA, N.Y. -- They go from bugs to drugs.  Thanks to the confluence of anew technology in virology and a recent patent in rearing insects,scientists at the Boyce Thompson Institute for Plant Research Inc. (BTI),located at Cornell University, have found a better way to producecommercial quantities of recombinant pharmaceutical proteins -- out ofinsect larvae. "These are valuable proteins, and they can't be produced this well anyother way," said H. Alan Wood, a virologist at BTI.  "Essentially, this isa protein factory.  We are using insects to raise raw pharmaceuticalproteins.  In effect, we are turning insects into little protein factories." Originally, the researchers were exploring ways to safely combatagricultural pests through biological means, but in their research theylearned that the proteins from these nearly dead pests could directlybenefit humanity.  Recombinant baculoviruses have been used before todevelop a panorama of pharmaceutical proteins but were made using theinsect cell culture method, a time-consuming, and expensive  process. Scientists can harvest the beneficial protein from the infected larvae oflepidoptera -- moths and caterpillars.  Genetically engineeredbaculoviruses, which are viruses shaped like rods, attack the inside of thelarvae, initiate a wholesale, metabolic change and kill the insect. "The baculovirus literally turns the insect to liquid," said Patrick R.Hughes, BTI researcher. "Right before the insect dies, we harvest theprotein, and the protein can be refined into pharmaceuticals." The virus spreads through the caterpillar within 24 hours, but the bugcontinues to grow, spreading virus through the caterpillar's body for threedays.  Just prior to the fourth day, or the fifth larval stage, theproteins being grown in the bug are ready for harvest.  Hughes says the bugnever reaches pupation, and if the protein is not harvested from thecaterpillar during this crucial larval stage, the proteins are destroyed. Farming the pharmaceuticals becomes easy using a recently patented systemcalled HeRD -- the high-efficiency rearing device.  Developed at BTI, HeRDcan raise thousands of insects all at once to produce protein, thusreducing the expense.  Using the HeRD system, the BTI researchers aregrowing caterpillars -- Trichoplusia ni -- a pest best known as the cabbagelooper, which feeds on cabbage, cotton and crucifers. But the insects are living on the edge.  "Patrick [Hughes] is a veryobservant man and because he's observant, he came up with a brilliant idea-- the HeRD system," Wood said.  What Hughes observed is that insectsprefer getting their footing on the edges of surfaces, not directly on flatsurfaces.  Hughes developed a box full of close-spaced pillars -- pillarsshaped like small popsicle sticks -- and puts the insects in the box. Healso put food in the box.  The insects are reared on the pillars in thebox, making it easy to infect them with baculovirus and then harvest theproteins. In the past 18 months, researchers report that recombinant baculovirus havebeen used for vaccine production.  Some of the diseases that can be foughtinclude human papillomavirus, human T-cell leukemia virus, hepatitis-Cvirus, Norwalk virus, rotavirus, porcine parvovirus and African swine fevervirus.  BTI researchers do not directly study these diseases. Producing proteins through insects was seen as an alternative to raisingproteins in cell culture, Hughes said.  For a while, it appeared as ifraising the proteins in cell culture was less expensive, but rearingproteins in insects is substantially less expensive than cell cultures."We don't have the many technical barriers we had before," he said. Hughes and Wood have published their presentation, "Recombinant ViralInsecticides: Delivery of Environmentally Safe and Cost-EffectiveProducts," in the July 24, 1997, edition of the journal Entomophaga, thepublication of the International Organization for Biological Control ofNoxious Animals and Plants. In addition to pharmaceuticals, the researchers said that the technologiesinvolved could be used for other purposes, like manufacturing inexpensiveviral insecticides as alternatives to pesticides.  Wood and Hughes saidthat with more than 30,000 chemical pesticide registrations being canceledin the past eight years, there is a need to develop natural and geneticbaculoviruses. The researchers believe that to make these insecticidescommercially viable, methods like HeRD will need to be employed to bringcosts down. BTI, the Boyce Thompson Institute for Plant Research Inc., is the largestnon-profit, independent plant research facility in the world. It wasfounded in 1924, by Col. William Boyce Thompson in Yonkers, N.Y.  Thepurpose of the institute was to find ways to meet the food and health needsof an increasing world population.  BTI moved to the Cornell campus in1978.
--------
351-> Reversing Heart Failure: Cold Virus Could Make Gene Therapy Possible
University of Maryland researchers have confirmed the link between a calcium-handling enzyme and the strength of the heart’s beat. They also have been able to enhance the heart’s  beating strength, using a genetically altered adenovirus (the virus that causes colds) to give heart muscle cells additional copies of the gene that produces the crucial enzyme. Their research could pave the way for gene therapy in certain kinds of heart failure, repealing a death sentence for many.  Cardiovascular diseases are the leading cause of death in the population as a whole. Dr. Guiseppe Inesi and Dr. Terry Rogers will present their findings to a New York Academy of Sciences meeting on September 29 at the Hyatt Regency on Capitol Hill in Washington, DC.  Inesi is professor and chairman of the Department of Biochemistry and Molecular Biology at the University of Maryland School of Medicine, where Rogers is a professor of biochemistry and molecular biology. During the four-day meeting, scientists from a variety of disciplines will review progress in characterizing the underlying mechanisms of heart failure, examine unresolved questions, and discuss potential therapies. The Maryland researchers made their discovery from two complementary experiments. Using thapsigargin—a substance extracted from a Mediterranean plant—to block the enzyme ATPase (adenosine triphosphatase) in heart muscle cells, Inesi and colleagues caused a marked weakening of contractions. Since ATPase is an enzyme that regulates the flow of positively charged calcium ions through heart muscle cells, the experiment showed  that the calcium movements sustained by this enzyme are vital to the development of a strong heart beat. "We observed a marked reduction of intracellular calcium ion transients and a negative effect on muscle contraction, demonstrating the prominent role of the calcium-handling ATPase in the contraction-relaxation cycle," Inesi said. In a related experiment, the Maryland researchers altered an adenovirus so that it can’t reproduce. Then, using recombinant DNA techniques, they  turned it into an efficient vehicle for transporting additional copies of the ATPase gene into heart muscle cells.  This gene-copy enrichment resulted in a marked increase in the ability of the cells to control intracellular movements of calcium ions and to develop contractile strength—a strong heart beat. "The complementary experiments with thapsigargin and recombinant adenovirus demonstrate that the calcium-handling ATPase is a crucial enzyme in regulation of contractile strength in heart muscle," said Inesi. "The conceptual understanding and the techniques established by this work are an important step in the possible development of gene therapy for certain types of heart failure." The research was funded by the National Institutes of Health. 
--------
352-> University of Florida Surgeons Test Wire Stent-Graft To Repair Abdominal Aneurysms
By Melanie Fridl Ross Shands Public Relations GAINESVILLE, Fla.---A 64-year-old Florida man is recovering afterUniversity of Florida surgeons and radiologists used a tiny metallic and fabric device to bolster the weakened wall of a major artery in his abdomen. The man had been diagnosed with an aortic aneurysm, a balloon-like swelling of the aorta caused by the pressure of blood flowing through it. The aorta is the main vessel supplying blood to the lower body. Over time, an aneurysm can rupture and cause fatal blood loss. During the experimental procedure, UF surgeons and radiologists inserted a small, flexible wire through a vessel in the man's leg, threading it toward the weak spot in the aorta, said Dr. James G. Caridi, an assistant professor of radiology at UF's College of Medicine. They then deployed the device, known as a stent-graft, through a small tube called a catheter. The heat-sensitive stent expands and attaches the fabric bypass graft to the artery by friction, sealing off the problem area while permitting normal blood flow to continue through the artery. UF surgeons are studying whether they can safely and effectively repair abdominal aortic aneurysms through this minimally invasive approach withfewer complications than major surgery, which involves replacing the weakened section of the affected artery with an artificial bypass graft. The new method could potentially lower the risk of death, eliminate the need for intensive care, shorten hospital stays and decrease health-care costs. "Surgery effectively repairs aneurysms without any question," said Dr. James M. Seeger, chief of vascular surgery at UF's College of Medicine. "The concern with the minimally invasive approach is how effective it will be in the long-term. No one knows the answer to that yet. "The advantages of this new approach seem obvious," he added. "This can be done through a small incision in the groin and potentially the patient can go home in a couple days, having avoided the stress of majorsurgery, which can lead to heart attack, kidney failure or even death." Up to 10 percent of patients experience significant complications after the standard surgery. Some are hospitalized for as much as 10 days and face up to a two-month recovery period afterward. A subset of patients requiring aneurysm repair are at significantly increased risk because of associated heart, lung and kidney disease, or advanced age. Up to 10 percent of these patients may die from the surgery, and complications rates can be as high as 50 percent, Seeger said. For the next five years, surgeons from UF and other universities nationwide will track 90 patients who undergo conventional surgery and235 who receive the stent-graft to repair aortic aneurysms. The study is sponsored by Meadox. The risk of rupture increases with the aneurysm's size and with time. Virtually 100 percent of aneurysms greater than 7 cm to 8 cm in size rupture within five years. The death rate associated with aneurysm rupture is 80 to 90 percent. To qualify for the study, patients must have aortic aneurysms that are at least 4 cm in diameter. "Abdominal aneurysms are a common problem and not an uncommon cause of death," said Seeger, who estimated 30 to 66 people per 1,000 will be diagnosed with an aneurysm. "Unfortunately, patients with aneurysms often have no symptoms and the aneurysms are found by accident. "The risk of developing an aneurysm increases with age without any question; it's a disease of the elderly," he added. "That is one of the reasons to look for less invasive ways of treating aneurysms. Most people who have aneurysmal disease are elderly and have other medicalproblems that increase the risk of surgery." Seeger and Caridi are working with UF College of Medicine colleaguesDr. Thomas S. Huber, assistant professor of surgery; Dr.Timothy C. Flynn, professor of surgery; and Dr. Dick Hawkins, professor of radiology. ----------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser tohttp://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser tohttp://www.health.ufl.edu/hscc/experts.h 
--------
353-> Hopkins AIDS Network Studies How Well Early, Aggressive Treatment of HIV Infection Works
Johns Hopkins AIDS researchers have launched a multi-center study to find out if early, aggressive treatment of HIV infection can reduce virus levels or even eliminate the virus. The study also will examine the effect of this treatment approach on the immune system during the first few months of infection. Funded by the National Institutes of Health, the research could lead to improved treatments and more effective vaccines. "We have very little information about the early stages of HIV infection," says Richard Chaisson, M.D., associate professor of medicine and director of the Johns Hopkins AIDS Service. Chaisson is a co-investigator for the project, which is led by Joseph B. Margolick, M.D., Ph.D., associate professor of molecular microbiology and immunology at the Johns Hopkins School of Public Health. "Most people who are HIV-positive don't even know it until they are tested for the virus years after becoming infected," notes Chaisson. The study will measure how effectively combination drug therapy works during the early stages of infection with HIV. In combination therapy, newly developed anti-HIV drugs called protease inhibitors are combined with older drugs, such as AZT and ddI, to give a double punch against the AIDS virus. The researchers want to learn if early, aggressive, combination therapy only reduces or actually eliminates HIV from the body. The researchers also hope to determine how long anti-HIV drugs need to be taken for maximum benefit. "We'd like to know whether we can reduce the damage caused by HIV infection if we start treatment early," says Chaisson. Another important goal is to determine how early HIV infection affects the activity of two important chemicals that help stimulate the immune system--interleukin-2 (IL-2) and interleukin-12 (IL-12). IL-2 and IL-12 stimulate the growth and functions of the immune system cells that HIV-1 kills, according to Margolick. "We are going to treat some of the patients with IL-2 to see if we can repair some of the damage the virus does to helper T cells during the first few months of infection," Margolick says. Helper T cells are white blood cells that regulate the immune system's response to infection. They are a major target of the AIDS virus. The study will recruit up to 50 individuals in the first year, primarily intravenous drug users, who were infected within six months of entering the program. Other institutions participating in this project include the University of Pittsburgh and Cornell University Medical College (New York, N.Y.). The Hopkins study is one of several being done across the country. Other institutions conducting similar studies include the University of California, San Francisco; University of Alabama; University of Colorado; University of Washington; and the Aaron Diamond Center (New York, N.Y.).
--------
354-> First Global Ocean-Color Images From New Sensor Show Promise For Climate, Biological Studies
Exciting ocean-color images from the Sea-viewing Wide Field-of-view Sensor (SeaWiFS) -- the first readily available ocean-color data in more than ten years -- should play a major role in studying the ongoing El Nino and in other global warming research. The SeaWiFS data also is giving scientists their first continuous look at the global biosphere -- the combination of living organisms and their environment. Ocean color is largely determined by the concentration of microscopic marine plants called phytoplankton. Accurately measuring phytoplankton concentration is important to climate change research and to local economic concerns such as commercial fishing. "The images are more than we ever could have hoped for," said oceanographer Dr. Gene C. Feldman, who heads SeaWiFS's data processing team at the Goddard Space Flight Center, Greenbelt, MD.  "Although originally designed to just study the oceans, we've also discovered a way of using it to study the land as well, and as a result, we can study the global biosphere for the very first time." "The new images clearly show areas of coastal upwelling along the northwest U.S., Argentina and western South Africa.  These upwelling events foster dramatic plankton blooms which are a critical source of food for major fisheries.  The data will be extremely valuable for fisheries management," said Dr. Charles McClain, SeaWiFS Project Scientist. SeaWiFS offers great potential for monitoring oceanic conditions that have serious, and often tragic, effects on human health.  Coastal blooms of algae have been associated with cholera outbreaks around the world.  Early detection of these blooms, and subsequent in-water sampling, may significantly reduce the impact of these outbreaks.  Red tides, ocean dumping of organic and chemical waste, and perhaps even oil spills can be tracked with SeaWiFS data, Feldman said. With SeaWiFS, NASA is leading an international collaboration of researchers.  More than 300 scientists representing 35 countries have already registered to use the data.  Thirty-eight ground stations spread over 18 countries will receive data from the spacecraft. NASA also has developed a software package called the SeaWiFS Data Analysis System (SeaDAS) for scientists worldwide to process the data.  More than 150 scientists have already been to Goddard  to learn how to use this package.  Another 79 scientists from 11 countries are signed up for SeaDAS training at the Center this fall. The SeaWIFS instrument is aboard a commercially built and operated satellite called OrbView 2, owned by Orbital Sciences Corp., Dulles, VA.  OrbView 2 was launched at 3 p.m. EDT Aug. 1, 1997, from Vandenberg Air Force Base, CA, aboard an Orbital Pegasus XL launch vehicle.  The SeaWiFS mission is unlike many other NASA missions.  NASA's SeaWiFS Project described the data they wanted to purchase without giving specific requirements for the spacecraft itself. "It's a whole new way of doing business," said SeaWiFS Project Manager Dr. Mary Cleave. The SeaWiFS instrument was built by Hughes/Santa Barbara Remote Sensing, Santa Barbara, CA, and is the only scientific payload on the SeaStar spacecraft, developed by Orbital Sciences Corp.  NASA is buying the data and is providing it to researchers throughout the world. SeaWiFS is a follow-on sensor to the Coastal Zone Color Scanner (CZCS), which operated aboard NASA's Nimbus-7 satellite from 1978-1986 and proved that satellite sensors could detect ocean-color from space.  SeaWiFS improves on CZCS by providing global coverage every 48 hours, giving a more accurate determination of phytoplankton concentration. Images  from SeaWiFS are available from the World Wide Web at URL: http://seawifs.gsfc.nasa.gov/SEAWIFS.html The SeaWiFS program supports NASA's Mission to Planet Earth enterprise, a long-term coordinated research effort to study the Earth as a global system and the effects of natural and human-induced changes on the global environment.  Using the unique perspective available from space, NASA is observing, monitoring and assessing large-scale environmental processes focusing on climate change.
--------
355-> Sniffing Danger -- Sandia Tests Explosive Detection Portal At Airport
ALBUQUERQUE, N.M. -- Some airline passengers visiting the main security checkpoint at the Albuquerque International Airport this week are being asked to try out tomorrow's technology for combating terrorism -- an "explosives-detection portal" under development at Sandia National Laboratories for the Federal Aviation Adminstration (FAA). The "portal" is intended to help prevent airliner hijackings and bombings by identifying passengers and airport visitors and employees who have recently been working with any of a wide variety of explosive chemicals. The detector relies on chemical preconcentrator technology developed by Sandia as part of its Department of Energy mission to protect critical nuclear weapons facilities. The portal itself has been in laboratory development for three years. During the two to four weeks the portal is in operation at the airport, the Sandia researchers plan to test more than 2,000 passengers having a range of body sizes and shapes. The purposes of the FAA-required tests are to gauge passenger acceptance of the technology, identify any reliability issues that need to be addressed, and optimize the detector's performance with the ultimate goal of its widespread adoption at airports across the country. Although specific information about the portal's capabilities (the types and quantities of explosives it can detect) cannot be disclosed for security reasons, it is capable of detecting very small concentrations of all "explosives of interest" to the FAA, says Kevin Linker, Sandia's lead researcher for the project. As usual, passengers and visitors to the airport's terminals will be required to pass through metal detectors and the usual carry-on baggage check regimen. A uniformed security officer then will ask some passengers to volunteer to help researchers test the explosives-detection portal. Volunteers can choose to stop participating at any time. The new portal looks like an airport metal detector with vents and nozzles on its inside walls and ceiling. Passengers who agree to participate will be asked to stand inside the portal for a few seconds as the detector passes a quiet, gentle "puff" of air over them. The air sample is then collected and passed through a chemical sensor called an ion mobility spectrometer, which recognizes the chemical "signatures" of a variety of explosives. If a passenger had even a minute concentration of explosive residue on his or her skin or clothing, the quantity and type of chemical would be displayed on an adjacent computer screen. If a participant tested positive for explosives during the tests, and if suspicions remained following additional screening, airport security would be notified. The portal is fully automated. It gives instructions to participants -- "enter the portal," "turn left," "exit the portal" -- in a friendly male voice. Once the tests are complete, Sandia will submit its findings to the FAA, which will use the data to determine the feasibility of licensing and manufacturing the explosives-detection portal technology for use at airports across the country. Ultimately the technology likely would be incorporated into airport metal detectors as a single walk-through unit, says Kevin. Besides airports, such portals could be useful at security checkpoints in public building entrances, and the basic technology could be adapted for drug detection. Sandia is a multiprogram Department of Energy laboratory operated by Lockheed Martin Corp. With main facilities in Albuquerque and Livermore, Calif., Sandia has research and development programs contributing to national security, energy and environmental technologies, and economic competitiveness.
--------
356-> The College Of Wooster's New Seismic Station Goes Operational – Detects Large Earthquake In The South Pacific
WOOSTER, Ohio - The area around the town of Anna in western Ohio isthe second-most active earthquake zone east of the Mississippi River, yetOhio has not had a functioning seismic station since 1992. All that changedthis past weekend when Wooster's Department of Geology began operating anew, long-period seismometer, which will be able to record earthquakes fromaround the world of approximately magnitude six and above on the Richterscale. During its first few hours of operation, the seismic stationsuccessfully detected a 6.9 to 7.2 earthquake near the Kermadec Islands inthe South Pacific. According to Robert Varga, an assistant professor of geology who isspearheading the project, the system will directly benefit the education ofWooster's students, provide readily available seismic event information tothe general public and establish the College as a leader in the nascentstatewide effort to assess seismic risk. In addition, since the stationwill be tied through the Internet to other seismic station networks inMichigan and Indiana, it will be an important tool for geologists elsewhere. As a result of the College's new station, Varga says that "Woosteris a primary source of data in northern Ohio immediately following eitherlocal earthquakes or following earthquakes of public interest elsewhere inthe world. Our station certainly will be invaluable for helping to locateepicenters to earthquakes in the central and northeastern U.S." By the end of this year, the Ohio Division of Geological Surveyplans to construct a seismic station at Alum Creek State Park in DelawareCounty. When that site joins Wooster as one of only two operatingseismometers in Ohio, geologists will have invaluable data for locating andassessing earthquakes in the state. Wooster is located close to the Northern Ohio Seismic Zone, one ofthree principal clusters in Ohio. The College's seismometer will be theonly instrument close to this zone and will be much more sensitive to localseismic events. Since the instrument will be linked to the MichSeis Networkin Michigan and the IndiSeis Network in Indiana, Wooster's data will beavailable to seismologists elsewhere and will contribute to the location ofseismogenic faults in Ohio, earthquake recurrence rates and to the generalstudy of seismic risk. "Earthquakes are fundamental geologic events which deeply affecthuman beings," observed Mark Wilson, professor of geology. "The more weknow about seismic events, the more we can prepare ourselves forearthquakes. With the new instrument, Wooster will be one of a very fewinstitutions collecting seismic information in this relatively unmeteredpart of the world." The Wooster seismic station also will be a valuable source ofinformation about earthquake activity for both the general public and themedia. "As a former Californian, I am particularly interested in seismicevents everywhere and am well aware of the high level of public interestsurrounding these events shortly after they happen," said Wooster PresidentR. Stanton Hales, who was instrumental in obtaining a gift to establish the$6,000 seismic station. "I recall the powerful role geologists at Cal Techplayed in the lives of Californians following earthquakes in the state oraround the world. Wooster has an opportunity to play a similar role in Ohioand the Midwest." Equally important are the instrument's educational possibilities.The operating software, which is being provided free of charge by geologistLarry Ruff at the University of Michigan, will allow students not only tosee the currently plotting seismogram for the Wooster station, but also toaccess files of past events. "Students will be able to observe seismic arrival times, determinethe type of first motions - related to fault type - and calculate Wooster'sdistance to epicenters," said Varga. "These are all things that we talkabout in lectures, but are much more exciting when experienced in realtime. Because of the considerable numbers of students not majoring ingeology in our courses, the seismic station will greatly increasescientific awareness among the general student body." During her first oceanography class session following theearthquake, Lori Bettison-Varga, associate professor of geology and actingchair of the department, used the printout from the seismic station in herlecture. "My students and I were talking about island arcs and subductionzones in class that day," said Bettison-Varga. "A subduction zone is whereone crustal plate descends below the edge of another. I was able to use theinformation from this earthquake as real-time evidence that deepearthquakes occur and that they can tell us about the nature of platemotion." The seismic station also will provide educational opportunities tostudents in area public schools. Varga intends to involve these students inlearning about earthquakes and their measurements by creating a Woosterseismic station page on the World Wide Web that students will be able touse to learn about the basics of earthquake study and to access thereal-time data recorded by the instrument. "In essence, these students will be able to use our instrument viathe Web in the same way as our own students in Scovel Hall," said Varga."This should also provide a great opportunity to involve geology majors whoare interested in education careers with in-service training. Interestedmajors could visit local schools to give presentations about earthquakes ingeneral and about the use of the data from the Wooster seismic station andwork with local teachers to develop seismic-related educational exercisesand research projects."
--------
357-> Bananas Get A Boost From Science At UF/IFAS Research Center
GAINESVILLE---In a state where citrus reigns supreme, most residents viewbananas as just something to slice up and toss on top of their Cheerios. But worldwide, bananas outrank citrus as a fruit crop, and scientists atthe University of Florida are assisting in global research efforts tomanage important banana diseases and make the fruit tastier. Researchers at UF's Tropical Research and Education Center (TREC) inHomestead have planted 36 varieties of bananas to see how they fare. Manyof the bananas are being tried for the first time in the WesternHemisphere, said Randy Ploetz, a scientist in UF's Institute of Food andAgricultural Sciences. "We hadn't grown these bananas here before, so we didn't know how consumersmight react to them," Ploetz said. "To date, several of those that we'veharvested have been quite popular with our informal taste panel here at TREC." Bananas rank fourth worldwide as the most valuable food crop, behind rice,wheat and potatoes. Almost 80 million metric tons are harvested annuallyaround the world, with 72 million tons harvested by poor farmers in thetropics. In Latin America and Africa, bananas are considered a staple food. InUganda, for example, per capita banana consumption is 1.3 pounds per day --about 16 times the amount consumed in the United States. "It's incredible how valuable bananas are," said Ploetz. "Instead of riceor wheat, much of the world eats bananas." Bananas are easily digested and high in vitamins A and C and in potassium.In fact, Ploetz said, "you could live indefinitely on a diet of just milkand bananas." The Florida banana crop consists of specialty cooking and dessert bananas,not the Cavendish variety found in supermarkets. It is a small industry --valued at about $1 million a year, compared with $1.5 billion a year forcitrus -- and concentrated in Dade County. But the research in Homesteadcould boost production in Florida and help producers manage diseaseproblems worldwide. And although the industry is small, it fills a unique market niche, saidUF/IFAS tropical fruits specialist Jonathan Crane. "Many people throughout Florida, especially Hispanic, Caribbean andAsian-Americans, are familiar with these specialty bananas," Crane said,"so there is quite a demand for them." Ploetz said researchers are keeping an eye on a devastating disease calledblack Sigatoka, which has turned up just 90 miles offshore in Cuba. WhileU.S. banana crops currently are free of the disease, it could easily becomea threat, Ploetz said. "This disease could blow across the Florida Straits in a storm or come inat Miami International Airport," Ploetz said. "If it does, we'll haveproblems here like a lot of other tropical areas of the world." Black Sigatoka affects many banana varieties, and while it does not killthe banana plant, it reduces yields by 50 percent and causes fruit to ripenprematurely and irregularly, a major problem for exported fruit. Bananabreeding programs now are developing resistant hybrids, which offer theonly hope for subsistence consumers. Moreover, as fungicides lose theirability to control this disease, the export trades may well be forced toreplace the Cavendish bananas with resistant banana clones developed inbreeding programs. Ploetz said researchers also are breeding bananas that resist fusariumwilt, also known as Panama disease. South Florida growers have lost entirefields to the disease, so Ploetz is screening the new bananas against thedestructive problem. Crane said South Florida growers are interested in the research because oneof the main sweet dessert bananas they grow, the 'manzana' or apple banana,is susceptible to Panama disease. Any breakthroughs could be usefulanywhere bananas are grown, he said. Breeding fruits and vegetables for disease resistance is popular now bothin the scientific community and among consumers, Ploetz said. Crops thatare resistant to diseases can be grown with fewer or no pesticides. "These crops are viewed as environmentally friendly and, in some cases, canbe marketed as pesticide-free," Ploetz said. "There's an increasing demandfor that type of commodity here in the United States and elsewhere in thedeveloped world." Although a state grant for research on tropical fruit recently ran out,Ploetz said he is continuing his work with bananas because of the fruit'simportance as a food crop. "We hope to find disease resistance in a fruit that the consumer likes,"Ploetz said.
--------
358-> Effects Of Space Environment On Mir To Be Measured With New Device
A new NASA device to monitor the structural health of the future International Space Station will soon be on its way to the Russian space station Mir for testing. The Space Portable Spectroreflectometer, a device for measuring the effects of the space environment on spacecraft materials, is scheduled to fly aboard the Space Shuttle Endeavour on the STS-86 mission.  Launch is targeted for no earlier than September 25. The device is designed to test spacecraft materials such as those being used to construct the International Space Station.  NASA and its international partners are scheduled to begin on-orbit assembly of the Space Station in June 1998. "The Spectroreflectometer is the first hand-held, battery-powered device of its kind," said principal investigator Ralph Carruth of NASA's Marshall Space Flight Center in Huntsville, AL.  "It will allow astronauts to monitor and assess the condition of actual spacecraft surfaces, rather than relying on information gathered from samples of previous experiments." During a spacewalk planned for later this year, Russian cosmonauts and a U.S. astronaut will use the device to measure how much energy can be absorbed by the thermal control coatings, or radiator surfaces, of the Mir space station.  "Radiators, where excess heat is dumped from the space station, are a vital part of the spacecraft's cooling system," said Jim Zwiener, co-investigator for the device at Marshall.  "If the radiators degrade, the cooling system degrades, so these are critical surfaces." Measurements will be used to determine the deterioration of radiator surfaces caused by the space environment.  "Also, in the vacuum of space, gases generated by -- and released from -- the spacecraft collect on the spacecraft's surfaces, resulting in contamination," said Zwiener.  The gas deposits are visible as a discoloration of the spacecraft's white paint surfaces. Measurements will be taken from four sites on Mir -- three on the core module and one on a smaller adjacent module.  To take measurements, the device will be held against the space stationÕs surface for approximately two minutes.  "During tests, light consisting of wavelengths from near ultraviolet to infrared will be emitted by sources within the device," explained Carruth.  "The device measures then how much of this light is reflected, which also indicates how much is absorbed and the extent of deterioration." The device will display the measurements on a small screen, and the astronauts will read the information to researchers on the ground.  "Following the spacewalk, more detailed information will be downlinked to the ground from the device via a computer aboard Mir," said Carruth. The radiator surfaces of Mir are very similar to those being manufactured for the Russian components of the International Space Station.  Based on ground testing, researchers have constructed models of expected surface deterioration for the future space station.  "Comparisons of findings from this study with computer models will allow researchers to better predict and plan for the health of the International Space Station," said Carruth. The experiment also will test the design of the measuring device.  "Plans are to not only use the device to monitor the effects of the space environment on the surfaces of the International Space Station," said Carruth,  "but it may also be used to monitor other spacecraft, such as the Hubble Space Telescope." NASA's Space Environments and Effects Program at Marshall will also use information gathered from the experiment to enhance the development of advanced technologies in the area of space environments for future NASA missions. The Space Portable Spectroreflectometer was built for NASA by AZ Technology, Inc., in Huntsville, AL.
--------
359-> Plant-Based Therapies Examined For Colon Cancer Prevention
Three therapies derived from plants will be tested atThe Rockefeller University in New York City for theirability to prevent colorectal cancer, which afflictssome 150,000 Americans each year.  The compounds havethe potential to be safer than cancer-thwartingnonsteroidal antiinflammatory drugs (NSAIDs), widelyused aspirin-like drugs known to prevent colorectalcancer as well as reduce related deaths by half. Eating diets rich in fruits and vegetables helpsreduce the risk of colorectal cancer as well as deathsfrom the disease, according to population-basedstudies.  However, the chemicals in these plantsresponsible for the anti-cancer effect are not wellknown.  "Certain plant-derived compounds calledphenolics act similarly to NSAIDs in hindering cancer,yet may lack their bad side effects such as irritatingthe stomach lining or damaging the liver or kidneys,"says Steven J. Shiff, M.D., assistant professor in theLaboratory of Human Behavior and Metabolism atRockefeller.  "If as effective or better than thedrugs, these plant therapies might be much bettertolerated for longer periods of time than NSAIDs." In the study, Shiff and his colleagues will comparethree plant-derived compounds, curcumin, rutin andquercetin, to the NSAID sulindac.  The study willdetermine whether these naturally occuring chemicals,all potent antioxidants and antiinflammatories, canaffect cells in a similar manner as sulindac, whichprompts the cells to "turn on" a program of regulatedcell death called apoptosis.  NSAIDs, which includeibuprofen and naproxen, are among the most commonlyused therapies worldwide for relieving pain andinflammation in joints and muscles. Curcumin, notes Shiff, has been used for centuries asan antiinflammatory agent.  The compound is thepigment that gives the yellow color to the seasoningcurry, mustard and turmeric, the powdered form of theroot of Curcuma longa Linn.  Curcumin is an approvedadditive for foods in the United States. Quercetin canbe naturally found in most fruits and vegetables, suchas cranberries and onions, as well as tea. Quercetin,when digested in the colon, breaks down into rutin. Many colorectal cancers begin as noncancerous growths,called polyps, in the mucosal lining of the colon andrectum, the last part of the digestive tract.  Aninherited defective gene can cause some forms of thedisease, but not all.  The polyps develop because thenormal routine of cell division and apoptosis goesawry.  When apoptosis is disabled, tissues that relyon it no longer have a way to regulate their cellpopulations and cancer may ensue. In the study, Shiff and fellow researchers willexamine the influence of administering differentamounts of either curcumin, rutin or quercetin on theamount of colorectal cells replaced and the speed ofthis process during the normal functions of theintestine.  The study includes looking for andmeasuring the size and kind of any intestinal polypsthat develop in the participants. "Ideally, we would like to find the lowest, optimaldose of each of the three plant compounds that wouldsafely inhibit the development of colorectal cancer,"explains Shiff. The study lasts for up to 10 weeks.  During the firsttwo weeks, participants eat a controlled diet so thatinitial information can be collected.  In thefollowing weeks, the investigators randomly assign theparticipants to continue on the initial diet alone ora diet supplemented with one of the plant phenoliccompounds or sulindac, the NSAID.  During this secondphase, participants stay for an additional four oreight weeks. For the study, the research team will recruit men andwomen aged 18 years and older who have a history ofcolon polyps.  Participants may not smoke and shouldbe healthy.  People interested in enrolling asparticipants should call Dawn Stoddard, M.S.,F.N.P., at 1-212-327-7458 or write tostoddad@rockvax.rockefeller.edu.  Furtherinformation can be obtained by visiting RockefellerUniversity Hospital¹s website athttp://clinfo.rockefeller.edu.  All information iskept strictly confidential. People accepted into the study must stay at TheRockefeller University Hospital, but may leave duringthe day to work after the initial week.  Allparticipants receive free medical examinations, allmeals and private lodging, and will be given a stipendfor their participation.  The National CancerInstitute, part of the federal National Institutes ofHealth (NIH), supports the Rockefeller study. The Rockefeller University Hospital is the oldesthospital in the United States devoted solely toexperimental medicine.  Established in 1910, thehospital links laboratory investigations with bedsideobservations to provide a scientific basis for diseasedetection, prevention and treatment.  This specialhospital environment served as the model for theWarren G. Magnuson Clinical Center, opened at the NIHin 1953, and similar facilities supported by federalfunding at more than 75 medical schools in the UnitedStates. Rockefeller University began in 1901 as theRockefeller Institute for Medical Research, the firstU.S. biomedical research center. Rockefeller facultymembers have made significant achievements, includingthe discovery that DNA is the carrier of geneticinformation and the launching of the scientific fieldof modern cell biology.  The university has ties to 19Nobel laureates, including the president, Torsten N.Wiesel, M.D., who received the prize in 1981.  Theuniversity recently created centers to foster researchof Alzheimer's Disease, of biochemistry and structuralbiology, of human genetics, of sensory neurosciencesand of the links between physics and biology.
--------
360-> Irradiation Can Protect Foods From E. Coli, Other Bacteria, UM-Rolla Professor Says
ROLLA, MO. -- Here's food for thought: Irradiation of meats, fruits andvegetables will keep them fresh longer and ward off the threat of E. coliand other harmful bacteria, a University of Missouri-Rolla researcher says. Many kinds of foods don't stay fresh-looking for very long after they havebeen brought home from the supermarket, and some of those foods can evenmake you sick. "Millions of people get sick every year due to foodcontamination, and some die as a result," says Dr. Gary E. Mueller, anassociate professor of nuclear engineering at UMR. According to some scientific sources, about 30 million people in the UnitedStates alone get food poisoning each year, and about 7,000 of those peopledie. The most recent food poisoning scare was the recalling of hamburger meatcontaminated with the E. coli bacteria, Mueller says. "Cooking that contaminated hamburger properly would have killed the E.colibacteria," Mueller says, but a safer and better approach to keeping foodsfree of contaminants is irradiation. Irradiation -- a practice approved in many countries including the UnitedStates -- keeps meats, fresh fruits and vegetables fresher andcontamination-free for months instead of just days, says Mueller. "A giant step toward a solution to the problem is to irradiate the food inthe processing before it is shipped to the market," he says. "First, the shelf life of the food can be extended because irradiationkills spoilage organisms and slows down the natural ripening processes,"Mueller says. "Secondly, the process reduces food-borne illnesses by reducing oreliminating pathogens, such as E. coli. And thirdly, the process is safe,cost effective, highly successful, and government-regulated by thosecountries now using the method." The food irradiation process consists of taking foods such as potatoes,spices, fresh fruits, red meats, dried vegetables, fish and poultry andirradiating it with gamma rays from a radioactive source. Some food shoppers are wary of buying and eating what they think might beradioactive. "One of the misconceptions is that when you irradiate foodsthey become radioactive, but that is not the case," Mueller says. Another concern is that irradiation of food will ruin its taste andnutritional value. But extensive research by the World Health Organization,the Joint Expert Committee of the Food and Agriculture Organization, andthe International Atomic Energy Agency has shown that below a certainradiation dosage, foods are not affected and the taste and nutritionalvalue is not changed, Mueller says. "The Food and Drug Administration in the United States has approved theradiation of foods since the 1960s but the practice is not yet used inlarge degrees," Mueller says. "Canada has been using the method for 40years and 40 other countries now irradiate over 50 food commodities." Just how long can food last after being irradiated? Mueller says that porkloins that have been irradiated and stored at refrigeration temperaturestakes about 90 days to spoil as compared to 40 days for that of treatedpork. "And the life expectancy of fresh fruits can be increased from a weekto a month. Strawberries, for instance, can be extended from a few days upto four weeks," he says. But are people willing to buy irradiated foods? Mueller believes that theyare. "Hawaii shipped processed papayas to California but before shipment some ofthe papayas were given a hot water treatment, which killed the bacteria and fruit flies," he says. The other papayas were irradiated, which alsokilled bacteria and fruit flies. "After those papayas were stocked inCalifornia markets consumers bought 10 irradiated papayas for every 11sold," Mueller says. "The process is safe and it works and people are convinced of that,"Mueller says. "Now we have to convince the food industry. And the UnitedStates has to embrace this technology that other countries are nowsuccessfully using."
--------
361-> Electron Microscope Reveals Magic Sizes In Metal Alloys
BERKELEY, CA -- Scientists at the Ernest Orlando Lawrence Berkeley National Laboratory (Berkeley Lab) have made the surprising discovery that tiny crystals of lead in an aluminum matrix come in only a few specific sizes -- and a handful of unusual shapes -- and avoid others. The discovery sheds new light on the strange behavior of solids at nanometer scale. Ulrich Dahmen, one of the discoverers of the "magic size" phenomenon and head of Berkeley Lab's National Center for Electron Microscopy (NCEM), says he and collaborators from the University of Copenhagen wanted to find out why the properties of nanoscale particles -- particles measured in billionths of a meter, a scale approaching that of atoms and molecules -- differ so dramatically from those of the same material in bulk. "We know from the work of Paul Alivisatos here in the Materials Sciences Division, and others, that with free nanoscale particles the melting point may be as little as half that of the bulk material," says Dahmen. "On the other hand, a crystal embedded in a matrix of a different solid may need to be superheated to melt." Dahmen's Danish collaborators, Erik Johnson and colleagues, observed in 1990 that to melt 150-angstrom lead inclusions, they had to be heated 60 degrees Kelvin above their bulk melt point. "This behavior is like an ice cube refusing to melt in boiling water," says Dahmen. "We didn't understand it, but we hypothesized that it was a shape effect -- the smaller the inclusions, the more likely they are to attain perfect shapes -- so we set out to measure how size and shape were related at this scale." Dahmen and his colleagues used NCEM's three-story high, one-million volt Atomic Resolution Microscope for their study. They chose to work with lead inclusions in aluminum partly because lead and aluminum, like oil drops in water, don't readily dissolve in each other; boundaries between them remain sharp. By means of vapor deposition the researchers laid a film of aluminum only a hundred nanometers thick on a silicon wafer, then implanted the lead with an ion beam. Finally the silicon was shaved away until the alloy sample was thin enough to be transparent to the microscope's high- energy electron beam. The micrographs showed numerous nanometer-sized islands of lead in a shallow aluminum sea, islands that assumed a few different shapes and came in a range of discrete sizes. "What surprised us was that some sizes were preferred, while others were avoided. At first it was puzzling, but on reflection it made perfect sense," says Dahmen, noting that a lead atom is about 20 percent larger than an aluminum atom. "Putting lead atoms into aluminum has been likened to shoving grapefruits among oranges. If you try to replace oranges with grapefruits three for three, you expend a lot of energy squashing the grapefruits. But replace five oranges with four grapefruits and they fit reasonably well. With lead and aluminum, we found that the most preferred fit was nine for eleven." The consistently repeating ratio of lead to aluminum was a clue to the forces at work at the nanoscale. Free crystals take shapes that minimize their surface energy, but embedded crystals have to conform to their neighbors in the solid matrix. In this environment, internal elastic energy is important and must be minimized, together with the interface energy. When the researchers analyzed their micrographs, two features became apparent. First, the "magic sizes" assumed by the lead inclusions corresponded to regularly repeating values of minimal strain energy. Just as multiples of four grapefruits replacing five oranges -- four or eight or 12 grapefruits replacing five or 10 or 15 oranges -- cause less squashing than one-for-one replacements, so some repeating ratios of lead to aluminum atoms cause less strain than others. Second, many of the lead inclusions, especially the smaller ones, were asymmetrical. The equilibrium shape of a large inclusion (where interface energy is dominant) is a cuboctahedron, a symmetrical double pyramid with its six vertices lopped off. Small inclusions, however -- where residual strain energy is dominant -- are forced to assume magic sizes even at the cost of their equilibrium shape. In the micrographs they appear as parallelograms which have been truncated at one or more vertices. By adopting asymmetrical shapes, small magic-size inclusions can maintain perfectly flat interfaces with the host matrix. This in turn suggests why small inclusions have to be superheated to melt: more heat energy is needed to overcome the constraint at the perfect interface of an asymmetrical, magic-size inclusion than at the imperfect interface of a symmetrical inclusion. "To learn something as simple as how ordinary lead-tin solder melts and resolidifies would be fundamental knowledge with far-reaching implications," Dahmen says. He and his collaborators, Erik Johnson in Denmark and Serge Hagüge in France, are currently working with lead- cadmium alloy inclusions in aluminum -- in what Dahmen calls "nanoscale crucibles" -- to understand the relationship of melting behavior and shape in more complicated miniature systems. Nanoscale manipulation can affect an alloy's electrical, magnetic, and optical properties as well as its mechanical and thermodynamic behavior. Says Dahmen, "As a practical result of these observations we can begin to talk about understanding, perhaps even engineering, inclusions with desired shapes and sizes -- and the resulting properties -- in all kinds of alloys." The researchers reported their results in a recent issue of Physical Review Letters (Volume 78, No. 3). Berkeley Lab is a U.S. Department of Energy national laboratory located in Berkeley, California. It conducts unclassified scientific research and is managed by the University of California.
--------
362-> Tractor Drivers Soon May Say, "Look, Ma! No Hands!"
Future farmers of America may never have to learn to drive a tractor. A Stanford research team has equipped a John Deere tractor with a satellite-based automatic control system that can guide the 20,000-pound farm vehicle more precisely than the best human drivers. Doctoral students Gabriel H. Elkaim and Michael O'Connor report that their team has perfected the system to the point that it can control the tractor at all speeds while pulling a variety of implements, with centimeter-level precision.  The team, which is supervised by Bradford Parkinson, the Edward C. Wells Professor of Aeronautics and Astronautics, previously had reported obtaining this level of precision at specific speeds and loads following both straight-line and closed loop paths . The students presented the new findings Sept. 19 at the Institute of Navigation's GPS-97 conference in Kansas City. "These guys have done an amazing job in controlling the tractor. They've taken it beyond anything we expected," said Gary K. Hendrickson, manager of product test and reliability for John Deere, who has been working with the Stanford team. The research group achieved this unprecedented level of control by using the Global Positioning System (GPS), a constellation of 24 satellites operated by the U.S. Department of Defense. The satellites circle the Earth every 12 hours. The system originally was designed and constructed primarily for military purposes, but it has been made available for civilian use. Normal civilian GPS receivers have a precision of about 100 yards; a system called differential GPS, which requires a local base station, can provide meter-level accuracy. At these accuracy levels the technology has found widespread use in the nation's farmland, as part of a movement called precision agriculture. In the days before agriculture was industrialized, farmers were familiar with the characteristics of their fields yard by yard, and successful farmers adapted their practices, such as seeding, cultivating and irrigation, to these variations. The advent of industrialization, however, forced farmers to prepare entire fields in the same way, regardless of the variations in soil conditions and other factors. By mapping their fields with GPS, innovative farmers now have begun to adapt their seeding and fertilization practices to take these small-scale variations into account once again. Using these electronic maps, for example, farmers have begun varying the amount of seed they plant and the fertilizer they apply. In some cases, they are doing these tasks manually, guided by an inexpensive handheld GPS receiver. In others, they are using GPS-guided systems that automatically vary the application rates. Although these efforts remain experimental, proponents argue that precision agriculture will improve farm productivity while reducing applications of fertilizers, herbicides and pesticides. Not only would this save farmers money, it also could reduce the adverse environmental impact of their operations. Some proponents even are calling these developments the "third agricultural revolution." Until now, however, the degree of precision available from GPS has been inadequate for control of farm vehicles. To achieve this control, the Stanford researchers adapted a method that they had developed for an automatic aircraft landing system in 1994. The system employs an additional ground station, called a pseudolite, that puts out GPS-like signals. When combined with differential GPS, the system provides information on the tractor's position and attitude with centimeter-level precision. Automatic control of ground vehicles has been a research objective for many years. Such control has many potential applications, including development of smart roads that automatically pilot vehicles to the destinations their users select; control of construction vehicles that build roads automatically; and control of vehicles operating in hazardous environments. "We think that farm vehicles will be the first major application," said graduate student O'Connor, citing several reasons: Solid objects such as mountains and tall buildings block the satellites' signals, so a large expanse of sky must be available for the GPS system to work properly, which is normally the case in agricultural fields. Farmers and farm equipment manufacturers already are embracing GPS technology, O'Connor said, and the potential economic benefits to farmers are large enough to provide a real incentive for its adoption. Although the ultimate application of this technology would be an autonomous tractor that a farmer can command and monitor from the office, there also are potential advantages to adding such a control system to tractors with drivers. Bedding, seeding, disking, fertilizing and similar procedures are among the most monotonous and time-consuming tasks that farmers face. Many farmers tell stories about falling asleep on the tractor and taking out a couple of rows of crops. "This kind of control system, which does the basic driving, frees the operator to make higher-level decisions," O'Connor said. It also could allow less experienced operators to plow more precisely than veterans. The accuracy of the best human tractor drivers that the Stanford researchers have been able to measure is about 10 centimeters. That compares to a 2-centimeter error with the satellite controller. Such high level of precision is not required for all field preparation, but it is necessary for some applications. In growing melons, for instance, farmers use buried hoses, called tapes, to water the crops. Once a field has grown up, however, it is difficult for farmers to locate the buried tapes. Typically, they dig up each end of the row to locate the end of the tapes and then mark them with flags. The tractor operator is expected to drive the entire length of the field and avoid the tapes by sighting on the distant flags. Despite their best efforts, the tractor operators do thousands of dollars' damage to the tapes annually. With the GPS control system, by contrast, the exact location of the tapes could be recorded at the time they are installed and the tractors programmed to avoid them. Such a system also would allow farmers to operate during the night, through heavy dust or fog. This capability could potentially minimize losses at times when crops must be harvested as quickly as possible. Satellite-based controllers also might allow farmers to do things that are impossible or impractical manually, such as enabling a single driver to operate a convoy of several tractors at the same time. Or it could allow farmers to plow their fields in a spiral pattern, rather than in parallel rows. A spiral pattern would allow a farmer to plow a large field continuously, without wasting time making U-turns at the end of each set of rows, but it is very difficult for drivers to do. The Stanford project began four years ago when O'Connor asked Parkinson if he could try to develop a control system for an electric golf cart. In a year, O'Connor and two other students had a working system. At that point, the Stanford researchers approached the John Deere Co. for support. The company supplied an older, mid-sized tractor model, the 7800, which weighs about 20,000 pounds, has a 140 horsepower engine and can travel at speeds up to 22 mph. Since then, the team has grown to seven students. In addition to O'Connor and Elkaim, doctoral students Tom Bell, Andy Rekow and Ajit Chaudhari work on various aspects of the system. Two undergraduates, Arti Garg and Seebany Datta-Barua, work on related topics. O'Connor, who will graduate in a few months, said he hopes to get a job building a commercial prototype of the tractor control system. The research has been supported by Deere and Company. It is a spin-off of previous Stanford research that was sponsored by the Federal Aviation Administration and the National Aeronautics and Space Administration. Trimble Navigation provided the GPS receivers used in the project.
--------
363-> Waltzing With A Black Hole -- Model Shows How Star May Trigger Bursts Of Radiation
In a last waltz, a star in the evolutionary twilight of its long life orbits a black hole. As the star, a shrunken but very dense sun known as a neutron star, spirals toward the black hole, it is torn apart, sparking massive bursts of energy that, like cosmic beacons, are detected millions of light years away as gamma rays. That, at least, is the picture painted by University of Wisconsin-Madison physicists Wlodzimierz Kluzniak and William Lee in a model that seeks to explain a conundrum of modern astrophysics. Their work was reported here last week (Sept. 19) at the Fourth Huntsville Gamma-Ray Burst Symposium. Since their discovery 30 years ago, scientists have searched for, pondered and debated the origin of mysterious bursts of gamma rays. Appearing uniformly across the sky on an average of once a day, and detected only by satellites in orbit above the Earth's atmosphere, these mysterious bursts of high-energy radiation have been an astrophysical puzzle, bedeviling scientists with questions about their nature and origin. "People have been struggling with this for 30 years," says Lee, a graduate student at UW-Madison, "and nobody's figured it out yet." Each gamma ray burst is unique, says Lee. Some last just a fraction of a second. Others last for minutes. All come without warning and seem to come from all directions, briefly outshining entire galaxies and their billions of stars. To be sure, the model presented today by Kluzniak, a professor of physics, and Lee is one of many competing ideas that seek to explain the mysteries associated with the brilliant bursts of radiation. There is, for example, no widespread agreement about what may cause the bursts. Some contend the sources are small black holes in nascent galaxies. Others suggest colliding neutron stars. Still other scientists think the bursts emanate from massive black holes that lie within quasars. Another layer of debate centers on how distant the sources are from our own galaxy, the Milky Way. Most astrophysicists think that the bursts of gamma rays come from great distances beyond our galaxy, while some eminent astrophysicists argue that the source of the bursts could be very near the Milky Way. One of the puzzles of gamma ray bursts, according to Lee, and one that his and Kluzniak's model seeks to answer, is the varying duration of the gamma ray bursts. In their model, the Wisconsin scientists suggest that a neutron star in orbit around a black hole is nearly pulled apart by the overpowering gravitational pull of the black hole. The idea, says Lee, is the "star comes close and a little matter is dumped on the black hole." When that happens, according to their simulations, enough energy is released to produce a brilliant burst of gamma rays that can travel for millions of light years. The process, while violent, is not enough to destroy the neutron star right away. Instead, the star is repeatedly stripped of mass, each time releasing energy in the form of gamma rays. "Our results show that if the neutron star is less massive than the black hole, it is not completely ripped apart," says Lee. "Instead, distinct, repeated episodes of mass transfer occur." The neutron star could dump material on the black hole many times until the star has so little mass left that it becomes unstable and explodes, an event that could also give rise to a flash of radiation, the Wisconsin scientists suggest. Computer simulations like Lee's and Kluzniak's will help set the stage for the solving of the gamma ray burst mystery. While satellites such as NASA's Compton Gamma Ray Observatory and the Hubble Space Telescope are investigating the mysterious bursts, no one has been able to identify a single source from which the bursts emanate. But groups of observers in the United States and abroad are constructing fast-reaction telescopes, some of which will be able to be pointed at a suspected source less than 30 seconds after a burst is first detected.
--------
364-> OHSU Scientists Discover Mice Lacking Dopamine Receptor Are Supersensitive To Alcohol, Cocaine And Methamphetamine
Scientists at Oregon Health Sciences University have discovered that mice lacking a certain brain cell receptor for the chemical messenger dopamine are supersensitive to alcohol, cocaine and methamphetamine. Their findings appear in the September 19, 1997, issue of the journal Cell and detail the increased locomotor activity of mice who lack the D4 receptor. "Branching nerve cells communicate with each other by secreting chemical messengers like dopamine that bind to receptors on neighboring nerve cells in a lock-and-key fashion," explains, David Grandy, Ph.D., OHSU scientist and senior author of the article. "Dopamine is one of the primary chemical messengers, or neurotransmitters, and plays numerous complex roles in both movement and emotional states. Disturbances in the dopamine system are known to be associated with human disorders such as Parkinson's disease, schizophrenia and addiction. Dopamine producing neurons continue to be the focus of research because of their widespread importance in regulating complex locomotor, emotional and motivational states." Grandy further explains that dopamine producing neurons are involved in mediating some of the positive reinforcing properties shared by drugs of abuse such as alcohol, cocaine, methamphetamine and opiates. "We examined mice that were genetically engineered to lack the D4 dopamine receptor to investigate the role of this receptor in mediating the effects of various drugs," says Grandy. "We discovered that mice given either alcohol, cocaine or methamphetamine displayed a dramatic increase in locomotor activity compared to normal mice. Prior to their treatment with these drugs, the mutant mice tended to be less active than normal mice. Following treatment their activity level increased greatly compared to normal mice. "Based on the observation that mice lacking the D4 receptor show a supersensitivity to certain drugs of abuse, we speculate that the D4 receptor is implicated in modulating the effects of such drugs," says Grandy. "Consequently, the D4 receptor may be a new target for the treatment of drug abuse." Grandy explains that humans show a wide variability in the gene that encodes the D4 receptor, and there are reports that some forms of the D4 gene may predispose an individual to drug taking and novelty seeking behaviors. The D4 receptor has been the focus of intense interest since its discovery in 1990 because of its high affinity for the antipsychotic drug clozapine, which is used to treat schizophrenia. Recently, several new D4-selective drugs that are similar to clozapine have been developed and are currently undergoing clinical trials for the treatment of schizophrenia. In addition to shedding light on the role that the D4 receptor plays in an organism*s response to drugs like alcohol, cocaine and methamphetamine, the new research reported by Grandy and his colleagues underscores the relevance of this receptor to antipsychotic drug development.
--------
365-> Wonder Thread: UD Scientists Report First Protein With Collagen And Elastin-Like Domains
Five times tougher and 16 times more extensible than a human tendon, the leathery, yet amazingly stretchy collagen threads produced by marine mussels might someday suggest strategies for developing better artificial skin and other biomimetic materials, say University of Delaware researchers whose work appears in the Sept. 19 issue of Science. Described as containing "the first known protein [with] both collagenous and elastin-like domains," byssal threads help mussels latch onto rocks, oil rigs, super-tankers and docks, the UD researchers say. Not surprisingly, mussels "create a major fouling problem on economically important surfaces exposed to the sea," says J. Herbert Waite, professor of marine biochemistry in UD's College of Marine Studies. Byssal threads feature "a stiff tether" at one end and a "shock absorber" on the end protruding from the mussel foot, explains graduate student Kathryn J. Coyne, lead author of the Science article, along with postdoctoral research associate Xiao-Xia Qin and Waite. This gradual transition, from one material to another, gives byssal threads a surprising mix of properties. "If a byssal thread were simply a stiff stick attached to an elastic tube, it wouldn't have an outside chance of surviving these relentless tidal beatings," Waite notes. "In fact, the collagen in byssal threads goes from being a stiff material, to something that's very stretchy--without any sudden transitions." It's not yet feasible to manufacture materials featuring such gradual transitions, Waite says. But, he adds, "It's fun to dream about versatile new materials for a whole host of products--from steel-belted radials to shoes, which must be soft and flexible, yet tough enough to pound the pavement." Waite emphasizes that his current work primarily provides fundamental insights into the molecular construction of byssal threads. In the future, however, a better understanding of byssal threads might help scientists design biomaterials that take advantage of their remarkable properties, says Harold Slavkin, director of the National Institute of Dental Research, one of the National Institutes of Health, which sponsored the UD study. "Insight into the molecular structure that makes the byssus strong yet flexible might suggest, for example, new strategies for designing more comfortable and pliable artificial skin," Slavkin says. Curious Forms of Collagen To find out what makes byssal threads so special, Qin and Waite first isolated two key collagens: Col-P and Col-D. They used pepsin, an enzyme secreted by stomach cells of vertebrates, to pinpoint the collagens. Unlike most proteins, Waite says, Col-P and Col-D don't break apart in response to pepsin. Since pepsin works best in an acidic environment, researchers simply placed byssal threads and pepsin in a weak solution of acetic acid. "Col-P and Col-D were the only proteins detectable after pepsinization," Waite explains. "Within byssal threads, these two collagens are distributed in a complementary gradient, with Col-P predominant in the elastic, proximal region, near the foot of the mussel, and more Col-D at the far, or distal end." The UD team also examined the protein precursors for Col-P and Col-D, found in the mussel foot, where byssal threads are produced. Specific antibodies--proteins designed to detect and fight off foreign molecules by binding with them--helped Coyne target preCol-P. First, messenger RNA (ribonucleic acid) containing the genetic code for the protein was extracted from mussel foot tissue. Next, RNA was converted to the more stable DNA (deoxyribonucleic acid) form and cloned into bacteria, which expressed the protein encoded by the mussel's RNA. Designer antibodies, produced by a laboratory animal injected with Col-P, quickly latched onto the protein precursor expressed by bacterial clones. Three Major Domains The preCol-P in byssal threads contains three major domains, Coyne says. The middle section of the protein precursor consists of a tough collagen-based domain, flanked on either side by a pair of elastin-like regions. These stretchy domains are then framed at each end by sections rich in the amino acid, histidine. The rubbery sections of preCol-P resemble bovine elastin, which is "very similar" to human elastin, Coyne reports. "Elastins typically are found in the skin and arteries of vertebrate species only," she notes. "The presence of these types of sequences in proteins from an invertebrate species is unusual." The elastin-like regions of preCol-P also contained high levels of glycine and alanine--the amino acids most prevalent in two forms of protein in spider silk, Waite says. Although the structural similarity between preCol-P and spider silk still must be verified, Waite says the possibility should interest biochemists. "Spider silk is so thin, it has been difficult for anyone but crystallographers to deal with it," he says. "Byssal threads could turn out to be an interesting substitute, or model for studying some aspects of spider silk." Curiously, the collagenous regions of preCol-P contain a missing glycine. "When a deletion like this is found in other structural collagens," Waite says, "it's certainly lethal to the animal. So, it's quite fascinating to find a missing glycine in a perfectly functional collagen subjected to great stress and strain in marine environments." It's possible, Waite speculates, that the missing glycine creates a 35-degree "kink" or bend in the collagen. But, he adds, "how that might contribute to the stretchiness of the protein is anybody's guess." Two histidine-rich domains, located at each end of preCol-P, may play a role in forming protein-zinc complexes, Qin says. Whenever histidine-rich domains occur in proteins, they usually bind with metal. In blood, for instance, histidine-loaded glycoprotein binds with zinc. In byssal threads, she says, these domains may react with metals to produce strong "bridges," which link up linear arrays of collagen. Breaks in some of these cross-linked sections appear to be promptly repaired, Waite says. "This is totally different from how vertebrate collagens form fibers in nature," he notes. "Bridge formation seems to be reversible, so that if you pull them apart, they reform when you bring them back into contact." Biomedical or consumer materials based on byssal threads are "a long way off," Waite says, but the UD findings suggest some tantalizing possibilities. "What this study contributes, at this point, is a completely new way of looking at the potential properties of structural collagen--the human body's most abundant protein," he says.
--------
366-> Archaeologists Identify Oldest Existing Mound Complex In New World
The earliest existing mound complex built by humans in the new world has been identified in Louisiana by a team of archaeologists and researchers from around the United States including Jim Feathers, a University of Washington research assistant professor of archaeology. Details of the discovery appear in the Sept. 19 issue of the journal Science. The complex of 11 mounds located near the town of Watson Break in northeast Louisiana was built between 5,000 and 5,400 years ago and predates other known existent mound complexes by 1,900 years, according to Joe Saunders, adjunct professor of geosciences at Northeast Louisiana University, who directed the project. He said a single burial mound found in Canada predates the Watson Break site and another now destroyed mound in Louisiana discovered in the1960s also may have been older. Saunders said archaeologists remain puzzled by such mounds, which are earthen structures several meters high. The mounds might have served a mix of religious, agricultural or domestic purposes but give indications that they only could have been built with planned engineering, he said. Saunders and his colleagues have been able to piece together a picture of life at the newly discovered site. They found that hunter-gatherers lived at Watson Break seasonally, living on river animals and plants. These people caught fish from spring to fall and also ate turkey, deer, raccoon and other animals. In addition, seeds found at the site indicate the mound dwellers collected plant species that later became the first domesticated plants in eastern North America, Saunders said. Feathers' contribution to the project was to date soil sediments found in mound fill using a technique called thermoluminescence. It uses heat and light to measures the number of electrons trapped in crystalline material and then calculates how long they have been trapped. Feathers operates the only thermoluminescence dating lab in the US that works with archaeological material.
--------
367-> Faster, Cheaper Computer Revolution May Soon End, Say UF Researchers
Writer: Randolph Fillmore rfill@nervm.nerdc.ufl.edu Source: Kevin Jones/Mark Law (352) 392-9872/ 392-6459 GAINESVILLE, Fla. --- The era of smaller, faster and cheaper computers may soon end because microscopic silicon chips are getting so small that eventually they will contain too few atoms to work, warn two University of Florida researchers. 	"The 'road map' says that in about the year 2010 the limit will be reached. Microprocessors will be as small and as fast as they can get. This unhappy news will have an enormous impact on the national economy," said Kevin Jones, professor of materials science and engineering and co-director of UF's SoftWare and Analysis of Advanced Material Processing, the SWAMP Center. Jones and SWAMP co-director Mark Law are concerned that the heart of the Pentium processor transistor, a layer that once was thousands of atoms thick, is getting so small that it soon will be only 50 atoms thick. They say the Pentium processor may eventually shrink itself out of function when it gets to be fewer than 10 atoms thick, in just over a decade. That means unless there is a revolutionary change in computer technology, the trend toward smaller, faster computers will have reached its limit. "The computer industry has its back against the wall," said Law, professor of electrical and computer engineering. "The enormous increase in speed and memory of today's computers came from the ability to make the heart of the microprocessor smaller. But the smaller devices get, the fewer atoms they contain. If the computer industry is going to keep growing and continue to deliver faster products to keep up with consumer expectations, this is a serious challenge that has to be overcome today." The crisis, they say, was predictable, but the industry has always been able to dodge the bullet. "For 30 years, people in the computer industry have predicted the 'just-a-decade-away' demise of the continually shrinking, ever-faster but still inexpensive computer chip," said Law.  "But clever people have been able to push that 10-year window ever farther out." The effectiveness of the incredible shrinking Pentium processor is threatened not only by the declining number of atoms, but also by the impurities in microscopic silicon chips.  To shrink the transistors requires an understanding of the impurities. Law and Jones are using 3-D computer simulation to investigate the nature of the impurities in silicon, which Law said can cause current to flow where it is not supposed to. "The bottom line is that impurities in silicon affect the transistors," said Jones. "The question facing us now is, how do you keep three atoms where you put them and keep the impurities from washing out the crystal? Impurities can cause catastrophic failure." The failure can occur when the impurities run into the crystal and cause the electronic switches to short circuit, said Law. "We are making predictive models for the industry, trying to do as much testing as possible using computer simulation because testing with real materials is so expensive. We need to know how impurities diffuse, at what rate and at what temperature," said Law.  "We can then code that data and build predictive models that allow the industry to design and build better chips."
--------
368-> International Symposium On Oxidative Stress And Brain Damage
The University of Illinois at Chicago will host the Second International Symposium on Oxidative Stress and Brain Damage Sept. 26-28 at the Hotel Inter-Continental, 505 N. Michigan Ave., Chicago, Illinois. The three-day program will cover aspects of basic intracellular mechanisms of oxidativestress-triggered neuronal degeneration, role of endogenous neuroprotective mechanisms, and therole of oxidative stress and neurodegeneration in the pathophysiology of neuropsychiatric diseases. The focus will be on the free-radical-induced injury and how it may play role in aging and in thepathophysiology of diseases such as Alzheimer's and schizophrenia. Among various endogenousmechanisms, the focus will be on the mitochondria, glutamate, and the neurohormone melatonin. The program will consist of lectures by leaders in the respective fields and poster presentations byregistered participants. This program is intended for physicians and basic neuroscientists interested in degenerativeneurologic and psychiatric diseases and new developments in the search for neuroprotectivetreatments. At the conclusion of the program, the participant will be able to: *understand the contribution of oxidative stress to mitochondrial injury and its link to neuronal       apoptosis and pathophysiology of brain neurodegeneration;          *compare the contribution of different neurotransmitter systems in the brain to the occurrence       of oxidative stress and apoptosis;            *trace the pathologic mechanisms that link neuronal degeneration and impaired brain function;               *discuss mechanisms of neurobiological action of the neurohormone melatonin and other        antioxidants and their relevance for neuroprotective therapies. EDITOR'S NOTE: Media covering medicine and science are encouraged to attend the conference. Please call Adrienne Paris at (312) 433-8356 to register.  For more information about the conference and its participants, contact Program Coordinator Dr. Hari Manev at the University of Illinois at Chicago via e-mail at HManev@psych.uic.edu The schedule of speakers and presentations is available on the Internet at http://www.psych.uic.edu/~obd
--------
369-> Blobs In Space: The Legacy Of A Nova
Nova eruptions by dying stars were thought to be simple,predictable acts of violence. Astronomers could point a telescopeat the most recently exploded novae and see an expanding bubbleof gaseous debris around each star. Scientists using NASA's HubbleSpace Telescope, however, were surprised to find that some novaoutbursts may not produce smooth shells of gas, but thousands ofgaseous blobs, each the size of our solar system. Astronomers acquired this new information by focusing the Hubbletelescope's cameras on the recurrent nova T Pyxidis, which eruptsabout every 20 years. Images from ground-based telescopes show asmooth shell of gas surrounding the nova. But closer inspectionby the Hubble telescope reveals that the shell is not smooth atall, but a collection of more than 2,000 gaseous blobs packedinto an area that is one light-year across. Resembling shrapnelfrom a shotgun blast, the blobs may have been produced by thenova explosion, the subsequent expansion of gaseous debris, orcollisions between fast- and slow-moving gas from severaleruptions. Back to the Drawing Board                                                          This new evidence suggests that astronomers may have to rewritetheir theory of nova eruptions and accompanying debris. "Based on these observations, our previously standard view ofwhat nova shells should look like may be fundamentally wrong,"says Michael M. Shara, of the Space Telescope Science Institutein Baltimore, Md. "The view is that a nova explosion is the samein all directions, with debris traveling at the same speed, sothat a fairly smooth cloud is formed. Instead, we've found thismyriad of individual knots [blobs]. This observation suggeststhat shells of other novae do the same thing, as recently ejectedmaterial plows into older, fossil material from previousexplosions." Stellar Detectives Shara and his colleagues collected this new information from fourobservations taken by the Hubble telescope's Wide Field andPlanetary Camera 2 during a 20-month period from 1994 to 1995.Their results appeared in the July issue of the AstronomicalJournal. The scientists selected T Pyxidis because of itscloseness to Earth and its long track record of outbursts. T Pyxidis is 6,000 light-years away in the dim southernconstellation Pyxis, the Mariner's Compass. Within the last 110years, T Pyxidis has been very active, erupting in 1966, 1944,1920, 1902, and 1890. The nova's active record lured Shara to its debris trail morethan a decade ago. His pre-Hubble spectral studies in 1985 usingground-based telescopes showed that the apparently smooth shellwas expanding at the rate of 780,000 mph (350 kilometers persecond). His recent Hubble observations, however, surprisinglyreveal that the material has slowed down considerably since 1985.In fact, the debris is barely moving at all. Images taken monthsapart show no measurable expansion of the debris. Sharadetermined that the knots must be moving slower than 90,000 mph(40 kilometers per second). This may seem fast, but actually thegaseous debris was racing through space almost 100 times fasterwhen it was first blown off the nova. Waves of Violence Ground-based and Hubble telescope observations have allowed Sharato reconstruct a sequence of a T Pyxidis blast. When the novaerupts, it flings waves of gaseous material at progressivelyslower speeds: the first wave of hot gas flies through space at4.5 to 6.7 million mph (2,000 to 3,000 kilometers per second),the last at 446,000 to 670,000 mph (200 to 300 kilometers persecond). About a few weeks after this eruption, the first waves of speedydebris collide with slow-moving fossil material from the previousoutburst, possibly forming the gaseous blobs. Shara observed, forexample, fast-moving gas from the 1966 eruption plowing intoslow-moving material from the 1944 detonation. As the speedy,newly ejected material slams into the older, plodding debris, itheats up, glows brilliantly, and slows almost to a halt. (Thisexplains the tremendous difference in the material's speedbetween the 1985 and the 1994-95 observations.) Eventually, thebright material fades as it cools down. This collision scenariois like cannonballs zipping through a furnace, heating up andglowing, then cooling and fading. Images of a few blobsbrightening and fading over several months were captured by theHubble telescope. Stellar "Tree Rings" The blobs are distributed in eight concentric circles around theexploding star, producing a pattern similar to tree rings. Justas tree rings furnish scientists with information about a tree'slife, so the circles of debris around T Pyxidis provideastronomers with a history of this prolific nova. "We think that we're seeing the collision between pairs oferuptions all the way back to a successive pair generated in theearly 1800's," Shara explains. "But we are seeing only the inner,brightest part of the ejected material; there are probably manymore knots out there that are too faint for even the Hubbletelescope to detect without the nova's future cooperation." Fortunately, the central star is due for another explosion. Sharais scheduled to take observations with the Hubble telescopewithin a few days of the next eruption so that he can map thefaint, ancient outer debris field, which will be illuminated bythe nova's next bright flash. The debris map will show if therecurrent nova has been regularly active for the past thousandyears or more, or if its eruptions occur in cycles. It also mightoffer clues to explain why some novae produce no visible shellsat all. Vampire Star Nova explosions are extremely powerful, equal to a blast of 100billion billion tons of dynamite. All this punch comes fromdying, faint, low-mass stars that have exhausted their hydrogenfuel. Called white dwarfs, these stars have puffed away most oftheir mass until only their cores are left. A nova erupts when a white dwarf has siphoned enough hydrogen offa companion star to trigger a thermonuclear runaway. As hydrogenbuilds up on the surface of a white dwarf, it becomeshotter and denser until it detonates like a colossal hydrogenbomb, leading to a million-fold increase in brightness in oneday. This tremendous flash of light prompted astronomers to callthese objects novae - Latin for "new" - because they abruptlyappeared in the sky. A nova quickly begins to fade in sever 
--------
370-> New Description Of Protein May Be Basis For Regulating Cholesterol
PROVIDENCE, R.I. -- Scientists have described the three-dimensional structure and inner workings of a terpene synthase, a type of protein that synthesizes a naturally occurring class of complex compounds whose members range from the essential oils of herbs, incense and perfumes to the well-known substance cholesterol. By describing a terpene synthase in three dimensions and offering useful clues as to how it operates, the findings provide the groundwork for understanding how to regulate creation of cholesterol in the body. Other common terpenes include pine resins and the essential oils of myrrh, rosemary and thyme. Reporting in the current issue of the journal Science, scientists from the University of Pennsylvania and Brown University present the three-dimensional structure of pentalenene synthase, an enzyme responsible for a key step in the formation of a natural antibiotic. The scientists also explain some of the protein's inner workings. They suggest that pentalenene synthase uses certain amino acids in an internal vessel-like cavity to fold, shape and transform a natural building block - a common plant alcohol derivative - into a particular product. In this case, the product is a terpene molecule that is eventually converted into an antibiotic. The study's lead author is David W. Christianson, a protein crystallographer at the University of Pennsylvania. Additional authors are Charles A. Lesburg, University of Pennsylvania and Brown's Guangzhi Zhai and David E. Cane. Two other papers in this week's Science describe matching structures and inner workings for proteins that form terpene molecules. "The processes involved are similar among all three proteins," said Cane, professor of chemistry and biochemistry. "This presents quite a rich view, indicating that hundreds of these compounds have similar origins." Cane and colleagues are interested in how the protein recognizes, processes and transforms the natural substrate into other products. The scientists used computer models to describe how the substrate might be folded and shaped into an active site in the protein, and identified where those sites were located. Terpenes can teach scientists about nature's chemical processes, Cane said. For example, the reactions discovered inside the proteins usually don't take place in or around water. Somehow, terpene synthases have devised a way to protect the reactions from surrounding water to make any one of hundreds of possible products, he said. Describing the protein's structure is a gateway to more probing studies, Cane said. These include engineering proteins in the laboratory to make new products with unique structures. "If we can understand how a particular protein is designed and works and how pieces of its system function, then in principle we can make designer-engineered proteins with particular properties so as to produce new antibiotics," he said.
--------
371-> Sandia Patents Extreme Ultraviolet Source
LIVERMORE, Calif. - The realization that atomic gas clusters could serve as part of a sort of "light bulb" that emits extreme ultraviolet (EUV) light when laser-heated has inspired a recently patented invention at Sandia National Laboratories. This light source enables research development of EUV lithography to pattern faster, more memory-dense microchips. Until this invention, synchrotron radiation was the most technically mature alternative for creating EUV light for research lithography systems. Advantages of creating EUV light from laser-heated clusters of xenon gas are that the EUV light that can be gathered and used is potentially brighter than that from a synchrotron (which sprays radiation out in a pinwheel pattern), and the light source takes less space. In the Sandia invention, a small jet of xenon gas is cooled to temperatures within a few degrees of absolute zero by supersonic expansion into a vacuum. Xenon clusters, in which thousands of atoms are held together by weakly attractive Van der Waals forces, form at these low temperatures. The xenon clusters are heated to about 500,000 degrees Kelvin with pulses of laser light, becoming a plasma. The plasma re-radiates some of this energy, producing EUV light in the process. Glenn Kubiak, a chemical physicist and Distinguished Member of the Technical Staff in Sandia's Advanced Electronics Manufacturing Technologies Department, received a patent on the laser plasma source invention in November 1996, along with Professor Martin Richardson of the University of Central Florida, who was working on creating laser plasma targets from clusters of water droplets. Kubiak began working on laser plasma sources through the Strategic Defense Initiative program 1987. Sandia began microchip lithography research in 1988. By 1990, Sandia's work on a high-fluence laser plasma source had received an R&D 100 award from R&D magazine. Sandia began a collaboration with AT&T on lithography research in the early 1990s. "It was a natural collaboration," Kubiak said, "because we already had several years of development of laser-produced plasmas at that time." In an EUV lithography research program review at Sandia in April 1996, this source of EUV light allowed lithography researchers to meet several technical milestones showing there were no "show-stoppers" to creating a tool for patterning microchips with this shorter wavelength of light. The shorter wavelength allows creating smaller features than possible with the current commercial process that uses visible light. "The cluster jet was the only thing that could have achieved that in the source area," Kubiak said. Among its advantages are its efficiency at converting the applied laser power to emission of EUV light, and the absence of debris. Creating plasmas from solid laser targets of gold, copper or tin generates debris that coats surfaces of the tool and ruins its ability to image the lithographic features to be patterned at reduced sizes on silicon wafers. This light source is being integrated into Sandia's laboratory research system capable of printing proof-of-principle, functioning microelectronics devices with EUV lithography. The first fully functional transistor patterned with EUV lithography was created on an earlier research lithography system in 1996. To further develop EUV lithography with entirely private funding, Sandia is working as part of a Virtual National Laboratory with Lawrence Livermore and Lawrence Berkeley national laboratories. Last week, Department of Energy Secretary Federico Peña announced the labs will receive $130 million over three years for EUV lithography research from an industrial consortium led by Intel Corp., Motorola Corp. and Advanced Micro Devices Inc. The consortium will spend an additional $120 million during that period on EUV lithography development. Sandia is a multiprogram Department of Energy laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national defense, energy, environmental technologies and economic competitiveness.
--------
372-> UM-Rolla Researchers To Study Aircraft Exhaust Over Ireland
ROLLA, Mo. -- University of Missouri-Rolla researchers will sample airparticles from the world's most heavily traveled flight corridor as part ofan international study of how aircraft exhaust affects the atmosphere. Drs. Donald Hagen and Philip Whitefield -- researchers from UMR's Cloud andAerosol Sciences Laboratory -- are conducting the tests from Shannon,Ireland, starting next week and continuing through Oct. 15. "There is no real problem that has been identified," Hagen says. "Thistesting is like going to the doctor to have a physical. You don't even havea pain in your side. But if we're going to see an effect, this is wherewe're going to see it." Because of the number of flights from North America to Europe, the NorthAtlantic Flight Corridor is the most heavily traveled flight corridor inthe world. In addition to the volume, the aircraft follow narrow,well-defined flight paths. "These paths -- called the Organized Flight Track -- make it particularlyinteresting to study," Hagen says. It's so interesting that American and European scientists are teaming upthrough two programs -- NASA's SONEX project and the European EconomicCommunity's POLINAT 2 program -- to conduct the tests. SONEX stands forSass Ozone and Nitrogen Experiment. POLINAT is the European EconomicCommunity's study, called Pollution From Aircraft Emissions in the NorthAtlantic Flight Corridor. "They decided to combine these operations because the value added would betremendous," Whitefield says. "Bringing the NASA DC-8 with all of its instrumentation on board and the Falcon (a German research plane) with allof its instrumentation on board, plus all the modeling by these scientists,will give us enormous data that will help us understand how aircraftemissions are affecting the atmosphere." The results of this study may one day "provide the evidence upon which thedecision whether or not aircraft engines need to be modified will be made,"Hagen says. This international coordination involves everyone from weather forecastersto air traffic controllers to scientists studying specific data. "We have to know the type of every single aircraft and its engine thatpasses through the flight corridor," Whitefield says. The study begins with the DC-8 operating from Bangor, Maine, gathering testdata from an air mass anticipated to traverse the Atlantic through theOrganized Flight Track. The German research aircraft (the Falcon) will flythrough that same air mass as it passes through the eastern end of theNorth Atlantic Flight Corridor. Tracking the air sample from start to finish is unique to this jointcampaign and will provide the basis for comparison that the scientistsneed, Hagen says. "This is something you couldn't do if you measured the air mass only on oneside of the ocean," Hagen says. "You'd always be trying to guess what theoriginal state of the clean air parcel was." After its initial stint in Maine, NASA's DC-8 will join the German Falconin Ireland. Shannon, Ireland, provides an ideal base of operations. It's not only nearthe flight track, but "we also have exceptional cooperation from the flightcontrollers,"  Whitefield says. Until five years ago, no one knew if it would be possible to measure theeffects of aircraft exhaust on the atmosphere. The first POLINAT, incombination with Germany's DLR program, Deutsche Forschungsanstalt furLuftund Raumfahrt, proved that it was possible. Hagen and Whitefield alsoparticipated in those studies -- in the winter of 1994 and the summer of1995 -- through NASA-funded research. The report on data from the first POLINAT was published in September 1996. "There was no one gusty, one-liner type conclusion," Hagen says. "What thereport did say was that it would be possible to define the effects ofaircraft on an air corridor." According to the report, the combined data shows that aircraft areresponsible for a significant increase in the number of particles oraerosols in the immediate atmosphere in the North Atlantic Flight Corridor. Beyond further testing, this joint campaign will overcome some of thechallenges the scientists have identified to date. During early testcampaigns, they discovered that the pollution from the aircraft exhaustspreads further than they had anticipated, "so we could never get out intoclean air in the studies that we were doing with the range of the aircraftthat we had," Hagen says. "This time the research aircraft will fly throughthe entire air mass between Iceland and the Azores, islands off the coastof Morocco. The plane will have to land and refuel before heading back." Scientists from Germany, Norway, England, France, Switzerland, theNetherlands and the United States are participating in this joint 30-daycampaign. "This is the cream of the cream of the European people in this field puttogether," Whitefield says. "It's a real honor and accolade for us to beinvited to participate."
--------
373-> University Of Cincinnati Archaeologists Uncover Statue Of Roman Emperor Augustus
Cincinnati -- A birthday "surprise" of sorts for Augustus, the first emperor of Rome -- known for his defeat of Egyptian queen Cleopatra and her lover, Marc Antony has been uncovered at Troy by an excavation team led by University of Cincinnati archaeologist Brian Rose. This Tuesday, Sept. 23, marks the 2,060th anniversary of Augustus' birth. Just in time to celebrate this ancient milestone, Rose's team has uncovered a sculpted head of the emperor, measuring slightly larger than life. Still in near-perfect condition, the marble Augustan had lain buried for 1,500 years until members of Rose's team, Cem Aslan, a former UC graduate student from Turkey, and William Aylward, UC graduate student in classics, unearthed it in late July. "Too bad we didn't find it in August, the month named after Augustus," said Rose, who is a native of Marietta, Ohio. "That would have been a nice touch." Rose, author of a book on Roman imperial portraiture published in 1996, recognized the marble face as Augustus immediately because of "his hairstyle, which almost always has two pincer shaped locks over his right eye, plus the shape of his nose and the lines of his forehead," Rose said. The head of what probably was once a more complete statue or bust looked like it was carefully buried outside a Roman theater called the Odeion. Rose, UC associate professor of classics, speculates that the statue once adorned the theater. Troy is most famous as the fabled site of the Trojan War, which, according to legend, took place centuries earlier, during the Bronze Age, but Rose and his team concentrate most of their energy on the Greek and Roman periods at Troy, which the Romans called "Ilion." Since 1988, Rose has worked at the site, which is located in modern-day western Turkey, in partnership with Troy excavation director Manfred Korfmann of the University of Tubingen (Germany). Augustus (63 B.C.-A.D. 14) was a great-nephew of Julius Caesar, who adopted him. He was born Gauis Octavius or as modern historians call him, Octavian. Octavian's reign as Roman emperor began in 27 B.C., and he took the name Augustus ("the Exalted"). His reign was regarded as a Golden Age of Latin literature and an era of civil peace and prosperity. He is known to have visited Troy in 20 B.C., probably to strengthen his claims that he was descended from Troy through Aeneas, who was said to have fled the burning city of Troy and made his new home in Italy. Rome considered its roots to be Trojan. Following Caesar's assassination in 44 B.C., Octavian's mother had urged him to flee further east, but he returned to Rome, gaining support from Caesar's old soldiers. He, Marc Antony and Marcus Lepidus formed a ruling triumvirate, but eventually Mark Antony and Octavian divided the empire between the two of them. Octavian defeated Antony at Actium in 31 B.C. and Egypt in 30 B.C.; afterward Antony and Cleopatra committed suicide. In the popular film, "Cleopatra," Augustus was played by Roddy McDowall. Augustus also showed up briefly in the well-known television series, "I, Claudius." The sculpted image found by Rose will be exhibited in the Canakkale Museum about a 30-minute drive from the site of Troy. The Turkish government has announced plans to construct a new museum near the entrance, which Rose said will allow the antiquities discovered at Troy to be viewed in their original context. The area around the site of Troy also has been designated as a national park, Rose learned this summer. "This will help to ensure that the archaeological remains in the vicinity will be preserved for generations to come. Otherwise, there would be rampant construction of vacation homes along the coast and this construction certainly would have destroyed many antiquities before they could be discovered and studied." Among other significant finds this summer at Troy, according to Rose, are: * Important evidence that Troy once had an extensive wooden fortification network unlike any other discovered so far in the Bronze Age (about 3000-1000 B.C.). This find, coupled with previous discoveries of a wide defensive trench and stone walls, shows that the city had at least three major points of defense, Rose said. "This certainly demonstrates the sophistication of Troy's defensive system during the late Bronze Age." However, the fortification wall cannot yet be linked to and does not prove a Trojan War occurred, Rose warns. * The wooden network included a wooden palisade, which formed a protective south boundary outside Troy's citadel. A parallel series of postholes undoubtedly held support beams for a sentry walk behind the wall, Rose said. Cuttings in the bedrock also provide evidence of an entryway measuring approximately three meters. * An electrum coin (made of a gold and silver alloy) dating to the late fifth century B.C., the earliest coin found so far at Troy. * A series of ovens for casting bronze, datable to the fourth and fifth centuries B.C. The channels into which the molten bronze was poured are similar in shape to modern-day tennis racquets. "None of us has ever seen anything like this," said Rose. The ovens indicate industrial activity in the sanctuary area. * The first Christian discovery since the current excavations began, a bronze reliquary probably dating to the 13th century A.D. The container for relics, shaped like a crucifix, had been emptied when the graveyard in which it was located was robbed.
--------
374-> Mouth-To-Mouth Ventilation's Role In CPR Questioned
A blue-ribbon panel of experts assembled by the American Heart Association has called into question the role of mouth-to-mouth ventilation as an integral part of cardiopulmonary resuscitation (CPR).Their analysis, to be published as a "Special Report" in the September 16 issue of the AHA's journal Circulation, will also appear in coming issues of the journals: Annals of Emergency Medicine, Journal of Respiratory Care, and Resuscitation. Although they are not yet ready to change the current AHA guidelines for performance of CPR, the Ventilation Working Group's consensus statement suggests that in many cases of adult cardiac arrest, mouth-to-mouth ventilation as a part of CPR rarely helps and may even harm the patient. The experts believe that mouth-to-mouth ventilation can interfere with the rescuer's efforts to perform chest compressions and cause significant adverse effects. It makes CPR more difficult to teach, learn and perform, and dissuades bystanders from initiating therapy. More than 350,000 people die from cardiac arrest each year in the United States. Nationally, only a little more than 30 percent receive any form of CPR. In Chicago, that rate falls to 22 percent. "Early CPR using chest compression clearly saves lives," said Lance Becker, M.D., associate professor of medicine at the University of Chicago and chairman of the AHA panel, "but in part because of the complications, complexity and concern associated with mouth-to-mouth ventilation, CPR is not performed for the majority of those who need it." More research needs to be done, the panel insists, to prepare new guidelines for the year 2000. Although it has a long history--the first references to mouth-to-mouth resuscitation involve the prophets Elijah and Elisha in the Old Testament--this form of assisted ventilation became part of CPR dogma only in the 1960s, when it replaced manual techniques such as raising and lowering the arms to encourage breathing. More recently, however, studies have cast doubt on the effectiveness of mouth-to-mouth ventilation in the setting of adult cardiac arrest, where the key determinant of survival is the time from arrest until defibrillation, when the heart is shocked back into a normal rhythm. Unlike victims of near drowning or choking where mouth-to-mouth ventilation can quickly improve oxygen levels, low blood flow is the primary disorder for those who suffer a cardiac arrest. Without significant blood flow, even with the low level of blood flow produced by chest compressions, forcing air into the lungs will not make much difference. Besides, when the heart stops, oxygen levels in the blood decline gradually. Many patients continue to gasp for air and chest compressions induce some air exchange. Assisted ventilation appears to become important only after four to 10 minutes of CPR. "It may be time to reshuffle the cardiac-arrest survival alphabet," suggests Becker, "from the old ABC (for Airway, Breathing and Circulation) to CAB (Circulation, Airway, Breathing), as they have already done in the Netherlands." Mouth-to-mouth ventilation has its own costs. Exhaled air contains 17-percent oxygen, less than the 21-percent of fresh air, and four-percent carbon-dioxide, which can inhibit cardiac contraction. Studies have found that from 10 to 35 percent of patients who receive CPR inhale stomach contents, emitted after air is blown into the stomach rather than to the lungs. And time allocated to ventilation, especially if only one rescuer is involved, is subtracted from the efforts to provide chest compressions. Even for healthcare professionals, with continuous coaching, only 15-percent involved in studies of one-rescuer CPR on a mannequin achieved the recommended rate of 80 compressions per minute when they tried to perform both chest compression and mouth-to-mouth ventilation. Perhaps most important, mouth-to-mouth ventilation appears to discourage bystanders from providing needed CPR. "When mouth-to-mouth ventilation is combined with chest compression, the CPR technique becomes a complex psychomotor task that can be difficult to learn, teach, remember and perform," note the authors. "A simpler technique might lead to more widespread performance," added Becker, "which would improve survival rates." Mouth-to-mouth contact also makes potential rescuers squeamish. Not only lay persons but many physicians, nurses and even CPR instructors are extremely reluctant to perform mouth-to-mouth ventilation. Although the risks of disease transmission are quite small, and there have been no reports of HIV transmission, there have been isolated reports of infectious agents such as herpes, TB, salmonella and others being exchanged during CPR. "It can be pretty yucky," admits Becker. "When people practice CPR on a dummy they imagine Cindy Crawford or Tom Cruise, but the guys who drop in the supermarket tend to resemble Rodney Dangerfield. I think that's yet another reason bystander CPR is already far too rare and is becoming even less common." Until new guidelines are formulated, Becker advises those who witness a cardiac arrest: "Just do it. First, call 911. Then, if mouth-to-mouth ventilation bothers you, skip it and concentrate on chest compressions. That is far, far better than doing nothing." The panel also emphasized that immediate mouth-to-mouth ventilation remains critically important for children and for adults where cardiopulmonary arrest results from airway obstruction, drowning, or respiratory problems. Other members of the panel were Robert A. Berg, M.D.; Paul E. Pepe, M.D.; Ahamed H. Idris, M.D.; Thomas P. Aufderheide, M.D.; Thomas A. Barnes, Ed.D., R.R.T.; Samuel J. Stratton, M.D.; and Nisha C. Chandra, M.D.
--------
375-> Attempts To Contact Lewis Spacecraft Unsuccessful; Re-Entry Likely Next Week
Repeated attempts to re-establish radio contact with NASA's Earth-orbiting Lewis spacecraft since it entered a slow spin on Aug. 26 have been unsuccessful.  Due to increasing atmospheric drag, the spacecraft's orbit is deteriorating.  Unless contact is regained early next week, it is expected to re-enter and burn up between Sept. 23-30, with Sept. 27 as the current most likely re-entry date, according to program officials. "Based on our previous experience with this type of spacecraft, we expect Lewis to burn up in the atmosphere.  The probability that any part of it will survive is very low, and it presents no significant threat to people on the ground," said Samuel Venneri, Chief Technologist at NASA Headquarters, Washington.  "The potential loss of this mission is an obvious disappointment.  However, the process of designing and building the spacecraft taught us a great deal about how to integrate cutting-edge technology into small missions and how to prepare the associated science teams, and we will apply those lessons to future projects." Lewis was launched on Aug. 22 (Aug. 23 EDT) from Vandenberg Air Force Base, CA,  aboard a Lockheed Martin Launch Vehicle (LMLV-1).  Built by TRW Space & Electronics Group, Redondo Beach, CA,  the 890-pound Lewis satellite is part of NASA's Small Spacecraft Technology Initiative. "We are aggressively applying the company's resources in our ongoing attempt to recover the satellite, and we greatly appreciatethe tremendous support that NASA and other government agencies havegiven us in this effort," said Paul Sasaki, vice president and generalmanager of the TRW Civil & International Systems Division. Initial operations and check-out of Lewis were proceeding satisfactorily until telemetry received early August 26 indicated that the spacecraft was spinning at approximately two revolutions per minute.   Preliminary indications are that unbalanced thruster firings occurred on the spacecraft, inducing a spin rate that went unchecked as Lewis remained in a previously commanded safehold. The solar arrays on Lewis were unable to generate significant power due to the spinning motion and their alignment with the Sun, and thus the spacecraft's batteries became almost fully discharged.  Initial hopes that sunlight would "trickle charge "the batteries sufficiently to allow the spacecraft's transmitter and computer to be accessed were not borne out by subsequent operations. An independent Lewis spacecraft anomaly review board, to be chaired by a non-NASA official, is being established.  It is expected to report its findings approximately 60 days after re-entry. Outfitted with advanced technology Earth-imaging instruments and subsystems intended to push the state-of-the-art in scientific and commercial remote sensing, Lewis featured remote-sensing instruments designed to split up the spectrum of light energy reflected by Earth's land surfaces into as many as 384 distinct bands.  Potential commercial applications included pollutant monitoring, analysis of endangered species habitats, estimation of forest and agricultural productivity, soil resources and crop residue mapping and assessments of environmental impacts from energy pipelines. The total cost to NASA of the Lewis mission, including its launch vehicle and one year of planned orbital operations, is $64.8 million.  NASA incurred an additional cost of $6.2 million for storage and maintenance of the spacecraft during a one-year delay due to launch vehicle issues. Lewis is part of NASA's Mission to Planet Earth enterprise, a long-term research program designed to study the Earth's land, oceans, air and life as a total system.  Upcoming Mission to Planet Earth spacecraft such as the New Millennium program's Earth Orbiting-1 mission, due for launch in June 1998, should help scientists address some of the planned applications of Lewis data. -end- EDITOR'S NOTE: The U.S. Space Command in Colorado Springs, CO, will perform its normal orbital tracking duties as the orbit of Lewis degrades.  Updated re-entry forecasts are available from its public affairs office at 719/554-6889.
--------
376-> Facing The Issue: New Research Shows That The Brain Processes Faces And Objects In Separate Brain Systems
WASHINGTON, D.C. September 15 -- Some hair is missing. Nevertheless, you recognize John McEnroe, the TV announcer who once ruled tennis with his intense serve and tantrums. New research indicates that ability to identify a face occurs in a special brain system. And surprisingly, the system is separate from the general purpose visual processing system that identifies objects such as tennis balls, sneakers, and stadiums. "The results provide one of the more startling demonstrations that the brain is comprised of highly specialized processing areas, even for the perception of complex stimuli such as faces," says the study's lead author, Morris Moscovitch, of Rotman Research Institute at Baycrest Centre for Geriatric Care and the University of Toronto at Mississauga, Ontario. Moscovitch's study, funded primarily by the Medical Research Council of Canada, is published in the September issue of the Journal of Cognitive Neuroscience. "The study presents such a clear and striking dissociation between face and object recognition," says Daniel Schacter, a memory expert at Harvard University. "This dissociation was suspected before, but this research is an exceptionally clear example." In the study, researchers performed 19 tests on a man known as CK who sustained brain damage in a road accident. CK can no longer read and has great difficulty recognizing common objects such as animals, flowers, trees, cars, furniture and utensils. "What is remarkable is that despite these difficulties, his ability to recognize faces seems to be completely normal, even though recognizing faces is much more difficult than recognizing that a small, straight, yellow object with a dark, pointy tip is a pencil," says Moscovitch. "The stark contrast between CK's normal face recognition and poor object recognition suggests that faces are special and that there are different brain systems devoted to recognizing faces and objects." In the experiments, CK reviewed groups of pictures and revealed that he could recognize a face under a variety of circumstances. The researchers found that CK could recognize faces in photos even when they were altered with wigs, facial hair, glasses and hats, or age. In addition, he could identify family resemblance between faces. "We also learned that the face-recognition system is not specialized for dealing only with the full human face, but can detect any reasonable facsimile of it," says Moscovitch. For example, CK could recognize caricatures of famous people and the faces of cartoon characters. Additional results indicate that the face-recognition system requires a visual code for activation. "The code is the upright configuration of facial features, especially the mouth, nose and eyes -- a facial template of sorts," says Moscovitch. "Anything that conforms to the code, even an arrangement of objects, will trigger the face-recognition system." For example, researchers found that CK could recognize faces comprised of different foods by the Italian painter Giuseppe Arcimboldo. While CK often was not aware that the pictures contained foods (objects), he knew that a large mushroom posing as a mouth, a turnip as a nose, and garlic as eyes, together depicted a face. On the other hand, CK's recognition of faces plummeted when the code was disturbed. He had difficulty making an identification if the face was inverted, fractured or if the top and bottom halves were misaligned. The researchers plan to identify more precisely the visual code of a face and locate the brain regions that constitute the face-recognition system. In addition, they plan to determine how the face- and object-recognition systems interact to produce a unified, seamless visual perception of the world. Moscovitch's co-authors were Gordon Winocur of Rotman Research Institute and Trent University and Marlene Behrmann of Carnegie-Mellon University. Moscovitch is a member of the Society for Neuroscience, an organization of more than 27,000 basic scientists and clinicians who study the brain and nervous system.
--------
377-> Duke Researchers Show How Hepatitis Infection Leads To Liver Cancer
DURHAM, N.C. -- Hepatitis B and C infections slowly eat away at a person's liver, severely damaging liver function and greatly increasing the risk of liver cancer. Now researchers at Duke University Medical Center have discovered the hepatitis virus makes the liver into a cancer time bomb by converting the organ into billions of cancer-prone cells. The finding, published in the Sept. 16 issue of the Proceedings of the National Academy of Sciences, demonstrates that once a hepatitis infection takes hold in the liver, even apparently healthy cells have lost one of two copies of a protective tumor suppressor gene called M6P/IGF2R, making them highly vulnerable to further genetic damage. Without a working copy of this suppressor gene, cancerous cell growth can't be stopped. "This finding demonstrates that hepatitis infection somehow favors survival of a subset of liver cells that are defective in a key cancer protective gene we know is an early marker for development of liver cancer," said Randy Jirtle, lead investigator of the study. "This is a first step in understanding how the hepatitis virus damages the liver and greatly increase the chance of developing liver cancer." In addition, he said a test for the gene may help surgeons determine how much tissue surrounding cancerous liver lesions needs to be removed. Some of that "normal-looking" tissue may already be on the path to cancer, he said. The discovery is particularly relevant because hepatitis, particularly hepatitis C, is responsible for about 85 percent of liver cancer cases in the United States. The Centers for Disease Control and Prevention (CDC) estimates that 3.9 million Americans are infected with hepatitis C. Complications from hepatitis C are blamed for 10,000 deaths per year, but the CDC estimates the fatality rate could triple or quadruple within 15 years. There is no effective treatment for hepatitis C, which is transmitted through contaminated blood. Most people become infected through intravenous drug use, which accounts for half of all infection. But nearly half of the people who become infected have no identifiable risk factors. Eighty percent of those who become infected develop chronic hepatitis, in which symptoms may be vague or missing for a decade or more. During this silent period, the viral infection is slowly killing off healthy liver cells. The cells that remain, the researchers discovered, are genetically damaged, but still capable of regenerating the liver. The result is that much of the liver becomes a clone of genetically identical pre-cancerous cells. Eventually, one of those cells may sustain additional genetic damage during its normal function of detoxifying chemicals. Since these cells are already cancer-prone, they may not be able to "fix" the genetic damage, said Jirtle, and they become cancerous tumors. The research was supported by a grant from the National Institutes of Health, and in part by Sumitomo Chemical Co. and Zeneca Pharmaceuticals. The research team included Jirtle, professor of radiation oncology at Duke; Tomoya Yamada of Sumitomo Chemical Co., Osaka, Japan; Angus De Souza of Zeneca Pharmaceuticals, Cheshire, U.K.; and Sydney Finkelstein of the University of Pittsburgh Medical Center. Previous studies by Duke researchers showed the tumor suppressor gene M6P/IGF2R, which stands for mannose 6-phosphate/insulin-like growth factor II receptor, is often mutated in early-stage liver tumors, demonstrating that it plays an important role in the initial progression to liver cancer. The new study now links loss of the gene to hepatitis infection. Normally, people have two copies of this cancer-fighting gene. Even if one copy of the gene has a mutation, the other good copy can usually compensate. But when the remaining good copy becomes deleted through a second mutation, the protein's tumor-fighting ability is lost completely. The M6P/IGF2R protein is present in all cells of the body, where it performs several important functions that control cell growth, Jirtle said. It deactivates the potent growth promoter, IGF2, and it helps to activate a potent growth inhibitor called transforming growth factor beta 1 (TGFB1). Hepatitis infection may favor survival of defective cells that lack one copy of this growth inhibitor gene because these cells have a growth advantage, Jirtle said. Another possibility is that these cells are somehow protected from viral infection, he said. "Our finding that M6P/IGF2R inactivation is an early event in the development of liver cancer may provide a powerful approaches for diagnosis and treatment of liver cancer," said Jirtle. "We now have a marker for one of the earliest events in the progression to liver cancer in hepatitis-infected patients."
--------
378-> UF Researcher: Elderly Who Live In Low Income Housing Largely Ignored
Writer: Cathy Keen -- (352) 392-3140 Source: Stephen Golant -- (352) 371-0797 GAINESVILLE, Fla. --- The Sunshine State is the sunset state for many of the 75,000 elderly people whose needs are left unserved in government subsidized housing, says a University of Florida researcher. While the popular image of Florida retirees includes retirement centers with tennis courts and golf courses, those who live in government housing are more likely to be frail, ignored or subject to the whims of their apartment managers, said Stephen Golant, a UF gerontology professor who is launching a statewide, 19-month study of the problem. The study is funded by the Chicago-based Retirement Research Foundation through a $170,000 grant to UF. Given the state's sizeable elderly population and the wave of aging baby boomers, the findings could provide guidance for the rest of the nation, he said. "The many older people who live in rent-subsidized housing are among the state's poorest and most vulnerable residents," Golant said. "The CASERA Project -- Creating Affordable and Supportive Elder Rental Accommodations -- is the first Florida study designed to understand the needs of an older population that, to a large extent, has been ignored. "There's a misunderstanding that because these people are in government subsidized housing that somehow their needs will be automatically taken care of," Golant said. "This simply is not the case. Federal programs are small and erratically funded." Because residents of subsidized housing are largely female with little education and no economic clout, managers often determine whether they remain in their apartments or are forced to move to nursing homes or someplace else with more supervision once they become frail, Golant said. "These older people are much more subject to administrative rules and the influence of housing managers than they would be if they lived in their own home or in a private apartment building," he said. "Their mishaps and illnesses are much less a private affair." Nationally, about 25 percent of older people living in low-income housing suffer from some form of frailty, making it difficult for them to get around and take care of themselves, whether it is shopping, cooking or bathing, Golant said. About 7 percent experience problems with mental functioning, ranging from occasional memory lapses to the early stages of Alzheimer's disease, he said. When an elderly resident of government housing breaks a hip and must spend months recovering in a rehabilitation center, the housing manager may decide it is too costly to keep the patient's apartment vacant and rent to someone else, he said. The aim of the UF study is to determine not only the extent of frailty among people 62 and older living in rent-subsidized housing in Florida, but also how apartment managers, service providers and state programs can help tenants deal with their frailties and which care strategies are likely to work better than others. The study's ultimate goal is to help elderly residents of low-income housing be able to age in their homes, Golant said. "Otherwise these people become prime candidates for nursing homes at taxpayer expense," he said. "Because they are poor, they can't afford to pay for their own long-term care. "Sometimes if an elderly person can receive just a little assistance, perhaps in the form of a personal aide coming to help with grooming or a bath, it may mean the difference between staying in what has become home and having to move out," Golant said. There also is a benefit for housing managers: an economic incentive for knowing which services their tenants could use to avoid major health problems, Golant said. By helping elderly residents stay put, managers can avoid the hassles of apartment turnover, such as advertising for new occupants or cleaning and painting rooms, he said. Such measures have the potential to reach a large and forgotten group of state residents, said Golant, who plans to survey Florida's apartment managers, service providers and directors of housing authorities.
--------
379-> Infants Have Keen Memory For Learning Words
Be careful what you say; little ears might be listening. And remembering. Experimental psychologists have found that infants seem toremember relatively complex words, even when they only hear thosewords in tape-recorded stories without the benefit of any otherstimuli. Audio-taped children's stories containing words like"peccaries" and "python" were played to 8-month-old infants once aday for 10 days; two weeks later, 36 words that occurred mostfrequently in the stories were played back to the babies in listform. Perhaps the most remarkable finding was that the babiesrecognized the words, even though they sounded different in listform than they did in the stories. "When we just read a list, we actually pronounce those wordsa little bit differently; those words have a very differentacoustic form than they had in the stories," said Peter Jusczyk,a professor in the Department of Psychology at The Johns HopkinsUniversity. But the experiments indicated that the infants rememberedthe words they had heard in the stories, suggesting that babiesmemorize words that occur frequently in speech, an importantprerequisite for learning language. The findings will be detailed in a paper to be published onSept. 26 in the journal Science. Although much work has been conducted to investigate howchildren learn the meanings of words, there has been littleresearch aimed at learning how infants focus on the sounds ofwords, said Jusczyk, who co-authored the paper with Elizabeth A.Hohne, a psychologist at AT&T Labs in Holmdel, N.J. The scientists recorded women narrating three differentchildren's stories, each lasting about 10 minutes. Thenresearchers visited the homes of 15 infants, playing the storiesto them every day for 10 days. In the end, the 8-month-old babieshad heard each story 10 times. The psychologists identified the 36 content words -- usuallynouns -- that occurred most frequently in the stories. Then theyarranged those words in lists of 12 words each. Two weeks after the final visit to the infants' homes, thebabies were brought to Jusczyk's lab at Johns Hopkins. One at atime, they were placed inside a special testing booth, where theylistened to the lists containing the words that occurred mostfrequently in the stories. Then they listened to lists of other,similar-sounding words that did not occur in the stories. A light flashed above the speaker through which the taperecording was played. When the infants looked at the light, theword lists began and continued to play as long as the infantslooked toward the light. Babies who stopped listening to thewords looked away from the light, telling the researchers howlong the infants had listened to specific lists of words. "What we found was that the babies listened longer to thelists of words from the stories, significantly longer," Jusczyk said. Previous research using the technique has shown that infantstend to listen longer to words that are more familiar to them. Theresearchers, however, wanted to make sure that the infants were not listeninglonger to the story words simply because they found them moreinteresting, so they brought a new group of infants to the labwho had never heard the stories on tape. When those infants heard the lists ofthe story words and the non-story words, they showed no preference andactually listened slightly longer to the non-story words. "That showed us that the experience the babies had had athome listening to the stories had an impact on what they reallyremembered," Jusczyk said. He noted that the infants learned the words eventhough they never had any personal contact with the women who narrated thestories. "So, imagine what happens when you actually have the baby inyour arms, and you are reading the story and you are turning thepages of the book," he said. "You'd expect that they would beeven more inclined to store some of that information." The babies who had never heard the stories listened anaverage of about six seconds to the story words and slightly morethan that for the non-story words. The infants who had heard thestories listened an average of less than six seconds to thenon-story words but nearly seven seconds to the story words. "A second doesn't sound like a lot of time, but it'sconsistent," Jusczyk said. "The whole object of this was to seewhether, when infants are listening to people talk or listeningto people read stories to them, they are storing any informationaway about sound patterns that occur frequently." Ultimately, scientists are trying to learn how youngchildren are able to learn and master the complexities oflanguage, a difficult task for the adult brain and the mostpowerful computers. At about 18 months, a child's vocabulary and grasp oflanguage suddenly expand, and scientists don't know why. Onepossible explanation is that children may begin storing thesounds and meanings of words while they are infants, and suddenlythey are able to connect the words with meanings. "It's sort of like working on a puzzle. You get a few piecesand then everything falls into place," Jusczyk said. Learning words requires storing both sounds and meanings.This study shows that infants sometimes store the sounds ofwords, even when they have not yet learned the meanings, he said. This research was supported by the National Institute of Child Health andHuman Development of the National Institutes of Health. More information on Jusczyk and his research is available from his WorldWide Web page at http://www.psy.jhu.edu/~jusczyk ### EMBARGOED FOR RELEASE AT 4 P.M. EDT ON THURSDAY, SEPT. 25, 1997 Johns Hopkins University news releases can be found on the World Wide Web athttp://www.jhu.edu/news_info/news/ 
--------
380-> Cancer Protection Compound Abundant In Broccoli Sprouts, Johns Hopkins Scientists Find
Johns Hopkins scientists have found a new and highly concentrated source of sulforaphane, a compound they identified in 1992 that helps mobilize the body's natural cancer-fighting resources and reduces risk of developing cancer. "Three-day-old broccoli sprouts consistently contain 20 to 50 times the amount of chemoprotective compounds found in mature broccoli heads, and may offer a simple, dietary means of chemically reducing cancer risk," says Paul Talalay, M.D., J.J. Abel Distinguished Service Professor of Pharmacology. Talalay's research team fed extracts of the sprouts to groups of 20 female rats for five days, and exposed them and a control group that had not received the extracts to a carcinogen, dimethylbenzanthracene. The rats that received the extracts developed fewer tumors, and those that did get tumors had smaller growths that took longer to develop. In a paper published in tomorrow's issue of the Proceedings of the National Academy of Sciences, Talalay and his coworkers describe their successful efforts to build on their 1992 discovery of sulforaphane's chemoprotective properties. Work described in the study is the subject of issued and pending patents. A systematic search for dietary sources of compounds that increase resistance to cancer-causing agents led the Hopkins group to focus on naturally occurring compounds in edible plants that mobilize Phase 2 detoxification enzymes. These enzymes neutralize highly reactive, dangerous forms of cancer-causing chemicals before they can damage DNA and promote cancer. Sulforaphane "is a very potent promoter of Phase 2 enzymes," says Jed Fahey, plant physiologist and manager of the Brassica Chemoprotection Laboratory at Hopkins, and broccoli contains unusually high levels of glucoraphanin, the naturally-occurring precursor of sulforaphane. However, tests reported in the new study showed that glucoraphanin levels were highly variable in broccoli samples, and there was no way to tell which broccoli plants had the most without sophisticated chemical analysis. "Even if that were possible, people would still have to eat unreasonably large quantities of broccoli to get any significant promotion of Phase 2 enzymes," Talalay says. Clinical studies are currently under way to see if eating a few tablespoons of the sprouts daily can supply the same degree of chemoprotection as one to two pounds of broccoli eaten weekly. The sprouts look and taste something like alfalfa sprouts, according to Talalay. Talalay founded the Brassica Chemoprotection Laboratory, a Hopkins center that focuses on identifying chemoprotective nutrients and finding ways to maximize their effects. Brassica is a plant genus more commonly known as the mustard family, and includes in addition to broccoli, Brussels sprouts, cabbage, kale, cauliflower and turnips. "Man-made compounds that increase the resistance of cells and tissues to carcinogens are currently under development, but will require years of clinical trials to determine safety and efficacy," Talalay notes. "For now, we may get faster and better impact by looking at dietary means of supplying that protection. Eating more fruits and vegetables has long been associated with reduced cancer risk, so it made sense for us to look at vegetables. "Scientists currently need to continue to develop new ways of detecting and treating cancer once it is established, but it also makes sense to focus more attention on efforts to prevent cancer from arising," he adds. Fahey and Yuesheng Zhang, M.D., Ph.D., a postdoctoral fellow, are also authors on the PNAS paper. Work in Talalay's laboratory is supported by the National Cancer Institute, philanthropic contributions to Brassica Chemoprotection Laboratory, and grants from the Cancer Research Foundation of America and the American Institute for Cancer Research. Talalay is establishing the Brassica Foundation, a foundation that will test and certify chemoprotective vegetables such as sprouts to raise funds for chemoprotection research.
--------
381-> Shuttle-Mir Program Readies For Next Phase -- The International Space Station
With three-fourths of the Shuttle-Mir program nearly complete, science investigators and mission managers are preparing for the next phase of cooperative efforts that will lead to the most ambitious peacetime scientific project ever undertaken -- the International Space Station. The next phase of Shuttle-Mir includes more planned science experiments than any previous stay by a U.S. astronaut. "The importance of this program cannot be overestimated," said Shuttle-Mir program manager Frank Culbertson.  "This is where theory meets reality, where the practical lessons we learn aboard the Mir are already paying large dividends as we prepare to start construction of the Space Station in less than a year." The launch of Dr. David Wolf aboard Atlantis next week on the STS-86 mission continues a research program started with Dr. Norm Thagard's stay on Mir in 1995 and includes 35 scientific studies and technology demonstrations spanning six research disciplines.  Wolf's flight furthers the continuous U.S. presence in space that began with Shannon Lucid on the STS-76 mission in March 1996. At the start of Wolf's mission, the total U.S. astronaut time aboard the Mir will be 22 months -- with 18 months of continuous occupancy since March 1996. Wolf's mission to Mir specifically involves six research disciplines including advanced technology, Earth sciences, fundamental biology, human life sciences, microgravity research and a category for learning the lessons necessary to successfully build the Space Station -- the engineers call it "risk mitigation." Despite the June 25 collision of a resupply vehicle with the Mir, most of the research for Wolf's mission will go ahead.  The loss of life sciences hardware will be partly offset by the launch of replacement equipment and by new techniques for achieving scientific goals.  Following two successful spacewalks, which increased available electricity aboard the Mir, U.S. science operations during Wolf's mission to Mir are not expected to be limited by power. The investigations from this mission will add to the growing body of results from the program.  To date, approximately 120 U.S. scientific studies have been conducted aboard Mir by researchers from the United States, Russia, Canada, France, Germany, Hungary and Japan.  Several significant accomplishments from Shuttle-Mir research are described below. - Of prime importance to the health of crew members and basic research is the monitoring of the Mir's environment.  Given time aboard the Mir, station researchers have learned to better monitor vital factors such as air and water quality and radiation levels.  These techniques have been validated and will continue to be used on the Space Station. These studies have shown that the Mir environment is safe for crew members, and in the case of occasional temporary incidents, proper monitoring and adequate protective measures are available. - Studies aboard the Mir have allowed more precise characterization of human physiology and psychology in space, in particular changes in bones and muscles, the neurovestibular system, the risk of developing kidney stones in space, and changes in the interactions among crew members and their ground support team over the course of the mission. - The space flight-induced changes seen in muscles and bones are similar to those seen in bedridden or osteoporotic patients and characterization of these changes in healthy crew members may lead to better methods of rehabilitation and treatment for patients on Earth.  The Shuttle-Mir program has allowed NASA to evaluate the effectiveness of the countermeasures that the Russians have developed over the past 25 years to minimize the effects of long-term weightlessness. - New techniques and methods have been used to produce protein crystals and other substances, providing both qualitative and quantitative improvements over ground-based and previous space-based experiments.  The long-duration nature of this program has allowed researchers to produce some crystals that cannot be grown on the Shuttle or on Earth.  Analysis of the higher quality crystals grown on Mir permits better understanding of their molecular structure, leading to better understanding of viral interactions with antibodies, enzyme functions, and possibly new pharmaceutical products. - Aboard a space station, microgravity experiments are especially sensitive to vibration.  A study using new sensors has measured vibration levels of normal work routines and how that may affect experiment processing.  The study, begun in 1996 by Shannon Lucid aboard Mir, has measured much lower vibrations on Mir compared with data obtained during the U.S. Skylab program of the 1970s.  This information is directly beneficial to the Space Station Program where it is being used to assess the potential impact of crew motion on the microgravity environment. - The promise of tissue culturing in space has been dramatically advanced by work aboard the Mir.  NASA was able to extend the duration of space tissue growth from 10 days to four months, with the successful culturing of cartilage cells in an onboard bioreactor.  Wolf was a member of the research team that originally developed the bioreactor design at the Johnson Space Center, Houston, TX. - On Earth, tissue culturing is largely limited to two dimensions.  In the space flight experiment, the tissue grew in a three-dimensional structure more like tissue in a living organism would grow.  In addition to the scientific result of the experiment, NASA learned how to upgrade the facility for future use on Mir as well as on the Space Station. - Growing plants in space is of scientific interest for botanists and future space flight operations.  A significant first in this area has been achieved during the Shuttle-Mir program when seeds generated by plants grown in space were planted and germinated to grow new plants -- the first so-called "seed-to-seed" experiment in space.  This is a significant development in the ability to grow plants in space and was achieved after the Spektr collision during the low-power period on Mir. - Russian, Canadian and U.S. facilities aboard Mir have been used to perform experiments in fluid physics, combustion science, colloid science, metallurgy and diffusion of liquids such as metals heated in a furnace.  The facilities included furnaces, a glovebox to contain experiments as required, and a system to isolate experiments from the station's vibration environment.  Some experiments tested, verified or modified basic theories in fluid physics. - The controlled combustion experiments provided a better understanding of how flames spread in space.  Colloids, solid particles suspended in liquid, are seen in every day life as cosmetics, paints and other industrial products, and their study in weightlessness without the disturbing influence of gravity can lead to better commercial products here on Earth. - The astronauts on Mir have substantially added to the growing database (about 300,000 images) of Earth observation photographs.  During their months aboard the Mir, crew members have observed and recorded long-term and seasonal changes in various areas of interest.  Agricultural patterns, global deforestation and drying up of lakes can be monitored over long periods of time.  In addition, astronauts have observed and photographed rapidly occurring events such as volcanic eruptions and fires that otherwise may have gone unobserved. - New findings about the South Atlantic Anomaly's northwestward migration have been published based on results from Mir, and a better understanding of the solar cycle has been made possible. - Investigators preparing for the International Space Station program have learned a great deal from experiments monitoring the external environment of Mir which, in many cases, will be similar to the external conditions around the Space Station.  Sensors placed on the outside of Mir have detected everything from micrometeoroids to leftover specks from spent rocket stages.  The data also show that large detectable pieces of orbital debris in some cases may be accompanied by clouds of particles too small to detect, but that may also cause deterioration of solar panels and other external structures.
--------
382-> Zebra Mussels Are Spreading Rapidly, USGS Reports
Zebra mussels expanded their range in the past year, invading 11new lakes in the Great Lakes region and dramatically increasing in LakeChamplain, according to U.S. Geological Survey biologists.  The smallfresh-water mussels have continued to impact industrial sites, watersupplies, natural ecosystems and motorized boats from Canada to the Gulf ofMexico, the scientists reported. Biologists have tracked the zebra mussel since 1988 when it wasfirst detected in Lake St. Clair, a small lake in the Great Lakes chain.  Anew 1997 distribution map shows zebra mussels have spread to 19 states inless than 10 years.  The USGS reports new locations in Lake Champlain onthe New York-Vermont border and along the Ohio and Monongahela Rivers. Older populations in the Great Lakes and the Mississippi River continue tospread.  And, biologists believe the population in the Tennessee River hasyet to reach its peak. Native to Eastern Europe and Asia, zebra mussels have few naturalenemies in the U.S. and their rapid reproduction has caused widespreadeconomic and environmental damage. Concentrating at underwater sites wherewater flows rapidly, zebra mussels have clogged intake pipes of communitywater systems and power stations and have fouled the engine cooling systemsof recreational boats, the USGS scientists said.  In May, it was reportedthat a paper company had to remove 400 cubic yards of zebra mussels fromits intake in Lake Michigan at a cost of $1.4 million. The USGS tracks and maps the spread of zebra mussels at its FloridaCaribbean Science Center in Gainesville.  Updated information is madeavailable to federal, state and local officials, universities and privateindustries. "The zebra mussel invasion is of grave concern. Our scientistsplay an important role in helping develop a blueprint for those chargedwith fighting its spread," said USGS Chief Biologist Denny Fenn. "The maps developed at Gainesville help focus our research programsby identifying vulnerable sites and conditions,"  Fenn said.  Other USGSbiological research centers are developing and testing a wide range ofstrategies to control the spread of the zebra mussel or minimize itsimpact, he said. "Zebra mussels are extraordinarily persistent," said Fenn. "Theyare small, can attach themselves to a variety of surfaces and can surviveseveral days out of water.  In fact, live zebra mussels have been reportedin California and Virginia where they were found attached to boats beingtrailered from the Great Lakes." Scientists fear that recreational boaters may unknowingly spreadthe zebra mussel from infested rivers and lakes to previously unaffectedwaterways.  "That's why we are being so vigilant in our mapping andmonitoring efforts," said Fenn. It is believed that zebra mussels entered the Great Lakes in theballast water of commercial ships from abroad.  As the ballast tanks wereflushed, the mussels were inadvertently introduced to an environment wherethey could thrive without natural enemies to control their numbers. Theirrapid distribution throughout the Great Lakes and major U.S. river systemsis attributed to their ability to attach to boats and barges using thesewaterways. Zebra mussels were named for the striped pattern of their shells.On average, zebra mussels are less than an inch long, yet each filtersabout a quart of water per day to feed on algae.  Zebra mussels attachthemselves to hard or rocky surfaces, and will even attach to vegetation. Layers of zebra mussels several inches thick coat large areas of substratein Lakes Erie and Ontario, USGS biologists reported, elevating concernsabout the survival of remaining native mussels. The invaders attach themselves to the native mussel species,interfering with their feeding, growth, movement, reproduction andrespiration.  This is of particular concern since North America has thegreatest variety of native mussel species in the world, many of which areendangered, said Chief Biologist Fenn. The zebra mussels' impact on the economy is felt at hydroelectricand nuclear power plants, industrial facilities, and public water supplieswhere colonies can be dense enough to cut off water flow and affectcondensers, firefighting equipment, air conditioning, and cooling systems. The U.S. Army Corps of Engineers reported new sightings of zebramussels this year on the Ohio River at Dashields Lock and Dam west ofPittsburgh and at Lock 3 on the Monongahela River near Elizabeth, PA. In states adjacent to the Great Lakes, zebra mussels continued to expand theirrange into many small lakes.  Zebra mussels were reported from 90 lakes inthe eight states bordering the Great Lakes, up from 79 a year ago.Biologists are extremely concerned about a dramatic increase inrange and reproduction of zebra mussels in Lake Champlain. Zebra mussels can be found throughout the lake, even in the northeastern arm where theyhad not been previously reported, USGS scientists said.Information on zebra mussel distribution is used by the U.S. Department of the Interior, National Oceanographic and AtmosphericAdministration (NOAA), the U.S. Army Corps of Engineers, Tennessee ValleyAuthority, state agencies, universities, and numerous U.S. and Canadianprivate industries. According to Amy Benson, the USGS zebra mussel database manager,"Distribution information is available to anyone who can access theInternet."  To see the zebra mussel maps and to track their spread from1988 to 1997, visit the USGS web site athttp://nas.nfrcg.gov/zebra.mussel/ Other USGS research centers cond 
--------
383-> Ships Depart To Launch Ice Station SHEBA In The Arctic Ocean
Two icebreaking ships will depart Tuktoyaktuk, Canada aroundSeptember 18 to establish Ice Station SHEBA in the Arctic Ocean,launching the largest and most complex science experiment eversupported in the Arctic by the National Science Foundation (NSF).One ship will be frozen into the pack ice of the Arctic Ocean andleft to drift as a floating science platform for 13 months.  Thetarget of the Surface Heat Budget of the Arctic Ocean project:charting the fate of the great canopy of pack ice about the sizeof the United States, which seals off the Arctic Ocean. SHEBA's ultimate goal is to better understand the climate ofthe Arctic so that forecasts of global climate change can beimproved, according to Mike Ledbetter, NSF program director forArctic system science.  The $19.5 million project, also funded bythe Office of Naval Research, is coordinated by the University ofWashington's Applied Physics Laboratory.  NSF is also supporting$2 million worth of other science related to SHEBA. The Canadian Coast Guard icebreakers Louis S. St. Laurentand Des Groseilliers will steam to the SHEBA site 300 miles northof Prudhoe Bay, Alaska -- approximately 75 degrees north and 143degrees west -- arriving about October 1. More than a century after Norwegian Fridtjof Nansen frozehis specially designed ship, the Fram, into the ice of the ArcticOcean and left it to drift for three years of scientificexploration, the Des Groseilliers will be left in place to serveas a floating dormitory and science quarters.  It will besurrounded by small huts and experiments on the sea ice, alongwith an airplane skiway for supply flights throughout the year.The Louis S. St. Laurent departs the site about October 15. Climate modelers currently differ over the future of theArctic's pack ice.  If carbon dioxide doubles in the atmosphere,an occurrence possible in less than a century, some modelspredict that the pack ice could disappear completely; otherssuggest less shrinkage.  All models concur, however, that Arcticpack ice will play an important role in climate change. The varied landscape of sea ice -- rent by cracks, pathwaysof open water called leads, pressure ridges tens of meters thickand other fantastic forms -- is constantly deformed and shifting.The ice also chills the atmosphere by blocking warmth from thesea in winter and reflecting most incoming sunlight in summer."More than half the Arctic pack ice melts and refreezes eachyear, but even the most sophisticated computer models cannotsimulate this change," said Richard Moritz, SHEBA project officedirector at the University of Washington. Pack ice looms large in several realms, its fate bearingupon shipping routes, petroleum extraction and a rich marineecosystem embracing whales, polar bears, fish and plankton, a webof life key to the livelihood of Arctic peoples. SHEBA scientists plan to trace the transfer of energybetween the atmosphere, sea ice and ocean waters over an entireyear of freezing and melting.  "SHEBA's hallmark is to gather acomprehensive data set documenting all the variables andprocesses at work," Moritz said. In addition to the frozen-in ship, the project will employ afleet of icebreakers, research aircraft and balloons, a U.S. Navynuclear submarine and satellites.  More than 50 scientists fromuniversities and agencies such as NASA and the Department ofEnergy will participate, along with researchers from Japan,Canada and the Netherlands carrying out related studies.
--------
384-> Experts Can't Tell The Difference Between False And True Accounts Of Children, Cornell Study Shows
ITHACA, N.Y. -- When preschool children were asked weekly about whether afictitious event had ever happened to them, more than half the 3- and4-year-old children by the tenth week reported that it had and providedcogent details, according to a Cornell University study. Even more surprising, however, is that more than one-quarter of thechildren could not be convinced the event never occurred when theresearchers and their parents explained that the events never occurred.Furthermore, professionals who specialize in interviewing children couldnot distinguish between children telling false or true accounts when theywere shown videotapes of the children's "recollections." "When young children, ages 3 and 4, are questioned by neutral interviewers,they do very well.  They recall events with 90 percent accuracy," saidStephen J. Ceci, Ph.D., the Helen L. Carr Professor of Psychology inCornell's College of Human Ecology who led the study. "However, when children are repeatedly interviewed over the course of weeksand months with misleading suggestions -- which sometimes occurs inforensic cases  --  many come to remember the false events as true andprovide detailed and coherent narratives about these false events," saidCeci, whose interviewers asked children, for example:  "Think real hard.Did you ever get your hand caught in a mousetrap and go to the hospital toget it off?" "So compelling did the children's narratives appear that we suspected thatsome of the children had come to truly believe they had experienced thefictitious events.  Neither parents nor researchers were able to convince27 percent of the children that the events never happened," said Ceci, awell-known research developmental psychologist who has been studying thesuggestibility of children's memories for more than a decade. With Cornell colleague Mary LynCrotteau Huffman, Ph.D., Ceci reported hisfindings on how suggestible the memories of preschool children are in theJuly issue of the Journal of the American Academy of Child and AdolescentPsychiatry (36:7, July 1997). "These false beliefs or false memories appear to arise when children forgetthe basis of an event's familiarity," said Ceci, co-author of the book,Jeopardy in the Courtroom: A Scientific Analysis of Children's Testimony(American Psychological Association, 1996).  "Young children are especiallyprone to what we call 'source amnesia.'" Ceci suggests that when children are asked to think periodically about afictitious event, they imagine a fictitious scenario, initially rejectingits authenticity because it is unfamiliar.  Weeks later, when asked aboutit again, however, they may falsely accept the event's validity because itis now familiar as a result of having imagined the scenario earlier. "Consequently, it is exceedingly, devilishly difficult for professionals totell fact from fiction when a child has been repeatedly suggestivelyinterviewed over a long period of time," Ceci said.  "These childrenfrequently display none of the indicators of lying or tricking; they lookand act the way children do when they are trying to be accurate and honest." These findings have important implications for cases involving youngchildren, including those related to child abuse and sexual child abusebecause in some of these trials children are interviewed many times overthe course of weeks, months, or even years.  In fact, the average child inthe courtroom is interviewed formally 3.5 to 11 times before a courtappearance and many more times informally. "When suggestive interviewing techniques are used, as in these studies andin real cases, they lead to high levels of correct disclosure when thechild actually experienced the event in question," Ceci pointed out."However, the problem is that they also lead to high levels of false assentwhen the event was not experienced." The studies were supported, in part, by a grant from the National ScienceFoundation.
--------
385-> Mars Global Surveyor Detects Martian Magnetic Field As Aerobraking Begins
Scientists have confirmed the existence of a planet-wide magnetic field at Mars using an instrument on-board NASA's Mars Global Surveyor orbiter, as the spacecraft began to circle and study the planet from a highly elliptical orbit. "Mars Global Surveyor has been in orbit for only a few days, yet it already has returned an important discovery about the Red Planet," said Vice President Al Gore.  "This is another example of how NASA's commitment to faster, better, cheaper Mars exploration that began with Mars Pathfinder is going to help answer many fundamental questions about the history and environment of our neighboring planet, and the lessons it may hold for a better understanding of life on Earth." The spacecraft's magnetometer, which began making measurements of Mars' magnetic field after its capture into orbit on Sept. 11, detected the magnetic field on Sept. 15. The existence of a planetary magnetic field has important implications for the geological history of Mars and for the possible development and continued existence of life on Mars. "Preliminary evidence of a stronger than expected magnetic field of planetary origin was collected and is now under detailed study," said Dr. Mario H. Acuna, principal investigator for the magnetometer/electron reflectrometer instrument at NASA's Goddard Space Flight Center, Greenbelt, MD.  "This was the first opportunity in the mission to collect close-in magnetic field data. Much more additional data will be collected in upcoming orbits during the aerobraking phase of the mission to further characterize the strength and geometry of the field. The current observations suggest a field with a polarity similar to that of Earth's and opposite that of Jupiter, with a maximum strength not exceeding 1/800ths of the magnetic field at the Earth's surface." This result is the first conclusive evidence of a magnetic field at Mars. "More distant observations obtained previously by the Russian missions Mars 2,3 and 5 and Phobos 1 and 2 were inconclusive regarding the presence or absence of a magnetic field of internal origin," said Acuna. The magnetic field has important implications for the evolution of Mars. Planets like Earth, Jupiter and Saturn generate their magnetic fields by means of a dynamo made up of moving molten metal at the core. This metal is a very good conductor of electricity, and the rotation of the planet creates electrical currents deep within the planet that give rise to the magnetic field. A molten interior suggests the existence of internal heat sources, which could give rise to volcanoes and a flowing crust responsible for moving continents over geologic time periods. "A magnetic field shields a planet from fast-moving, electrically charged particles from the Sun which may affect its atmosphere, as well as from cosmic rays, which are an impediment to life," Acuna said. "If Mars had a more active dynamo in its past, as we suspect from the existence of ancient volcanoes there, then it may have had a thicker atmosphere and liquid water on its surface." It is not known whether the current weaker field now results from a less active dynamo, or if the dynamo is now extinct and what the scientists are observing is really a remnant of an ancient magnetic field still detectable in the Martian crust. "Whether this weak magnetic field implies that we are observing a fossil crustal magnetic field associated with a now extinct dynamo or merely a weak but active dynamo similar to that of Earth, Jupiter, Saturn, Uranus and Neptune remains to be seen," Acuna said. Mars Global Surveyor's magnetometer discovered the outermost boundary of the Martian magnetic field -- known as the bow shock -- during the inbound leg of its second orbit around the planet, and again on the outbound leg. The discovery came just before Mars Global Surveyor began its first aerobraking maneuver to lower and circularize its orbit around Mars, said Glenn Cunningham, Mars Global Surveyor project manager at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA. "This first 'step down' into the upper atmosphere was performed in two stages," Cunningham said. "On Sept. 16, during the farthest point in the spacecraft's orbit, called the apoapsis, the spacecraft fired its main engine for 6.5 seconds, slowing Global Surveyor's velocity by 9.8 miles per hour (4.41 meters per second).  This maneuver  lowered the spacecraft's orbit from 163 miles (263 kilometers) to 93 miles (150 kilometers) above the surface of the planet. At its closest approach to Mars this morning, known as the periapsis, the spacecraft dipped into the upper fringes of the Martian atmosphere for 27 seconds, allowing the drag on its solar panels to begin the long aerobraking process of circularizing its orbit." Mars Global Surveyor will continue aerobraking through the Martian atmosphere for the next four months, until its orbit has been circularized and it is flying about 234 miles (378 kilometers) above the Martian surface.  All systems and science instruments onboard the spacecraft continue to perform normally after six days in orbit around the red planet. Additional information about the magnetic field discovery and the Mars Global Surveyor mission is available on the World Wide Web by accessing the JPL home page at: http://www.jpl.nasa.gov or at the Goddard Space Flight Center magnetometer site at: http://mgs-mager.gsfc.nasa.gov Meanwhile, NASA's Hubble Space Telescope (HST) has continued monitoring the atmospheric conditions on Mars to help planning for the Mars Global Surveyor aerobraking activity.  The latest HST Mars image, taken Sept. 12 with the Wide Field Planetary Camera 2 under the direction of Phil James of the University of Toledo and Steve Lee of the University of Colorado, is available on the Internet at the following URLs: http://oposite.stsci.edu/pubinfo/PR/gif/mars0609.gif (GIF),    http://oposite.stsci.edu/pubinfo/PR/jpeg/mars0609.jpg (JPEG) and via links in: http://oposite.stsci.edu/pubinfo/PR/97/31.html Mars Global Surveyor is the first mission in a sustained program of robotic Mars exploration, known as the Mars Surveyor Program.  The mission is managed by the Jet Propulsion Laboratory for NASA's Office of Space Science, Washington, DC. JPL's industrial partner is Lockheed Martin Astronautics, Denver, CO, which developed and operates the spacecraft. JPL is a division of the California Institute of Technology, Pasadena, CA.
--------
386-> Infectious And Parasitic Diseases Still Threaten World Health
Health officials worldwide are struggling to understand the latest outbreaks of diseases once thought to be on the wane and to mobilize resources to do battle with these ancient killers, called infectious and parasitic diseases. Among this class of diseases are such familiar diseases as malaria, tuberculosis, and cholera as well as more exotic ones such as dengue hemorrhagic fever, Ebola, and Chagas' disease. "These diseases are a major cause of death and disability in low-income countries and are re-emerging as a serious health problem in developing countries," said Dr. Bruce Carnes, one of the authors of a new 52-page Population Bulletin from the Population Reference Bureau, "Infectious Diseases: New and Ancient Threats to World Health." One such disease, smallpox, was eradicated in the 1970s. That achievement led many health experts to believe that other infectious and parasitic diseases would one day be completely eradicated, the report notes, adding that developments since then have shattered that belief. In recent years, newspaper accounts of terrifying outbreaks of Ebola, dengue hemorrhagic fever, Hantaan viruses, cholera, and other exotic diseases have captivated the public and generated best-selling books like "The Hot Zone" and the hit movie "Outbreak." "Unfortunately," Carnes said, "the threat posed by these diseases is not fiction. They have been responsible for more deaths throughout history than any other cause, including old age. And they still are." Carnes, a biologist, heads research into aging and demography at Argonne National Laboratory's Center for Mechanistic Biology and Biotechnology near Chicago. Other authors of the Population Reference Bureau report are biodemographer S. Jay Olshansky of the University of Chicago, sociologist Richard G. Rogers of the University of Colorado, and epidemiologist Len Smith of the Australian National University. The team of scientists points out in the report that infectious and parasitic diseases are not disappearing. The HIV/AIDS epidemic alerted health officials to the fact that these diseases had been on the rise for the past quarter-century. Old diseases are appearing with increasing frequency, new forms of old diseases that resist treatment are appearing in increasing numbers, and new diseases rarely or never before experienced by humans are surfacing. More than 28 new disease-causing microbes have been identified since 1973, the report notes. These include a new strain of cholera that has killed thousands of people in Africa and Asia and new forms of tuberculosis and meningitis that are resistant to most known antibiotics. Outbreaks of such deadly diseases as diphtheria, Hantaan virus, bubonic plague, tuberculosis, malaria, cholera, meningitis, and Ebola have been reported recently. The death toll is high. More than 17 million people died from these diseases in 1995, accounting for more than one-fourth of all deaths. About 97 percent of deaths from these diseases occur in low-income countries. The vast majority of these deaths, the authors said, could have been avoided. They added that the mortality and health problems these diseases cause retard social and economic development in low-income countries, perpetuating the poverty, poor health, and squalid living conditions that contribute to the spread of these diseases. The developed nations are no longer safe from these diseases, the report says. The diseases can travel in a matter of hours to any part of the globe, thanks to modern air travel. In addition, the United States records 600,000 cases of pneumonia each year, resulting in 25,000 to 50,000 deaths, and between 10,000 and 40,000 deaths due to influenza. The new states of the former Soviet Union experienced an epidemic of diphtheria in 1990, with more than 40,000 cases reported in 1994. A host of natural and human actions influence the introduction and spread of these diseases, the authors contend. Among them are certain agricultural developments and practices, urbanization, migration and travel, and natural disasters. The authors note that otherwise beneficial developments such as medical advances also can provide new ways for infectious agents to jump from person to person. They add that overuse and misuse of antibiotics have led to resistant strains of bacteria. Carnes and his fellow authors believe that public health experts and policymakers can collaborate to respond to the increase in infectious parasitic disease cases. They call for: Strengthening infection control precautions. Ensuring appropriate laboratory-based surveillance of diseases resistant to available drugs. Developing more rapid diagnostic tests. Instituting surveillance of the use of antibiotics or other antimicrobial agents. Improving physician prescribing practices. Encouraging pharmaceutical companies to develop new antimicrobial agents. Developing new or improved vaccines and effective means to distribute them throughout the world. Educating the public about appropriate antimicrobial agent use and the dangers of inappropriate use. Copies of "Infectious Diseases: New and Ancient Threats to World Health" may be purchased for $8.50 (price includes postage) from the Population Reference Bureau by calling 1-800-877-9881 or 202-483-1100. Founded in 1929, the Population Reference Bureau is a private, nonprofit organization dedicated to the dissemination of timely and objective information on population trends. With more than 200 major research programs, Argonne National Laboratory is operated by the University of Chicago as part of the U.S. Department of Energy national laboratory system.
--------
387-> Out Of Pure Light, Physicists Create Particles Of Matter
A team of 20 physicists from four institutions has literally made something from nothing, creating particles of matter from ordinary light for the first time. The experiment was carried out at the Stanford Linear Accelerator Center (SLAC) by scientists and students from the University of Rochester, Princeton University, the University of Tennessee, and Stanford. The team reported the work in the Sept. 1 issue of Physical Review Letters. Scientists have long been able to convert matter to energy; the most spectacular example is a nuclear explosion, where a small amount of matter creates tremendous energy. Now physicists have succeeded in doing the opposite: converting energy in the form of light into matter -- in this experiment, electrons and their anti-matter equivalent, positrons. Converting energy into matter isn't completely new to physicists. When they smash together particles like protons and anti-protons in high-energy accelerator experiments, the initial particles are destroyed and release a fleeting burst of energy. Sometimes this energy burst contains very short-lived packets of light known as "virtual photons" which go on to form new particles. In this experiment scientists observed for the first time the creation of particles from real photons, packets of light that scientists can observe directly in the laboratory. Physicists accomplished the feat by dumping an incredible amount of power -- nearly as much as it takes to run the entire nation but lasting only for a tiny fraction of a second -- into an area less than one billionth of a square centimeter, which is far smaller than the period at the end of this sentence. They used high-energy electrons traveling near the speed of light, produced by SLAC's two-mile-long accelerator, and photons from a powerful, "tabletop terawatt" glass laser developed at Rochester's Laboratory for Laser Energetics. The laser unleashed a tiny but powerful sliver of light lasting about one trillionth of a second (one picosecond) -- just half a millimeter long. Packed into this sliver were more than two billion billion photons. The team synchronized the two beams and sent the electrons head-on into the photons. Occasionally an electron barreled into a photon with immense energy, "like a speeding Mack truck colliding with a ping pong ball," says physicist Adrian Melissinos of the University of Rochester. That knocked the photon backward with such tremendous energy that it collided with several of the densely packed photons behind it and combined with them, creating an electron and a positron. In a series of experiments lasting several months the team studied thousands of collisions, leading to the production of more than 100 positrons. The energy-to-matter conversion was made possible by the incredibly strong electromagnetic fields that the photon-photon collisions produced. Similar conditions are found only rarely in the universe; neutron stars, for instance, have incredibly strong magnetic fields, and some scientists believe that their surfaces are home to the same kind of light-to-matter interactions the team observed. This experiment marks the first time scientists have been able to create such strong fields using laser beams. By conducting experiments like this scientists test the principles of quantum electrodynamics (QED) in fields so strong that the vacuum "boils" into pairs of electrons and positrons. The scientists say the work could also have applications in designing new particle accelerators. Spokesmen for the experiment, funded by the U.S. Department of Energy, are Kirk McDonald, professor of physics at Princeton, and Melissinos, professor of physics at Rochester. Also taking part in the experiment were William Bugg, Steve Berridge, Konstantin Shmakov and Achim Weidemann at Tennessee; David Burke, Clive Field, Glenn Horton-Smith, James Spencer and Dieter Walz at SLAC; Christian Bula and Eric Prebys at Princeton; and seven other physicists from Rochester, including Associate Professor David Meyerhofer; graduate students Thomas Koffas, David Reis, Stephen Boege, and Theofilos Kotseroglou; research associate Charles Bamber; and engineer Wolfram Ragg.
--------
388-> Scientists To Meet At Johns Hopkins To Discuss Factors Affecting Production Rates Of Vital Ocean Fisheries
Scientists from around the world will descend on The JohnsHopkins University campus on Sept. 22 to discuss issues of majorinterest to all nations: factors affecting the production ratesof vital ocean fisheries. The International Council for the Exploration of the Seawill hold a three-day symposium at Hopkins beginning that day as aprelude to the organization's annual science conference, also inBaltimore. Symposium speakers will focus on the central questionconcerning fisheries: What are the specific processes andinteractions that determine how many fish will be produced in agiven season? Because fish represent a major global food source, fisheriesproduction is a critical issue. "If you look at the statistics, we seem to have peaked, interms of global fisheries production," said Thomas Osborn, aprofessor in the Johns Hopkins Department of Earth and PlanetarySciences, who specializes in physical oceanography and helpedorganize the symposium. The high mark was in 1989, when the seas yielded about 85million metric tons -- or 187 billion pounds -- of fish. "It has since leveled off, but has not sharply declined,"said Michael Fogarty, a fisheries scientist at the University ofMaryland who also helped organize the symposium, which willattract scientists from more than 20 nations. The meeting "is dealing with topics that have received a lot ofattention in the general press because of the perception of afisheries crisis throughout the world," Fogarty said. Crisis would be the right term to describe the conditions ofsome fish stocks; for example, the decline of cod off of theNewfoundland coast "is an ecological and an economic disaster,"Fogarty said. "There are declines in many other species," he said. However, not all the news is bad; regulations andrestrictions are helping to restore some fish stocks. Herring andmackerel, once decimated by foreign fishing fleets, are nowabundant again off the New England coast. "It took over a decade for them to come back, but they havecome back," Fogarty said. Scientists use the term "recruitment" to define thedevelopment of eggs to offspring that eventually become largeenough to be fished. "Fish produce many, many more eggs than become adults,"Osborn said. "You don't keep track of how many eggs there are.The important thing is how many returned to enter the fishery." But researchers have been mystified by regional fluctuationsin the numbers of fish from year to year. "Almost any farmer can tell how much fertilizer he shouldput on the field for a desired yield, but we still don't know howto predict the number of fish that are growing in the ocean,"said Osborn, a member of ICES' United States delegation. About 150 scientist are expected to attend the symposium,entitled: Recruitment Dynamics of Exploited Marine Populations. "By exploited, we mean things that are fished, like cod,haddock, salmon, all the things that have economic value," Osbornsaid. ICES, headquartered in Denmark, is the oldest intergovernmentalorganization in the world dedicated to marine and fisheries science. It hasmembers from 19 countries, including all of the European coastal nations. The95-year-old organization gives advice to the European Union, as well as togovernmental bodies, regarding fisheries. The symposium, which charges a registration fee of $100, or$35 for students, is open to scientists and students who areinterested in the interactions between processes in marineenvironments and the dynamics involved in recruitment. Journalists interested in learning more about the symposium maycall Fogarty 410-326-7289, or Osborn at 410-516-7039. Registration begins at 8 a.m. on Monday at Shriver Hall, onthe Johns Hopkins Homewood campus, at 3400 N. Charles St. in Baltimore. The opening talk is at 9:30 a.m. The symposium continues through Wednesday.Research findings will be presented in poster papers on display in LeveringHall's Glass Pavilion throughout the three days of talks. Symposium talks will cover a wide range of subjects, fromoverfishing to environmental and physical factors that affect thepopulations of different species. The annual science conference, at the Renaissance Plaza indowntown Baltimore, will follow the symposium. The conferencerepresents the culmination of a year of meetings and discussions.It begins on Thursday, Sept. 25, and ends Oct. 3. Information about ICES isavailable on-line, at http://www.ices.dk.                                                                      ### Johns Hopkins University news releases can be found on the World Wide Web athttp://www.jhu.edu/news_info/news/
--------
389-> UPMC Study Shows Lack Of Sleep Causes Differences In Thinking Patterns In Brain
PITTSBURGH, Sept. 15 -- "Burning the midnight oil" may do more harm than good for people who believe they work best at night. In a study at the University of Pittsburgh Medical Center's (UPMC) Western Psychiatric Institute and Clinic, researchers have found that the body's need for sleep, influenced by its circadian rhythms, may slow down thinking processes at night. Also, researchers at the UPMC said, losing sleep at night can slow down your thinking skills the next day. From a practical point of view, results suggest that in addition to safety concerns resulting from night workers' and night drivers' tendency to fall asleep, it should be recognized that even if they are wide awake, they may be thinking more slowly. The UPMC study, published by Timothy H. Monk, Ph.D., professor of psychiatry, and Julie Carrier, Ph.D., postdoctoral research fellow, in the current issue of the academic journal Sleep, suggests that circadian rhythms, the body's internal clock, can affect the speed at which the brain processes information. According to Dr. Monk, the study's principal investigator, night-time thinking may slow down because people need to fight their urges to sleep. Eighteen healthy young adults participated in the 36-hour study that involved constant wakeful bedrest, or being kept awake while in bed, for the duration of the study. Participants also had no knowledge of clock time, and meals were replaced by hourly nutritional supplements. This was done to avoid feelings of sleepiness that accompany big meals. A series of performance tests involving figuring out whether sentences were true or false were given every other hour, and the speed and accuracy of the responses were recorded. Using questions phrased in both the positive and negative voice, the researchers found that negative-voiced sentences took longer for participants to respond to than positive-voiced ones due to an increase in information-processing requirements. By plotting the speed with which this extra processing was done at each time of day and night, Drs. Monk and Carrier were able to factor out overall effects of sluggishness and inattention and get directly at the speed of thought itself. The study concluded that people think more slowly at night, perhaps because they approach a task differently at night than during the day. It also showed a slowing in the speed of information processing during the day after the lost night of sleep.
--------
390-> Hubble Stays On Trail Of Fading Gamma-Ray Burst Fireball, Results Point To Extragalactic Origin
New NASA Hubble Space Telescope observations of the ever-fading fireball fromone of the universe's most mysterious phenomena -- a gamma-ray burst -- isreinforcing the emerging view that these titanic explosions happen faraway in other galaxies, and so are among the most spectacularlyenergetic events in the universe. The most recent finding from observations with Hubble's Space TelescopeImaging Spectrograph (STIS) made on Sept. 5 - nearly six months after theblast - is  being reported today at the Fourth Huntsville Symposium onGamma Ray Bursts, at the Hilton Hotel in Huntsville, Al. "Hubble is the only telescope capable of continuing to watch theaftermath of this explosion, because it has faded to 1/500th itsbrightness when first discovered by ground based telescopes last March,"says Andrew Fruchter of the Space Telescope Science Institute inBaltimore, Md. "These observations provide an unprecedentedopportunity to better understand the catastrophe behind such incredibleoutbursts." Hubble's key findings are: 1.      The continued visibility of the burst, and the rate of its decline overtime, support theories that the light comes from a gamma-ray burst in a "relativistic" fireball (expanding near the speed of light) located at extragalactic distances. A burst in our galaxy, at the observed brightness, would have been slowed by the interstellar medium within the first few weeks, and faded from sight by now. 2.     The observations contradict earlier claims, by some astronomersthat the gamma-ray burst is moving against the sky background (thisoffset is called proper motion). Had proper motion been detected, thegamma-ray burst would have had to be no further away than about 30,000 light-years, or about the distance to the center of the galaxy. 3.     The fuzzy companion object the fireball is embedded in - as firstconfirmed by Hubble in March 26 observations -- has not noticeablyfaded. This means it is not a relatively nearby nebula produced by theexplosion, but in all likelihood a host galaxy. 4.      Since the burst did not occur at the center of the hostgalaxy, but near its edge, the gamma-ray burst phenomenon is not relatedto activity in the nucleus of a galaxy. The Hubble observations supportthe "fireball" model for a gamma-ray burst. "These observations are consistent with colliding neutron stars creatingthe fireball, but do not require it. The cause of that fireball is stillnot determined.  Though colliding neutron stars is one theoretical meansof producing such a fireball it is not the only one," says Fruchter. Hubble observations over the past six months show the fireball is fadingat a constant rate, as predicted by theory. Eventually, gas plowed infront of the stellar tidal wave should build up enough resistance tobring the fireball to a halt like snow piling up in front of a plow -and it should blink out.  But the fact that hasn't happened yet offersmore clues to solving the gamma-ray burst mystery. If the burst happened nearby, the resulting fireball should have hadonly enough energy to propel it into space for a month or so before"hitting the wall" of accumulated gas and dying out. The fact that thisfireball has expanded to gargantuan size, sweeping out a bubble of spaceone light-year across, means the explosion was truly titanic and, tomatch the observed brightness, must have happened at the vast distancesof galaxies. When Hubble first acquired the fireball, on March 27 (several weeks after the initial discovery) it was at 26th magnitude.  The magnitude scale isused to measure the brightness of objects in space.  The lower the magnitude,the brighter the object.  The unaided eye can detect objects of the 6thmagnitude. By the Sept. 5 observation, it had faded to 1/5th that brightness to 27.7 magnitude (approximately 1/500,000th) the brightness of the faintest star). The suspected host galaxy has remained at approximately 25th magnitude. Only Hubble has the resolution and contrast capability to stilldistinguish the fading fireball from the now brighter host galaxy. Theresearchers hope for follow-up observations to continue keeping track ofthe burst's optical counterpart until it fades away. The research team: Andrew Fruchter (STScI), Elena Pian (ITSR), SteveThorsett (Princeton), Marco Tavani (Columbia), Mario Livio (STScI), KailashSahu (STScI), Filippo Frontera (ITSR), Larry Petro (STScI) and DuccioMacchetto (STScI). * * * * The Space Telescope Science Institute is operated by the Association ofUniversities for Research in Astronomy, Inc. (AURA) for NASA, undercontract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation betweenNASA and the European Space Agency (ESA). EDITOR'S NOTE:  Photos, captions and press release text are available via the World Wide Web at http://oposite.stsci.edu/pubinfo/PR/97/30.html and via links inhttp://oposite.stsci.edu/pubinfo/Latest.html orhttp://oposite.stsci.edu/pubinfo/Pictures.html. Image files also may be accessed via anonymous ftp from oposite.stsci.eduin /pubinfo:  gif/grb0228b.gif (GIF) and jpeg/grb0228b.jpg (JPEG).
--------
391-> Hunt For Early Heart Attack Genes Begins
More than 2,000 people will be enrolled in ahunt for the genetic causes that underlie "early"heart attacks that strike men and women in middleage.  The study is part of the research program ofthe Starr Center for Human Genetics at TheRockefeller University in New York City. "Finding the genes that contribute to heartattacks is the first step towards developing bettermethods for the prevention, early diagnosis andtreatment for this disease that is single largestkiller of American men and women," says Jan L.Breslow, M.D., head of The Rockefeller University'sLaboratory of Biochemical Genetics and Metabolismand the immediate past-president of the AmericanHeart Association (AHA). Nearly 57.5 million Americans have one or moretypes of cardiovascular disease, which includesheart attacks, high blood pressure and stroke,according to the AHA.  Heart attacks, which claimedmore than 487,000 lives in 1994, cause one in every4.7 American deaths.  People younger than 65account for 45 percent of heart attacks. "We have good evidence that heart disease,including heart attacks, runs in families.  Heartattacks result from a person's complex geneticmakeup and his or her interactions with theenvironment including what he or she eats, how muchhe or she exercises and if he or she smokes.  Whilewe know a great deal about the influence of diet,exercise and cigarettes on heart disease, we do notyet know the identity of genes that would explainsusceptibility to heart attacks," explainscoinvestigator Elizabeth De Oliveira e Silva, M.D.,research associate at Rockefeller. To locate and determine the structure andfunction of one or more genes involved in heartattacks, the scientists will examine blood samplesand medical histories of 2,000 people who haveheart attacks at an early age.  Because heartdisease is likely to have various genetic causes,enrolling such a large study population will helpthe scientists hunt for several genes at the sametime, notes Breslow, Frederick Henry LeonhardtProfessor and a senior physician at The RockefellerUniversity Hospital. Specifically, they will recruit: …  men who had a first heart attack before age45 and women, before age 55. …  men who had a first heart attack before age55 and have a living sibling who has had a firstheart attack before 55 (brothers) or before 65(sisters). …  women who had a first heart attack beforeage 65 and have a living sibling who had a firstheart attack before 55 (brothers) or before 65(sisters). People interested in enrolling asparticipants should call Mary Lou Klimek,M.A., R.N. at 1-888-920-9100 or 212-327-7445for more information.  All information is keptconfidential.  People accepted into the study willbe offered free blood cholesterol and lipoproteinanalysis and information about modifying theirrisks of having a heart attack. Participants will not need to come to theuniversity for the study.  The scientists will makearrangements to receive patient's medical historiesand have samples of their blood analyzed at theRockefeller University Hospital, the oldesthospital in the United States devoted solely toexperimental medicine.  Established in 1910, thehospital links laboratory investigations withbedside observations to provide a scientific basisfor disease detection, prevention and treatment.This special hospital environment served as themodel for the Warren G. Magnuson Clinical Center,opened at the National Institutes of Health in1953, and similar facilities supported by federalfunding at more than 75 medical schools in theUnited States. Rockefeller University began in 1901 as theRockefeller Institute for Medical Research, thefirst U.S. biomedical research center.  Rockefellerfaculty members have made significant achievements,including the discovery that DNA is the carrier ofgenetic information and the launching of thescientific field of modern cell biology.  Theuniversity has ties to 19 Nobel laureates,including the president, Torsten N. Wiesel, M.D.,who received the prize in 1981. In addition to theStarr Center for Human Genetics, the universityrecently created centers to foster research ofAlzheimer's Disease, of biochemistry and structuralbiology, of sensory neurosciences and of the linksbetween physics and biology.
--------
392-> Researchers Find Association Between Alzheimer's Gene And Mental Impairment After Cardiac Surgery
DURHAM, N.C. -- Physicians at Duke University Medical Center have found that patients who experience mental impairment after open heart surgery are more likely to carry the gene that predisposes people to Alzheimer's disease. While up to three-quarters of all heart surgery patients experience some degree of cognitive impairment following surgery using heart-lung bypass machines, patients with the Alzheimer's- related gene apoliprotein E-4 (APOE-4), are more susceptible to this damage, a preliminary study of 65 patients found. Since normal APOE is involved in nerve cell repair, they believe the variant APOE-4 is unable to make such repairs efficiently, as evidenced in patients with Alzheimer's disease. The study findings were published Tuesday in the September issue of the Annals of Thoracic Surgery. The study was supported by grants from the National Institutes of Health, National Institute on Aging, the American Heart Association and the Anesthesia Patient Safety Foundation. "We noticed that after major heart surgery, the neurologic deficits of many patients -- attention, concentration and memory problems -- were very much like the early symptoms of Alzheimer's disease," said Duke's Dr. Mark Newman, chief of cardiothoracic anesthesiology and the study leader. "After controlling for other characteristics, we found a statistically significant correlation between patients with the APOE variant and neurological damage after surgery. "Patients with the APOE variant were more susceptible to neurological damage than the other patients," Newman said. "The fact that this association was found in such a small study population leads us to believe the results will be borne out in larger studies." Physicians say that while they can do nothing now to offset this susceptibility, it may be possible to develop drugs or other strategies to protect brain cells in these patients. During major heart surgery, little blood clots and/or tiny fragments of atherosclerotic plaques can be dislodged and travel to the brain, leading to potential neurologic problems. The researchers believe that since the normal APOE gene is involved in nerve cell repair, the variant versions of the gene are unable to repair the subtle physiological changes caused by surgery, Newman said Each year, more than 400,000 patients undergo open heart surgery requiring cardiopulmonary bypass, and as many as 75 percent suffer neurological complications, ranging from transient cognitive changes to stroke. While the elderly are known to be at higher risk, in more than half the cases the underlying predisposition for impairment is not known. In the study patients were given a battery of cognitive tests prior to surgery and 6 weeks after surgery. The study also showed that a higher level of education is protective of cognitive decline. "We don't know the exact reason for this, but it is probably that more well-educated people have a greater functional reserve of brain cells, have more experience in test-taking, and may have developed more alternative neurological pathways," Newman said. While these findings do not explain every case of cognitive decline following heart surgery, Newman said that they will be important in developing protective strategies for susceptible heart patients. At this point, the situation is similar to that of Alzheimer's disease -- physicians can determine who is the most susceptible, but, there are no current treatments. Newman believes that these findings give more information to patients and their physicians as they weigh the risks and benefits of heart surgery. He stressed that further studies with more patients are needed to prove a definite link between cognitive decline and the APOE variant. Newman and colleagues plan to follow heart patients for five years to determine how their cognitive status changes. Joining Newman in the study were Dr. Barbara Tardiff, Ann Saunders, Ph.D., Dr. Warren Strittmatter, James Blumenthal, Ph.D., William White, Narda Croughwell, Dr. Duane Davis, Dr. Allen Roses and Dr. J.G. Reves, as well as the entire Neurological Outcome Research Group of the Duke Heart Center.
--------
393-> Common Cold And Flu Medicines Tire School-Age Children And May Affect Learning, Says Researcher At National Jewish Medical And Research Center
Over-the-counter antihistamines are widely available, heavily marketed, inexpensive and regularly used by parents to control a child’s cold and flu symptoms. What parents may not know is that some antihistamines make it more difficult for children to stay awake and concentrate at school.  But a doctor-prescribed, non-sedating antihistamine does exist—although it costs more and takes more effort to get. "If you give kids an antihistamine and send them off to school in the morning they’ll be sleepy," says Bruce Bender, Ph.D., head of Neuropsychology at National Jewish Medical and Research Center. "Children might fall asleep, and if they don’t fall asleep, they might be drowsy and not absorb information well."	Over-the-counter antihistamines—such as chlorpheniramine, diphenhydramine and hydroxyzine—used to dry runny noses and stop itchy, watery eyes, have been shown to cause drowsiness in some children. But there are steps parents can take to make sure children get better and stay awake in school.  Watch a child closely if he or she takes antihistamines over a long period.  Ask your child’s teacher if he or she acts tired in class.  Only give medication formulated for a child, unless otherwise instructed by a pediatrician.  "Kids aren’t just small adults," Bender says.  But a child may become sleepy even when given medicine designed for a children. "The fact that it is marketed in a pediatric form doesn’t mean it won’t make a child sleepy," he adds.  "Parents need to be vigilant in reading the label instructions." Dosages should be given doses based on weight not on age. An alternative is to have the child’s doctor prescribe a non-sedating antihistamine.  "It’s worth the extra time to talk with a pediatrician," he says.
--------
394-> Largest Tyrannosaur Fossil Unearthed In Montana
A fossilized skeleton believed to be the largest specimen of a Tyrannosaur ever unearthed was found this summer by a field crew headed by J. Keith Rigby, a University of Notre Dame paleontologist. The fossil, which has been only partially excavated, lies in a vast dinosaur graveyard in northeastern Montana near the Fort Peck Reservoir. According to Rigby, the fossil is nearly complete and is either a Tyrannosaurus rex or something very much like it. Certain aspects of the anatomy are different than the 15 or so known skeletons of T. rex, he says, and it appears to exceed all measured skeletons of the dinosaur. "What we do know is that it's the largest carnivore on the planet.," he says. Rigby reports that the pubis, one of three main bones in the pelvis, measures at least 52 inches, compared to 48 inches in the largest known T. rex. The femurs or thigh bones, which paleontologists normally use to estimate the size of dinosaurs, await excavation at the site. Unfortunately, former owners of the cattle ranch on which the fossils were found entered the site and began digging up the bones that remained in the ground, including the skull. Contending they still own the land, they evidently planned to sell the fossil to a private collector. On Sunday (Sept. 14), Federal law-enforcement officers descended on the site, which a title search indicates lies on land now owned by the U.S. Dept. of Agriculture's Farm Service Agency, and forced the former owners to vacate the premises. Rigby and the Earthwatch Institute, which funded a major part of the research, had planned to complete the excavation and receive independent corroboration of the fossils before jointly announcing the discovery, but the events unfolding on the site have forced their hand. Rigby had temporarily closed the site in August and returned to Notre Dame to begin the fall semester. He is likely to visit the site soon to assess the damage done in his absence. Situated in the picturesque badlands of eastern Montana, the site lies in the Hell Creek, a geological formation famous for preserving dinosaur bones. The bones date from the end of the Cretaceous period 66 million years ago. In the Late Cretaceous, the now bone-dry site sppears to have been a river channel, according to Rigby. When the dinosaurs died, their bones washed into the channel and collected together there. Sediments covered and preserved the bones until they were discovered in July by the Notre Dame/Earthwatch team. Rigby credits four Earthwatch volunteers for playing a critical role in the discovery. Carol Schuler of Brooklyn, N.Y., and Rhonda King of Hollidaysburg, Pa., were the volunteers who located the fossil bed rich in dinosaur remains and unique because of the diversity represented. And Steve Begin, a forestry consultant from Manistee, Mich., and Louis Trembley, an earth science teach from Avon High School in Avon, Conn., found the large Tyrannosaur. According to Rigby, Trembly drew the group's attention to the site by literally stumbling overa protruding bone. Judging from the position of both surface bones and the bones so far unearthed, Rigby believes the bone bed may cover 15 acres, making it one of the largest dinosaur graveyards of the Late Cretaceous ever found. "All of these discoveries await complete excavation of the fossils and rigorous scientific analysis, including independent corroboration," says Rigby. Rigby plans to donate the fossils to a proposed museum in Fort Peck, Mont., tentatively known as the Fort Peck Dam Interpretive Center and Museum. Slated to open in 2005, the museum as currently conceived will feature the largest dinosaur exhibit in the world. "Rigby's donation will be a major contribution to a world-class museum," says Larry Mires, who heads the museum effort. Earthwatch is a nonprofit organization that funds more than 130 scientific field research projects worldwide every year. Since it was founded in 1972, more than 50,000 paying volunteers -- 4,000 each year -- have shared the cost and labor of the expeditions, which investigate questions in the earth, life, and social sciences. "We are concerned that the fossils be properly excavated and prepared for placement in the museum for the benefit of the general public," says Roger Bergen, president of Earthwatch. Rigby has received Earthwatch support for field research for the past nine years and a total of 420 Earthwatch volunteers have worked on his field crews. Rigby can be reached in his office at (219) 631-6245. For Earthwatch information, contact Blue Magruder or Peter Tyson at Earthwatch at (617) 926-8200.
--------
395-> Mutant Gene Not Sole Explanation For HIV Non-Progression
A recently described genetic mutation does not fully explainwhy a small proportion of people infected with the humanimmunodeficiency virus (HIV) remain completely well for a decade ormore, according to investigators at the National Institute of Allergyand Infectious Diseases (NIAID). Instead, the researchers say, the good health of such "long-term nonprogressors" probably is due to multiple factors, which mayvary from individual to individual. Oren Cohen, M.D., a medical officer in NIAID's Laboratory ofImmunoregulation (LIR); LIR Lab Chief and NIAID Director AnthonyS. Fauci, M.D.; and their colleagues report their findings in the Sept.15, 1997 issue of The Journal of Clinical Investigation.  The studyinvolved 33 patients from LIR's cohort of long-term nonprogressors,the NIAID-supported Multicenter AIDS Cohort Study, and the SanFrancisco City Clinic Cohort. "This study fortifies the concept that HIV long-termnonprogressors represent a diverse group," says Dr. Fauci.  "Multipleimmune system factors, genetic and other host factors, and viralfactors contribute to the clinical profiles of these patients, who usuallyhave preserved immune function and low levels of HIV in theirbodies." Recent research has shown that most infecting strains of HIVuse a cellular receptor called CCR5, in addition to the CD4 molecule,to enter certain of its target cells.  HIV-infected people with a specificmutation in one of their two copies of the gene for this receptorgenerally have a slower disease course than people with two normalcopies of the gene.  People with two mutant copies of the CCR5 geneappear -- in most cases -- to be completely protected from HIVinfection. Several epidemiological studies have shown that individualswith one mutant copy of the CCR5 gene are disproportionatelyrepresented among long-term nonprogressors.  The LIR defines long-term nonprogressors as people who have been HIV-infected for morethan seven years, have stable CD4+ T cell counts above 600 percubic millimeter (mm3) of blood, have no history of HIV-related symptoms, and who have not taken antiretroviral drugs. Drs. Cohen, Fauci and their team began recruiting long-termnonprogressors five years ago to determine the specific factors thatprotect these people from HIV disease progression.  Soon after thediscovery of the role of CCR5 in HIV disease and the association ofthe mutant CCR5 gene with slower disease progression, the LIR teamfound that people with one copy of the mutant gene (and one copy ofthe normal gene) were over-represented in their cohort of long-term nonprogressors. With that information in hand, they asked the question, dolong-term nonprogressors with one copy of the mutant CCR5 genehave less virus in their bodies and higher CD4+ T cell countscompared with long-term nonprogressors with two normal copies ofthe CCR5 gene -- a situation that would help explain the associationof the CCR5 mutation and long-term nonprogression?The answer, Dr. Cohen says, "was a resounding no."  Theinvestigators found that nonprogressors with one copy of the mutantCCR5 gene were indistinguishable from nonprogressors with twonormal copies of the gene with regard to all immunologic and virologicparameters they measured, including CD4+ T cell counts and viralload in the bloodstream and lymph nodes. "Although an HIV-infected individual who carries one copy ofthe mutant CCR5 gene has an increased chance of becoming a long-term nonprogressor, other factors in the complex interaction between HIV and the body allow individuals with normal copies of the gene to maintain similar immunologic status." What explains the epidemiological data that show manypeople with the CCR5 gene mutation in cohorts of long-termnonprogressors? "Around the time of initial infection with HIV,  people with thespecific mutation in the CCR5 gene have lower levels of virus in theirblood and a smaller initial decline in CD4+ T cells, as compared to other patients," says Dr. Cohen.  (See Huang, et al. Nature Medicine 1996;2:1240-1243).  "This lower 'set point' probably has an important influence on the subsequent rate of disease progression." The LIR continues its studies of long-term nonprogressors,and will report important new data from their cohort at the upcomingInterscience Conference on Antimicrobial Agents and Chemotherapylater this month. "Studies of long-term nonprogressors have contributed greatlyto our understanding of the HIV disease process, and provideperhaps the best evidence that protective immunity may exist in HIVinfection," says Dr. Fauci.  "We owe an enormous debt to the manypatients who have come to Bethesda to take part in our studies.  Thecontribution that these individuals have made to science and the fightagainst AIDS is immeasurable." Dr. Cohen's and Fauci's collaborators include Mauro Vaccarezza, M.D., Gordon K. Lam, Barbara F. Baird, Kathryn Wildt, Philip M. Murphy, M.D., Ph.D., Peter A. Zimmerman, Ph.D., Thomas B. Nutman, M.D., Cecil H. Fox, Ph.D., Shelley Hoover, Joseph Adelsberger, Michael Baseler, Ph.D., James Arthos, Ph.D., Richard T. Davey, Jr., M.D., Robin L. Dewar, Ph.D., Julia Metcalf, Douglas J.Schwarzentruber, Ph.D., Jan M. Orenstein, M.D., Ph.D., SusanBuchbinder, M.D., Alfred J. Saah, M.D., Roger Detels, M.D., JohnPhair, M.D., Charles Rinaldo,  Ph.D., Joseph B. Margolick, M.D.,Ph.D., and Giuseppe Pantaleo, M.D. NIAID, a component of the National Institutes of Health (NIH),supports research on AIDS, malaria and other infectious diseases, aswell as allergies and asthma.  NIH is an agency of the U.S.Department of Health and Human Services.                                              ###Press releases, fact sheets and other NIAID-related materials areavailable on the Internet via the NIAID home page athttp://www.niaid.nih.gov. Reference:Cohen OJ, et al.  Heterozygosity for a defective gene for CCchemokine receptor 5 is not the sole determinant for the immunologicand virologic phenotype of HIV-infected long term non-progressors. Journal of Clinical Investigation  1997;100(7):1581-15 
--------
396-> Independent NASA Satellite Measurements Confirm El Nino Is Back And Strong
Pacific Ocean sea-surface height measurements and atmospheric water vapor information taken from two independent Earth-orbiting satellites are providing more convincing evidence that the weather-disrupting phenomenon known as El Nino is back and strong. "The new data collected since April 1997 confirm what we had earlier speculated upon and what the National Oceanic and Atmospheric Administration (NOAA) has predicted -- a full-blown El Nino condition is established in the Pacific," said Dr. Lee-Lueng Fu, project scientist for the U.S./French satellite TOPEX/POSEIDON satellite at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA. The five years of global ocean topography observations made by TOPEX/POSEIDON have been a boon for El Nino researchers, who have been able to track three El Nino events since the satellite's launch in August 1992. "The recent data are showing us that a large warm water mass with high sea-surface elevations, about six inches (15 centimeters) above normal, is occupying the entire tropical Pacific Ocean east of the international date line. In fact, the surface area covered by the warm water mass is about one-and-a-half times the size of the continental United States," Fu said. "We watched this warm water mass travel eastward from the western Pacific along the equator earlier this spring.  Right now, sea-surface height off the South American coast is 10 inches (25 centimeters) higher than normal, which is comparable with the conditions during the so-called 'El Nino of the century' in 1982-83." In addition, recent atmospheric water vapor data collected from NASA's Upper Atmosphere Research Satellite (UARS) show tell-tale signs of an El Nino condition in the tropical Pacific Ocean. "The Microwave Limb Sounder experiment on UARS is detecting an unusually large build-up of  water vapor in the atmosphere at heights of approximately eight miles (12 kilometers) over the central-eastern tropical Pacific. Not since the last strong El Nino winter of 1991-92 have we seen such a large build-up of water vapor in this part of the atmosphere," said JPL's Dr. William Read. "Increased water vapor at these heights can be associated with more intense wintertime storm activity from the 'pineapple express,' a pattern of atmospheric motions that brings tropical moisture from Hawaii to the southwestern United States. This phenomenon is an example of how the ocean and atmosphere work together to dictate the severity of El Nino events." An El Nino is thought to be triggered when steady westward blowing trade winds weaken and even reverse direction.  This change in the winds allows the large mass of warm water that is normally located near Australia to move eastward along the equator until it reaches the coast of South America.  This displaced pool of unusually warm water affects evaporation, where rain clouds form and, consequently, alters the typical atmospheric jet stream patterns around the world. The change in the wind strength and direction also impacts global weather patterns. In May, NOAA issued an advisory regarding the presence of the early indications of El Nino conditions. Subsequent El Nino forecast activities supported by NOAA indicate the likelihood of a moderate or strong El Nino in late 1997. The forecast model operated at NOAA's National Centers for Environmental Prediction used data collected by the TOPEX/POSEIDON satellite. "The added amount of oceanic warm water near the Americas, with a temperature between 70-85 degrees Fahrenheit, is about 30 times the volume of water in all the U.S. Great Lakes combined," said Dr. Victor Zlotnicki, a TOPEX/POSEIDON investigator at JPL.  "The difference between the current, abnormally high amount of heat in the near-surface waters and the usual amount of heat in the same area is about 93 times the total energy from fossil fuels consumed by the United States in 1995." On-going NOAA advisories on El Nino conditions are available on the Internet at the following URL: http://nic.fb4.noaa.gov:80/products/analysis_monitoring/ensostuff/index.html The climatic event has been given the name El Nino, a Spanish term for a "boy child," because the warm current first appeared off the coast of  South America around Christmas.  Past El Nino events have often caused unusually heavy rain and flooding in California, unseasonably mild winters in the Eastern United States and severe droughts in Australia, Africa and Indonesia.  Better predictions of extreme climate episodes like floods and droughts could save the United States billions of dollars in damage costs.  El Nino episodes usually occur approximately every two to seven years. Developed by NASA and the French Centre National d'Etudes Spatiales (CNES), the TOPEX/POSEIDON satellite uses an altimeter to bounce radar signals off the ocean's surface to get precise measurements of the distance between the satellite and the sea surface. These data are combined with measurements from other instruments that pinpoint the satellite's exact location in space. Every ten days, scientists produce a complete map of  global ocean topography, the barely perceptible hills and valleys found on the sea surface.  With detailed knowledge of ocean topography, scientists can then calculate the speed and direction of worldwide ocean currents. The Microwave Limb Sounder instrument was originally designed to study atmospheric ozone depletion, but scientists have devised new ways of using the data to study atmospheric water vapor.  The Upper Atmosphere Research Satellite is completing its sixth year of operation after being designed for only a two-year mission, and is conducting an extended mission of longer-term global monitoring. The Jet Propulsion Laboratory, a division of the California Institute of Technology, Pasadena, CA, manages the TOPEX/POSEIDON mission and the MLS instrument for NASA's Mission to Planet Earth enterprise, Washington, DC.  The UARS satellite is managed by NASA's Goddard Space Flight Center, Greenbelt, MD. NASA's Mission to Planet Earth is a long-term science research program designed to study the Earth's land, oceans, air, ice and life as a total system.
--------
397-> Artificial Intelligence Improves Heart Attack Diagnosis
DALLAS, Sept. 16 -- Drawing on artificial intelligence technology, researchers have for the first time found that machines show promise of improving on human's ability to diagnose heart attacks, according to a study in today's American Heart Association journal Circulation. Called "artificial neural networks," the computer-based method was more accurate than the cardiologist in reading the electrocardiogram (ECG), a test used to diagnose heart attacks in patients seen for chest pain in hospital emergency departments. The study was reported by Lars Edenbrandt, M.D., Ph.D., and co-author Bo Heden, M.D., Ph.D., of the University Hospital, Lund, Sweden. "The neural networks performed higher than an experienced cardiologist, indicating that they may be useful as decision support," says Edenbrandt, a consultant in the department of clinical physiology at the University Hospital. Neural networks are designed to "think" like humans, drawing knowledge and decision-making capabilities through experience. To teach a neural network how to recognize heart attacks, researchers exposed the computer memory to thousands of electrocardiogram readings, "more than any cardiologist could possibly read in a lifetime," notes Edenbrandt. In the study researchers included 1,120 ECG records of people with heart attacks and 10,452 ECGs records that were normal. The neural networks were found to be 10 percent better at identifying abnormal ECGs than the most experienced cardiologists on staff. An estimated 25 percent of ECG readings are "misjudged or overlooked" by the physician, and a person may be sent home from the hospital without a correct diagnosis, according to the scientists. However, the technology still won't replace a skilled physician who understands the fine points of the "the art of medicine because the ECG reading is only one of several tests used by physicians to diagnose a heart attack. Doctors will still need to talk to patients about their symptoms and medical history," he says. Other co-authors are Hans Ohlin, M.D., Ph.D., and Ralf Rittner, M.Sc. Circulation is one of five medical journals published by the Dallas-based American Heart Association.
--------
398-> Chernobyl Animals Highly Contaminated But Undeformed
When University of Georgia researchers hold a Geiger counter over rodents living near the Chernobyl Nuclear Power Plant in the Ukraine, the clicks grow quickly into a continuous roar. "You wouldn't want to handle an animal like that, and yet they are surviving," said Cham E. Dallas, a UGA associate professor of pharmacology and toxicology, who - with fellow researchers - has made eight expeditions to Chernobyl since 1991. The wildlife near Chernobyl, the site of the world's worst nuclear disaster, not only survives, it abounds in the area, now largely abandoned by humans. Species of fish and rodents do exhibit genetic change, but no apparent defects, according to Dallas. The surprising data suggest that the environmental damage caused by Chernobyl was less severe than many experts had feared. Nevertheless, Dallas cautioned, it is too early to tell what the long-term effects of the disaster will be. Dallas is presenting a paper summarizing his Chernobyl research during the American Chemical Society's 1997 annual meeting in Las Vegas, which runs through Friday, Sept. 12. He and his colleagues also have published their findings in Nature and journals devoted to ecotoxicology and similar areas of study. The research is funded by the U.S. Department of Energy. A 1986 explosionand fire in Chernobyl's Reactor 4 released 100 times more radioactivity than was released by the combined atom-bomb explosions at Hiroshima and Nagaski in 1945. UGA researchers have documented unprecedented levels of radiation in fish and rodents living in the area. UGA researchers have considerable experience in radioecology, the study of bioeffects in the environment, through their work at the Savannah River Ecology Laboratory. Since 1951, SREL scientists have conducted ecological research at the Savannah River Site, a nuclear weapons materials processing complex on the Georgia-South Carolina border near Aiken, S.C. Experience at the SREL has shown that, "a great deal of contamination over time ended up in aquatic species," Dallas said. Catfish, carp and other species of fish that Dallas has examined near Chernobyl show levels of radioactive contamination three to five times higher than anything found in the United States. Rodents such as voles show even higher levels of contamination, as much as 10 times the levels found in U.S. rodents. "No one has ever seen levels like that before," Dallas said. UGA researchers also have found genetic changes in these animals. "I use the word change and not damage," Dallas said, because the implications of the changes remain unclear. "We found no deformed animals. None at all." Dallas and his colleagues recently expanded their Chernobyl studies to include humans. The government of the former Soviet Union allowed the reactor to burn for three days before informing the 50,000 residents of nearby Pripyat of the accident. Pripyat residents, meanwhile, went about their regular business. Some even watched the reactor burn from their balconies. The UGA researchers are focusing their human studies on the "liquidators," the thousands of people who cleaned up the contamination around the reactor accident site with "bucket and shovel technology." Many cleanup personnel have developed thyroid cancers from radioactive iodine, which the reactor accident released in large quantities. "Their health is really hurting," Dallas said. Most of the human contamination is clustered along transportation arteries, especially train routes. People in the area buy their food on train platforms, much as they did in the United States 50 and 100 years ago. Many of these trains passed through the contaminated area. The human health problems could worsen as the years pass. "In human populations, we're still waiting for the big effects," Dallas said. Dallas initiated his Chernobyl studies because the site offered an unmatched opportunity to study the impact of a large release of radioactivity into the environment. The project led to the first application of clinical analysis techniques, such as superoxide dismutase (SOD), to field studies. Nutritionists use SOD to measure levels of oxygen scavengers, which gobble up harmful, chromosome-damaging oxygen radicals in the body. Radioactivity produces oxygen radicals, so Dallas's team can use SOD as an indirect measure of its presence. The UGA researchers conduct their month-long field trips to Chernobyl under logistically trying conditions. They must take their own food into contaminated areas guarded by machine-gun-toting soldiers. Gas for their vans is hard to come by. And they must often work wearing protective suits, respirators and radiation monitors. Still, the effort is worth the trouble, according to Dallas. "We're getting a picture no one else has been able to get," Dallas said. Although the Chernobyl accident happened 11 years ago, there could be more catastrophic releases of radiation into the environment in the future. Another nuclear-reactor accident is a possibility, but so is a nuclear-bomb attack by terrorists. "We're going toneed to know how to guage that sort of impact," Dallas said.
--------
399-> How They Know Where They're Going: New Research On Cabbies Shows That The Brain's Right Hippocampus Is Key For Navigation
WASHINGTON, D.C. September 16 -- Immediate left on Puddledock, right on Queen Victoria Street, left on Friday Street. New research for the first time shows through systematic brain imaging tests on London taxi drivers that a human's ability to remember the route to a destination requires the right hippocampus of the brain. "This research shows that the hippocampus in humans houses the mental maps that we use to find our way around," says the study's lead author, Eleanor Maguire, of London's Institute of Neurology. "The discovery helps to open up the study of human navigation and suggests that different brain networks support different types of memory." Maguire's study, funded by the Wellcome Trust, is published in the September 15th issue of The Journal of Neuroscience. "While it has been known for some time that the hippocampus is involved in spatial cognition in animals, Maguire's work is very important because it suggests this also may be true for humans," says Patricia Sharp, a learning and memory expert at Yale University. In the study, the researchers analyzed spatial navigation by imaging the brains of 11 taxi drivers with positron emission tomography (PET). London taxi drivers have to train for several years and undergo strict testing before they can gain a license to work. "Therefore, they were the ideal people to study in order to ascertain the brain regions that are involved in the use of a well-developed mental map of a large city," says Maguire. The PET images, which highlight neural activity by measuring changes in brain blood flow, indicated that the right hippocampus was activated significantly when the taxi drivers recalled complex routes, but not during other types of complex memory recall. For example, it was not activated when the drivers were asked to recall the plots of familiar, famous films -- a test that also requires the recall of information involving a sequence of events. The brain areas activated during the film recall test were located in the left frontal lobe. "The results show that the right hippocampus is not merely activated in all types of complex memory recall, but is specially recruited for route recall," says Maguire. The research also investigates the role of the right hippocampus in navigation. "A network of brain regions may support the construction of a mental map of space, but only the right hippocampus is specifically involved in relating the elements of a route together in an overall framework for navigation," says Maguire. For example, the scientists found that when taxi drivers remembered information about individual world-famous landmarks such as New York's Statue of Liberty, the activated brain regions included the occipitotemporal regions, posterior cingulate gyrus, medial parietal area and parahippocampal gyrus. The route memory test also triggered activation in these brain areas. The right hippocampus, however, was activated only during the route memory test. In future studies, the researchers plan to investigate further the specific operations that the right hippocampus performs during navigation. Maguire's co-authors, Richard Frackowiak and Christopher Frith are also from the Institute of Neurology. Maguire and Frackowiak are members of the Society for Neuroscience, an organization of more than 27,000 basic scientists and clinicians who study the brain and nervous system.
--------
400-> A New State Of Matter Turns A Solid World Into A Melting One
A new form of matter, clusters of atoms, has been oberved in recent years behaving in curious ways. Now research indicates that clusters have another, previously unsuspected property: they can melt at different temperatures from "solid" matter. An experiment described in last week's Science (Sept. 12) paints an exotic portrait of certain substances seemingly confounding nature by existing as a liquid, instead of a solid, at room temperature. George Bertsch, a theoretical physicist at the University of Washington, describes how the experiment with clusters of sodium atoms found that the atoms did not follow sodium's normal pattern, melting at 97.8 degrees Centigrade (208 degrees Fahrenheit). Instead, the small clusters of atoms melted at minus 6 degrees Centigrade (21 degrees Fahrenheit), well below room temperature. The discovery was the work of Hellmut Haberland at the University of Freiburg in Germany. Bertsch, who has been following the field of cluster research for the past decade, writes that as a result of the experiment, scientists are now challenged "to understand what happens to the liquid and solid phases in small particles." European researchers are working on a number of practical applications for the cluster phenomenon. Attempts are being made to produce thin films of silicon clusters that would process signals carried by light. Others are researching the use of clusters to improve the magnetic recording of data. And Haberland has been reported to have produced clusters of the element molybdenum that will even stick to Teflon. Clusters have been called a new type of matter, says Bertsch, because they appear to be a bridge between atoms and the world of normal size, and have strange magnetic, electrical and optical properties. What is particularly curious, he says, is that the properties of the clusters depend on the number of atoms they contain. Bertsch notes that most clusters are very unstable collections -- "they touch a wall and they are gone." But a decade ago it was discovered that certain clusters contain "magic numbers" of atoms that make them particularly stable. These numbers begin with just two atoms, and continue through eight, 20 and 40 and into the hundreds of atoms. The German researcher used magic-number clusters of 139 sodium atoms. The melting point was observed by forming condensation 'droplets', rather like hot steam hitting a cold window, and passing the condensate through a mass spectrometer and finally an electric field. Bertsch concedes that the research is controversial, and there are physicists who insist there can only be one melting temperature for each of the 92 natural elements. But, he says, "as scientists we have to look at the evidence." What's more, he believes there is evidence that the same phenomenon that the German researcher demonstrated with sodium, also exists with atomic clusters of both tin and lead. The UW scientist is hesitant to attempt an explanation of what is causing the lower melting point of these elements. However, he notes, it has been suggested that there is a relation to a theory known as surface melting: when a substance reaches melting temperature, only a small surface layer melts immediately. "As solid sodium reaches melting temperature, a small layer of liquid might form on top of the solid," he says. "In a cluster, all you would have is this outer, liquid layer." It could be said, says Bertsch, that this new type of matter is "practically all surface." If there is already something strange happening at the surface of certain elements, "then you accentuate that behavior when you create clusters."
--------
401-> First Images Of Key Viral Protein Could Lead To New Strategies For Human Gene Therapy
New images of an L-shaped molecule on the surface of a mouse leukemia virus could help scientists realize the promise of human gene therapy--the effort to cure disease by inserting genes directly into human cells. The images, published in the September 12 issue of Science, show the crystal structure of a piece of the virus's envelope protein--the piece required to recognize and bind to receptors on the surface of a mammalian cell. "This is the first high-resolution structure of any retrovirus receptor-binding domain," says Dr. Peter S. Kim, a Member of the Whitehead Institute for Biomedical Research and an Associate Investigator of the Howard Hughes Medical Institute (HHMI). "Knowing the structure is critical for understanding how retroviruses bind to and enter cells and should help improve the effectiveness of human gene therapy." Dr. Deborah Fass, first author of the Science paper and a post-doctoral fellow in Dr. James Berger's laboratory at the Whitehead Institute, explains: "Retroviruses are simultaneously a profound human medical problem and a potential medical solution. Natural retroviruses cause AIDS, leukemia, and other diseases in both humans and animals. But remodeled retroviruses, stripped of their ability to cause disease, can be ideal vehicles for gene therapy." Retroviruses are designed by nature to transport their genetic information into the nucleus, or command center, of the cells they infect. The retrovirus DNA inserts itself into the cell's DNA where it is duplicated every time the cell divides. In a natural infection, the retrovirus DNA eventually subverts the cell's command machinery, forcing it to make thousands of new virus particles. Almost twenty years ago, researchers discovered that they could disable some retroviruses and trick them into ferrying human genes, instead of their own genetic material, into cells. These tiny delivery vehicles, produced from a mouse leukemia virus, lack the genes required to make new virus particles. They have the potential to combat disease by inserting normal genes into tissues of patients with severe genetic diseases or cancer--a strategy called somatic cell gene therapy. Retroviral vectors have been used in clinical trials to treat severe combined immune deficiency disease (SCID, the disease made famous by the "Bubble Boy"), and a very small number of other diseases, including several forms of cancer. Efforts to apply the technique more broadly have been limited, in part because of the inability to target retroviral vectors to specific types of cells. Ideally, if you were treating a genetic disease involving the nervous system, you would want a gene delivery vehicle that carried its cargo directly to nerve cells in the brain or spinal cord; for a muscle disorder, such as muscular dystrophy, you would want a vehicle that attached itself exclusively to muscle cells. Researchers have not had much success targeting retroviral vectors, in part because no one knew which part of the retrovirus's envelope protein was responsible for recognizing receptors on the surface of target cells. There had to be a "key" that allowed the retrovirus to lock on to one type of cell and bypass others. The current studies, conducted jointly by the Kim and Berger laboratories at the Whitehead Institute and by Dr. James Cunningham's HHMI laboratory at Brigham and Women's Hospital in Boston, have identified that key. On the outer surface of the retrovirus envelope protein (on the short leg of the "L" that makes up the binding domain), two helices and a series of loops fit together to form a precise pattern of ridges and valleys. This pattern is the key that determines which cells are accessible to the virus and which are not. "By adding cell-specific hormones or other factors to the critical loops, gene therapy researchers can begin to reprogram retroviruses to bind to specific target cells," Dr. Cunningham says. "Most importantly, we can also answer fundamental questions about the role of the receptor-binding apparatus in the retrovirus life cycle." Researchers have been trying to find the elusive receptor-binding site for more than a decade. Dr. Fass says, "The breakthrough came when Robert Davey, a post-doctoral fellow in Jim Cunningham's laboratory, purified the critical domain of the binding subunit and devised a way to obtain crystals using large quantities of the domain. By optimizing the conditions for crystal formation, we were able to solve the structure at high resolution using X-ray crystallography." This research collaboration was supported by the Howard Hughes Medical Institute. The X-ray crystallography studies were conducted in the W.M. Keck Foundation X-ray Crystallography Suite at the Whitehead Institute.
--------
402-> Better Maternal Nurturing Means Better Physical And Physiologic Response To Stress For Adult Rats
The more newborn rat pups are licked and groomed by their mothers, the better equipped they are to handle acute stress in adulthood, report Emory University's Paul M. Plotsky, Ph.D., and his McGill University colleagues in this week's issue of Science. Dr. Plotsky and his colleagues at Emory are applying the current findings and those of their earlier work to observational human studies of maternal support (or lack thereof) of infants born prematurely or born to mothers diagnosed with significant postpartum depression. Those rats in the current investigation who received the most infantile stimulation handled stress well both externally -- by exhibiting appropriate behaviors -- and internally -- as evidenced by an appropriate and balanced response by the animal's endocrine system and brain chemistry. Researchers have long suspected that early experiences affect the long-term development of a complex aspect of the central nervous system (CNS) known as the hypothalamic-pituitary-adrenal (HPA) response. The basis for this hypothesis can be attributed in great part to earlier work that showed "handling" during infancy improved behavioral and endrocrine stress responses. Handling involves separating, as a group, a litter of rat pups from their mother for a few minutes each day for the first 10 days after birth. The action is seen not as maternal deprivation, since mother rats routinely leave the nest for varying periods of time after birth, but as a form of infantile stimulation. The current study shows a high correlation in "handled" rat pups between optimum maternal care -- as measured by amount of licking and grooming, and an arched back form of nursing -- and better stress responses in later life as compared to animals experiencing moderate maternal deprivation. "These findings provide support for the Levine hypothesis that the effect of postnatal handling on HPA development is mediated by effects on mother-pup interaction," the authors report. "Thus handling increases the frequency of licking/grooming and these maternal behaviors are, in turn, associated with dampened HPA responsivity to stress." Several physiologic measurements noted by the McGill-Emory team verified the association in adult rats between the desirable trait of HPA inhibition and maternal care. Specifically, pituitary adrenocorticotropic hormone (ACTH) and corticosterone response to acute stress were reduced, levels of hypothalamic corticotropin-releasing hormone (CRH) messenger RNA were reduced, and glucocorticoid feedback sensitivity was enhanced. "We believe that the effects of early environment on the development of HPA responses to stress reflect a naturally-occurring plasticity (adaptability) whereby factors such as maternal care are able to program rudimentary, biological responses to threatening stimuli," the authors say. "Like humans, Norway rats inhabits a tremendous variety of ecological niches, each with varied sets of environmental demands. Such plasticity could allow animals to adapt defensive systems to the unique demands of the environment. Since most mammals usually spend their adult life in an environment that is either the same or quite similar to that in which they were born, developmental "programming" of CNS (central nervous system) responses to stress in early life is likely to be of adaptive value to the adult..." Long range goals of this line of research are to develop interventions for human infants in whom the HPA and behavioral responses to stress are at risk of being compromised -- and to design drugs for adults in whom the stress response has been adversely affected and who are thus at risk for affective disorders such as addiction, anxiety disorders and depression, says Dr. Plotsky, who is professor of Psychiatry and Behavioral Sciences and directs the department's Stress Neurobiology Laboratory at the Emory University School of Medicine. Authors of the current paper, listed in order, include: Dong Liu (first author), Josie Diorio, Beth Tannenbaum, Christian Caldji, Darlene Francis, Alison Freedman, Shakti Sharma, Deborah Pearson, Paul M. Plotsky and Michael J. Meaney; with the exception of Dr. Plotsky, all are from the Developmental Neuroendocrinology Laboratory, Douglas Hospital Research Center, Departments of Psychiatry, and Neurology and Neurosurgery, Faculty of Medicine, McGill University, Montreal, Canada.
--------
403-> Discovery Of A Shiny Marine Fossil Is Latest Evidence That British Columbia Was Once Part Of Baja California
Small sea creatures that have lain in pristine condition for eons have given a University of Washington researcher the clearest evidence yet that about 80 million years ago a southern landmass began migrating to the north. And what today are rainy British Columbia and chilly southern Alaska were once the sunny climes of Baja California. For years scientists have been arguing about the theory of the wandering West, and whether it would have been possible for plate tectonics to have moved massive chunks of the Earth's crust northward along a gigantic faultline. Now UW paleontologist Peter Ward and his collaborators report in tomorrow's Science magazine that the discovery of pearly fossil shells of an extinct mollusk on two islands off the eastern coast of Vancouver Island give clear evidence that the region was once nearly 2,000 miles to the south. "Everything that we now recognize as coastal British Columbia was once off the coast of what is now Mexico or Southern California. It was nowhere near its present latitude," says Ward. Ward's study was aimed at proving that traces of magnetism in rocks on the British Columbia coast were the actual relic of the Earth's ancient magnetic field. As the layered, or sedimentary, rocks were deposited under the sea, mineral crystals became magnetized, freezing the magnetic field. If the rocks had been formed at the equator, the direction of the magnetism in the formation would have been horizontal. At the poles, it would have been vertical. Thus if rocks in British Columbia show a magnetic field slightly tilted from the horizontal, the implication is they were formed far to the south. But there is a catch. As the Earth's crust is heated, particularly by volcanic upheavals, the mineral crystals in the rocks can become remagnetized, leaving no trace of the earlier, ancient magnetic field. So those British Columbia rocks may not have moved north, but simply been remagnetized over time. Ward calls the 131 rock samples he obtained from the two islands, Hornby and Texada, "critical and crucial" in resolving doubt they were deformed by heating. The evidence comes from the shelled marine animals, called ammonites, which Ward's team recovered from sites on the islands. The fossil shells, each the size of a man's hand, still had a pearly luster, indicating the presence of the original aragonite, or mother of pearl. If the surrounding rocks had been subjected to heating, the calcium carbonate in the shells would have turned to black calcite. Indeed, Ward says, all of the ammonites discovered to date on neighboring Vancouver Island are black. The researchers took their core samples only where they found the shiny fossils. In every case, the sedimentary rocks showed a magnetic field closer to horizontal than would be expected for northerly latitudes. Since there was no evidence of heating, and remagnetization, the conclusion was that the rocks were formed far to the south 70 to 80 million years ago, based on the evidence of fossil dating. Ward concedes that criticisms are certain to be leveled at the new findings. Some geologists have theorized that the sedimentary rocks in the region of British Columbia have been affected by compaction as one layer is deposited on top of the other, causing the magnetized crystals to flatten. Ward, however, notes that if that were the case, the ammonites would also be flat and deformed. "An ammonite is very squishable. If you had compaction the fossil would not be as pristine as our samples," he says. The researcher acknowledges that his calculation of the speed of the northward drift of the rocks is too fast for some. He theorizes that the rocks began migrating from Baja California perhaps 75 million years ago, arriving at their present position about 60 million years ago. That rate of movement, about 2,000 miles in 15 million years, indicates a slippage of about 21 centimeters (about 8 inches) a year, compared with the San Andreas fault's current movement of 4 centimeters a year. "That is fast, but not science- fiction fast," says Ward, noting that crustal movements around Indonesia also are rapid. Such a huge landmass, he says, must have slipped its way north along a giant crustal fault stretching from California to British Columbia. However, critics say, there is no evidence of such a fault. The UW researcher believes the fault is certainly extinct, and because it is buried deep in the Earth's crust, it may never be detected. Ward also dismisses observations that fossils in the British Columbia rocks show no evidence of tropical marine life, typical of Baja California. He points out that the rocks were formed in the Cretaceous era when the Earth was uniformly warm, with very little latitudinal differences in animal and plant life. This study of fossils to confirm the ancient origin of rocks, says Ward, brings new excitement to a theory that gigantic blocks of rock "drifted that far that quickly."
--------
404-> Electrically Based Technologies Heat Up The Cleanup Market
RICHLAND, Wash. -- Technologies that promise faster, cheaper and more effective cleanup of certain contaminated soils now are available commercially through a new company formed jointly by Battelle and Terra Vac Corporation of Irvine, Calif. Current Environmental Solutions LLC will bring to market two electrically based technologies -- Six-Phase Soil Heating and In Situ Corona. Six-Phase Soil Heating is a rapid, cost-effective technique that steam strips contaminants from soils in place, eliminating the need for excavation or soil pretreatment. In Situ Corona is designed to destroy toxic materials such as chlorinated solvents, PCBs, pesticides and industrial fuel oils and lubricants. The technologies were developed by Battelle researchers at Pacific Northwest National Laboratory through Department of Energy funding. Battelle operates Pacific Northwest for DOE. CES, based in Richland, Wash., initially will focus on the deployment of Six-Phase Soil Heating as well as further development of In Situ Corona. Six-Phase Soil Heating relies on an electrical current to heat the soil, causing moisture to boil and strip volatile and semi-volatile contaminants from soil particles. The contaminated steam is removed through venting and treated above ground. The splitting of conventional three-phase electricity into six separate electrical phases allows for more uniform heating and larger treatment areas. Unlike conventional vapor extraction methods, CES's technique is effective in tightly bound soils, such as silts and clays, as well as saturated soils. The process not only is less expensive than many conventional technologies, but quicker, requiring weeks to remediate large sites versus months or years with other soil-venting technologies. Whereas the soil heating technique removes contaminants for above-ground treatment, In Situ Corona is designed to destroy organic contaminants underground. Higher voltages are used to create an ionizing plasma, similar to a match flame, that destroys organic contaminants in place, or in situ. This method is effective at destroying nonvolatile contaminants such as greases, pesticides and transformer oils containing PCBs. In Situ Corona is still under development; however, Six-Phase Soil Heating has been demonstrated at several sites across the United States over the past four years. In a field demonstration at the Savannah River Site in 1993, soil heating was used to treat more than 675 metric tons of soil contaminated with trichlorethylene and perchloroethylene, including organics suspended in a clay layer nine meters (29.5 feet) below the surface. Within 25 days, 99.7 percent of the contaminants were removed. Most recently, the technique was used to treat contaminated soil at an electronics manufacturing plant, where more than 4,990 kilograms (11,000 pounds) of perchloroethylene was removed from tight clay soil within six months. Six-Phase Soil Heating also is being developed to treat dense organic liquids in aquifers, an application that was tested successfully at Dover Air Force Base. For more information, contact Theresa Bergsman, Current Environmental Solutions, at (509) 943-8810. Terra Vac is a multinational environmental engineering firm specializing in in situ soil and groundwater remediation and site assessments with 11 offices on three continents. Battelle serves industry and government clients in 30 countries by developing, commercializing and managing technology.
--------
405-> Space Station Technology Will Bring Expert Medical Care To Remote Areas On Earth
Soon people who do not live in or near large cities with major medical facilities will have expert medical care readily available.  Patients in remote or medically underserved areas of the country will benefit from an experiment in advanced telemedicine conducted jointly by NASA's Lewis Research Center, Cleveland, OH, and Ames Research Center, Moffett Field, CA, and James D. Thomas, M.D., FACC, of The Cleveland Clinic Foundation, Cleveland, OH. Recently, a "patient" undergoing an echocardiographic examination at Lewis was "remotely" diagnosed by Dr. Thomas at Ames.  He viewed a real-time display of echocardiographic video images transmitted over the broadband NASA Research and Education Network (NREN).  Dr. Thomas interactively guided the technician administering the procedure through a two-way voice link between the two sites. "I was very pleased with the diagnostic quality of the echocardiograms," said Dr. Thomas.  "Digital echocardiographic equipment will be on the International Space Station when it is operational.  Echocardiography is more practical for life in space than other imaging techniques, such as magnetic resonance imaging (MRI) because it requires less power, is noninvasive, is small and versatile, and is not magnetic or radioactive.  The early results of our experiment support our belief that this technology holds great promise for use in space as well as use on Earth by means of telemedicine." Echocardiography is a medical technique that applies the methods of ultrasound imaging to the cardiac system, providing a "motion picture" of the heart in action.  A small, rural clinic may have access to an echocardiograph machine but not to a technician specially trained in its operation, or to a staff cardiologist.  If the clinic were connected to a major metropolitan medical facility through a high-speed communications network, a minimally trained technician could carry out the procedure under the supervision and guidance of qualified echocardiography personnel. While many telemedicine requirements can be satisfied by the transmission of still images (e.g., X-ray photographs), the challenge of procedures such as echocardiography is that high-resolution, moving images must be transmitted in real time.  This requires a reliable broadband network and a robust data-compression mechanism. "In the demonstration, we used the NREN to assess the clinical feasibility of conducting remote echocardiography, as well as the technical feasibility of supporting remote echocardiography, by determining the minimum network needed and the maximum video compression required to produce a transmission of high-resolution medical imagery," said Christine Falsetti, NREN project manager at Ames. The NASA Research and Education Network is NASA's cornerstone project of the interagency Next Generation Internet (NGI) Initiative.  In Oct. 1996, President Clinton and Vice President Gore announced their commitment to the NGI initiative based upon the strong research and development programs across Federal agencies. "This experiment was a step toward reaching the goals of the NGI," said David A. Foltz, networking project manager at Lewis.  "Pushing current networking technologies to the limit helps us understand how to design, build and operate a national communications network for the future." Reaching these goals will affect health care on Earth and will pave the way for physicians on Earth to view the heart function of an astronaut aboard the International Space Station. During the experiment, Lewis provided network engineering staff and hardware support to Dr. Thomas, while Ames provided overall network management of the NREN and related technical support to Lewis personnel.  The Cleveland Clinic Foundation provided echocardiograph equipment and support personnel used to examine the volunteer "patient" at Lewis. This experiment is a part of the cooperative agreement involving a two-year, $4 million grant to support the research and development of a digital echocardiography lab at The Clinic, that NASA announced earlier this year.
--------
406-> Research Links Brain Damage & Violent Crime -- USC Studies Point To Underlying Causes Of Violent Crime In Young Offenders
Some murderers show significant metabolic abnormalities in as many as six areas of the brain, several of which can suffer damage during gestation or birth, according to research published in the current (Sept. 15) issue of the Journal of Biological Psychiatry. But it appears to take the added complication of specific forms of maternal rejection to predispose a perinatally brain-injured youth to violence, according to another study in the current (September) issue of the American Journal of Psychiatry. "It's becoming increasingly clear that we're never going to solve the problem of violent crime if we don't address the link between brain damage and criminal behavior," says University of Southern California researcher Adrian Raine, Ph.D., who directed both studies.  "Better prenatal, perinatal and postnatal care and better support for inadequate parents now appear to be the most promising forms of intervention." For the Biological Psychiatry study, Dr. Raine directed scientists at USC and the University of California at Irvine as they used positron emission tomography (PET) to scan the brains of 41 murderers who had pleaded not guilty by reason of insanity.  The scientists also scanned the brains of 41 control subjects matched for known mental disorders and for age and gender.  Mental disorders among the subjects included schizophrenia, organic brain damage and a history of head injury. PET scans measure the uptake of blood sugar (glucose) in various brain areas during the performance of simple, repetitive tasks.  (Glucose is the basic fuel that powers most cell functions.  The amount used is directly related to the amount of cell activity.) On average, the murderers showed significantly lower rates of glucose uptake in three areas of the brain -- the prefrontal cortex, the corpus callosum and the posterior parietal cortex.  Their rates were 4, 18 and 4 percentage points lower, respectively, than the rates measured in control subjects performing the same tasks. When the researchers compared the brain's two hemispheres for glucose uptake rates, they found that murderers consistently showed weaker activity in the amygdala and the hippocampus of the brain's left -- or more rational -- hemisphere.  These glucose uptake rates were each 4 percentage points lower than the rates measured in control subjects performing the same tasks. But the murderers showed stronger activity in the thalamus, the amygdala, and the hippocampus of the right -- or more emotional -- hemisphere.  These glucose uptake rates were 6, 6 and 3 percentage points higher, respectively, than the rates measured in control subjects performing the same tasks. € The prefrontal cortex is involved in the inhibition of aggressive behavior. Studies have shown that damage to the region correlates with impulsiveness and unpredictable, uncontrolled actions. € The corpus callosum acts as a sort of computer modem, communicating information between the brain's left hemisphere, which is associated with reason and language, and the brain's right hemisphere, which is associated with emotion. € The posterior parietal cortex is involved in the integration of sensory input and the formation of abstract concepts.  Reduced glucose uptake in a portion of this region (the left angular gyrus) has been correlated with reduced verbal ability, while damage has been linked to deficits in reading and arithmetic.  Violent offenders have consistently been shown to do worse in school than their law-abiding peers. € The thalamus, the amygdala and the hippocampus are among the principal regions comprising the brain's limbic system -- a complex system of nerve pathways and networks.  The thalamus relays impulses from the amygdala and the hippocampus to the prefrontal cortex, the region of the brain at the very front of each cerebral hemisphere.  The functions of the prefrontal cortex are profoundly concerned with emotions, memory, learning and social behavior. "Poor functioning of these limbic areas helps explain why violent offenders fail to learn from experience and are less able to regulate their emotions," Raine says.  "The subcortical findings are new and need to be replicated, but they are consistent with previous cognitive studies indicating that the more dominant left hemisphere may be less able to control the more emotional right hemisphere in violent offenders." In 1994, Raine published the first evidence that murderers' brains show significantly lower rates of glucose uptake.  The initial research looked only at the prefrontal lobe, an area of the brain where deficits had already been linked with several mental illnesses, including schizophrenia and depression. Raine's latest research demonstrates a more powerful link between brain damage and criminal violence, because it eliminates the possibility that mental disorders alone could have predisposed the criminal to violence.  "No mental disorder has been found to involve brain damage to all six of these brain areas showing metabolic abnormalities," Raine explains. The lower glucose uptake observed in the six areas does not appear to reflect generalized brain dysfunction, he said.  Nor does it appear to be related to age, handedness, ethnicity, or recorded history of head injury. If reduced metabolic activity in the six areas is in fact connected to homicidal tendencies in humans, then interventions to help reduce the damage would help reduce violence.  "Interventions must be made at an early age to have maximal impact," Raine cautions. Known sources of brain damage to the six brain regions include vigorous shaking (which can lacerate white fibers that link the cortical circuits); fetal alcohol syndrome (which damages the corpus callosum); and eclampsia, an advanced stage of toxemia in pregnancy (which can damage the infant's hippocampus).  Other perinatal complications resulting in brain damage are less consistently related to specific regions of the brain. Forceps-related injuries, for example, can damage a number of brain areas. Despite the strong link between brain damage and a propensity to violence in murderers, perinatal complications alone do not appear to predispose all individuals to crime, according to the American Journal of Psychiatry article. Raine directed a team that looked at the medical histories of 4,269 Danish males born in the years 1959 through 1961. The team's obstetricians assessed birth complications at the time of delivery.  Interviews conducted with the infants' mothers at the end of the first year determined whether the boys had experienced maternal rejection.  Possibilities included mothers who simply did not want their pregnancies, who made unsuccessful attempts to terminate the pregnancy or who institutionalized their babies for more than four months in the first year of life. USC researchers combed the Danish National Criminal Register to determine which of the subjects had a record of violence, theft or any other criminal behavior by the ages of 18 or 34.  The database, which includes all police contacts and court decisions involving Danish citizens, is one of the world's most comprehensive and accurate crime registers. By the age of 18, boys whose mothers had experienced obstetrical complications were no more likely to have committed a violent crime than boys whose mothers had not.  But when these boys also experienced maternal rejection, their chances of committing a violent crime -- including robbery, murder and rape -- more than doubled (9% versus 4%).  Neither mental illness in the mothers nor recidivism among the offenders could account for the higher crime rates among this group. Maternal rejection and obstetrical complications did not, however, seem to have the same effect among offenders who committed their first violent crime between the ages of 19 and 34.  Adults with these two biosocial risk factors were no more likely than normal adults to commit a violent crime, Raine said. "Better prenatal care and counseling for at-risk mothers could lower the rate of violence perpetrated by juveniles and young adults, but it probably would not have the same effect on violent crimes perpetrated by older adults," Raine said.  "For late-onset adult offenders, we don't know as much about the underlying causes of violence.  The cause might be a head injury sustained in a traffic accident.  It might be alcoholism or other substance abuse.  Or it may turn out that these crimes are far more situational -- that is, caused by stress, a bad marriage or other sources of conflict." Birth complications and maternal rejection appeared to predispose offenders to some kinds of criminal offenses but not others.  Offenders with both risk factors were nearly twice as likely as control subjects to rob, rape and commit murder.  While fewer than 5% of the control group had committed a violent crime by age 34, about 8% of the group with biosocial risk factors had done so.  The risk-factor subjects also were more likely than control subjects to commit an assault or domestic violence (5.5% versus 7.5%). No such disparities were found, however, when the crimes involved threats of violence and weapons violations.  "The double hit of maternal rejection and obstetrical complications seems to predispose an individual to certain kinds of violent behavior, but not to lawlessness in general," Raine says. The research team, which in 1996 discovered a link between these biosocial risk factors and the propensity to commit crime in a smaller group of subjects, also was able to determine which of the three types of maternal rejection interacted most strongly with perinatal complications. In so doing, the researchers were able to rule out merely having negative feelings about the pregnancy as a risk factor for violent crime.  "Expectant mothers who don't want to bear children are often able to change their minds and bond with their child," Raine points out.  "It's the ones who take steps to rid themselves of their fetus or institutionalize their child who are the most problematic." Institutionalizing a child for four months or more during the first year of life proved the most detrimental form of maternal rejection.  A mother's failed attempt to abort her fetus was the second most detrimental form.  "Either form of maternal rejection may predict child abuse and/or neglect," Raine notes. "Proper bonding is important in the development of human compassion and empathy," Raine concludes.  "One ingredient of becoming a reckless, violent offender is being callous toward others.  The less an offender cares about you, the easier it is for him to hurt you to get what he wants." Both studies were funded by a Research Science Development Award from the National Institutes of Health. Raine is a professor of psychology in the USC College of Letters, Arts and Sciences and a research affiliate of USC's Center for the Study of Crime and Crime Control.  He is the author of "The Psychopathology of Crime:  Criminal Behavior as a Clinical Disorder" (1983) and has served as a consultant to the National Academy of Sciences on the biological bases of violence.
--------
407-> University Of Illinois At Chicago Tests Anti-Cancer Tablet
As the University of Illinois at Chicago's Institute for Tuberculosis Research celebrates  its 50th anniversary, researchers here are moving forward to identify components of the tuberculosis vaccine, BCG, that are effective in the treatment of cancers when taken orally. The institute first made headlines in 1950 when its renowned director, the late  Dr. Sol Roy Rosenthal, developed what appeared to be a new substrain and superior form of BCG, called the Tice substrain (after his mentor). The Tice substrain was the only effective TB vaccine available in the United States, though other BCG vaccines have been used in Western Europe for decades. With the decline of TB cases in the United States and a growing body of research showing BCG to be an effective stimulant of the immune system and anti-cancer agent, researchers at the Institute shifted the focus of their work. They began to extract and identify the components of BCG that are effective against cancer and tested those components in laboratory and animal studies. The UIC institute's most recently published research offers promise for an effective non-surgical treatment of breast and other hormone-dependent cancers that would be delivered orally and fight cancer using the patient's own immune system. Researchers identified an orally active compound from BCG that suppressed a hormone-dependent, human breast-cancer cell line growing in mice without functioning immune systems. BCG already is an established clinical treatment for bladder cancer, and tests also have shown it to be effective against colon and lung cancers. To work, BCG cells must have direct contact with tumor cells. Patients being treated with BCG for bladder cancer, therefore, must be injected with the vaccine. Injecting BCG close to the tumor, however, carries a risk. A blood vessel may be nicked and the living organism can grow in the patient. The anti-cancer component of BCG identified by UIC researchers not only may be taken orally, but also may be produced inexpensively. Researchers estimate that a human dose could cost as little as $3. The compound developed at the Institute for Tuberculosis Research has the added benefit of having no unpleasant side-effects, such as the flu-like syndrome that accompanies immunization with the TB vaccine. Further investigation into the active BCG component and its mode of action is planned and will be necessary before the institute can begin human clinical testing. (Editor: For more information, call Jody Oesterreicher, 312/996-8277; joest@uic.edu)
--------
408-> University of Florida Study Reveals Loss In Sensory Perception       May Not Be Linked To Aging
By Connie Daughtry	GAINESVILLE, Fla.---A University of Florida researcher says you can pick out a lemon at any age -- at least if you smell it. After six years of volunteers smelling lemons and some 40 other scents including natural gas and bubble gum, Dr. Marc Heft has determined that aging has little effect on smell, taste or touch. "There is a belief that as you age, everything deteriorates. The truth is there is only a modest change in sensory functioning," said Heft, director of the Claude Pepper Center for Research on Oral Health in Aging at UF's College of Dentistry. "There are a number of older folks that can smell and taste just as well as many of the young." Ruling out various factors, including disease and whether the participants were smokers, the researchers found less than 10 percent of the differences in sensory perceptions are age-related.  	Heft said the findings mean good news for older people, who are experiencing a higher quality of life and are living longer. "In Florida alone there are more than a million people over the age of 75, and they are a fairly healthy, vivacious population," Heft said. "What's emerging is a more upbeat vision of aging." 	UF researchers recruited 180 healthy volunteers between the ages of 20 and 88 for the study. The researchers' goal was to look at normal changes in the senses of taste, touch and smell as a person ages. They also tested the volunteers' abilities to feel pain and tell differences in temperature. The volunteers participated in five one-hour sessions to identify which stimuli they could perceive, their threshold level (the lowest amount of a stimulus a person could perceive and identify) and how well they perceived differences in sensations above their threshold level. Using a probe about the size and shape of a pencil, the researchers asked the volunteers to identify various temperatures and pressures. The tests involved stimulating the area above the upper lip and the chin with the probe. 		"The face is a wonderful model to look at sensory perceptions because day to day we sample our environment through our nose, eyes and mouth," Heft said. The researchers used a test known as the Pennsylvania Smell Identification Test, in which participants scratched and sniffed cards with different scents on them ranging from licorice to paint thinner. The researchers noted that women are better smellers than men. "The women were able to identify the different scents better, but we don't know why that it is yet," Heft said. "There were no differences between gender regarding the other senses." Heft said the body uses the senses in various ways, including protecting it from harm, and that may be why senses are stable throughout life. 	"The take-home message is, there are going to be a number of immutable factors that to some degree will play a part in your sensory perception. Disease and your inherited genetic makeup are two factors," he said. "However, there are factors you can control to a degree, such as for your motor system, by the amount of exercise you get. Cognitive aging is affected by how you develop your mind through activities such as reading," Heft said. "A big factor also is the amount of sun exposure you receive, which affects the skin's aging and indirectly affects the skin's senses." The UF research is funded by the National Institute of Dental Research. --------------------------------------------------------------------------------	Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html Academic components of the UF Health Science Center include the colleges of Dentistry, Health Professions, Medicine, Nursing, Pharmacy and Veterinary Medicine.  Clinical enterprises of the UF Health Science Center include Shands Hospital at UF, the UF Faculty Group Practice and a statewide network of UF-affiliated hospitals and clinics.  Point your browser to http:// www.vpha.health.ufl.edu
--------
409-> Designing Chicken Manure -- Poultry Nutritionist Looks At Ways To Balance Chicken Diets And Reduce Waste
Managing the 19.5 million tons of chicken and turkey manure produced each year by the U.S. poultry industry is no simple task, but a Penn State poultry nutritionist is looking at ways to more carefully balance chicken diets and reduce waste. "Nutrient management is an important aspect of chicken production and benefits both cost and animal health," says Dr. Paul H. Patterson, assistant professor of poultry science. "Management of poultry feed can also control the amounts of nitrogen and phosphorus that passes through the birds and becomes a waste disposal problem." The options for manure use are many, but the more practical ones are fuel, feed and fertilizer. Chicken manure can be burned, producing one third the fuel value of coal, or converted to methane in biomass converts. Chicken manure can also be used to feed ruminant animals, such as cattle, that can extract unused nutrients. However, the most common use for chicken manure today is as a fertilizer for agricultural fields. Excess nutrients in fertilizer are a source of non point source pollution targeted by environmental initiatives like the Chesapeake Bay Pollution Program. The two components of chicken manure that cause the most concern for runoff are nitrogen and phosphorus, but both elements are necessary for good bird health, egg laying and weight gain. "U.S. lawmakers are looking to the Netherlands' Policy on Manure and Ammonia as a model because it aims for nutrient equilibrium," Patterson told attendees today (Sept. 9) at the fall meeting of the American Chemical Society in Las Vegas, Nev. "The Dutch approach is to match the amount of nitrogen and phosphorus in fertilizer applications with the crop requirements. "Today, some producers manage their birds to minimize manure and nutrient production, in essence, designing chicken manure to reduce the load on the environment." Farmers can control the nitrogen content of manure by using better feed formulation, lower protein diets, and feed additives. In many cases, these approaches save money as well as control the nitrogen output of the birds. Modern breeds of laying and meat birds are more efficient than older varieties. In a study funded by the Pennsylvania Poultry Foundation, Patterson has reevaluated the nutrient balance of modern birds to better optimize nutrition and cost. "By looking at available rather than total protein, farmers can lower the protein content of feeds and reduce the amounts of nitrogen in manure," says Patterson. "Synthetic amino acids are also cost effective and reduce nitrogen waste." The practice of phase feeding -- tailoring feed to the life cycle of the bird -- also reduces nitrogen waste. Feed additives that allow birds to better use available nutrients can also help. Controlling excess phosphorus centers around supplying phosphorus in a form the birds can use. Feeds such as corn and sorghum contain only 19 to 22 percent bioavailable phosphorus with the rest in a chemical form difficult for the birds to digest. The phosphorus in meat or fish meal is 81 to 100 percent bioavailable so birds require less phosphorus in their feed thereby reducing the amount of phosphorus in the manure. "Some forms of vitamin D can improve phosphorus retention by 20 percent," says Patterson. "Enzymes added to the diet can also improve phosphorus uptake." Reducing the nitrogen and phosphorus in feeds, in many cases, decreases the cost of the feed. Lowering the nitrogen and phosphorus levels in the manure can also reduce disposal costs for the enormous amounts of chicken manure produced by the poultry industry each year.
--------
410-> Hopkins Researchers Study Space Flight's Effects On Blood Vessels
Are astronauts at risk of developing coronary artery disease from spending time in space, or can their blood vessels adapt to the change in gravity? To find out, Johns Hopkins researchers are preparing a cargo of special cells to board the shuttle Atlantis for a 10-day trip including a stop at space station Mir. The shuttle is scheduled to launch from Cape Canaveral, Fla., on Sept. 25. The first-of-its-kind Hopkins experiment is one of several supported by the Space Tissue Loss Program, an ongoing effort by the Department of Space Biosciences at the Walter Reed Army Institute of Research, the National Aeronautics and Space Administration and the Department of Defense. Investigators are looking at changes that develop in various types of cells at zero gravity. At Hopkins, the target is endothelial cells, the cells that line the inside of arteries and veins. Endothelial cells are responsible for making sure blood flows smoothly through the body without clotting. Healthy endothelial cells also suppress arteriosclerosis, known as hardening of the arteries. These cells are continuously subjected to the "shear stress" generated by the force of blood flow across their surfaces. When these cells are healthy, they can sense shear stress and alter their function as necessary to continue serving their protective role. Barbara J. Ballermann, M.D., associate professor of nephrology at Hopkins and principal investigator, says that microgravity could have a wide variety of effects on endothelial cells. "We are very excited to participate in this research collaboration," Ballermann says. "Although it is not possible to predict our results, we hope to find out how endothelial cells respond to changes in their physical environment. Any favorable or detrimental effects of space flight on these cells could have implications for future prolonged excursions into space." Researchers from Ballermann's lab, Eudora Eng, M.D., and Veronica Fergusson, will travel to the Kennedy Space Center a week before lift-off to prepare the cells in a series of 16 specially designed cartridges. Eight will ride in a research bay in the mid-deck of the shuttle -- the same section where astronauts reside during space flight. The remaining eight will serve as a control by staying in a lab on the ground. The bioreactor cartridges, manufactured by Cellco Inc., of Germantown, Md., are flown in cell culture modules specifically designed at Walter Reed to aid in the study of microgravity effects at the cellular level. Tom Cannon, payload manager for the cell culture module experiment, says this collaboration is a truly advanced research effort that takes advantage of a unique cell culture modeling technique developed jointly by Ballermann and Cellco. The endothelial cells will be placed inside groups of hollow fibers that simulate either arteries or veins, which experience different stresses. A liquid medium will be pumped through the fibers to simulate blood flow and measure shear stress. The Hopkins team will set up some cartridges to study high shear stress, as would affect arteries, and others to study low shear stress, as would affect veins.
--------
411-> Pioneering Team Spending Winter Atop Greenland Ice Sheet
Winter has already begun for a crew of four who will spend the entire season atop the Greenland ice sheet studying the weather at a remote outpost called Summit. The camp at the apex of the ice sheet, where the sun will set in November and not reappear until late January, is the first attempt supported by the National Science Foundation to over-winter in Greenland. "This is the first time we will be able to examine the entire annual cycle of air and snow chemistry," said Mike Ledbetter, program manager for Arctic system science at NSF. "Ultimately, it will help us to better interpret climate history and how human beings are affecting climate." If the project goes well, NSF may explore establishing a permanent year-round camp at Summit. Up to now, winter at Summit has been like the dark side of the moon for scientists, who have not been able to stay on the scene to study the snowfall in the winter. They do not even know when most of the snow falls. The structures and airplane skiway that comprise the station at Summit cluster atop a broad swell of ice cap almost two miles thick, 481 miles from its supply point on Greenland's west coast. NSF extracted the Northern Hemisphere's longest ice core at Summit from 1989-1993. The core drilled by researchers with The Greenland Ice Sheet Project 2, along with another core drilled nearby by European scientists, furnish an icy archive of over 100,000 years of climate information. The annual layers in the ice cores store a finely detailed atmospheric record, as well as traces of volcanic eruptions, forest fires, ocean storms, atomic bombs and pollution. "The falling snow, which eventually becomes compacted into ice, stores information about the atmosphere at the time it fell -- the water vapor, temperature and dust content," said Jack Dibb, the University of New Hampshire climatologist who heads the wintering project. "The Greenland ice cores have already shown us that there were unexpectedly rapid and dramatic shifts in climate. How closely do these changes in ice composition actually record the changing chemistry of the atmosphere? The idea is to turn these records into a history of the atmosphere's composition." Dibb's project this year will assist this translation. "Our goal during this first year-round occupation of Summit will be to determine what controls the composition of air just above the ice sheet, to see how closely the composition of snow reflects that of the air, and to understand how air and snow exchange water, energy and chemical compounds through the winter," Dibb said. The wintering crew--an electronics technician, a mechanic, and two science technicians--will spend most of their time at Summit in "The Greenhouse," a one-story, 32-by-36 foot building serving as combined bunkroom, living room, and laboratory. The structure rests on skis and can be moved from year to year to avoid burial by snow. The winter-overs will have electronic mail but not telephone contact with the outside world. A supply flight in November will rotate one crew member, with another such flight in February. The University of Nebraska's Polar Ice Coring Office provides logistics for the effort. Winter temperatures at Summit can drop to -60 Fahrenheit or lower, hampering attempts at winter research with automated instruments in the past. This winter, however, the station's crew will be on hand if something goes awry. If this winter's experiment goes well, NSF will explore setting up year-round quarters at Summit for a wider range of studies in future years, possibly with international partners. This spring, at a workshop in Greenland sponsored by NSF and the Danish Research Commission, scientists from four countries explored the potential to use a year-round station at Summit to study snow deposition, atmospheric chemistry, the ozone hole, magnetospheric physics, and other disciplines.
--------
412-> Intercourse Not A Risk Factor For Premature Labor
Some expectant parents fear that intercourse during pregnancy may cause premature labor.  But a study by researchers at the University of Illinois at Chicago College of Medicine found that there is no direct and clear link between sexual intercourse and spontaneous labor. The findings were presented recently at the annual meeting of the Pediatric Academic Societies. "There has been some controversy concerning the role of sexual intercourse in mid-pregnancy and spontaneous labor onset," said Dr. Tonse Raju, professor of pediatrics and lead researcher in the study. "But we found that the relative risk for labor onset following sexual intercourse was not high, when considering sexual intercourse any time during the seven days before labor." In the study, Raju and his colleagues interviewed 100 women who went into labor 22 to 35 weeks into their pregnancies (interviews were conducted within 24 hours of labor).  A control group of 312 pregnant women who did not go in labor during the time period when the interviews were conducted also were questioned.  The women were asked about their lifestyle habits for the previous seven days, including frequency of sexual intercourse, condom use and orgasm. Sexual intercourse frequency of one, two or three times in the preceding seven days was reported by 26 percent, 11 percent and 2 percent, respectively, of the women who went into labor; and by 26 percent, 18 percent and 13 percent of the control group, respectively. Nine percent of the labor onset group reported having sexual intercourse one day prior to labor and 7 percent of the control group reported having sexual intercourse one day prior to being interviewed. Sixty-one percent of the women who went into labor and 42 percent of the control group reported having no sexual intercourse during the preceding week. "In most cases, our study found that sexual intercourse per se may not be the direct cause of preterm labor, although it is possible that some women who had sex prior to labor onset might not have told us the truth out of guilt feelings," said Raju. "And whether sexual intercourse during pregnancy is safe cannot be determined by this kind of study. There are certain conditions during pregnancy, such as an unusually sensitive cervix or uterus or abnormal placental position, in which it may be advisable for an expectant mother not to have sex. Women should talk to their doctor about those situations."
--------
413-> Risk Factors For Heart Disease A Mystery For Many
Health professionals say that smoking, high blood pressure and high cholesterol levels are three risk factors for heart disease that people can help reduce. But a study, published in the March-April issue of Heart & Lung, found that many patients with heart ailments do not recognize these factors as causing their own problems. In the study, researchers at the University of Illinois at Chicago, University of Rochester and Monroe Community College asked 105 patients who were hospitalized after a first heart attack, or for a coronary angiography (an x-ray procedure used to identify sites of narrowing or blockage in arteries) after having been diagnosed as having coronary artery disease, to describe what they believed were the contributing factors to their heart disease. Although 79 percent of the patients named at least one of the three modifiable risk factors -- smoking, hypertension and high cholesterol levels -- only 7 percent identified all three. Patients known to have risk factors varied in their recognition of those risks as a cause of their heart disease. Only 15 percent of patients with high blood pressure recognized high blood pressure as a cause, while 64 percent of smokers recognized smoking as a cause of their heart disease. And many of the patients, 13 percent, were unsure whether heart disease is a chronic disease.   Another 28 percent believed the situation would be short term. "We have assumed that people make links between risk factors and their own heart disease," says lead researcher Julie Zerwic, assistant professor of medical-surgical nursing at UIC. "But we found that despite general knowledge about coronary artery disease, individuals with known risk factors continue to be largely ignorant of their personal risks and, to some extent, of the course of the disease." Zerwic says these findings have serious implications for prevention and treatment of heart disease. "If people don't recognize the risk factors, they are less likely to seek treatment for symptoms," she said.  "Educational pamphlets are not doing the job. Health care professionals need to do more one-on-one education and tell each patient, ‘Here's your situation, and here's what you need to do.'"
--------
414-> Sleep Apnea Problems In African-American Children
African-American children with obstructive sleep apnea have significantly lower blood-oxygen levels compared to other groups, according to a study by sleep disorder researchers at the University of Illinois at Chicago College of Medicine. The study, conducted by researchers at UIC's Center for Sleep and Ventilatory Disorders, evaluated nearly 200 children, 128 of whom were diagnosed with obstructive sleep apnea, a potentially life-threatening disorder in which breathing intermittently stops during sleep. The researchers found that the blood-oxygen saturation for African-American children was nearly 10 percent lower than all other children during sleep apnea episodes. "We see many children with serious breathing problems because of sleep apnea," says researcher Edward Stepanski, associate professor of clinical psychology in medicine. "But we were surprised to find racial differences among children who experience dips in blood-oxygen levels even though they have similar severity of sleep apnea. African-American children with obstructive sleep apnea are experiencing faster and further drops in blood-oxygen levels." "We don't know why this is happening," Stepanski adds. "Perhaps, it's related to hemoglobin or it could be the result of undiagnosed sickle cell anemia; or it might be the result of some physiological difference such as larger tonsils. We need to do further study to determine what biological processes account for this." Previous studies have suggested that sleep apnea should be considered a risk factor for hypertension and cardiovascular problems, and can have a significant impact on cognitive function, mood, and reaction time.
--------
415-> Asthma Management Program Benefits Patients
Sept. 9, 1997					CONTACT:  Jordan Gruener(303) 398-1002 National Jewish Asthma Management Program Decreases Medical Needs, Increases Quality of Life’ for Medicaid, Commercial Health Care Population Patients DENVER-People with moderate to severe asthma spend less time in the hospital and the emergency room, use less steroids and miss fewer days of work, school or daycare after participating in Disease Specific Case Management through National Jewish Medical and Research Center, according to David Tinkelman, M.D. In addition, Medicaid and commercial health care patients significantly improved their overall quality of life and mood, lessened moments of breathlessness, and had strong appreciation and satisfaction with Disease Specific Case Management (DSCM). "Helping people feel better is the goal of the doctors and nurses at National Jewish," says Dr. Tinkelman, vice president, Health Initiatives at National Jewish.  "The nurse and the patient are a team working to control, and ultimately defeat, asthma." DSCM at National Jewish includes regular telephone contact between a patient and a registered nurse, who assesses the patient’s medical needs and, if necessary, contacts the patient’s physician with treatment recommendations.  National Jewish has DSCM contracts with 10 health plans in more than 10 states. Personal contact is important to the people who use the program.  "When I asked the nurses questions, I got answers I understood," one patient in the program says. The following changes occurred in Medicaid and commercial health care populations after six months in the National Jewish DSCM program. Medicaid patients· Hospitalizations down 50 percent· Emergency room visits down 61 percent· Steroid bursts (used to treat an emergency asthma attack) down 48 percent· Days missed from work/school/daycare by the patient and/or caregiver down 68 percent Commercial health care population patients · Hospitalizations down 72 percent · Emergency room visits down 77 percent · Steroid bursts (used to treat an emergency asthma attack) down 54 percent · Days missed from work/school/daycare by the patient and/or caregiver down 81 percent For more information about DSCM, call LUNG LINE, (800) 222-LUNG.
--------
416-> Hubble Finds A Bare Black Hole Pouring Out Light
Probing the heart of the active galaxy NGC 6251, NASA's Hubble SpaceTelescope has provided a never-before-seen view of a warped diskor ring of dust caught in a blazing torrent of ultraviolet lightfrom a suspected massive black hole. This discovery, which is reported in the September 10 issue ofthe Astrophysical Journal Letters, suggests that the environmentsaround black holes may be more varied than thought previously,and may provide a new link in the evolution of black holes in thecenters of galaxies. "This is a completely new phenomenon which has never before beenseen. It blew my mind away," says Dr. Philippe Crane of the EuropeanSouthern Observatory, in Garching, Germany.  "Before Hubble youcould never do this kind of research. We used a lightly exploitedfacility of Hubble: its extremely high resolution imagingcapability in the near ultraviolet provided by the Faint ObjectCamera (FOC), built by the European Space Agency." Previously, black holes observed by Hubble have been largelyhidden from view because they are embedded inside a torus, adonut-shaped distribution of dust that forms a partial cocoonaround the black hole. In galaxies previously studied, the intense light from super hotgas entrapped by the black hole's powerful gravitational fieldshines out from inside the "donut hole" of the torus and isrestricted to a narrow beam, like a searchlight. But this is the first clear example of an "exposed" black holethat illuminates the surrounding disk.  Because Hubble seesultraviolet light reflected on one side of the disk, astronomersconclude the disk must be warped like the brim of a hat. Such a warp could be due to gravitational perturbations in thegalaxy's nucleus that keep the disk from being perfectly flat, orfrom precession of the rotation axis of the black hole relativeto the rotation axis of the galaxy. The suspected black hole's mass has not yet been confirmed throughvelocity measurements of entrapped material, though yetunpublished Hubble measurements have been made with the FaintObject Spectrograph (FOS), prior to its replacement during the 1997Hubble servicing mission. However, strong circumstantial evidence for the black hole isprovided by the powerful 3 million light-year-long jet ofradiation and particles emanating from the black hole's locationat the hub of the elliptical galaxy.  The galaxy is located 300million light-years away  in the constellation Virgo. Hubble's sensitivity to ultraviolet light, combined with theexceptional resolution of the FOC which can see details as smallas 50 light-years across, allowed Crane and his team to look forstructure in the hot gas near the black hole at the base of thejet.  Crane was surprised to see a peculiar finger-like objectextending from the nucleus, at right angles to the main jet. Comparing the FOC image to a visible light image taken withHubble's Wide Field Planetary Camera 2 (WFPC2),  Crane realized thefinger-like extension ran parallel to a 1,000 light-year-widedust disk encircling the nucleus.  He concluded that the ultraviolet light must be reflecting off fine dust particles in a disk,or possibly the back wall of a ring.  A ring-like structure wouldhave been shaped by a torrent of radiation coming from theexposed black hole, which would have plowed out a cavity aroundthe hole. The Hubble astronomers are hoping to confirm ideas aboutscattering by looking at the disk's spectrum with ground-basedtelescopes.  They will propose to use Hubble to look at severalother extragalactic jet sources which have dust. Co-investigator: Joel Vernet (European Southern Observatory)                              * * * * The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc. (AURA) for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency (ESA). EDITOR'S NOTE:  Images to accompany this release are available to news media representatives by electronic means only. Photos, captions and press release text are available via the World WideWeb at http://oposite.stsci.edu/pubinfo/PR/97/28.html  and via links in http://oposite.stsci.edu/pubinfo/Latest.html  or http://oposite.stsci.edu/pubinfo/Pictures.html. Image files also may be accessed via anonymous ftp from oposite.stsci.eduin /pubinfo: GIF			JPEGgif/ngc6251.gif	        jpeg/ngc6251.jpggif/n6251ils.gif	jpeg/n6251ils.jpg Higher resolution digital versions (300 dpi JPEG) of the release photographare available in /pubinfo/hrtemp:  97-28.jpg (color) and 97-28bw.jpg (black& white).  Full resolution TIFF images are available in /pubinfo/PR/tiff/1997:28a.tif, 28b.tif and 28c.tif.
--------
417-> Computational Shortcut Speeds Quantum Chemical Calculations
LAS VEGAS -- A Duke University theoretical chemist has described the development and application of a "divide and conquer" method requiring far fewer calculations to model the electronic structure of large molecules. Weitao Yang described the technique in two invited talks prepared for this week's annual national meeting of the American Chemical Society. His research is supported by the National Institutes of Health and the National Science Foundation. Until Yang developed his computational method, theoretical chemists trying to precisely describe the electronic structures of large molecules were stymied by the daunting size of their calculations. To show how the hordes of electrons in a large molecule interact scientists must use the complex equations of quantum mechanics, said Yang, an associate professor of chemistry. Such interaction determines the molecule's shape and possible functions. Quantum mechanics describe the behavior of electrons and other subatomic particles so tiny that they no longer behave as everyday objects. They may act as both waves and pinpoint particles, for example, and their locations at any given instant can usually be defined only as probabilities. "Electrons do not fit in our picture of the classical world," Yang said in an interview. "We need quantum mechanics to describe electrons. And when we do that, we are able to describe chemical reactions, the breaking and formation of chemical bonds, and many other interesting processes in chemistry and biology." But, traditionally, chemists doing such quantum mechanical calculations had to look at the big picture. "If they wanted to calculate one part of the molecule they had to calculate the entire molecule at the same time," Yang said. Such calculations were impossible for molecules bigger than a few hundred atoms, he noted, because the required computations rose by a cube of the number of those atoms. "You soon run out of computer capability," he added. Yang and his associates changed all that by introducing a method that allows such big quantum mechanical calculations to be vastly speeded up by breaking up the problem. "We call it the `divide and conquer' method," he said. "In essence, the method enables us to calculate a molecule one piece at a time in a very sophisticated way. Such division is possible because we chemists know that the properties of a molecule are very localized. And these properties depend on the local structure." Calculations done by Yang's method rise linearly with molecule size, rather than rising by the cube of the molecule's size. "If it takes an hour to do the calculation for 100 atoms, it would take two hours to do the calculations for 200," he explained. "So it's much quicker. We are able to do calculations on our workstations that were impossible before." Yang first reported on his concept in a paper entitled "Direct Calculation of Electron Density in Density Functional Theory" in the March 18, 1991, issue of the journal Physical Review Letters. His Duke research team subsequently reported on refinements and applications of the method in articles in other journals. Yang's co-investigators include Taisung Lee, now a post doctoral fellow at Duke, and Darrin York, now a National Institutes of Health postdoctoral fellow at Harvard. Because Yang's method predicts electron properties so precisely, it can provide researchers a more refined picture of the behavior of big molecules, such as proteins. "We think of proteins as being made up of atoms," he said. "But those atoms have electrons, and electrons are the mediating forces between the atoms." In joint research with the University of North Carolina at Chapel Hill, Yang's method was recently used to reveal the locations of some of the hydrogen atoms in an enzyme called cytidine deaminase. He said knowledge of the locations of two particular hydrogen atoms is very important for illuminating details of the enzyme's mechanism. Knowledge of how the enzyme promotes chemical reactions may have important therapeutic uses in anti-tumor drugs, he said. Hydrogen atoms, made up of a single electron and proton, are too light to be revealed by the standard analytical protein mapping process called X-ray crystallography. That test reveals only the heavier atoms in the protein. "So it is not possible to really tell where all the hydrogens were from experiments," Yang said. "One can only guess. But our calculations have nailed down hydrogen." In that work, he is collaborating with UNC-CH theoretical biophysicist Yan Hermans and experimental biochemist Charles Carter, as well as a jointly shared postdoctoral researcher, James Lewis.
--------
418-> Super-Thin Computer Screens Near Reality For Use In Tight Spaces
Writer: Randolph Fillmore Source: Paul Holloway (352) 392-6664 GAINESVILLE, Fla. --- Hospital rooms, surgery suites, fighter plane cockpits and tanks -- high-priced real estate where space is at a premium. They also are perfect places for super-thin color computer monitors that will result from technology being developed at the University of Florida. 	Researchers are working to provide color for computer screens so small they can be mounted on the head or helmet and still display brilliant, accurate colors comparable to a color television picture. "Now that we have computer-assisted surgery and smart weapons, the last thing surgeons and fighter pilots need is a big computer monitor crowding their valuable and small work space," said Paul Holloway, professor of material science engineering at UF, a member university of the Phosphor Technology Center of Excellence. Here, experiments are under way to improve the efficiency of thin films of phosphor that emit light and color when struck by electrons. These phosphor films will be used in a new breed of thin color monitors. What makes today's computer color monitors so long and deep is the cathode ray tube inside.  The electron gun at the back of the cathode ray tube needs length to bombard the inside of the TV screen with electrons, said Holloway. The new, slim color monitors instead will use Field Emission Display (FED) technology. FED monitors, equipped with hundreds of miniature electron guns firing a short distance instead of the single large electron gun firing a long distance, will spray electrons to create images. Phosphor films will react to the electrons to create color. But brilliant, lasting colors will be a reality only after researchers perfect efficient, long-lived, thin phosphor films. True, today's laptop computers have thin screens, but they use liquid crystals that are either monochrome or, at best, render poor quality lighted colors and have other  drawbacks, said Holloway. "You can't see liquid crystal screens from a large angle. Also, the liquid crystals that provide the visual image are not rugged enough to stand up to vibrations such as those that rattle a tank," said Holloway. "Neither limitation is good for monitors used in combat or surgery." Holloway said making dependable, thin FED monitors with good color display is vitally important to medicine and defense. "Soon, instead of looking up at a computer screen when doing endoscopic procedures, surgeons will be able to wear a helmet with a small, thin, FED screen just in front of their eyes," he said.  "Of course, in surgery it is important to be able to see tissue colors accurately and right in front of you. FEDs with good color will make that possible. Likewise, soldiers driving tanks will wear goggles that will have a display feature. But the visual display must work at 20 degrees below zero in Siberia or 120 degrees above in Saudi Arabia.  Liquid crystals are too temperature sensitive." Head- and helmet-mounted displays have been around awhile, Holloway said, but current versions are cumbersome and heavy. FED technology promises to make monitors wafer-thin compared with today's. Once the phosphors for FEDs are perfected, they will be useful in virtual reality systems as well as in the "real time" world of the cockpit or surgery suite. Holloway said the UF researchers want to get the best colors possible from the thin phosphors while expending the least amount of electron energy. "We can make the phosphors work for 1,000 hours, but we're shooting for 10,000 hours," said graduate student Sean Jones, who is working to improve the efficiency of thin film phosphors. "Also, the color quality standard set by your color TV is what we're working toward."
--------
419-> Temperature Of Pacific Ocean Influences Midwest Rains, Scholar Says
CHAMPAIGN, Ill. - A correlation between summertime sea-surface temperatures in the Pacific Ocean and precipitation rates in the Great Plains may lead to improved seasonal predictions of drought and flood potentials, researchers at the University of Illinois report. "The flood of 1993 and the drought of 1988 raised serious questions about the causes of summertime climatic fluctuations over the central United States," said Mingfang Ting, professor of atmospheric sciences at the U. of I. "The closer we come to answering those questions, the better our predictions will become. That should lessen the tremendous socio-economic impacts caused by severe floods and droughts." To identify a clearer cause-and-effect relationship between ocean and atmosphere, Ting and graduate student Hui Wang analyzed climatological data gathered from 1950 to 1990. Included in the study were precipitation measurements collected throughout the Midwest and sea-surface temperatures from both the tropical and northern regions of the Pacific Ocean. In general, the warmer the ocean, the wetter the weather, the researchers found. But it's not a simple matter of moisture evaporating from the Pacific Ocean being dropped over the Great Plains, Ting said. "Because the mountains along the West Coast effectively block most of the moisture arriving from the Pacific Ocean, the moisture source for the central United States is actually the Gulf of Mexico. So, the temperature of the Pacific Ocean is also influencing the moisture transport from the Gulf of Mexico." Ting believes the sea-surface temperatures in the Pacific Ocean affect both the position and the intensity of the jet stream over the central United States, which in turn modifies the circulation pattern from the gulf. "Warmer sea-surface temperatures shift the jet stream farther south, leading to more storm activity, which pumps more moisture up from the gulf," Ting said. "In contrast, cooler sea-surface temperatures shift the jet stream farther north, resulting in reduced storm activity and drier conditions." While meteorologists have long recognized a connection between abnormally warm or cold conditions in the tropical Pacific and precipitation rates over the United States, Ting said the relationship does not account for all the fluctuations that appeared in the 40-year study. A much stronger correlation exists between the sea-surface temperatures in the north Pacific and rainfall over the Great Plains. "Currently, only tropical Pacific sea-surface temperatures are being plugged into the forecast model to make seasonal precipitation predictions," Ting said. "By also including the north Pacific msea-surface temperatures, I think we can obtain more accurate predictions." The researchers' findings appeared in the August issue of the Journal of Climate.
--------
420-> Weekly Reader Launches Science Spin To Bring Timely Science News To Elementary School Students
Stamford, CT, Sept. 10, 1997 -- Weekly Reader: The Largest Newspaper For Kids InThe World ® announces the launch of Science Spin, a monthly, grade-specificpublication that helps teachers update their science curriculum and bringstimely news of life, earth and physical science to the classroom. Each issue of Science Spin  meets the National Science Education Standards. Science Spin will be published as a four-page supplement to Weekly Reader andoffered 7 times throughout the school year beginning in September.  It will havean initial paid circulation of 500,000 and will be available in six versionsdesigned for curricula from kindergarten through grades 5/6. Every issue isaccompanied by a Teacher's Guide. "Science Spin brings news that enables students to see how science is happeningall around them, right now," says Sandra F. Maccarone, Editor in Chief of WeeklyReader.  "It uses photography, interesting facts, and interactive techniquesthat engage the students." Science Spin's departments include: Weekly Reader, with a classroom circulation of 8 million for grades Pre-Kthrough 6, also publishes nine educational products for middle and high schoolstudents, including: Current Science, Current Events, Read, Know Your WorldExtra, Writing!, Current Health 1 & 2, Career World, and World Newsmap of theWeek. Weekly Reader, which has been bringing important news to America's classroomsfor 70 years, can also be found on the world wide web through its new Galaxywebsite for kids, teachers, and parents (http://www.weeklyreader.com). Thisyear, as an enhancement to Science Spin, the website will include the scienceexperiment feature 'Try It!'. Weekly Reader is a K-III Communications company. For additional information about Science Spin, and a complimentary copy, contactCarol Zimmerman at: (203) 705-3415 or e-mail: Czimmerman@weeklyreader.com.
--------
421-> Evidence Of Tobacco Carcinogen In Non-Smokers Passively Exposed To Cigarette Smoke
LAS VEGAS, Sept. 9 -- New research shows, for the first time under real-life conditions, evidence of a cancer-causing substance in non-smokers who work in smoke-filled rooms. That substance, called NNK, was biologically processed and its metabolite detected in their urine. The study is being presented here today at a national meeting of the American Chemical Society. "This is the first time that a metabolite of a tobacco-specific lung carcinogen has been found in the urine of non-smokers exposed to environmental tobacco smoke under field conditions," says Dr. Stephen Hecht of the University of Minnesota Cancer Center. NNK is an abbreviation for 4-(methylnitrosamino)-1-(3-pyridyl)-1-butanone. It is the only known lung carcinogen found solely in tobacco smoke and is formed from nicotine. According to Dr. Hecht, NNK is particularly efficient at inducing adenocarcinoma in animals, a cancer of the lung periphery common in smokers. Hecht also says, "Adenocarcinoma is the type of lung cancer that's most commonly found in non-smokers who are exposed to environmental tobacco smoke." Lung cancer is normally rare in non-smokers. The nine subjects of this study were non-smoking hospital workers caring for live-in patients in the smoking area of a Canadian veterans hospital. Their urine samples were collected three times during one day at the end of a work week. The samples were then sent to Hecht's laboratory where they were analyzed using highly sensitive equipment custom-designed to detect a human by-product (metabolite) of NNK called NNAL-Gluc. All nine test subjects had detectable NNAL-Gluc levels. The levels were about 70 times lower than those found in smokers. However, Hecht says no NNAL-Gluc could be found in control samples (water blanks and urine from laboratory personnel not known to have been exposed to cigarette smoke). He concludes, "I feel certain that in a much larger study you would see the same kind of results." Though risk varies widely, any contact with a carcinogen creates some chance of getting cancer and Hecht says this study "provides a link between the assumption that a person is being exposed to carcinogens and the reality that they actually are." Curtis Harris, MD, chief of the Laboratory of Human Carcinogenesis at the National Cancer Institute adds, "It certainly gives an indication that a person's been exposed. That information will be useful in further epidemiological studies to confirm the link between environmental tobacco smoke and lung cancer." In 1993, Dr. Hecht was co-author on a New England Journal of Medicine paper that detailed similar tests on five non-smokers experimentally exposed to environmental tobacco smoke from a smoking machine while enclosed in a small chamber. That test was the first demonstration that non-smokers could take up and metabolize NNK. However, smoke exposure under those conditions was about 2-3 times higher than in the present "real-life" study. The laboratory method used in the current study was 20 times more sensitive than that used for the New England Journal of Medicine paper. Dr. Hecht hopes to now use the new method to study larger samples of non-smokers exposed to environmental tobacco smoke.
--------
422-> Heart Problems In Victims Of Tropical Disease May Not Be Caused By Autoimmune Rejection -- New Treatment Indicated
ATHENS, Ga. -- New evidence by scientists from the University of Georgia indicates that victims of a common tropical disease may be receiving inadequate treatment because of a major misunderstanding of how the illness progresses. Chagas' disease, caused by a protozoan parasite, infects up to 18 million people in Latin America, and 90 million individuals are at risk of infection. Most people die from heart failure during the chronic phase of the disease rather than complications of acute infection. Indeed, Chagas' disease is thought to be the single most common cause of congestive heart failure in the world. In a new study, however, scientists have shown through heart transplants in mice that heart damage associated with Chagas' disease is not caused by autoimmune reactions as was commonly thought. Instead, heart damage -- and its resulting sudden death -- among victims of the disorder are almost certainly caused by the immune reaction to parasites in the heart itself. "The results of these studies have considerable implications for the treatment or prevention of Chagas' disease," said Dr. Rick Tarleton, a cellular biologist. "This study provides definitive data show we should reduce the parasite load in patients to prevent disease progression." The research was funded by the National Institutes of Health and the Burroughs Wellcome Fund and was published in April in the Proceedings of the National Academy of Sciences. Co-authors of the study were Dr. Myron Downs of the University of Georgia's College of Veterinary Medicine, and Lei Zhang, a student in the department of cellular biology. Chagas' disease is caused by the parasite Trypanosoma cruzi. The disorder causes numerous varieties of sickness, but none is more deadly than heart failure. Scientists had thought for years that sudden cardiac death was caused by the body's autoimmune response to heart tissue, but Tarleton and his colleagues showed that is clearly not the case. Instead, they found that the actual presence of the parasites appear to promote heart disease -- something that had been discounted because of the sheer difficulty of finding T. cruzi in heart tissue. Indeed, many researchers still consider autoimmunity to be the likely cause of Chagas' disease, but Tarleton said that hypothesis is "largely circumstantial." In order to test his hypothesis, Tarleton took advantage of a routine technique to test immune rejection -- the transplantation of a living heart from a mouse into the ear skin of another genetically identical mouse. One might think such a heart would die immediately, but it doesn't. In fact, it develops its own vasculature and begins to beat within several days. "The transplanted hearts must be from newborns or those just about to be born," said Tarleton. "Though the transplanted heart serves no useful function, it gives us a way to see how it reacts to the presence of the parasites in the host animal." If, as other scientists have theorized, Chagas' disease is caused by an autoimmune reaction to heart tissue, then the hearts transplanted into mice with chronic T. cruzi infections should have been rejected by this same anti-self immune response. Instead, the new hearts continued to beat for months and months with no signs of disease. Even more interesting, they showed no sign of acquiring parasites, even months after transplantation, showing just how efficient the anti-parasite immune response is in controlling the spread of parasites to other areas of the body. Tarleton credited Zhang with developing a very sensitive technique for the discovery of parasites in the mouse hearts. "It is strange that the theory for Chagas' disease as an autoimmune disorder is so shaky yet so widely accepted," said Tarleton. "The autoimmune theory dominates treatment and prevention protocols for the disease." Treatment for the disease usually comes in the acute phase, when the body is first reacting to the presence of the parasites. After that phase has passed, victims of the disease usually are not treated at all, largely because physicians have considered the autoimmune response would be difficult, if not impossible to treat. Treatments that are used are harsh and can cause severe side effects, leading many people to refuse it entirely. Unfortunately, those with chronic Chagas' disease are susceptible to sudden death from heart failure associated with the disorder. Tarleton now calls this lack of treatment for chronic-disease sufferers a "serious miscalculation." A Brazilian doctor has made medical history in the past few years by actually cutting part of the heart muscle away from victims of Chagas' disease suffering from congestive heart failure. The risky surgery is now being performed in the United States on rare occasions. Despite the millions of people at risk, there is currently no vaccine-development program in progress to prevent infection with T. cruzi. The main reason appears to be the previous ideas of an autoimmune origin for the disease. "A vaccine only heightens the immune response, so the fear has been that a vaccine would make those infected even sicker," said Tarleton. "My gut feeling is that the autoimmune component of the disease is inconsequential. We can't prove that autoimmunity doesn't exist, but even if autoimmunity is a component, we cannot treat this as an autoimmune disease. We must treat it as a parasitic infection. We must develop protocols to clear the parasites. If we do that, we can get rid of the disease." From a practical point of view, Tarleton believes that the development of a vaccine could hold the promise of a major new tool in the fight against a disease that sickens millions each year.
--------
423-> New Way To Make Chips Could Lead To More Powerful Computers
CHAMPAIGN, Ill. - A novel method of making computer chips could produce personal computers that would be a thousand times more powerful than today's desktops, says a University of Illinois scientist who helped develop the technique. The new process, called SCALPEL (for "scattering with angular limitation projection electron lithography") can make chips with extremely small features. "The smaller the feature, the faster the device and the more components you can pack into a computer chip," said Murray Gibson, a professor of physics and of materials science and engineering, and associate director of the Frederick Seitz Materials Research Laboratory. "Today's integrated circuits are produced by optical lithography," Gibson said. "The process consists of projecting a pattern of light onto a light-sensitive material, which can then be transferred to make a very dense array of tiny transistors. Currently, the smallest feature that can be manufactured has a width of about 10 millionths of an inch." Improvements in computer speed and memory in the last decade have been tied directly to the increase in density of these transistors; that is, to reducing the minimum feature size, Gibson said. "However, optical technology will soon reach an impasse because light has too large a wavelength for producing patterns much smaller than today's." For a long time, researchers have dreamed of using electron beams to write patterns, because electrons do not suffer from the wavelength limitation and therefore can produce patterns more than a hundred times smaller. However, an electron-based lithography system fast enough to be used economically in production proved elusive, until the invention of SCALPEL. By employing a novel projection method for writing large areas with electrons, SCALPEL overcame this major limitation. In 1989, Gibson coinvented the technique with Steven Berger of Integrated Solutions Inc. while both were employed at AT&T Bell Laboratories (now Lucent Technologies). Recently, a SCALPEL proof of concept (SPOC) machine was built at Lucent and demonstrated the feasibility of manufacturing features with widths of less than 3 millionths of an inch -- a size required for the next century's computer improvements. Gibson assisted with the design of the SPOC machine, especially the basic electron optics of the lenses that project the image onto the chip. The SPOC machine also demonstrated the feasibility of the method to reach production within the next decade. The industry consortium, SEMATECH, has identified SCALPEL as a leading technological contender for the manufacture of future computer chips. "Although nearly $50 million of private and government support has been invested in SCALPEL, and the concept has been proven, it will take closer to $1 billion investment worldwide over the next decade to lead to actual production with SCALPEL," Gibson said. "These numbers, although sobering, are not untypical for the industry, where a single factory line for chip production costs about $1 billion."
--------
424-> University Of Cincinnati Chemists Develop High-Efficiency Method To Synthesize And Screen Potential Antibiotics
Cincinnati -- University of Cincinnati researchers have developed a system for quickly synthesizing and screening potential replacements for standard antibiotics, such as penicillin and amoxicillin. All of these antibiotics fall into the category known as beta lactams. Chemistry graduate student Jie Wang will explain a key part of the system Sunday, Sept. 7 during the national meeting of the American Chemical Society in Las Vegas. The system, developed by Professor Richard Day, uses a patented intermediate compound (a Leuchs anhydride) for rapid synthesis of novel antibiotics. It is coupled with a high- throughput method for screening the compounds' activity. The complete process takes about two days. "We have over 1,000 novel beta lactams," said Day. "Most of them test out as being very effective against a wide range of bacteria." More importantly, several of the compounds are effective at extremely low levels. The typical minimum inhibitory concentration (or MIC) of prescription beta lactams falls between 0.1 and 1.0 microgram per milliliter. Some of the compounds developed in Day's lab were effective at the sub-nanogram level. That might make it possible to develop antibiotic skin patches. The patches have an advantage over pills, because the patient would not have to remember when to take medicine, and doctors would not have to worry that the patient did not finish all the medication. The most promising antibiotics have been tested in the lab against both Gram-negative and Gram-positive bacteria, against resistant and non-resistant strains of bacteria, and against a "defanged" version of the microbe that causes tuberculosis. The results were encouraging, although Day knows these compounds have a long way to go before any of them could reach human testing. "We can make beta lactams that take out the tuberculosis bacteria without any trouble, but there's a big jump between the test tube and elsewhere," Day readily admits. The focus of Wang's presentation will be on the analytical methods used to identify and separate the various isomers produced by Day's synthetic approach. "The important result to having access to all these isomers is we found some are lytic and some are non-lytic to bacteria," said Day. The lytic antibiotics actually burst open the bacterial cells. The non-lytic forms inhibit growth without destroying the bacteria. That's important, because some bacteria contain extremely dangerous toxins which can cause severe complications. For example, the plague bacteria contains a heart toxin and the bacteria which causes meningitis contains a neurotoxin. Non-lytic antibiotics may prove to be much safer than currently available drugs.
--------
425-> Study Sheds Light On Behavior Of Middle-Age 'Undertaker' Bees
CHAMPAIGN, Ill. - It's a dirty job and only about 1 percent do it at any one time. But middle-aged honey bees that serve as undertakers -- removing dead bees from the hive -- appear to be a distinct cadre of workers that are developmentally ahead of their peers. In this social world known for its division of labor, there also were unexpected discoveries by researchers: Undertakers don't get better with experience, and they don't do well working together. The findings are detailed in papers by Gene E. Robinson, a University of Illinois entomologist, and his former postdoctoral researcher Stephen T. Trumbo, now a professor at the University of Connecticut in Waterbury, Conn. The study on development, also written by U. of I. entomologist Zhi-Yong Huang, appears in the September issue of Behavioral Ecology and Sociobiology. The research on the undertakers' learning, or lack thereof, will be published in the fall in the journal Ethology. The work -- which involved identifying the undertakers, marking them with tiny, colored and numbered plastic tags, and following them closely through middle age -- provides the first close look at undertakers. Since bees' nests are built in cavities, such a specialty is important for keeping the nests clean. "Undertakers had very similar activity levels as other bees," Trumbo said. "They just do a little bit less of the other middle-aged tasks, like building the comb and storing food brought in by older foragers. They also remove debris, which fits in nicely with undertaking." Undertakers also develop slightly faster than other midde-aged bees, moving on to foraging before food storers and hive builders. Middle age lasts about 10 days. Undertakers usually removed dead bees for a day or two, but "one extraordinary bee remained at the task for 13 days," Trumbo said. Undertakers respond to the odor of the dead, locating the bodies and carrying them out of the hive for 50 to 100 meters before dropping them. The researchers also monitored how swiftly undertakers worked. "We didn't find any evidence for learning for this particular task," Trumbo said. "This rules out one of the major hypotheses that has been put forward for middle-aged specialization: That social insects will get better and better at what they do." Previous research had shown that learning is important for the older foragers, who get more efficient as they learn what flowers are producing nectar at what time. Not only did undertakers not improve in efficiency, Trumbo said, they also got in each other's way and slowed their efficiency. Robinson had shown previously that some bees are genetically inclined to be undertakers. "We're beginning to get a clearer picture of the behavioral profiles of interesting types of specialist bees, such as undertakers," Robinson said. "Understanding the career choices of bees is a useful model for understanding behavior in general. This new information should enable us to develop new hypotheses about how neurons and genes in the brain function to produce the marvelously complex behavior seen in honey bee society."
--------
426-> New State Of Matter Found In High-Temperature Superconductors
CHAMPAIGN, Ill. -- Recent experiments on yttrium-barium-copper-oxide (YBCO) superconductors have generated a clearer understanding of the peculiar behavior of this unconventional material. Most significant among the findings, by studying a characteristic called the zero-bias conductance peak, scientists at the University of Illinois -- working with scientists at Northwestern University -- have discovered the first example of a solid superconductor displaying broken time-reversal symmetry. "The really hot news in the field of high-temperature superconductors is that the zero-bias conductance peak splits at low temperatures in the absence of an externally applied magnetic field," said Laura Greene, a U. of I. professor of physics who directed the research effort. "Not only does our experiment again prove that the dominant symmetry in YBCO superconductors is d-wave, it also shows that two different pairing mechanisms -- or order parameters -- can coexist in the same material, creating spontaneous currents that are a signature of broken time-reversal symmetry." The surprising result offers proof of a new state of matter that has eluded researchers for years, Greene said. "This is the first case of a solid superconductor breaking both gauge symmetry and time-reversal symmetry. The only other material proven to break both symmetries is the unconventional superfluid helium-3, the discovery of which was awarded the 1996 Nobel Prize in physics." To perform the experiment, Greene and her colleagues grew thin films of YBCO by off-axis magnetron sputter deposition. The researchers then used planar tunneling spectroscopy to measure the tunneling conductance across different junctions as a function of crystallographic orientation, temperature and externally applied magnetic field. "Our team of experimentalists worked closely with Jim Sauls, a theorist at Northwestern," Greene said. "In fact, our two papers appeared together in the July 14 issue of Physical Review Letters. What we found was exactly what Sauls had predicted." According to the experimental results, at 90 degrees Kelvin (the critical temperature for YBCO) the superconductor has d-wave symmetry, Greene said. "When cooled to about 7 degrees Kelvin, however, a second superconducting channel opens up which has s-wave symmetry. Because the two symmetries coexist, the differences between their phases spontaneously generate a current. The current creates a magnetic field, and that is what splits the zero-bias conductance peak." The spontaneously generated current is also what breaks the time-reversal symmetry, Greene said. "Because the current is flowing in a certain direction, you can tell whether it's going forward or backward with respect to time." The research team also comprised Mark Covington, Marco Aprili and Elvira Paraoanu at the U. of I., and Chad Mirkin, Feng Xu and Jun Zhu at Northwestern. The research was supported by the National Science Foundation through the Science and Technology Center for Superconductivity.
--------
427-> Study Links Trans Fatty Acids To Breast Cancer
CHAPEL HILL -- Analyzing tiny fat samples from 698 European women's buttocks revealed that those with breast cancer had higher levels of trans fatty acids stored in their bodies than women without breast cancer, according to a new international study. The study -- the first to show a significant association between such fats and the life-threatening illness -- is important because people can reduce trans fatty acid consumption by changing diets, researchers say. They suspect, but have not proven, that trans fatty acids may contribute to breast cancer development and that by cutting back on them, some women can protect themselves from the disorder. "We also know that American women have higher levels of stored trans fatty acids on average than the European women studied because American diets contain more of those special fats," said Dr. Lenore Kohlmeier, professor of epidemiology and nutrition at the University of North Carolina at Chapel Hill schools of public health and medicine. "The vast majority of trans fatty acids are naturally occurring in our diets. Most of what we get are from production of oils and fats used in food preparation." A report on the research appears in the September issue of the journal Cancer Epidemiology, Biomarkers & Prevention. Besides Kohlmeier, who is lead author and a member of the UNC Lineberger Comprehensive Cancer Center, authors include Drs. Neal Simonsen, postdoctoral fellow in epidemiology, and Barry Margolin, chairman of biostatistics, both at UNC-CH. They found about a 40 percent increased risk of breast cancer in the women who had higher levels of trans fatty acids, Kohlmeier said. All subjects, either women newly diagnosed with breast cancer or randomly selected controls, were postmenopausal and between the ages of 50 and 74. Researchers controlled statistically for smoking, drinking, degree of overweight, age at first childbirth, family history of breast cancer, age at menarche and menopause and other habits and conditions that might bias the outcome. "Another interesting finding was that among our subjects, women who reported low intakes of polyunsaturated fats while showing the highest levels of trans fatty acids had the greatest risk of breast cancer," she said. "That suggests there might be an interaction between the two types of fat such as competition at the molecular level resulting in polyunsaturated fats having a protective effect." The increased risk of breast cancer appeared to be three and a half times as great among women with high intakes of trans fatty acids and low intakes of polyunsaturated fats (which come from fish and corn oils) compared to women who consumed significant amounts of polyunsaturated fat. Examples of foods often high in trans fatty acids are french fries, processed snack foods, bakery products and margarine, Kohlmeier said. "Since trans fatty acids already have been associated with cardiovascular disease, the preference is, of course, to reduce trans fatty acid intake," she said. "If you do reduce that intake, it would take a year or two to show a reduction of the acids in stored body fat." Among strengths of the study were that it included a relatively large group of patients and control subjects. Direct measurement of fat avoided errors involved in asking volunteers to try to remember what they had eaten and what brands of food, Kohlmeier said. "This work, because it is the first to show a significant association between breast cancer and trans fatty acids, needs to be confirmed with other studies," the scientist said. "Still, we think it is important because so many women are at risk of breast cancer, and there are so few factors, especially dietary factors, known to reduce the risk." The study took place in the United States, the Netherlands, Northern Ireland, Spain, Switzerland, Germany and Finland and was part of the European Community Multicenter Study on Antioxidants, Myocardial Infarction and Breast Cancer (EURAMIC). It was financed by participating countries as a Concerted Action by the Commission of European Communities. Co-authors of the new report include Drs. Pieter van't Veer, John J. Strain, Jose M. Martin-Moreno, Jussi K. Huttunen, Joaquin Fernandez-Crehuet Navajas, Blaise C. Martin, Michael Thamm, Alwine F.M. Kardinaal and Frans J. Kok. Some European companies already have begun trying to eliminate trans fatty acids from margarine they produce, Kohlmeier said. To her knowledge, U.S. firms have not yet begun to do so.
--------
428-> Basin Traps Air Pollution In Mexico City: International Study Has Implications For U.S. Cities
RICHLAND, Wash. -- The first detailed measurements in Mexico City of pollutants such as peroxyacetal nitrate show concentrations similar to those that burned eyes and lungs in Los Angeles in the early 1970s, according to preliminary results of a field study conducted earlier this year. Peroxyacetal nitrate also is implicated in the production of ozone, another irritant that makes breathing difficult. An international team of scientists conducted the study, which was part of the Department of Energy's Atmospheric Sciences in Complex Terrain program -- a long-term effort to study the effects that geographical features such as mountains and valleys have on air movement and pollution. The study was funded by DOE and the Mexican government. Pacific Northwest National Laboratory organized the meteorological portion of the project and staffed one of six data-collection sites. "The complex movement of air in the high basin makes it difficult to predict where the pollution will concentrate at any given time," says Pacific Northwest?s Chris Doran, science director of the project. "The close coupling of meteorological and chemistry measurements and analysis is necessary to understand how the surrounding terrain affects the transport and diffusion of pollutants." The study may help explain how fine particles form in the atmosphere. These particles are potentially the most hazardous because they can lodge in the lungs, and the U.S. Environmental Protection Agency has proposed new standards for fine particles. "This study will be relevant to our understanding of the nature and causes of fine particle air pollution throughout the world, including that found in U.S. cities," said Pacific Northwest's Sylvia Edgerton, project director. The data will be used to improve computer models designed to predict atmospheric conditions and potentially guide responses to pollution -- such as changing the location or timing of pollution releases. Mexico City, with 20 million residents, sits at 2,255 meters (7,400 feet) and is largely surrounded by mountains, creating a basin where inversions of colder air can be trapped by warmer air. Pollution from human activities collects in the air over four- to six-day cycles, similar to Western U.S. cities.
--------
429-> Up, Up, And Away (Bit By Bit) -- Satellites On A String
"The nation that controls magnetism controls the universe." So proclaimed comic strip character Diet Smith in the 1960s when he would fly Dick Tracy from Earth to Moon in a magnetically driven Space Coupe. Smith's proclamation was a bit over the top, but it carried a kernel of truth: you can cut space travel costs by using an extension cord to tap into a planet's magnetic field. Scientists and engineers at NASA's Marshall Space Flight Center are developing a test model of such a device that will use Earth's magnetic field to make a rocket stage re-enter the atmosphere in a few days instead of months. If it works, then America will have a powerful new tool to keep satellites up - even to explore the solar system - without using rockets. It could even trim $2 billion a year off the cost of operating the International Space Station. It won't quite work the same as a Space Coupe with steerable magnets. Instead, ProSEDS will use a 20 km (12-mile) extension cord that plugs into the magnetosphere and turns the cord into an electric motor that slowly raises or lowers a satellite's orbit. The concepts behind ProSEDS - the Propulsive Small Expendable Deployer System - are derived from the Tethered Satellite System flown on the Space Shuttle in 1995 and 1996. Although the tether broke as it reached its 19.6 km (12-mile) length on its 1996 flight, scientists gathered a great deal of data about tether behavior during five hours of operation. "There's a new model out there on how you collect electrical current in space," said Dr. Nobie Stone, project scientist for the Tethered Satellite System. Stone and Dr. Dennis Gallagher, both in NASA Marshall's Space Sciences Laboratory, are advising Marshall engineers on the electrodynamic aspects of the ProSEDS experiment. The Tethered Satellite System employed a large deployment mechanism, resembling a deck winch, in the Space Shuttle payload bay. The winch unreeled 20 km of insulated, conducting tether with a spherical satellite at the end. As the Shuttle orbited the Earth, the electrical wire cut through the Earth's magnetic field , and the motion produced an electrical current. Electrons - which make up a current - were collected by the satellite, through the tether, and flowed out the Shuttle by way of an electron gun that dumped the charge as it built up. What Stone and other scientists found was that the tethered system produced more current that expected. "The theoretical models were not accurate on tether," Stone said, "and the currents were higher than we expected." Specifically, the models require that the voltage be 10 times greater to collect a current than what was observed. Before the flight, the models predicted that the tether would produce 0.5 amp (0.5 A) under ideal conditions. Instead, it produced more than 1 amp under less than ideal conditions. "The models were a factor of two or three off because they don't include the effects of orbital motion through the plasma (electrified gas) of the ionosphere," Stone said. While motion of a conductor through the magnetic field is crucial (it's also how a generator in a power plant works), motion through the electrons in space was thought to be a miniscule effect. The Shuttle moves at 7.7 km/s (17,500 mph) while the electrons move at 200 km/s (115,000 mph). It turns out that the current carried by those electrons connected nicely with the tethered system and "contributed significantly" to the power generated. Juan San Martine of Spain predicted that a tethered system did not need a large sphere at the end of the line to work. The motion of a satellite through space generate a plasma shield that stands off about 1 cm (0.4 in) away from the spacecraft surface. On the 1.8 m (6 ft) diameter TSS, that 1 cm standoff adds only about 2 percent to the collecting area. On a wire, it increases the collecting area 400-fold or more, so that an 82-meter wire now has as much effective collecting area as the 1.8-meter sphere. "If this new bare wire tether works as advertised," Stone said. "it would allow us to collect considerably more current for a given length of tether." As a result, shorter tethers could be used for propulsion or to generate electrical power. "The applications of this are, potentially, to produce power or thrust on the International Space Station," Gallagher explained. The tether could provide extra electricity to the station, or help maintain its altitude so it does not re-enter Earth's atmosphere. The tether will produce just a little force. The force on the Shuttle was 0.4 newton (0.1 lb). But applied steadily, for hours or days, it makes a difference. Les Johnson of Marshall's Advanced Systems and Technologies Office predicts that a 10 km (6 mi), 10 kilowatt tether system could boost a 1,000 kg (2,200 lb) satellite as much as 400 to 540 km in one day, depending on the orbit and other conditions. Johnson and others in the Advanced Systems and Technologies Office are developing the ProSEDS concept to test this innovative idea. "The big thing we're trying to do is demonstrate the propulsive utility of an electrodynamic tether," Johnson said. "We view this as a precursor to a lot of different approaches that we've been studying." ProSEDS is much smaller than the Shuttle's Tethered Satellite System. In operation on future satellites, the tether, which will look more like dental floss than TSS's high-tech rope, will unreel from a bobbin in a can. The can is released from the satellite and the difference in Earth's gravity - even across a difference of a few feet in altitude - pulls the can down. Eventually, the tether is unwound to a distance of 25 km.About 5 km (3 miles) of tether near the spacecraft would be bare; the rest is non-conducting and provided to put enough distance on the tether so it stays taut. In the ProSEDS demonstration flight, the satellite will be the second stage of a Delta rocket. ProSEDS will ride as a piggyback payload for the launch of a larger satellite (an assignment is being sought). The tether bobbin will stay on the rocket and a weight will be unreeled upward on the tether. After the satellite is injected into orbit, the second stage normally would be slowly pulled back from 400 km (240 mi) to Earth by atmospheric drag. After 120 days, it re-enters and burns up. Johnson, Stone, and Gallagher want to do that in about 15 days. Their plan is for the tether to increase drag by acting as an electrical generator to power batteries on the ProSEDS telemetry package. This package, equipped with sensors that Stone will develop from designs proven on the Space Shuttle and satellites, will measure precisely how well the bare-wire tether concept works). Among other things, the ProSEDS team wants to study the tether's behavior to see whether the differences between night and day would make the tether swing like a pendulum out of control. Operated the other way around, a tether powered by solar cells - such as those on International Space Station - would boost a satellite's orbit and keep it from re-entering. "We're not as fast as chemical rockets, but we have the efficiency of electrical propulsion," Johnson said. Electrical engines provide more thrust per pround of propellant than chemical enbgines. Since a propulsive tether expends no propellant, its efficiency will be measured in its cost compared to rockets. And that can be as little as 8 percent the cost of chemical rockets. A propulsive tether would weigh about 90 kg (200 lbs.). In turn, it would eliminate the need to haul up to 4,000 kg (8,800 lbs.) of chemical propellants to the station. Atmospheric drag on the station will be about 0.3 to 1.1 newton (depending on the time of year), and the tether could produce 0.5 to 0.8 newton of thrust. A reusable space tug - called an electrodynamic tether upper stage - could be built using the propulsive tether to haul satellites from a launch vehicle in low orbit to higher orbits. The sky is not quite the limit on propulsive tethers. The technique requires an ionosphere, a region of electrified gas which acts as part of the electrical circuit. Around the Earth, it tapers off around 1,500 km (900 miles). The solar plasma and magnetic field of the sun are too weak for interplanetary voyages. Most of the planets do not have the right conditions for propulsive tether operations. Even Jupiter, with its intense magnetic field, does not have the right gravity gradient to keep a tether strung out to help move a satellite in exploring its moons. However, conditions are right around the moons themselves. This would eliminate the problem of storing chemical propellants at the right temperatures so they work in deep space, or carrying complex electrical thrusters. At the request of the Jet Propulsion Laboratory, the MSFC Program Development Office is studying a propulsive tethert o help explore icy Europa, and Gallagher has studied science data to determine which Jovian moons would be the best candidates for such a mission. "Io is most interesting because it is electrically connected" through its volcanoes which spew sulfur dioxide into space, Gallagher said. All that is a few years off. The ProSEDS demonstration has been approved and is being developed for flight, possibly in 1999 or 2000. 
--------
430-> Seeds Without Sex -- Research Could Make Male Plant Parts Redundant
CSIRO research could make male plant parts in crops redundant, and dramatically lift grain production around the world. The research program aims to develop plants which can produce seed without sex. It is a 15-year collaboration between CSIRO, the Australian Centre for International Agricultural Research (ACIAR), and the International Rice Research Institute (IRRI). "The normal process of pollen formation and transfer is very sensitive to a range of weather conditions - it cannot be too dry nor too windy and so forth. It is estimated that $400 million is lost in rice production alone around the world each year because of drought-related pollination failure," said Dr Abed Chaudhury, of CSIRO Plant Industry. In a world-first discovery, CSIRO scientists have found a gene that allows Arabidopsis - a test plant used by scientists because of its rapid life cycle - to bypass the normal pollination process and begin seed formation. This is the crucial first step in developing plants which can produce seed without pollination. The hunt is now on to find equivalent genes in commercial plants like rice - the world's biggest crop, and the staple diet for billions of people globally. "In most crop plants, the male parts of the flower transfer pollen to the female parts, prompting the grain to develop," Dr Chaudhury said. "But we are aiming to produce grain without the need for male plant parts." Plants that do not require pollination for seed-set undergo an alternative, sexless process called apomixis. CSIRO scientists aim to identify the genes involved in apomixis and then use them in pollination-reliant crop species. "If we can produce commercial crop plants that don't need pollination, the benefits would be enormous in terms of higher yields and more efficient production methods," Dr Chaudhury said. ACIAR have estimated that the minimum likely benefits from the research will be $7 billion to $8.6 billion worldwide with the benefit to Australia estimated at $16 million to $19 million.
--------
431-> Mars Global Surveyor Mission Set To Begin Orbiting On Sept. 11
For researchers like the University of Colorado at Boulder's Bruce Jakosky who are involved in NASA's unmanned Mars Global Surveyor mission slated to enter planetary orbit Sept. 11, patience is a virtue. Unlike Mars Pathfinder mission team members -- who achieved their science objectives during the first week of operation -- the MGS team will spend nearly two years collecting data as the spacecraft methodically maps the planet's surface and atmosphere. For the first six months of the mission, the craft will shift from a large, elliptical orbit to a low-altitude, circular orbit using a technique known as aerobraking, which relies on the drag of a planet's atmosphere rather than fuel-powered engines to trim the spacecraft's path around around a planet. In mid-March, when the spacecraft is orbiting Mars every two hours at an altitude of about 235 miles, a suite of instruments will begin taking data to develop a global portrait of Mars' topography, mineral composition, atmosphere and interior. After the project is completed in one Mars year -- the equivalent of roughly two Earth years -- scientists should be able to assemble the most sophisticated map yet of the planet's dynamic surface and atmosphere through each of the Martian seasons. "Compared to Pathfinder, The Mars Global Surveyor mission will be a long, drawn-out affair," said Jakosky, a research associate at CU-Boulder's Laboratory for Atmospheric and Space Physics who is serving as an interdisciplinary scientist for the MGS effort. "But this mission has the potential to completely revolutionize our understanding of Mars." Managed by NASA's Jet Propulsion Laboratory in Pasadena, the MGS spacecraft is carrying six instruments to study the planet's surface, atmosphere, and gravitational and magnetic fields. They include a high-resolution camera, a thermal-emissions spectrometer, a laser altimeter, a magnetometer, a radio science experiment and a communications relay instrument. For Jakosky and CU-Boulder postdoctoral research associate Michael Mellon, the mission should provide new insights into the seasonal water cycles of the planet. Data from the thermal-emissions spectrometer should help the researchers estimate the amounts and location of water in the atmosphere and the sources and sinks of water on and below the planet's surface, including the polar caps. "Water is the centerpiece of the Mars exploration program," said Jakosky, also an associate professor in CU-Boulder's geological sciences department. Although Mars is now a cold, dry planet, portions of the terrain show the remnants of large flood channels that resemble catastrophic flood channels seen on Earth today. "These flood channels suggest that there is still lots of water beneath the surface," he said. "How much remains today and where the rest has gone over time is still the subject of vigorous debate." Geologic evidence indicates significant volcanic activity occurred on Mars early in its history, and there is some evidence that occasional volcanic eruptions may even occur on Mars today, Jakosky said. Heat from underground magma created by volcanic activity on the planet could conceivably fuel hot springs like those on Earth, which have been shown to harbor primitive forms of life. The author of a book slated for publication next year by Cambridge University Press titled "The Search for Life on Other Planets," Jakosky believes it is possible that primitive life forms may exist today on Mars. Jakosky is one of about 50 science team members on the MGS mission. He worked as a graduate student at the California Institute of Technology on NASA's unmanned Viking missions to Mars in the 1970s and was one of 12 senior scientists for the unmanned Mars Observer mission believed to have exploded as it was approaching orbit insertion at the Red Planet in 1993. "Any space exploration is risky," he said. "But we learned a lot from the Mars Observer experience, and I am optimistic about this mission." Following the completion of the mapping project in late January 2000, the MGS spacecraft will be used as a communications satellite to relay data back to Earth from surface landers launched to the Red Planet as part of future NASA missions.
--------
432-> Pawpaw Shows Promise In Fighting Drug-Resistant Tumors
LAS VEGAS -- The pawpaw tree, which bears the largest fruit native to North America, may bear new fruit for scientists seeking ways to fight cancer. Purdue University researcher Jerry McLaughlin, working with doctoral student Nicholas Oberlies, has found compounds in the bark of the tree that have shown preliminary success in fighting some drug- resistant cancers. The studies show that the pawpaw compounds not only are effective in killing tumors that have proven resistant to anti-cancer agents, but also seem to have a special affinity for such resistant cells. McLaughlin will talk on the anticancer properties of the pawpaw compound Thursday, Sept. 11 at the American Chemical Society national meeting in Las Vegas. The findings also were published this summer in the journal Cancer Letters and the Journal of Medicinal Chemistry. Though further studies are needed to pinpoint exactly how the pawpaw compounds work within the cancer cell, McLaughlin says their effect is to pull the plug on the energy-producing mechanisms in the cell. McLaughlin notes, however, that the effect on drug-resistant cells has been studied only in laboratory cultures and will require additional study in animals before it can be tested in humans. "Multidrug-resistant cancer is hard to treat because the cancer cell has developed a mechanism to get around the anti-cancer agent," says McLaughlin, professor of pharmacognosy in Purdue's School of Pharmacy and Pharmacal Science. "Tumor cells that survive chemotherapy treatments often recover with increased resistance to the agent used in the original treatment program as well as to other related drugs." Such resistance can develop when surviving cancer cells develop one or more mechanisms to accelerate the removal of noxious substances, including anti-cancer drugs. One of the most common mechanisms used to circumvent the anti-cancer agents is to develop a "pump" that is capable of pushing anti-cancer agents out of the cell before they can kill it. These pumps are called P-glycoprotein mediated pumps and are named for the type of protein used to construct and operate them. Though all cells have the ability to develop such a pump, normal cells seldom do. Even in cancer cells, which do not respond normally to the body's control mechanisms, only a small percentage of cells develop this pumping mechanism. "If having this pump was such a good deal, all cells would have it. But all cells don't," McLaughlin says. "In a given population of cancer cells in a person, maybe only 2 percent of the cancer cells possess this pump. But it's those 2 percent of cancer cells that eventually grow and expand to create drug-resistant tumors." One of the tricks currently attempted in treating cancer patients is to flood the body with other compounds to keep the pump busy, and then administer high doses of an anti-cancer agent in hopes that some of it will be able to stay in long enough to kill the cancer cell. "But the high doses of the drugs required for this treatment often produce side effects, such as loss of blood pressure, so the patient often succumbs to the side effects of the treatment," McLaughlin says. Though this pump mechanism is efficient at eliminating most anti- cancer agents, McLaughlin, whose research group has identified more than 40 pawpaw compounds with anti-cancer properties, discovered a series of the compounds, called Annonaceous acetogenins, that were capable of killing cancer cells that employed this mechanism. He then designed a laboratory study to analyze the cytotoxic or cell- killing effects of one of the compounds, called bullatacin, on human mammary cancer cells. The study compared bullatacin's effects on standard, nonresistant cancer cells and on multidrug-resistant cells. In the June issue of Cancer Letters, the research team reported that bullatacin preferentially killed the multidrug-resistant cells by inhibiting the production of adenosine triphosphate, or ATP. ATP is a compound that works to release energy in a cell and is essential to all cell processes. "A multidrug-resistant cell requires a tremendous amount of energy to run the pump and extrude things out of the cell," McLaughlin says. "By inhibiting ATP production, we're essentially pulling the plug on its energy source." Though the pawpaw compounds also inhibited ATP production in noncancerous cells and nonresistant cancer cells, those cells were not affected as dramatically, McLaughlin says. "Normal cells and standard cancer cells may be able to minimize the effects of this compound because they don't require the vast amounts of energy needed by the pump-running cells," McLaughlin says. "The resistant cell is using its extra energy for this pump as well as to grow, so it is really taxed for energy. When we mess with the energy supply, it kills the cell." McLaughlin and his group then did a follow-up study to test a series of 14 structurally similar pawpaw compounds to determine the structural features that maximize this biological activity in multidrug- resistant cancer cells. The results were published in the June issue of the Journal of Medicinal Chemistry. "This study tells us how to maximize this activity, so we have a pretty good idea what compounds we'd like to try in animals with multidrug-resistant tumors," McLaughlin says. If proven effective in animals and humans, McLaughlin says, the compounds may be used to treat multidrug resistance in a variety of cancers, because many types of cancer cells develop resistance by employing a pump. The studies were funded by National Institutes of Health/National Cancer Institute, the Indiana Elks Cancer Research Fund and Purdue Research Foundation. Purdue has filed a patent on the use of the pawpaw compounds. Source: Jerry McLaughlin, (765) 494-1455; e-mail, jac@pharmacy.purdue.edu Writer: Susan Gaidos, (765) 494-2081; e-mail, susan_gaidos@uns.purdue.edu ABSTRACT: American Chemical Society National MeetingTHWARTING RESISTANCE: ANNONACEOUS ACETOGENINS AS NEW PESTICIDAL AND ANTITUMOR AGENTS Jerry L. McLaughlin, Department of Medicinal Chemistry and Molecular Pharmacology, School of Pharmacy and Pharmacal Sciences, Purdue University. The Annonaceous acetogenins are C-32 or C-34 long chain fatty acids that have been combined with a 2-propanol unit at C-2 to form a terminal a, b-unsaturated g-lactone. They often cyclize to form one, two, or three tetrahydrofuran (THF) or tetrahydropyran (THP) rings near the middle of the aliphatic chain. To date, over 230 of these compounds have been isolated from several genera of the plant family, Annonaceae. Biologically, they are among the most potent of the known inhibitors of complex I (NADH:ubiquinone oxidoreductase) in mitochondrial electron transport systems and of the plasma membrane NADH: oxidase that is characteristic of cancerous cells. These actions induce apoptosis (programmed cell death), perhaps as a consequence of ATP deprivation. Applications as pesticides and antitumor agent hold excellent potential, especially in the thwarting of resistance mechanisms which require an ATP- dependent efflux. (Aided by RO1 grant no. CA30909 from the National Cancer Institute, NIH)
--------
433-> Nationwide Hunt For Rheumatoid Arthritis Genes Launched
The National Institute of Arthritis and Musculoskeletal and Skin Diseases (NIAMS), the National Institute of Allergy and Infectious Diseases (NIAID) and the Arthritis Foundation are joining forces to support a national consortium of 12 research centers in the search for genes that determine susceptibility to rheumatoid arthritis. Genetic factors are known to play a role in predisposing people to the disease, in part because rheumatoid arthritis tends to run in families. But scientists do not yet know much about the specific genes that are involved. In what is the largest such effort in the world, researchers participating in the North American Rheumatoid Arthritis Consortium (NARAC) hope to learn more about genes that play a role in the disease. They plan to collect medical information and genetic material (DNA) from 1,000 families nationwide in which two or more siblings have rheumatoid arthritis that began when they were between 18 and 60 years old. The project will be headed by Peter K. Gregersen, M.D., of North Shore University Hospital in Manhasset, NY. North Shore will serve as a central registry of information on sibling pairs with rheumatoid arthritis (including clinical, x-ray and laboratory data) and as a repository of serum, blood cells and DNA from patients. "Findings from this project should give us a window onto the causes of rheumatoid arthritis, which opens up the possibility of developing new ways to diagnose and treat the disease," says Stephen I. Katz, M.D., Ph.D., director of the NIAMS. "We're very pleased to be participating in a partnership with the NIAID and the Arthritis Foundation to reach these common goals." Adds Anthony S. Fauci, M.D., director of the NIAID, "This collaborative effort promises to provide important new insights into a disease that exacts an enormous toll, both in terms of human suffering and economic costs. We look forward to participating in this important initiative to better understand this debilitating autoimmune disease." Doyt L. Conn, M.D., Senior Vice President for Medical Affairs of the Arthritis Foundation, says: "The state of knowledge and technology today make this type of study possible. The Arthritis Foundation will not only provide financial support for the study, but through its chapters and publications will help in recruiting siblings with the disease." "This collaboration is a synergistic way to reach the goal of identifying these genes," says Debra Lappin, Esq., Chair of the Arthritis Foundation. "This is the first time in the history of the Foundation that we have joined in a partnership to support a collaborative research endeavor." Rheumatoid arthritis, which affects over 2 million people in the United States, or about one percent of the adult population, is a potentially disabling inflammatory form of arthritis that causes pain, swelling, stiffness and loss of function in the joints, and may also affect other body systems. As rheumatoid arthritis progresses, the inflammation processówhose hallmarks include redness, swelling, warmth and pain--can cause erosion, or destruction, of bone and cartilage in the joints. The disease has a major impact on both the individual and society, causing significant pain, impaired function and disability, as well as costing millions of dollars in healthcare expenses and lost wages. Rheumatoid arthritis is an autoimmune disease, so-called because a personís immune system attacks his or her own body tissues. Scientists donít know the cause, but they believe it results from a combination of genetic factors that make a person susceptible to the disease and some type of environmental trigger--possibly an infectious agent such as a virus or bacterium. Treatment for rheumatoid arthritis includes a variety of medications as well as lifestyle strategies such as exercise and self-management programs. No treatment is ideal, however, and there is no cure. Development of new treatments and even ways to prevent the disease are active areas of research supported by both the NIH and the Arthritis Foundation. The consortium's first goal in the next 3 to 5 years is to find and begin to study 1,000 families with two or more siblings who have rheumatoid arthritis and, if possible, at least one surviving parent. With help from the Arthritis Foundation, the researchers will be looking for pairs of siblings in which at least one sibling has relatively severe disease, as indicated by a hand X-ray that shows some erosion of bone. Studies show that if a person has rheumatoid arthritis, their siblings are somewhere between 2 to 10 times more likely to develop the disease than other people in the population. Researchers at 10 of the centers (listed below), including the NIAMS intramural Arthritis and Rheumatism Branch, will collect medical information and blood samples from each patient. (Two additional centers are participating in the project but not recruiting patients.) Blood samples will be sent to North Shore University Hospital, where researchers will prepare DNA from white blood cells. The researchers will analyze DNA from affected siblings to look for genetic regions that they share more frequently than would be expected by chance--that is, more than 50 percent of the time. These shared regions are likely to contain genes that are involved in the disease. The researchers expect to find a number of genes that are involved in causing rheumatoid arthritis. "I think itís unlikely that the same genes are going to be involved in every person," says Gregersen. "It will probably be fairly complicated, with different gene combinations involved in different people." Scientists hope that by identifying genes that play a role in the disease, they will gain a better understanding of the disease itself, which Gregersen notes is still poorly understood. Explaining the long-term goals of studies such as this, Gregersen says: "Specific treatments for rheumatoid arthritis are what we all hope will ultimately come out of this." People with rheumatoid arthritis who have a brother or sister with the disease and are interested in participating in the study can call the coordinating center at North Shore University Hospital toll free at 800-382-4827 or send e-mail to narac@nshs.edu. The Web site for the consortium can be found at http://www.medicine.ucsf.edu/narac/narac.html This project is funded by the NIH (NIAMS and NIAID) in partnership with the Arthritis Foundation, with additional funding from the NIH Office of Research on Womenís Health (ORWH). NIAID, NIAMS and ORWH are components of the NIH, U.S. Department of Health and Human Services. The principal investigators and participating centers in the consortium are: Peter K. Gregersen, M.D.North Shore University Hospital Manhasset, N.Y. (coordinating center) Mark H. Wener, M.D.*University of WashingtonSeattle, Wash. David S. Pisetsky, M.D., Ph.D.Duke University Medical Center Durham, N.C. Christopher Amos, Ph.D.* University of TexasM.D. Anderson Cancer CenterHouston, Texas Richard M. Pope, M.D.Northwestern UniversityChicago, Ill. Lindsey A. Criswell, M.D., MPHUniversity of California San FranciscoSan Francisco, Calif. Salvatore Albani, M.D.University of California San Diego (UCSD)La Jolla, Calif. Daniel O. Clegg, M.D.University of Utah Health Sciences CenterSalt Lake City, Utah J. Lee Nelson, M.D.Fred Hutchinson Cancer Research CenterSeattle, Wash. Harry W. Schroeder, M.D., Ph.D. The University of Alabama at BirminghamBirmingham, Ala. (co-principal investigator S. Louis Bridges, Jr., M.D., Ph.D.) Michael F. Seldin, M.D., Ph.D. University of California DavisDavis, Calif. Ronald Wilder, M.D., Ph.D. and Daniel Kastner, M.D., Ph.D.NIAMS, NIHBethesda, Md.
--------
434-> Discovery Of Genetic Pathways May Provide New Ways To Combat Candida Infections
A new study has uncovered the genetic wiring diagram underlying the infectiousness of Candida albicans, a fungus that causes thrush in babies, vaginal infections in women, and life-threatening infections in chemotherapy and AIDS patients. The study, led by Dr. Gerald R. Fink, Director of the Whitehead Institute for Biomedical Research, reveals that one key to Candida's infectiousness lies in its ability to switch from a rounded form to filamentous forms. When the wiring diagram underlying this switch is inactivated, Candida infections are no longer deadly in mice. The implications of these results for humans are enormous, given that current treatment options for invasive fungal infections are seriously limited. "If we could design drugs that inactivate or block Candida's filamentation pathways, we might be able to fight the organism's insidious and devastating effects on patients with weak immune systems," says Dr. Fink. "Our study also shows that this genetic pathway is a common theme among fungal pathogens and so may provide important insights on how plant and animal pathogens work." The results are reported in the September 5 issue of the journal Cell by first author Hsiu-Jung Lo and her colleagues from Dr. Fink's lab, Children's Hospital in Boston, MA, and Schering-Plough Research Institute in Kenilworth, NJ. Using state of the art videomicroscopy techniques, Dr. Fink and his associates recently captured on video the fate of immune cells infected with Candida in a petri dish. When Candida enters a host, the organism is eaten up by cells called macrophages, which are the sentinels of the immune system. But soon, the fungi fight back, switching to a filamentous form and tearing through the macrophage walls, destroying them. Fortunately, in people with healthy bone marrow, other immune system cells called neutrophils come to the rescue to destroy the filamentous Candida. However in patients with weakened immune systems, who lack healthy bone marrow and do not make neutrophils, this second line of attack is not available. In these patients, Candida can take over, as evidenced by the havoc this organism wreaks in patients after chemotherapy. In Friday's Cell paper, the scientists report that two parallel genetic pathways account for Candida's ability to filament and that inactivating one pathway is not enough to stop filamentation. Inactivating both pathways, on the other hand, renders Candida harmless to both macrophages and mice. Background Fungal infections in hospitalized patients have almost doubled throughout the 1980s, often with life-threatening results in individuals with weakened immune systems. Candida, in particular, poses a serious threat and is associated with high mortality rates in patients undergoing chemotherapy. Candida is also a major cause of infection in hospitalized patients, especially those in Intensive Care Units, patients after major injuries or surgery, patients with burns, and premature babies. Physicians now recognize a real need for new ways to combat these infections; however, finding these new avenues has been a challenge. For one, developing broad spectrum antibiotics against fungi has been difficult. Fungi are more similar to humans than are bacteria, and few anti-fungal agents can kill fungi without harming normal human cells. The drug fluconazole is one of the few antibiotics that works without severe side effects, but increasingly, physicians are encountering fungal strains that are resistant to fluconazole. Scientists had suspected that one key to Candida's infectiousness may lie in its ability to switch to one of several filamentous forms, but until recently, they had hardly attempted to figure out this wiring diagram because Candida albicans, the most common pathogen, is asexual and therefore intractable for genetic studies. Although common baker's yeast is an excellent system for genetic studies, scientists had never considered it to be a good model for studying fungal disease because they thought yeast couldn?t switch to a filamentous form. However, four years ago, Dr. Fink and his colleagues discovered that yeast cells could filament, opening new doors for research into fungal infections. Yeast as a Model for Candida In this study, Dr. Fink and his colleagues used molecular biology techniques to identify the components of the filamentation circuit in yeast. With the recently completed yeast genome to guide them, the scientists began to knock out suspicious genes and, by a process of elimination, discovered the culprits that are responsible for filamentation. Once scientists identified the key yeast filamentation genes, they simply plucked out the analogous genes in Candida. "Candida albicans is three hundred million years apart evolutionarily from yeast-as far away in evolution as humans are from turtles-and yet, the basic logic circuit was conserved," says Dr. Fink. But more work needed to be done before scientists could think about reaping the benefits of this remarkable discovery. The key question was whether preventing filamentation in Candida could render the fungus non-infectious. Scientists began to answer this question using macrophages in petri dish, which are normally ineffective against filamentous Candida. When challenged by Candida strains with both pathways knocked out, macrophages emerged victorious. This was good news to researchers, but the real test would come when the Fink lab scientists, in collaboration with scientists at Schering Plough, began experiments with mice. In general, Candida infections are lethal in mice, and strains with only one filamentation pathway knocked out are still lethal to mice. But when the scientists infected mice with Candida strains with both pathways knocked out, the mice survived and did not succumb to the infection. Based on Dr. Fink's work, other scientists at Purdue University have knocked out analogous genes in a strain of fungus that causes disease in rice plants, rendering the fungus harmless. These findings will have implications for agriculture. The work reported in the Cell paper was supported by grants from the National Institutes of Health and Schering-Plough Research Institute, and a National Research Service Award. Dr. Fink is an American Cancer Society Professor of Genetics.
--------
435-> World's Largest Known Prime Number Found -- 2^2976221-1 Is The 36th Known Mersenne Prime
Gordon Spence, using a program written by George Woltman, has discovered what is now the largest known prime number.  The prime number, 2^2976221-1, is one of a special class of prime numbers called Mersenne primes.  This is only the 36th known Mersenne prime.  Gordon Spence, a 38-year-old I.T. Manager for Thorn Microwave Devices Ltd, is from Hampshire, England.  George Woltman is a 39 year-old programmer living in Orlando, Florida. Peter Butcher Managing Director at TMD said "We congratulate Gordon & George on their discovery. As a world leader in Microwave R&ve.tD we appreciate the value of research and were glad to donate thousands of hours of computer time to the search." The new prime number, discovered on August 24th, is 895,932 digits long - more than twice the length of the previous record prime!  If printed, the number would fill a 450 page paperback book. It took Spence's 100 MHz Pentium computer 15 days to prove the number prime. Alan White Managing Director at Technology Business Solutions, who provided the historic PC, said "We were delighted to donate the computer that has made this exciting discovery." The new Mersenne prime was independently verified on a Cray T90 supercomputer by David Slowinski, discoverer of seven Mersenne primes between 1979 and 1996. Spence is one of over 2000 volunteers world-wide participating in the Great Internet Mersenne Prime Search (GIMPS).  This prime number is the second record prime found by the GIMPS project. Joel Armengaud discovered the previous largest known prime number last November.  The GIMPS project was started by Woltman in early 1996. Discovering prime numbers of this size would have been impossible just a few short years ago.  GIMPS is an example what can be accomplished when people, using spare computer time that would otherwise be wasted, combine forces over the Internet. Working alone, it would have taken Spence's computer 940 years to find this prime number.  Woltman said, "All 2000 volunteers share in the credit of this discovery -- Gordon would not have suceeded without their help." Gordon Spence said of his discovery, "I was just lucky to get the right range of numbers to check, but it is a great feeling to become a part of history and join a very exclusive club." There is a well-known formula that generates a "perfect" number from a Mersenne prime.  A perfect number is one whose factors add up to the number itself.  The smallest perfect number is 6 = 1 + 2 + 3.  The newly discovered perfect number is 2^2976220 * (2^2976221-1). This number is 1,791,864 digits long. The search for more Mersenne primes is already under way.  There may be smaller, as yet undiscovered Mersenne primes, and there are certainly larger Mersenne primes waiting to be discovered. Anyone with a reasonably powerful personal computer can join GIMPS and become a big prime hunter.  All the necessary software can be downloaded for free at http://www.mersenne.org/prime.htm. What are Mersenne Primes?  Why are they useful? An integer greater than one is called a prime number if its only positive divisors are one and itself. For example, the number 10 is not prime because it is divisible by 2 and 5.  A Mersenne prime is a prime of the form 2^p-1.  The study of Mersenne primes has been central to number theory since they were first discussed by Euclid in 350 BC. The man whose name they now bear, the French monk Marin Mersenne (1588-1648), made a famous conjecture on which values of p would yield a prime. It took 300 years and several important discoveries in mathematics to settle his conjecture. With undertakings such as the race to the moon in the 1960's, it is the byproducts that are most useful to society.  The same is true in the search for large primes.  When testing Mersenne numbers to see if they are prime one must repeatedly multiply very large integers.  Recently Richard Crandall at Perfectly Scientific discovered ways to double the speed of some Fast Fourier Transforms which are used in numerous other scientific applications.  Richard Crandall also patented the Fast Elliptic Encryption system which uses Mersenne primes to encrypt and decrypt messages. School teachers in elementary through high-school grades have used GIMPS to get their students excited about doing mathematics. Students who run the free software are contributing to mathematical research. Historically, searching for Mersenne primes has been used as a test for computer hardware.  The free GIMPS program used by Spence has identified dozens of hardware problems in PCs.  Intel now uses the program to test every Pentium II and Pentium Pro chip before it ships.
--------
436-> Two Voyager Spacecraft Still Going Strong After 20 Years
Twenty years after their launch and long after their planetary reconnaissance flybys have been completed, both Voyager spacecraft are now gaining on another milestone -- crossing that invisible boundary that separates our solar system from interstellar space, the heliopause. Since 1989 when Voyager 2 encountered Neptune, both spacecraft have been studying the environment of space in the outer solar system.  Science instruments on both spacecraft are sensing signals that scientists believe are coming from the heliopause -- the outermost edge of the Sun's magnetic field that the spacecraft must pass through before they reach interstellar space. "During their first two decades, the Voyager spacecraft have had an unequaled journey of discovery.  Today, even though Voyager 1 is now more than twice as far from the Sun as Neptune, their journey is only half over, and more unique opportunities for discovery await the spacecraft as they head toward interstellar space," said Dr. Edward Stone, the Voyager project scientist and director of NASA's Jet Propulsion Laboratory, Pasadena, CA.  "The Voyagers owe their ability to operate at such great distances from the Sun to their nuclear electric power sources which provide the electrical power they need to function." The Sun emits a steady flow of electrically charged particles called the solar wind.  As the solar wind expands supersonically into space, it creates a magnetized bubble around the Sun, called the heliosphere.  Eventually, the solar wind encounters the electrically charged particles and magnetic field in the interstellar gas.  The boundary created between the solar wind and interstellar gas is the heliopause.  Before the spacecraft reach the heliopause, they will pass through the termination shock -- the place where the solar wind abruptly slows down from supersonic to subsonic speed. Reaching the termination shock and heliopause will be major milestones for the spacecraft because no one has been there before and the Voyagers will gather the first direct evidence of their structure.  Encountering the termination shock and heliopause has been a long sought-after goal for many space physicists, and exactly where these two boundaries are located and what they are like still remains a mystery. "Based on current data from the Voyager cosmic ray subsystem, we are predicting the termination shock to be in the range of 62 to 90 astronomical units (AU) from the Sun.  Most 'consensus' estimates are currently converging on about 85 AU.  Voyager 1 is currently at about 67 AU and moving outwards at 3.5 AU per year, so I would expect crossing the termination shock sometime before the end of 2003," said Dr. Alan Cummings, a co-investigatoron the cosmic ray subsystem at the California Institute of Technology. "Based on a radio emission event detected by the Voyager 1 and 2 plasma wave instruments in 1992, we estimate that the heliopause is located from 110 to 160 AU from the Sun," said Dr. Donald A. Gurnett, principal investigator on the plasma wave subsystem at the University of Iowa.  (One AU is equal to 93 million miles (150 million kilometers), or the distance from the Earth to the Sun.) "The low-energy charged particle instruments on the two spacecraft continue to detect ions and electrons accelerated at the Sun and at huge shock waves, tens of AU in radius, that are driven outward through the solar wind.  During the past five years, we have observed marked variations in this ion population, but have yet to see clear evidence of the termination shock.  We should always keep in mind that our theories may be incomplete and the shock may be a lot farther out than we think," said Dr. Stamatios M. Krimigis, principal investigator for the low energy charged particle subsystem at The Johns Hopkins University Applied Physics Laboratory. Voyager 2 was launched first on Aug. 20, 1977, and Voyager 1 was launched a few weeks later on a faster trajectory on Sept. 5.  Initially, both spacecraft were only supposed to explore two planets -- Jupiter and Saturn.  But the incredible success of those two first encounters and the good health of the spacecraft prompted NASA to extend Voyager 2's mission to Uranus and Neptune.  As the spacecraft flew across the solar system, remote-control reprogramming has given the Voyagers greater capabilities than they possessed when they left the Earth. There are four other science instruments that are still functioning and collecting data as part of the Voyager Interstellar Mission.  The plasma subsystem measures the protons in the solar wind.  "Our instrument has recently observed a slow, year-long increase in the speed of the solar wind which peaked in late 1996, and we are now observing a slow decrease in solar wind velocity," said Dr. John Richardson, of the Massachusetts Institute of Technology, principal investigator on the plasma subsystem.  "We think the velocity peak coincided with the recent solar minimum.  As we approach the solar maximum in 2000, the solar wind pressure should decrease, which will result in the termination shock and heliopause moving inward towards the Voyager spacecraft."         The magnetometer instrument onboard the Voyagers measures the magnetic fields that are carried out into interplanetary space by the solar wind.  The Voyagers are currently measuring the weakest interplanetary magnetic fields ever detected and those magnetic fields being measured are responsive to charged particles that cannot be detected directly by any other instruments on the spacecraft, according to Dr. Norman Ness, principal investigator on the magnetometer subsystem at the Bartol Research Institute, University of Delaware. Other science instruments still collecting data include the planetary radio astronomy subsystem and the ultraviolet spectrometer subsystem. Voyager 1 encountered Jupiter on March 5, 1979, and Saturn on Nov. 12, 1980, and then, because its trajectory was designed to fly close to Saturn's large moon Titan, Voyager 1's path was bent northward by Saturn's gravity sending the spacecraft out of the ecliptic plane, the plane in which all the planets but Pluto orbit the Sun.  Voyager 2 arrived at  Jupiter on July 9, 1979, and Saturn on Aug. 25, 1981, and was then sent on to Uranus on Jan. 25, 1986, and Neptune on Aug. 25, 1989.  Neptune's gravity bent Voyager 2's path southward sending it also out of the ecliptic plane and on toward interstellar space. Both spacecraft have enough electrical power and attitude control propellant to continue operating until about 2020 when the available electrical power will no longer support science instrument operation.  Spacecraft electrical power is supplied by Radioisotope Thermoelectric Generators (RTGs) that provided approximately 470 watts of power at launch.  Due to the natural radioactive decay of the plutonium fuel source, the electrical energy provided by the RTGs is continually declining.  At the beginning of 1997, the power generated by Voyager 1 had dropped to 334 watts and to 336 watts for Voyager 2.  Both of these power levels represent better performance than had been predicted before launch. The Voyagers are now so far from home that it takes nine hours for a radio signal traveling at the speed of light to reach the spacecraft.  Science data are returned to Earth in real-time to the 34-meter Deep Space Network antennas located in California, Australia and Spain.  Voyager 1 will pass the Pioneer 10 spacecraft in January 1998 to become the most distant human-made object in our solar system. Voyager 1 is currently 6.3 billion miles (10.1 billion kilometers) from Earth, having traveled 7.4 billion miles (11.9 billion kilometers) since its launch.  The Voyager 1 spacecraft is departing the solar system at a speed of 39,000 miles per hour (17.4 kilometers per second). Voyager 2 is currently 4.9 billion miles (7.9 billion kilometers) from Earth, having traveled 6.9 billion miles (11.3 billion kilometers) since its launch.  The Voyager 2 spacecraft is departing the solar system at a speed of 35,000 miles per hour (15.9 kilometers per second). JPL, a division of the California Institute of Technology, manages the Voyager Interstellar Mission for NASA's Office of Space Science, Washington, DC.
--------
437-> MGH-Led Team Finds Gene For Crippling Neurologic Disorder
A research team led by investigators from the Massachusetts General Hospital (MGH) has identified and cloned the gene responsible for early-onset dystonia, a crippling, inherited neurological disorder that begins in childhood. The discovery, announced in the September issue of Nature Genetics, is the culmination of more than 15 years of work and contains important clues that could lead to better understanding of the disease and possible preventive treatments. There are many types of dystonia, a term that generally refers to sustained, involuntary muscle contractions that can twist and contort parts of the body. Early-onset dystonia, usually appearing before the age of 11, is the most common and severe hereditary form of the disorder, affecting about 50,000 people in North America. Symptoms usually begin in the legs or arms and spread to the rest of the body, causing it to twist into unnatural postures; symptoms worsen when patients are fatigued or stressed. Patients with advanced dystonia may be confined to a wheel-chair or bedridden. The lifelong condition is more prevalent than Huntington's disease or amyotrophic lateral sclerosis (ALS or Lou Gehrig's disease) among the general population and has a higher frequency among Ashkenazi Jews, those of Eastern European ancestry. "We look on dystonia as a 'stealth crippler'," says Xandra O. Breakefield, PhD, of the MGH Molecular Neurogenetics Unit, leader of the research team. "In contrast to other movement disorders, like Parkinson's disease, there is no visible evidence of damage to the brain and no truly effective drug treatment. Only after identifying the responsible gene and then determining the function of its protein can we understand exactly how this disease produces its symptoms." Along with scientists from Breakefield's MGH lab, the paper's coauthors include researchers from the Columbia University College of Physicians and Surgeons and Mount Sinai School of Medicine in New York, Oregon Health Sciences University in Portland, Stanford University in California and the Howard Hughes Medical Institute at the MGH. In the Nature Genetics paper, first author Laurie Ozelius, PhD, and her collaborators describe their pinpointing the location of the gene, called DYT1, on chromosome 9 and their discovery that virtually all cases of early-onset dystonia are attributed to the same mutation -- the deletion of three "letters" in the genetic code that spells out the sequence of amino acids in a protein. In other genetic diseases different mutations in the same gene are usually found in different families. "This situation, with only one mutation being associated with disease, is unique," Ozelius says. "It suggests that this specific area of the gene and of the protein it codes for must be crucial to its function, which is still unknown." The researchers also found that the DYT1 protein has significant similarities to the heat-shock proteins and proteases. Found in virtually all living organisms, the heat-shock proteins/proteases help cells recover from stresses including heat, traumatic injury and chemical poisoning. Until now, no human disease has been associated with these proteins. "This is quite exciting, because it may help us understand how stress situations bring on a variety of neurological diseases, including this one," says Breakefield. She explains that only 30 percent of those inheriting the DYT1 gene mutation actually develop dystonia and that vulnerability to the disease seems to disappear after age 28. "The disease needs a trigger ? perhaps an environmental stress, infection or a change in another gene. If the mutated gene product is set off, there is no stopping it, but if the process does not start by 28, people with the mutation are virtually free from the risk of developing symptoms. We now have an important clue to help us find that trigger and, we hope, to stop it." The members of this research team have been searching for the DYT1 gene since the early 1980s, when many of them worked together at Yale University. In 1989, they discovered the first marker for the gene, which localized it to a segment of chromosome 9. While the MGH researchers worked out the genetic and molecular aspects of this discovery, their work relies on crucial contributions from their collaborators. Susan Bressman, MD, Stanley Fahn, MD, and members of the Dystonia Clinical Research Center at Columbia Presbyterian Medical Center -- including Mitchell Brin, MD, now at Mount Sinai -- provided blood and DNA samples from dystonia patients and their family members. Patricia Kramer, PhD, at Oregon and Neil Risch, PhD, at Stanford, provided key statistical information tracing patterns of the gene's inheritance, including its prevalence among Ashkenazi Jews. A collaboration between Risch and the Columbia group confirmed that the gene mutation was dominant -- requiring inheritance from only a single parent -- and disproved the previous theory that it was recessive and had to be inherited from both parents. One of the most immediate applications of this discovery will be the availability of a simple, inexpensive blood test to confirm whether children with dystonia symptoms have this disorder rather than other diseases -- like cerebral palsy or early-onset Parkinson's disease -- that can appear similar. If future research discovers the triggers that set off dystonia in vulnerable individuals, identifying these carriers of the mutation could allow application of preventive treatments. Supporters of this research include the Dystonia Medical Research Foundation, the National Institute of Neurological Disorders and Stroke, the Jack Fasciana Fund for the Support of Dystonia Research, the Histadrut Foundation and the Bachmann-Strauss Dystonia and Parkinson Foundation at Mount Sinai. 
--------
438-> Cornell And Australian Scientists Clone The Gene Regulating Stem Growth In Pea Plants
ITHACA, N.Y. -- Plant scientists from Cornell University and the University of Tasmania, Australia, have successfully cloned one of history's first-studied genes -- the gene for stem growth in peas, according to a report in the latest issue of journal The Plant Cell, which was published today. Cloning the gene gives scientists a new way to account for why some plants are tall and some are short. "This is one of the most important genes in history as it illustrates the principles of genetics," said Peter Davies, Cornell professor of plant physiology, who worked on this research during a recent sabbatical in Australia. In a monastery more than 130 years ago, in what is now the Czech Republic, Augustinian monk Gregor Mendel selected seven distinct characteristics of pea plants and traced how those characteristics were passed through generations. One of the principal traits on which he worked was stem length, the primary determinant of plant height. The plant scientists working at the University of Tasmania, Hobart, Australia, isolated, cloned and obtained the DNA sequence of Mendel's historic tallness gene, and showed that it codes for gibberellin 3-beta-hydroxylase, a biosynthetic enzyme crucial to the division and elongation of the cells in the plant's stem. Researchers Diane R. Lester, a molecular biologist; John J. Ross, a plant physiologist and James B. Reid, professor of genetics, all at the University of Tasmania, and Davies, will publish "Mendel's Stem Length Gene (Le) Encodes a Gibberellin 3b-Hydroxylase" in the August issue (Vol. 9, published August 26, 1997) of The Plant Cell, the journal of the American Society of Plant Physiologists. In 1984, the Tasmanian group demonstrated that tallness in pea plants is regulated by an acid called gibberellin, or GA1, with promotes stem growth. Gibberellic acid had been discovered in the 1950s, but it was not until the early 1980s that the group connected it to stem height. Now, the researchers have demonstrated that in the tall pea plants used by Mendel, the tallness gene codes for an enzyme that adds a hydroxyl (HO) group at a very particular location onto GA20, which is the is the immediate precursor of GA1. In the dwarf plants there is a change of one base in the DNA sequence, which leads to a change of one amino acid in the resulting protein. In turn, this results in an enzyme that is still active in converting GA20 into GA1, but at 1/20th the rate. Therefore, dwarf peas are less efficient at synthesizing the gibberellic acid responsible for promoting stem growth. The plant becomes growth deficient. Gregor Mendel (1822-1884), the father of genetics, conducted experiments on the hybridization of plants, particularly peas. The results of his research were included in two lectures delivered in 1865 to the Natural History Society of BrŸnn, Davies said. Subsequently, Mendel published a long paper in an 1866 issue of the Proceedings of the Natural History Society. Mendel's description of units of heredity, the formulation of the Laws of Segregation and Independent Assortment, and his coining of the concepts of dominant, recessive, and discrete factors -- later called genes -- remain the foundations of genetics today. Little attention was drawn to Mendel's work in his own lifetime, Davies said. At the turn of the century, the Royal Horticultural Society of Great Britain commissioned an English translation from German of Mendel's work, and it was published in 1901. News of the findings spread. His work was highlighted at the International Conference on Plant Breeding and Hybridization, which met in New York City in 1902. Davies said a review of the conference showed that many plant breeders had never heard of Mendel or his experiments. They were excited by the "new" findings and soon put theory into practice. From these humble beginnings, genetics and later molecular biology, evolved. "Mendel's experiments are now included in every high school biology class," said Davies. 
--------
439-> Trojan Horse Virus Controls HIV Infection
National Institute of Allergy and Infectious Diseases (NIAID)grantees at Yale University have converted a common livestock virusinto a Trojan horse that selectively targets HIV-infected cells and thendestroys them.  As reported Sept. 5 in the journal Cell, this strategyeffectively controlled HIV infection in laboratory-grown T cells anddramatically reduced infectious HIV to levels that were barely or nolonger detectable. "This is a completely new approach, targeting a virus to aninfected cell," explains the study's senior scientist, John K. Rose,Ph.D., from Yale's Departments of Pathology and Cell Biology.  "Theconcept could be used to develop a whole new class of agents thatare useful for controlling disease." "Although additional in vitro and animal studies need to be performed before this novel virus can be tested in humans," comments NIAID Director Anthony S. Fauci, M.D., "this concept of cell-targeted delivery has enormous potential applications for HIV, cancer or other diseases." In their report, Dr. Rose, Matthias J. Schnell, Ph.D., and theircolleagues describe how they modified the vesicular stomatitis virus(VSV) genome, deleting its envelope gene and replacing it with thegenes for a pair of cell surface receptor -- CD4 and the coreceptor CXCR4 -- normally found on human T cells.  These receptors enableHIV to attach to, enter and infect T cells. These receptors also permit cell-to-cell HIV infection to occur. HIV-infected cells flag themselves for destruction by the body'simmune system by displaying HIV's outer coat protein.  But thisprotein, HIV gp120, is the same one that attaches to the T-cellreceptors and leads to infection.  Cell-to-cell infection occurs whenthe HIV gp120 on an infected cell first hitches up to the receptors onan uninfected T cell, resulting in the fusion of the cell and viralmembranes, and transfer of virus from the infected to the uninfectedcell. Turning around what occurs naturally, the remodeled shell ofVSV -- which now looks like an uninfected T cell -- tricks HIV-infected cells into fusing with it instead.  This enables VSV, which easily kills cells, to gain entry into the HIV-infected cell and destroy it.  The modified VSV cannot infect normal cells because it lacks its normal surface protein.  Thus, it targets, enters, multiplies in and kills only Tcells that, through the display of HIV gp120, signal that they are infected. In their experiments, the Yale team infected human T cell lineswith a laboratory strain of HIV.  To these cells lines -- in which abouthalf of the cells were now HIV-infected -- they added the novel VSV ateither three or five days postinfection.  This ultimately slashedinfectious HIV to extremely low or undetectable levels, at least 300-fold to10 thousand-fold lower than the levels of HIV produced incontrol cells. "Until there are data from animal models," Dr. Rose cautions,"we cannot gauge how well the potential treatment might work inpeople."  But he regards it as "likely to be safe," and would like to seethe concept tested in human clinical trials as soon as possible.  Suchdiscussions are already under way, but Dr. Rose estimates thepossibility is at least a year away and that trials in animal models area necessary first step. The report says the novel VSV described would be mostappropriate for limiting HIV production in people with late-stagedisease, but the Yale team has moved on to develop VSV constructsthat incorporate other HIV coreceptors such as CCR5 and CCR3 inan attempt to affect HIV strains that target macrophages and typicallypredominate in early HIV infection. The virus involved, VSV, causes vesicular stomatitis, adisease mainly of cattle, horses and pigs that causes blister-likebumps on the hoofs and tongue.  Nearly all animals recovercompletely from the illness. Occasionally, people become infected with VSV through closecontact with infected livestock or via laboratory exposure.  Manypeople with VSV have no symptoms, and those who become illusually have a mild, limited flu-like disease.  No human deaths linkedto VSV infection have been reported. The modified VSV is defective because it no longer has itsnormal coat protein.  Therefore, it can not enter normal cells andcause infection in livestock or humans. In their paper, the authors note several positive features oftheir system.  For example, levels of the novel VSV would beexpected to decline as HIV declines, since the VSV only targets andmultiples in HIV-infected cells.  Moreover, resistance to the novel VSVwould not be expected to develop, because that "would require loss of HIV's ability to bind CD4 or [the] coreceptor and would therefore not be selected," the authors write. Nava Sarver, Ph.D., chief of the targeted interventions branchin NIAID's Division of AIDS says, "This is a very exciting advance. We are getting closer to solving one of the major problems in targeteddelivery of genes to specific cells for treatment and possibly diseaseprevention: specifically, how to deliver what you want to the cell youwant it to go to." Currently, most gene delivery is done by removing certaincells from the body, modifying and then growing more of them, and,finally, reintroducing them back into the body.  "This is a very labor-intensive, time-consuming task," says Dr. Sarver.  In addition, there'sa tremendous dilution effect because the amount of cells reintroducedis very small. She adds, "The Yale group has crossed a major hurdle thatmay allow direct, in vivo delivery of a vector that can find its destinedtarget in the body.  There should be no need for ex-vivo manipulationof cells."  She envisions many potential applications of this research. Surface-modified live vectors like VSV could be used to shuttle intothe body viruses or toxins to destroy infected or cancerous cells, ortherapeutic genes to protect uninfected cells against an invadingvirus.  Moreover, such vectors could be used as novel vaccines todeliver antigenic genes to antigen-presenting cells, such as dendriticcells, for mounting immune protection against an invading pathogensuch as HIV. NIAID, a component of the National Institutes of Health (NIH),supports research on AIDS, malaria and other infectious diseases, aswell as allergies and asthma.  NIH is an agency of the U.S.Department of Health and Human Services.                                              ###Press releases, fact sheets and other NIAID-related materials areavailable on the Internet via the NIAID home page athttp://www.niaid.nih.gov. Reference:Schnell MJ, Johnson JE, Buonocore L and Rose JK.  Construction ofa novel virus that targets HIV-1-infected cells and controls HIV-1infection.  Cell 1997;90(5):849-8 
--------
440-> Patients Benefit From University Of Florida Epilepsy Research Leading To FDA Approval Of Vagus Nerve Stimulator
By Melanie Fridl Ross Shands Public Relations GAINESVILLE, Fla.---The road to independence has been a long one for Carolyn Short. The 43-year-old Palm Springs resident now pilots a 1997 light green Saturn, but for years she relied on others to transport her around town, because the epileptic seizures that wracked her body daily prevented her from driving herself. Her freedom came in the form of a small pacemaker-like device known as the vagus nerve stimulator, which just last month received federal Food and Drug Administration approval. The stimulator interrupts epileptic seizures by sending an electrical stimulus to the brain and is used to treat patients who aren't helped by anticonvulsant medications. Researchers at the University of Florida and Gainesville Veterans Affairs Medical Center were among the first to study the device in patients at Shands Hospital at UF and at the VAMC, tracking its effectiveness and safety since 1989. In many patients, the number of seizures has decreased with the treatment, says Dr. Basim Uthman, a neurologist at the UF Brain Institute and Gainesville's Veterans Affairs Medical Center. Other patients may have significant reductions in both the intensity and duration of seizures, and report the vagus nerve stimulator helps them "snap out" of a seizure faster, Uthman said. Short had small seizures from the time she was a baby, but when she entered her 20s she started having up to 15 convulsions a day -- many of them classified as grand mal, which caused her to lose consciousness. "My life changed because I had to be dependent on people. I always hated asking for rides," Short recalled. "I didn't have my parents take me a lot of places because I didn't want to bother them." In 1990 she received the vagus stimulator. The device, about the size of a stopwatch, is inserted through a small incision under the skin of the chest and is programmed to emit timed electrical impulses through wires that tunnel to the left side of the neck, then spiral around the vagus nerve. The operation takes up to two hours and is done on an outpatient basis, said Uthman, associate chief of the VAMC neurology service, director of the VAMC's clinical neurophysiology lab and associate professor of neurology at UF. "Right away my seizures weren't as severe as before, they stopped faster and I felt better afterward," Short said. During the first several years after Short received the implant, physicians adjusted how frequently the device fired and switched her medication. She has now been seizure-free for more than two years. Called the "wandering nerve," the vagus is the longest of 12 cranial nerves and sends messages to many organs, including the heart, lung and stomach. This nerve also communicates with a portion of the brain stem linked to regions thought to be involved in certain epileptic seizures. Vagus nerve stimulation appears to work by calming "hyperexcited" nerve cells and reverting brain activity to its normal pattern. It also may enhance the release of chemical building blocks that bolster cellular membranes in the central nervous system, adding stability to neurons and making them less excitable. Because seizures occur unpredictably, physicians program the device to fire every few minutes and hope the impulses will hit just as a seizure starts. The impulses also may interfere with some events that lead to a seizure and thus prevent it from happening. Patients also can trigger the device with a magnet if they sense a seizure is imminent. Patients with the implants, who remain on antiseizure medications, may notice their voice vibrate or detect a mild tingling in their necks during stimulation. They also may cough during stimulation for a short time after they first receive the implant. The Epilepsy Foundation of America estimates about 2.5 million Americans have epilepsy. Of the nearly 150,000 people who develop the disorder each year, at least 10 to 20 percent suffer from uncontrolled seizures. Epilepsy is the world's second-most-prevalent neurological disorder, affecting an estimated 50 million people worldwide. Sherry Douglas, a 33-year-old substitute teacher from Live Oak, also has benefited from the device. Douglas had up to 10 seizures a month, some very strong. Since receiving the stimulator, she is down to two or three a month and has cut back on her medications. "I no longer have grand mal seizures and the seizures I do have are shorter and not as intense," said Douglas, whose epilepsy stems from a head injury she suffered while falling out of a bed when she was a baby. "So even though I know I might have a seizure I don't have that fear like I used to if I feel one coming on. "I'm on a lot less medicine and that was my goal," she added. "I'm real sensitive to medications -- they would make me sleepy and weak. The vagal stimulator  doesn't have any side effects like that." ------------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html For Shands Hospital news releases, point your browser to http://www.shands.com/framehmpg.html
--------
441-> Hubble Reveals Huge Crater On The Surface Of The Asteroid Vesta
Astronomers have used NASA's Hubble Space Telescope to discover a giant impact crater on the asteroid 4 Vesta.  The crater is a link in a chain of events thought responsible for forming a distinctive class of tiny asteroids as well as some meteorites that have reached the Earth. The giant crater is 285 miles across, which is nearly equal to Vesta's 330 mile diameter.  If Earth had a crater of proportional size, it would fill the Pacific Ocean basin.  Astronomers had predicted the existence of one or more large craters, reasoning that if Vesta is the true "parent body" of some smaller asteroids, then it should have the wound of a major impact that was catastrophic enough to knock off big chunks.  The observations are described in the Sept. 5 issue of Science Magazine. "In hindsight we should have expected finding such a large crater on Vesta," says Peter Thomas of Cornell University, Ithaca, NY.  "But it's still a surprise when it's staring you in the face."  Another surprising finding is that such a large crater, relative to Vesta's size, might have been expected to cause more damage to the rest of the minor planet. "This is a unique opportunity to study the effects of a large impact on a small object," says Michael Gaffey of Rensselaer Polytechnic Institute, Troy, NY.  "This suggests that more asteroids from the early days of the solar system may still be intact." The collision gouged out one percent of the asteroid's volume, blasting over one-half million cubic miles of rock into space.  This tore out an eight-mile deep hole that may go almost all the way through the crust to expose the asteroid's mantle (Vesta is large enough to be differentiated like Earth -- with a volcanic crust, core and mantle, making it a sort of "mini-planet".) Because of the asteroid's small diameter and low gravity, the crater resembles smaller craters on the Moon that have a distinctive central peak.  Towering eight miles, this cone-shaped feature formed when molten rock "sloshed" back to the bullseye center after the impact. One clue for a giant crater came in 1994 when Hubble pictures showed that one side of Vesta's football shape appeared flattened.  "We knew then there was something on Vesta that was unusual," says Thomas. The astronomers had to wait for a better view from Hubble when Vesta made its closest approach to Earth in a decade, in May 1996, when the asteroid was 110 million miles away. A total of 78 Wide Field Planetary Camera 2 pictures were taken.  The team then created a topographic model of the asteroid's surface by noting surface irregularities along the limb and at the terminator (day/night boundary) where shadows are enhanced by the low Sun angle. The immense crater lies near the asteroid's south pole.  This is probably more than coincidental, say researchers.  The excavation of so much material from one side of the asteroid would have shifted its rotation axis so that it settled with the crater near one pole. Unlike some other large asteroids that have jumbled surfaces due to the asteroids' breakup and recollapse, the rest of Vesta's surface is largely intact, despite the cataclysm.  This is based on previous measurements showing it has a surface of basaltic rock -- frozen lava -- which oozed out of the asteroid's presumably hot interior shortly after its formation 4.5 billion years ago, and has remained largely intact ever since. Approximately six percent of the meteorites that fall to Earth are similar to Vesta's mineralogical signature, as indicated by their spectral characteristics.  Vesta's spectrum is unique among all the larger asteroids.  The crater may be the ultimate source of many of these meteorites. Most meteorites are believed to come from other asteroids, but their specific objects of origin cannot be determined in most cases.  Thus the distinctive mineralogical makeup of these meteorites means that Vesta is the only world other than the Earth, the Moon and Mars, for which scientists have samples of specifically known origin. A mystery has been that the meteorites could not have traveled directly from Vesta because at Vesta's location in the asteroid belt, there are no perturbing gravitational forces that would cause pieces to fall into orbits intersecting the inner planets like apples shaken out of a tree.  However, Vesta's "daughter" asteroids  -- literally "chips off the block" which have color characteristics similar to Vesta -- are near a "chaotic zone" in the asteroid belt where Jupiter's gravitational tug can redirect fragments into orbits that intersect Earth's orbit. A good determination of the shape of Vesta was necessary for the next step in interpretation, which will use multi-color images of Vesta obtained with Hubble to study the detailed mineralogy of surface regions, including the region of the giant crater.  Also, a team led by Don McCarthy of the University of Arizona plans to obtain additional images of Vesta at longer wavelengths this fall using the new Near Infrared and Multi-Object Spectrometer science instrument onboard Hubble. Members of the Vesta research team are Principal Investigator Ben Zellner of Georgia Southern University; the Co-Investigators are Richard Binzel, MIT; Michael Gaffey, Rensselaer Polytechnic Institute; Alex Storrs, Space Telescope Science Institute; Peter Thomas, Cornell University, and Dr. Ed Wells, Computer Sciences Corporation. The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc., for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency. -end- EDITOR'S NOTE:  An image to accompany this release is available to news media representatives by calling the Headquarters Imaging Branch at 202/358-1900.  Photo number is: Color:  97-HC-616 Image files in GIF and JPEG format and captions may be accessed on the Internet via anonymous ftp from oposite.stsci.edu in /pubinfo. GIF                    JPEGPRC97-27       Vesta   gif/vesta3.gif         jpeg/vesta3.jpg Higher resolution digital versions (300 dpi JPEG) of the release photograph are available in /pubinfo/hrtemp: 97-27.jpg (color) and 97-27bw.jpg (black & white). GIF and JPEG images, captions and press release text are available via the World Wide Web at:http://oposite.stsci.edu/pubinfo/PR/97/27.html and via links in http://oposite.stsci.edu/pubinfo/Latest.html    orhttp://oposite.stsci.edu/pubinfo/Pictures.html.
--------
442-> Nitric Oxide Gas May Treat, Prevent Sickle Cell Crisis
A study by researchers at the Massachusetts General Hospital (MGH) and other Boston hospitals suggests that inhaled nitric oxide gas might successfully treat sickle cell disease and its characteristic episodes of debilitating pain, called sickle cell crisis. Described in a report in the September Journal of Clinical Investigation, the new approach would be the first to attack directly the abnormal "sickle" hemoglobin that causes sickle cell crisis, a condition that currently can be treated only with pain-killing drugs. If follow-up studies prove successful, patients might someday treat or prevent sickle cell crisis symptoms by self-administering nitric oxide with inhalers similar to those used by asthma patients. "The effect of inhaled nitric oxide on sickle hemoglobin is totally separate from its effects in the lungs, which have proven life-saving for people with several critical illnesses," says C. Alvin Head, MD, the MGH anesthesiologist who led the study. "This is a totally new application of this molecule, which has generated a lot of interest over the past several years." Study co-author Kenneth Bridges, MD, director of the Joint Center for Sickle Cell and Thalassemic Disorders at Brigham and Women's Hospital and the MGH, adds, "This discovery gives us two things: a possible means of interrupting sickle cell crisis once it's started -- something we don't have right now -- and a real possibility for long-term, outpatient treatment." In sickle cell disease, a genetic disorder, affected individuals have an abnormal form of hemoglobin, the protein in red blood cells that carries oxygen from the lungs to tissues and organs throughout the body. After this abnormal hemoglobin releases its oxygen, it clumps together into an abnormal shape, deforming the red blood cells -- normally flexible discs -- into rigid, elongated "sickle cells." These sickle cells can become stuck in tiny blood vessels, blocking blood flow to various parts of the body. The result is sickle cell crisis, excruciating pain in the affected area that can require hospitalization in the most serious cases. The current report describes how nitric oxide causes sickle hemoglobin molecules to bind oxygen with greater affinity, which should reduce formation of the sickle cells. The result was seen both in laboratory studies and in several volunteer patients with sickle cell disease who breathed low concentrations of nitric oxide. The common gas nitric oxide -- not to be confused with the anesthetic nitrous oxide -- plays many roles in the body, including relaxation of blood vessels. Researchers at the Massachusetts General Hospital (MGH) Department of Anesthesia and Critical Care pioneered the study of nitric oxide by inhalation and have shown that it can effectively treat several life-threatening lung conditions. The gas has been successful in expanding constricted blood vessels in the lung without effecting the rest of the body's circulatory system. The effect is limited to the lungs because the gas binds with hemoglobin upon entering the bloodstream, neutralizing its vessel-expanding properties. Head explains, "Our researchers who looked at how nitric oxide binds to hemoglobin found that it had no effect on normal hemoglobin. But I started to wonder if there might be any effect on abnormal hemoglobin -- particularly in sickle cell disease." To pursue this question, Head entered into a collaboration with several local sickle cell specialists, including Carlo Brugnara, MD, of Children's Hospital and Bridges, as well as MGH investigators specializing in nitric oxide research. They first added low concentrations of nitric oxide -- similar to those used therapeutically -- to normal red blood cells and those from sickle cell disease patients. They found that the gas, while having no effect on the normal blood cells, caused the sickle hemoglobin to hold on to oxygen more avidly than it usually would. They then took blood samples from nine volunteer patients with sickle cell disease and three normal volunteers before and after the volunteers inhaled low levels of nitric oxide in air for 45 minutes. In eight of the nine sickle cell disease patients, breathing nitric oxide caused their red cells to give up oxygen less readily than before, while the cells from the normal patients showed no change. The increased oxygen retention by the sickle cell patients' red cells persisted for a least an hour after they breathed the nitric oxide gas. Co-author Brugnara, director of the hematology lab in the Department of Laboratory Medicine at Children's, has conducted research into sickle cell treatment approaches designed to keep the blood cells from dehydrating. He says, "Dr. Head's very novel idea of applying this interesting molecule to sickle cell disease may turn into one of the most significant treatment developments of this decade." Additional co-authors of the paper include Warren M. Zapol, MD, senior author and chief of the MGH Department of Anesthesia and Critical Care; Ricardo Martinez-Ruiz, MD, Robert Kacmarek, RRT, David Kuter, MD, and Kenneth Bloch, MD, all of the MGH. The next step the researchers will undertake is a multi-center, randomized double-blind study to determine whether nitric oxide inhalation acutally can decrease symptoms in patients experiencing sickle cell crisis. The earliest stages of such a study have just begin, based at the MGH. 
--------
443-> E. Coli Genome Reported: Milestone Of Modern Biology Emerges From Wisconsin Lab
MADISON - A team of scientists headed by Frederick R. Blattner of the E. coli Genome Project in the Laboratory of Genetics at the University of Wisconsin-Madison has determined the complete genome sequence of the E. coli bacterium, it was reported today (Sept. 5) in the journal Science. A genome is the sum total of the genes of an organism. Genes are encoded in the sequence of chemical base pairs that make up the intertwining strands of DNA. In the case of E. coli, a total of 4,403 genes have been identified in the 4,639,221 base pairs of DNA sequenced by the Wisconsin team. Of these, one-third are of completely unknown function. E. coli holds a unique place in modern biology. It is arguably the single most studied cell in all of science. Humans have about 25 times as many genes as E. coli, but in the future a similar complete analysis will be possible for human DNA. For this reason E. coli is considered a model organism in the Human Genome Initiative of the National Institutes of Health (NIH). For more than 70 years, Escherichia coli has been a mainstay of basic biology, and recent developments in biotechnology and genetic engineering have depended heavily on it. Related strains of E. coli are also responsible for several human diseases. Although not the first bacterial genome to be completed, E. coli is by far the most complex and the most eagerly awaited by scientists around the world. "Determination of the complete inventory of the genes of organisms is one of the holy grails of biology, analogous to development of the periodic table of the elements in chemistry," said Blattner. "Once they are all known and relationships between them become evident, a classification system for understanding the basic functions of life can be erected." E. coli's natural habitat is the lower intestinal tract of animals, including humans. Originally isolated in 1922 from a convalescent diphtheria patient, the strain of E. coli sequenced by Blattner's team rose to prominence as an experimental organism in 1945 when it was used in the discovery of spontaneous gene transfer or bacterial sex. As a result, the strain, known as K-12, was universally adopted for fundamental work in biochemistry, genetics and physiology. In recent years, it has become the workhorse of biotechnology and is used as a living factory to produce human insulin and other medicines. The most important result of the work reported today is the sequence itself, said Blattner. In January, the data were made freely available through on-line databases such as GenBank to scientists worldwide. The E. coli genome is a huge one, and required an additional nine months to describe in detail in Science. With more than 4.6 million bases, it is two or three times bigger than other bacteria sequenced to date. Sequencing of the base pairs that make up DNA is analogous to deciphering a language. It is done with the aid of specialized chemical analysis machines, but can only be accomplished with considerable human effort. More than 269 people - including many undergraduates getting their first taste of science - participated in the project at the UW-Madison. The individual chemical bases that make up the genome correspond to the letters of the genetic alphabet which, grouped into words and paragraphs corresponding to genes, are read by the living cell as the instructions for assembly and function of all of life's processes. Knowledge of the genetic code, a major effort of modern biology, permits the scientist to translate the instructions for the purpose of understanding life processes, Blattner said. Knowing the precise order of the chemical base pairs for an entire genome allows the encoded life program to be read in its entirety leading, in principle, to a very complete level of understanding of physiological processes. The report published in this issue of Science is a global analysis of the data collected by Blattner's team in collaboration with Monica A. Riley of the Marine Biological Laboratories in Woods Hole, Mass., and Julio Collado-Vides of the University of Mexico at Cuernavaca. The report, first and foremost, represents a record of the genes that make up the genome of the organism, and the establishment, where possible, of their functions. A surprising number of the genes, Blattner said, are new. The work also details the similarity between every gene of E. coli and every gene of every other completely sequenced organism. The comparison, according to Blattner, shows that some genes appear commonly throughout nature while others are unique to E. coli. Such information is essential to any understanding of how E. coli and other bacteria have evolved, and what genes are required at a minimum to create life. In addition to the base order of the chemical building blocks that make up the E. coli genome, and a better sense of its evolution and relationship to other organisms, the work of Blattner's team has yielded a lode of new information about the organization of E. coli genes and how the information stored there is distributed. It was noticed, too, that some of the DNA may have been added within the recent evolutionary history of the microbe. This immigrant DNA, said Blattner, is seemingly related to the genes of bacteria that cause disease, fueling speculation that the K-12 strain of E. coli has relics of a pathogenic past or, alternatively, is a pathogen waiting to happen. The E. coli strain used in the Wisconsin study does not cause disease, but related strains are toxic and have been implicated in an increasing number of human food poisonings from products ranging from ground beef to unpasteurized apple juice to fecally contaminated lettuce. With the K-12 E. coli genome in hand, Blattner said it will soon be possible to make a gene by gene comparison with its pathogenic relatives and illuminate genes that govern the toxic nature of the bacteria. The sequencing of the E. coli genome, said Blattner, was a necessary precursor to the sequencing of the human genome, now underway as part of the Human Genome Project under the direction of the National Human Genome Research Institute (NHGRI) of NIH. When scientists achieve this monumental goal, they will begin the daunting task of reading and understanding all of our protein-coding genes. They will accomplish this task, in part, by searching databases to find conserved biological motifs, first elucidated using simple model organisms like bacteria, yeast, worms and flies. By decoding the human genome, scientists can begin to decipher the genetic aspects of all disease, leading to improved treatments and even cures. The NHGRI, a component of NIH, is a major partner in the Human Genome Project, the international research effort to map the estimated 50,000 to 100,000 genes and to read the complete set of genetic instructions encoded in human DNA. NHGRI also supports research on the application of genome technologies to the study of inherited disease, as well as the ethical, legal and social implications of this research. While primary funding for E. coli work came from the NHGRI, critical equipment was provided by the Division of Research Resources of the NIH. Substantial remodeling funds were provided to create the E. coli Genome Center by the WISTAR program of the State of Wisconsin, and research support was also provided by Genome Therapeutics Inc., SmithKline Beecham Inc., Dnastar Inc., and IBM.
--------
444-> Getting The Lead Out -- Lead Concentrations In Lakes And Reservoirs Decline But Not Yet Back To Starting Gate
Lead concentrations in the sediments of several selected lakes andreservoirs across the country have declined significantly in the lastdecade or more, but are not yet back to the baseline levels of the 1950'sand 60's, according to a new U.S. Geological Survey (USGS) report. USGS scientists said the declines occurred despite significantincreases in both the population and the number of motor vehicles driven inthe urban drainage basins studied.  Although lead concentrations in thesediments declined as much as 70 percent since the 1970's and 80's, theyremain almost twice as high as the baseline levels of the 1950's and 60's.The article, "Reservoir Sediment Cores Show U.S. Lead Declines," by EdwardCallender and Peter Van Metre, which is published in the September issue ofEnvironmental Science and Technology, shows results of the study. "We purposely picked lakes and reservoirs that were under urbanpressure and likely to be affected by lead contamination," said RobertHirsch, USGS Chief Hydrologist.  "The significant declines in lead in theseurban lakes are very encouraging.  These declines are a good indicationthat the switch to unleaded gasoline in the late 1970's, coupled withenactment of the Clean Air Act, have produced a positive effect on theNation's water resources." Previous studies by the USGS show a significant downward trend inlead concentrations in the Nation's streams. The newest sediment studiesare particularly important because lake and reservoir sediments tend to belong-term "traps" that accumulate sediment and associated heavy-metalcontaminants, such as lead.  Lead in sediment accumulations can becomesources of future water pollution. The lake and reservoir study is part of the national synthesis effortof the USGS National Water Quality Assessment Program (NAWQA), which is thefirst comprehensive, ongoing study of trends in the quality of the Nation'ssurface- and ground-water resources. Hydrologists used gravity-type coring devices and "grab box cores" tocollect samples of the sediments at the bottom of the lakes and reservoirs.>From these samples, scientists can discern a "signature" of the quality ofthe water in the lake or reservoir and its drainage basinover time.  Because lakes and reservoirs efficiently trap sediments fromrivers and streams, the accumulated sediments can provide a valuablehistorical record of what has been happening regarding the presence of leadin a particular drainage basin.  Heavy metals like lead, for example, tendto accumulate in sediment.  Scientists can look at the lead concentrationsin the core and determine the time frame when leaded gasoline was beingused in the basin.  Looking at lead concentrations in the older depositedsediments in the core is like moving backward in time to see if there hasbeen a change in the percent of lead present in sediments deposited in morerecent times.  Radiochemical dating was used to determine the timerepresented by specific points along the length of the core. Additional sediment sampling of Lake Anne and Lake Fairfax in Reston,Virginia, and urban-suburban lakes in Minnesota, Colorado, and New Jerseyis planned to look at other contaminants and the effects of urbanization onthe chemistry of sediments in lakes and reservoirs.  Significant componentsof the NAWQA Program include consistent methods for sampling and the useof complex "clean" sampling protocols that ensure thevalidity and integrityof the data. As the Nation's largest water and earth science research andinformation agency, the USGS routinely monitors the quality and quantity ofsurface- and ground-water resources at more than 50,000 sites across thecountry in cooperation with more than 1,200 State, local and other Federalagencies. Visit the USGS at http://www.usgs.gov/ on the World Wide Web.
--------
445-> Electric Utility Deregulation Could Prompt 'Unimagined Innovation' And 'Corner-Store Competition,' Cornell Economist Predicts
ITHACA, N.Y. -- Twenty years ago, when the Public Utility Regulatory PolicyAct (PURPA) was written and large central-station steam-turbine facilitieswere the best way to generate electricity, no one expected thetechnological development of the small-scale, super-efficient,combined-cycle gas turbines that independent power producers and manyutilities use today. Now that deregulation is increasing competition in the power generationpart of the electric utility industry and is beginning to offer consumers achoice through their local distribution companies, innovation lightningcould strike again, a Cornell University economist and engineer predicts.New technologies, new materials and a renewed notion of public service,according to Richard E. Schuler, could give consumers "corner store access"to competitive electricity, communications, entertainment and informationservices -- all in one super cable. Schuler, who is a Cornell professor of economics and of civil andenvironmental engineering  as well as the director of the Cornell Institutefor Public Affairs, made his prediction to the Institute of Electrical andElectronics Engineers (IEEE).  Speaking June 11 in Washington, D.C., to anIEEE Technology Policy Council symposium, Schuler envisioned "a far richervariety of business types and forms" and "a broader diversity of commercialand technological innovation" as electric utility deregulation reaches theconsumer interface. Unregulated competition for utility customers is nothing new, notedSchuler, who served as a member of the New York State Public ServiceCommission from 1981 to 1983.  There were once 373 independent electricsystems in New York state -- and eight separate electric utilities servingNew York City -- many vying for each other's customers at their serviceborders, he recalled.  But technological advances in generation andelectric transmission equipment allowed the amalgamation of small entitiesinto the mega-systems that may one again be realigned in response tocompetition. "It is the unimagined innovations that offer the greatest potential socialrewards from a transition to markets," Schuler told the IEEE councilsymposium.  "One hint of possible opportunities is the unforeseentechnological response in the U.S. to the enactment of PURPA.  By providingmanufacturers with a steady market for small combustion turbines, atechnology that had been on the drawing board for over 50 years, thecombined-cycle gas turbine was brought to commercial fruition.  The resulttoday is a generating technology with lower capital costs and greaterthermal efficiencies than the state-of-the-art, large central station steamturbine facility of 20 years ago." Schuler said he dreads as much as the next consumer the annoyingdinner-time calls from telemarketers trying to get him to switch hiselectricity supplier.  Yet the "local wires" level of utilities may be theplace to watch for unimagined innovation, Schuler said.  If individuallocal  telephone, cable television, electricity and Internet accesscompanies were allowed to package and sell all once-separated services,perhaps scale economies would lower the cost of maintenance, metering andbilling, he suggested. While this new local super-monopoly might remain regulated, it would act asa "corner store" offering consumers a wide competitive array ofcommunication, information and energy services.  This new institution couldprompt development of new materials that combine conductors for all theseservices in one multi-talented line, Schuler predicted.  And of course, newmaterials will require new methods for installing and maintaining all thatconduit, but the economist-engineer isn't going too far out on the limb. "Under a competitive scenario, it is important to resist predictions aboutthe future shape of the delivery systems," he said.  "Competition leads totechnological innovations in very unpredictable ways." -30- EDITORS:  Prof. Schuler's report to the IEEE council, "DeregulatingElectricity Markets:  Why are We Pulling the Plug? How And for Whom?" isavailable from the Cornell News Service at (607) 255-9736  or 
--------
446-> Cassini To Survey Worlds Of Saturn And Titan; Sends First Probe To Moon Of Another Planet
The planet Saturn, its famous icy rings, and its enigmatic moon, Titan, are the prime scientific targets of the international Cassini mission, the most ambitious and far-reaching planetary exploration ever mounted.  Final preparation of Cassini is now underway for a launch from Cape Canaveral, FL, in October 1997. The mission marks the first time a space probe has attempted to land on the moon of another planet, providing the first direct sampling of the Earth-like atmosphere of Titan and the first detailed pictures of its previously hidden surface.  Titan is Saturn's largest moon, nearly the size of Mars and bigger than either Mercury or Pluto. Cassini, in development since October 1989, is a cooperative endeavor of NASA, the European Space Agency (ESA) and the Italian Space Agency, or Agenzia Spaziale Italiana.  The mission will send a sophisticated robotic spacecraft equipped with 12 scientific experiments to orbit Saturn for a four-year period and study the Saturnian system in detail.  The ESA-built Huygens probe that will parachute into Titan's thick atmosphere carries another six scientific instrument packages. "With its bright, complex rings, 18 known moons and magnetic environment, Saturn is a lot like a solar system in miniature form," said Dr. Wesley T. Huntress, NASA's associate administrator for space science.  "Saturn's family of rings and moons is a one-stop treasure trove, offering countless clues to the history of planetary and solar system evolution.  Cassini and the Huygens probe represent our best efforts yet in our ongoing exploration of the solar system." The launch period for Cassini's nearly seven-year journey to Saturnopens on Oct. 6 at 5:39 a.m. EDT and closes Nov. 15, 1997.  A U.S. Air ForceTitan IVB/Centaur launch system, the most powerful launch vehicle in the U.S. fleet, will loft Cassini onto the interplanetary trajectory that will deliver the spacecraft to Saturn almost seven years later on July 1, 2004.  Cassini's primary mission concludes in July 2008. Saturn is the second-largest planet in the solar system and is made up mostly of hydrogen and helium.  Its placid-looking, butterscotch-colored face masks a windswept atmosphere where jet streams blow at 1,100 miles per hour and swirling storms roil just beneath the cloud tops.  Spacecraft passing by Saturn found a huge and complex magnetic environment, called a magnetosphere, where trapped protons and electrons interact with each other, the planet, rings, and surfaces of many of the moons. Saturn's best known feature -- its bright rings -- consists not just of a few rings but of hundreds of rings and ringlets broad and thin, composed of ice and rock particles ranging in size from grains of sand to boxcars.  "Shepherd moons" found orbiting near the edges of some of the rings gravitationally herd in ring particles that would otherwise spread out into deep space. Although it is believed to be too cold to support life, haze-covered Titan is thought to hold clues to how the primitive Earth evolved into a life-bearing planet.  It has an Earth-like, nitrogen-based atmosphere and a surface that many scientists believe probably features chilled lakes of ethane and methane.  Scientists believe that Titan's surface is probably coated with the residue of a sticky brown organic rain. On Nov. 6, 2005, Huygens will descend by parachute into Titan's sky, providing our first direct sampling of Titan's atmosphere and the first detailed photos of its hidden surface. The Cassini spacecraft is the most complex interplanetary spacecraft ever built.  Because of Cassini's challenging mission, the long distance Cassini must travel, and the value of its scientific return, each component and the system as a whole has undergone an unprecedented program of rigorous testing for quality and performance. "Every phase of the mission has been reviewed and validated internally and externally by NASA and independent experts," said Huntress. Because of the very dim sunlight at Saturn's orbit, Cassini could not conduct its mission to Saturn on solar power.  Electrical power is supplied to Cassini by a set of radioisotope thermoelectric generators (RTGs) which convert the heat from the natural decay of plutonium.  RTGs have been used on 23 previous U.S. missions.  Plutonium dioxide also is used in 117 radioisotope heater units placed on Cassini and Huygens to keep electronics systems at their operating temperatures.  These units were most recently used on the Mars Pathfinder mission's Sojourner rover to keep the system from failing during cold Martian nights. The mission is named for two 17th century astronomers:  Italian-French astronomer Jean-Dominique Cassini made several key discoveries about Saturn, and Dutch scientist Christian Huygens discovered Titan. Development of the Huygens probe was managed by an ESA team located at the European Space Technology and Research Center (ESTEC) in Noordwijk, The Netherlands.  The Cassini orbiter was designed, developed and assembled at NASA's Jet Propulsion Laboratory (JPL), located in Pasadena, CA.  JPL is a division of the California Institute of Technology.  The overall mission is managed by JPL for NASA's Office of Space Science, Washington, DC. -end-
--------
447-> One Chimp Can Perceive States Of Awareness In Others
CHICAGO -- A new study has shown that chimpanzees may be able to determine whether their partners know they are in danger. This suggests that these primates are able to decide how ignorant or informed their peers are about an unexpected situation. The finding, made by a team of researchers at Ohio State University's Comparative Cognition Project, suggests that chimps share with humans the ability to perceive the knowledge state of a peer, and perhaps the intention to protect that peer. Earlier experiments with both rhesus and Japanese macaque monkeys failed to show the same abilities in those animals. These new results strengthen the argument that in some ways, chimpanzees are closer to humans than they are to other primates. The studies were presented Aug. 16 in Chicago at the annual meeting of the American Psychological Association.Sally Boysen, associate professor of psychology at Ohio State and director of the project, said the fundamental question for the test was whether one chimpanzee could tell if another was ignorant of a specific situation, in this case, of a threat or a reward. Boysen and her colleagues tested three pairs of chimpanzees at the Ohio State colony. Two adult males, Kermit and Darrell, who had been together for 18 years, were tested, along with a pair of females, Sarah and Abagail, and a male and female -- Bobby and Sheba. For the tests, Boysen modeled both a treat and a threat to the chimps. She used grapes, a food the chimps highly desired, as the hidden treat. A member of the research group hiding with a tranquilizer dart was the threat. All of the animals in the study had previously been sedated by a dart or had seen a tranquilizer dart used, and saw it as a threat. In half of the test conditions, both animals in the pair were able to watch as either the grapes were hidden in the cage, or a researcher with the tranquilizer dart hid as a predator. For the rest of the experiments, one animal was placed in an adjoining cage with a clear view of the food or threat while the other animal was kept off in a nearby room. Boysen wanted to know if one animal would "tell" the other about the reward or threat. If they did, it would mean one animal would have to decide how well-informed the other was about a given situation. When she tested the animals with the hidden grapes, absolutely nothing happened. No information was exchanged between the two chimps. "You wouldn't expect it to work with the food since no chimpanzee is going to willingly inform another about the presence of food that they themselves don't have access to," she said. But when the grapes were replaced by the predator, the results changed dramatically. When Kermit was released into the cage area where the researcher was hidden out of sight behind a wall, Darrell became extremely agitated. He turned to Kermit displaying fear grimaces and alarm vocalizations -- two common warning gestures for chimpanzees. Darrell's hair also stood on end all over his body, which reflected his state of arousal. Kermit mirrored the same fear responses, turned and left the cage area before getting close to the hidden predator. "Based on what we believe about the emergence of these skills in humans," Boysen said, "this suggests that Darrell, in a sense, put himself in Kermit's place. I think Darrell was aware that Kermit couldn't have known that the predator was hidden in there." During the research all six animals ran through the same experiments and the results were always the same -- the chimps "told" their peers of the hidden predator. "This suggests that one chimp does recognize the different knowledge state in the other chimp," Boysen said. "Darrell didn't know what the predator was going to do so he had to make a prediction, a rapid assessment of the situation. He made the decision that there would be trouble if he didn't let Kermit know about the predator." Primatologists have long known that chimpanzees in the wild will give off warning calls when they see a potential threat. Boysen said that these were generalized warnings -- not specific ones. These experiments removed most of the variables that exist in the wild and tested if one chimp would warn another specific chimp of a threat. "They responded dramatically when a threat was present but only when the other animal in the pair was uninformed," Boysen said. Since the strongest reactions during the tests occurred with Kermit and Darrell, Boysen thinks that the social bond between two animals may be the key to their ability to warn each other. The stronger that bond, the greater the warnings the animals gave. Boysen's work is supported by grants from the National Institute of Mental Health.
--------
448-> New Land Mine Detectors Could Help Fulfill Princess Diana's Dream
Writer: Randolph Fillmorerfill@nervm.nerdc.ufl.edu Source: Alan Jacobs(352) 392-2549 GAINESVILLE, Fla. --- A revolutionary new land mine detection system, developed at the University of Florida originally for military use, is ready to be converted for a humanitarian effort to rid the world of leftover land mines lurking in former war areas. The system, which could be ready in early 1998, could play a part in fulfilling the dreams of the late Diana, Princess of Wales. In the months leading up to her death Sunday in a Paris car crash, Diana was deeply involved in ridding the world of land mines. It also could help define the agenda of concerned diplomats from around the world convening this week in Oslo, Norway, to hammer out an international treaty halting the production and sale of land mines. From Afghanistan to Bosnia, old-but-active land mines kill and maim an estimated 25,000 people -- mostly civilians -- annually. UF scientists hope to make the world safer, especially for children, who most often fall victim to the lurking artifacts of bygone wars. 	"Our immediate mission has shifted from military applications to humanitarian applications," said Alan Jacobs, a professor with UF's nuclear and radiological engineering department. "We plan to make a device immediately, with existing technology and equipment." To combat the threat from land mines, Jacobs, Associate Professor Edward Dugan and their research team have developed the technology to make a small, mobile land mine detector using an X-ray probe that not only locates land mines but accurately identifies them by type. A proposed partnership between UF and BioImaging Research of Chicago soon could put lateral migration backscatter radiography, the portable X-ray technology, on a small all- terrain vehicle. Within a year, it could be available to governments and humanitarian agencies around the world. Jacobs and his team developed the technology during the past few years for military use with funding from the U.S. Army. But the Army is eagerly awaiting the development of a much larger X-ray unit that can detect land mines in a 14-foot-wide swath at 5 mph. An X-ray generator that can do what the Army wants probably is feasible, Jacobs said, but not yet a reality. So, in the meantime, the researchers decided to see if the technology could be used to help clear the world's estimated 120 million active landmine in former war zones. "Most buried land mines are made of predominantly plastic and are impossible to detect accurately with current techniques," said Jacobs. The backscatter technique, said Jacobs, uses X-ray photons that bounce off the electrons of materials. Explosives and plastics bounce back more photons than soil does, and they scatter them more widely, which can create more accurate images of the mines. Rocks, wood, roots and other materials create very different images and cannot be confused with land mines. When Jacobs and his team recently employed real land mines in their tests rather than simulated land mines, even they were surprised with the results. "The backscatter technique is even more accurate than we'd thought," said Jacobs. "It's many times better than what we had before and uses low wattage to drive the X-ray machine. With sufficient funding, the backscatter detector could be on the job next year." A recent technology transfer grant from the Department of Defense to develop a more efficient unit unites Jacob's efforts at UF with Raton Technology Research of New Mexico and the Los Alamos National Laboratory. For the larger unit, RTR will provide an antenna that can quickly scan an area 100 square meters to locate land mines. Los Alamos will provide a detector that can determine the presence of explosives at the site of a mine image.		-30-
--------
449-> Researchers Discover First Animal Strain of Hepatitis E Virus
Scientists at the National Institute of Allergy and InfectiousDiseases (NIAID) in Bethesda, Md., have identified a strain ofhepatitis E virus in pigs that is very similar to the strain that causesdisease in humans.  However, there is no evidence that the pig viruscauses disease in either humans or pigs. The finding, published inthe Sept. 2, 1997 issue of the Proceedings of the National Academyof Sciences, should help advance studies of hepatitis E disease inhumans and eventually could lead to the development of a vaccine. "This is a very interesting finding that will open new avenuesof research, and contribute to strategies to treat or prevent hepatitis Edisease," says Robert H. Purcell, M.D., chief of the hepatitis virusessection in NIAID's Laboratory of Infectious Diseases (LID) and seniorauthor of the study.  "Unlike hepatitis A, B and C, hepatitis E diseasealmost never occurs in the United States.  However, epidemics of thedisease do occur periodically in developing nations in Africa andAsia." Hepatitis E virus is most commonly transmitted to peoplethrough contaminated drinking water in areas with poor sanitation. The disease generally affects young adults and usually is not life-threatening, except in pregnant women infected with the virus wherefatality rates of 15 to 20 percent have been reported. According to the Centers for Disease Control and Prevention(CDC), virtually all cases of acute hepatitis E in the United Stateshave occurred among travelers returning from areas where hepatitisE disease is endemic.  Nevertheless, recent studies have shown thatupwards of 20 percent of healthy people in this country -- even thosewho have not traveled abroad -- have antibodies to hepatitis E virusor related agents in their blood.  Similar evidence of exposure tohepatitis E virus or related agents also has been documented inprimates and swine. To explore the nature of these infections in pigs, Xiang-JinMeng, M.D., Ph.D., working with Dr. Purcell and their LID colleagueSuzanne U. Emerson, Ph.D., screened swine blood samples with anassay designed to detect antibodies to strains of human hepatitis Evirus.  Most of the samples, taken from swine herds in the MidwesternUnited States, tested positive for hepatitis E virus antibodies. In a separate analysis, piglets born to antibody-negative sowswere found to seroconvert (develop antibodies to hepatitis E virus)when raised in large pens with other  piglets.  None of the piglets,however, showed any clinical signs of disease after seroconversion. Using polymerase chain reaction (PCR) techniques, the LIDscientists isolated putative hepatitis E virus genetic material fromswine blood samples and compared its genetic sequence to that ofhuman hepatitis E virus.  They found that the swine virus was closelyrelated to, but distinct from, human strains of the virus. "At the amino acid level, the swine and human strains areabout 90 percent alike," explains Dr. Meng.  Amino acids are themolecules from which proteins are made.  "Among most humanstrains of hepatitis E virus, amino acid identity is between 97 and 99percent."  The researchers say their findings strongly suggest that apreviously unrecognized strain of hepatitis E virus circulates in theswine population. "It's important to remember that the virus strain isolated fromthe swine in this study is distinct from the strains known to causedisease in humans," explains Dr. Meng.  "Still, further studies areneeded to determine whether swine hepatitis E virus is species-specific or is circulating in the human population without causingdisease.  These subclinical infections of humans with swine hepatitisE virus might explain the relatively high prevalence of hepatitis Eantibodies in healthy individuals in the United States." If that were the case, says Dr. Meng, the strong immunologiccross-reactivity of the swine and human strains suggests that swinehepatitis E virus could prove useful as a vaccine against the humanvirus.  The similarities between the swine and human viruses alsosuggest that pigs might provide an alternative animal model forstudying hepatitis E virus infection.  Currently, scientists must useexpensive primate models to study the virus. "The possibility that swine hepatitis E virus may infect humansalso raises a public health concern regarding the use of pig organs inhuman transplantation," cautions Dr. Purcell.  "Nonpathogenic pigviruses could possibly become pathogenic in human transplantrecipients, particularly since transplant patients receive immune-suppressing drugs." Apart from these concerns, Dr. Purcell adds, there is noevidence that the pig virus poses any threat to healthy humans orpigs. "Swine hepatitis E virus is probably common throughout theworld," he says.  "Antibodies to hepatitis E or related agents havebeen found in healthy swine as well as in several other species ofdomesticated and wild animals in a number of countries.  Similarly,such antibodies have been found in most human populations, evenwhere hepatitis E disease does not occur.  Furthermore, the degreeof genetic divergence of the swine virus from human hepatitis E virussuggests that it has been around for a long time." In addition to the NIAID scientists, collaborators on this studyinclude Patrick G. Halbur, D.V.M., Ph.D., of the Iowa State UniversityCollege of Veterinary Medicine; Dale M. Webb, D.V.M., Ph.D., of theIllinois Department of Agriculture; James R. Lehman, D.V.M., ofAtlanta, Ill.; and other veterinarians in Iowa and Illinois. NIAID, a component of the National Institutes of Health (NIH),supports research on AIDS, malaria and other infectious diseases, aswell as allergies and immunology.  NIH and CDC are agencies of theU.S. Department of Health and Human Services.                      ### Press releases, fact sheets and other NIAID-related materials areavailable on the Internet via the NIAID home page athttp://www.niaid.nih.g 
--------
450-> Electric Cars Could Be Power Source Of The Future, UD Researchers Say In New Study
Zero-emission vehicles, as mandated in California, New York and Massachusetts have the potential to replace large central utilities as the major source of power generation in the U.S, a University of Delaware research scientist writes in a recent issue of Transportation Research. Willett Kempton, senior policy scientist with UD's Center for Energy and Environmental Policy, calculates that the U.S. passenger-vehicle fleet has 10 times more potential to generate electricity than all the nation's electricity-generating equipment combined. "If a substantial fraction of the vehicle fleet were electrified," he writes, "it would dwarf the generation capacity of electric utilities, at lower capital cost, comparable availability, and with siting closer to loads." Battery-powered vehicles would provide power at times of peak demand and be recharged from the electric grid, when demand is low. Hybrid and fuel-cell vehicles have the potential for producing continuous power. He says a fuel-cell electric vehicle, fueled from a natural gas tap at home and/or work, could provide consistent power whenever garaged and run on hydrogen or methanol. Kempton found that battery electric vehicles, which are plugged in to refuel, would require only a 220-volt, alternating current, three-phase, 40 amp. connection and charge/discharge unit to transmit up to 8kw of peak power from a vehicle to the utility. This is within the range of present house wiring and could be used during peak demand or a system failure. He computes a savings to the utility of $2,370 and suggests the utility could pass part of that savings on to the vehicle owner in the form of battery replacement, lower electric rates or a lump sum payment. Because battery electric vehicles are already being produced by GM, Chrysler, Toyota, Honda and a number of smaller companies, the UD scientist urges a shift in research to focus on designing a battery for more charge/discharge cycles, developing fuel-cell vehicles, choosing acceptable payment options and identifying good candidates for initial large-scale programs.
--------
451-> Mars is a peaceful planet, say geologists
While the NASA Pathfinder rover, Sojourner, sniffs rocks on the surface of Mars, University of Michigan geologists have completed their own analysis of Mars rocks here on Earth. Results of a U-M analysis of tungsten isotopes in Martian meteorites, published in this week's issue of Nature, show that Sojourner is sitting on a planet whose internal structure has remained essentially unchanged since the earliest history of our solar system. "The tungsten isotopic composition of the eight meteorites analyzed in our study indicates that large-scale convection, which drives plate tectonic motion and mixes the Earth's mantle, appears to have been unimportant during most of the history of Mars," said Alexander N. Halliday, a U-M professor of geological sciences. "The data also suggest that Mars formed fast and differentiated early in the solar system's history -- about 20 to 40 million years faster than the Earth's own differentiation into a dense metal core, partially molten silicate rock mantle and thin surface crust." Scientists believe the planets in our solar system began forming about 4.57 billion years ago from a huge cloud of interstellar gas, dust and debris leftover from the birth of the sun. The Earth and other rocky planets in the inner solar system built up gradually over millions of years as their gravitational pull attracted larger and larger chunks of material from the cloud. "Mars appears to have formed over a 10-million-year period very early in the solar system's existence," said Der-Chuen Lee, a U-M post-doctoral research fellow in geological sciences and co-author of the study. "During this formation period, energy released from the incoming rock and debris and decay of short-lived radioactive nuclides would have quickly built up inside the growing planet. This interior heat may have produced a shallow magma ocean near the Martian surface." Metallic liquids in this magma ocean would have settled to the planet's center to form the core, while lighter silicates floated to the top, according to Lee. The process was essentially complete sometime between 10 and 30 million years after the solar system formed. "Since then, geologic activity on Mars has been sluggish, episodic and localized compared to activity on Earth. Without the constant churning, melting and mixing of mantle and surface crust produced by active plate tectonics, some features of the chemical and isotopic composition of the Martian interior have been preserved since the core formed more than 4.53 billion years ago," Halliday said. Segregation of a metallic core on Earth was not completed for another 20 to 30 million years, according to Halliday. In previous tungsten isotopic studies, Lee and Halliday found evidence indicating that the Earth's core was not formed until at least 50 million years after the solar system began. "It is likely that this protracted development on Earth included a collision with a massive object -- triggering wholesale melting and mixing of material in the growing planet. Our current study, however, produced no evidence for such a late collision on Mars," Halliday said. Halliday and Lee used a new technique called multiple-collector, inductively-coupled plasma mass spectrometry to measure relative amounts of tungsten isotopes in Martian meteorites and acondrites -- silicate-rich debris from asteroids formed soon after the solar system developed. "Hafnium-182 is an extinct radioactive isotope, which was relatively abundant in the early solar system. By comparing relative amounts of hafnium and tungsten with the relative enrichment of the daughter isotope tungsten-182 in these meteorites, we can calculate how quickly hafnium-to-tungsten ratios changed in early solar system objects," Halliday said. "Hafnium tends to be incorporated into silicate minerals in rocks, while tungsten has an affinity for iron. When dense iron-rich melts separate from silicate melts, tungsten sinks into a planet's metallic core, while hafnium concentrates in the mantle. If you remove part of the tungsten early, the effects of the entire subsequent decay process are altered. We can tell when this occurred by measuring the abundance of tungsten-182. With the new mass spectrometry technique of multiple collector ICPMS, we can detect differences in isotopic ratios in as little as a few billionths of a gram of tungsten." The research was funded by the National Science Foundation, the U.S. Department of Energy, NASA and the University of Michigan. Meteorites analyzed in the study were from the collections of NASA, the Smithsonian Institution in Washington, D.C., Museum National d'Histoire Naturelle in Paris, and the Field Museum in Chicago.
--------
452-> New Electrical Abnormality Found In Heartbeat Of Heart Failure Patients
Some heart failure patients have an electrical abnormality that prevents the heart from recovering normally after each beat, Johns Hopkins physicians have discovered. In an article published in the Sept. 2 issue of the journal Circulation, the researchers showed that although patients with heart failure maintained a steady heart rate, the ability of their hearts to recover after each beat was erratic and unstable. "This is an important finding that requires further study clinically, to see if this is a predictor for dangerous rhythm disturbances, and mechanistically, to examine on a cellular level why this happens," says Ronald D. Berger, M.D., Ph.D., an assistant professor of medicine at Hopkins and lead author of the paper. In the study, researchers looked at 83 patients with dilated cardiomyopathy (DCM), or heart failure, a potentially fatal form of heart disease in which the lower left chamber of the heart becomes stretched and weakened. They were compared with 60 control subjects who had no history or evidence of heart disease. Researchers took electrocardiogram readings of each person to study the electrical activity of their heartbeats. Each heartbeat consists of three parts: the contraction of the atria (upper chambers), the contraction of the ventricles (lower chambers) and the recovery of the ventricles to their normal state. A computer-based algorithm was then created to examine the QT interval, or time it takes for the cells of the ventricle to recover electrically from being contracted during a beat. Results showed that in patients with DCM, the QT interval from beat to beat varied widely despite the fact that these patients had relatively stable heart rates. By contrast, in healthy patients, the QT interval from beat to beat was relatively stable, while the heart rate was more varied. Also in healthy patients, heart rate is directly related to the QT interval. For example, if the heart rate goes up, the recovery rate is quicker. In the patients with heart disease, the coupling between heart rate and QT interval was lost. Approximately two million Americans have heart failure. Roughly 300,000 die from it each year, half from arrhythmias. The research was supported by two grants from the National Heart, Lung and Blood Institute and from Johns Hopkins. The study's other authors were Edward K. Kasper, M.D.; Kenneth L. Baughman, M.D.; Eduardo Marban, M.D., Ph.D.; Hugh Calkins, M.D.; and Gordon F. Tomaselli, M.D. --JHMI-- 
--------
453-> Jefferson Scientists Find Potential Deadly Effects Of Two Missing Cancer-Suppressor Genes
Cancer geneticists at the Kimmel Cancer Center of Thomas Jefferson University, Philadelphia, studying specially bred "knockout" mice, have found that two genes that normally protect against cancer may play a greater role than previously suspected in female development. In the September issue of Nature Genetics, Richard Fishel, Ph.D., and postdoctoral fellows Aaron Cranston, Ph.D. and Tina Bocker, M.D., report that female mice that lack a pair of tumor-suppressor genes, p53 and MSH2, stop growing and die a little more than a week after conception. Fishel, professor of microbiology and immunology at Jefferson Medical College, and co-discoverer of the human MSH2 colon cancer gene, thinks the answer lies with the X chromosome, one of two sex chromosomes responsible for sexual development. Somehow, he theorizes, the missing genes throw off normal cell proliferation and development. He believes that by getting a better handle on the mechanisms by which these genes actually can affect female development, scientists may better understand the genes' roles in both normal and abnormal cancer development, as well as lead to important new therapeutic strategies. "The observation goes to the heart of how tumors develop and to tumor genetics," he points out. "It was previously found that this particular combination of altered genes is significantly lower in human tumors--our results may suggest why that is the case. These are two of the most commonly altered genes in colorectal cancer and understanding their mechanism in carcinogenesis is crucial to the development of therapeutic strategies." When one cancer-protecting--so-called tumor suppressor--gene is missing, mice--and people--are much more likely than normal to develop cancer. When two such genes are absent or defective, the thinking goes, the likelihood of cancer development would be greater still. P53 is the most common known genetic defect in human cancers. It may contribute to the development of several cancers, such as breast, colon, and lung, among others. Normally, p53 is a kind of genetic guardian. If genes become damaged, p53 shuts down everything until the damage can be fixed. MSH2 is a gene that helps cells' DNA spell-check and repair itself during replication. In 1993, Fishel and colleague Richard Kolodner showed that when MSH2 is altered, it accounts for about half of all cases of genetically linked hereditary non-polyposis colorectal cancer (HNPCC)--one of the most common human cancer predisposition syndromes (Fishel, R. et al., Cell, 74:1027, 1993). Knockout mice lack a working gene or genes and are used as models to study the effects of cancer gene alterations, often helping scientists understand cancer mechanisms and develop effective therapies. The researchers found that male knockout mice died from cancer at an average of 273 days, which is perhaps two to three times as quickly as they might die with only one missing gene. They expected that. But they didn't expect to find that the combination of missing genes was lethal to the female mouse embryos. By day 9.5 of gestation the female mice stopped developing and died. "The embryo was undergoing global apoptosis, or programmed cell death," he said. "These embryos are self-destructing. As many as 60 to 90 percent of the cells underwent apoptosis." Men have an X and a Y chromosome; women carry two Xs. During normal embryonic development, certain genes of one of the X chromosomes may be turned off, a process called X-inactivation. Normally, there is some damage to the X and other chromosomes when cells duplicate and go through a "cell cycle." Cells have an innate repair mechanism to fix the problem; both p53 and MSH2 are involved in regulating this cycle as well as controlling the genetic repair mechanism. Without these two genes, the result is "global, catastrophic cell death in developing females," according to Fishel. One mystery that remains is the precise role of the two genes in preventing such mass cell death and allowing normal development. The p53 gene has been thought to have a critical role in apoptosis. Fishel sees several possibilities. "The interesting observation is that they are undergoing global apoptosis independent of p53," he noted. "Many studies suggest that cells that decide to undergo apoptosis do it in a p53 dependent pathway. That presents two intriguing questions: what is this p53 independent pathway, and why are they [cells] dying? The only differences between males and females are the extra X or a Y chromosome. It might be that one of the X chromosomes is damaged [beyond repair] or the Y chromosome provides protection," he said. "At the moment we favor the 'excessive X chromosome damage' argument since both MSH2 and p53 are involved in managing DNA repair." Colleagues at both Jefferson and at the University of Toronto also contributed to the work.
--------
454-> A New Biochemical Link Established Between Stress, Sex And Dominance
Stress can get you down. Worse: Stress can keep you down ­ at least that's what happens to the male African cichlid fish when a bigger, rowdier male controls a coveted patch of lake-bottom territory. In a study published Aug. 15 in the Journal of Neuroscience, a research team led by Stanford neurobiologist Russell Fernald has shown that continuous high levels of a stress hormone, cortisol, work to prevent most male cichlids from developing the bright, warlike colors, the extra muscles and the fully mature sex organs of a dominant "territorial" male. Stress appears to prevent all but the dominant males from achieving reproductive success. Fernald said that since many species have evolved dominant and non-dominant males, the role of stress hormones in social systems may be widespread. "The interesting new thing we have found is that stress depends not only on the social state of the individual male but also on the stability of the community," Fernald said. Fernald is the Benjamin Scott Crocker Professor of Human Biology and director of the Human Biology program at Stanford. He is also a professor of psychology and a member of the Neurosciences program faculty. He and members of his laboratory already have shown that for cichlid fish, social position determines physiology. It's not so much that the biggest, brightest fish becomes dominant. Instead, a fish must earn his bright "macho" colors by proving to himself and others that he can control and defend a patch of food-laden gravel. Those males that prove themselves ­ Fernald and his students call them "territorial" ­ experience a dramatic transformation, switching color within minutes from a camouflaged sandy gray to bright blue or yellow. Within days, they put on weight, mature sexually and sport a threatening, warpaint-like stripe next to their eyes. As in the movies, the macho fish also gets the girl: He offers grazing rights to entice breeding females to lay their eggs in a sheltered nook within his territory. Only territorial males have the fully developed gonads capable of producing sperm to fertilize those eggs. All in the head All of this is reflected in a patch of cells in the fish's brain that increase eight-fold in volume while they pump out big doses of gonadotropin releasing hormone (GnRH), the coordinator of sexual development for all vertebrates, including humans. Most remarkably, if a territorial fish is defeated by another territorial male and loses his status, he loses the symbols of status as well. The colors and eyepatch fade, the GnRH cells in the brain shrink and so do the gonads. "In our lab, we have shown that behavior influences the brain," said Fernald. "We've seen that behavioral encounters can modify the GnRH producing cells, and we know that this hormone in turn triggers changes in body structures that influence reproductive success. Now we want to know how social behavior can produce such changes in brain cells." He and his students looked at cortisol as a possible mechanism. Cortisol is the "fight or flight" hormone, squirted out by the adrenal gland to give an animal a sudden burst of strength or speed so it can fight off an attacker or zip away from a predator. Other scientists have shown that cortisol levels remain high in the body if an animal ­ or a human ­ is constantly under stress. The hormone appears to be a trigger for many of the physiological effects linked to long-term stress, from sour stomach to heart disease. Territorial rights The Fernald lab is stacked with aquariums equipped to imitate the conditions of life in shallow pools of Lake Tanganyika, where this breed of cichlid fish originated. On the aquarium floor, a layer of gravel is piped with plastic tubing to deliver fish food from below ­ in the wild, cichlids sift through gravel to eat the decaying plant matter collected there. Overturned flower pots imitate the rocky nooks that male cichlids defend as spawning sites in their territories. By setting up various versions of this environment and introducing various combinations of male and female fish, Fernald has been able to study social behavior and the physiological and neurological changes that it entails. The cortisol research was primarily conducted by three students. Helen E. Fox, a 1994 graduate of Swarthmore, worked in the Fernald lab for two years before starting graduate studies at the University of California-Berkeley. Stephanie A. White earned her Ph.D. in neurosciences at Stanford this year and is now a postdoctoral fellow at Duke University. Mimi H.F. Kao won a Firestone Medal for her cortisol research while earning her bachelor's degree in human biology at Stanford in 1995. Now she is working toward a graduate degree in neurosciences at the University of California-San Francisco. They tested the hormonal response to stress by capturing the fish and taking blood samples before returning them to the tank. First, they determined that if a sample was taken within four minutes after capture, cortisol levels represented the baseline amount of hormone that was in the fish's bloodstream in the tank, not the big spurt pumped out by the adrenal gland during capture. Fernald said that the team's major finding came from an experiment where 20 male and female fish were introduced to a large aquarium, with gravel and potsherds placed over half the floor and the other half left bare as a refuge from territorial wars. The fish were all new to one another; none had been raised in the same tanks. Most of the males were still sexually immature. The males immediately began vying for patches of territory. For the first few weeks, ownership changed frequently ­ and so did the males' bright colors, switching on or off depending on which male perceived himself to be the victor. Perhaps most important, Fernald said, was the fact that no females elected to lay eggs during this period of social instability. Eventually, several males established permanent territories and began their transformation into large, bright, dominant animals. The other males remained almost indistinguishable from females. That nondescript coloring has its advantages: A non-territorial male can sneak into a dominant male's territory by impersonating a female, and snatch extra food. This behavior is the same as in Africa, where Fernald has done field work. And in the wild, a brightly colored fish is more likely to be snatched up by a wading bird. But Fernald's team knew from previous experiments that if males were raised alone, they would take on the flashy traits of a dominant fish. What happens in social situations to suppress some males' maturation? The scientists found two kinds of evidence that cortisol is at least one of the factors mediating between behavior and physiology. Early in the period of social instability, both territorial and non-territorial males showed similar cortisol levels, with males that were territorial at the time of a blood test showing somewhat higher levels than non-territorial males. That is consistent with cortisol's known role as a fight-or-flight hormone, marshaling the resources needed for a battle. Once the social system was stable, however, the territorial males' cortisol levels dropped dramatically ­ even though such fish are constantly active, chasing away other males and enticing females. Meanwhile, the stress hormones in the blood of non-dominant males skyrocketed once their competitors had control over all the available territory. Those cortisol levels stayed high for the remainder of the study. The differences in cortisol levels between territorial and non-territorial males and between stable and non-stable social situations provide evidence that this stress hormone response tracks both the individual's social status and the dynamics of its social scene, the scientists concluded. The hormone differences also offer tantalizing evidence that cortisol might be the mediator between the social situation and the non-territorial males' failure to mature. Continuous high levels of stress hormones might affect the size of GnRH producing brain cells, Fernald said ­ but this study does not offer positive proof of that hypothesis. More research, involving implants of cortisol and a cortisol antagonist in selected fish, may answer that question in the future. -30- NOTE TO REPORTERS: The article "Stress and Dominance in a Social Fish" by Helen E. Fox, Stephanie A. White, Mimi H.F. Kao and Russell D. Fernald appears in the Aug. 15 issue of the Journal of Neuroscience. An abstract is available on the journal's website at http://www.jneurosci.org/. A review article, "Changing Through Doing: Behavioral Influence on the Brain," by Stephanie A. White and Russell D. Fernald appears in the 1997 Endocrine Society publication, Recent Progress in Hormone Research, Vol. 52. Copies of both articles are available from the Stanford News Service, and from Russell Fernald. By Janet Basu
--------
455-> Evidence Discovered Of New Subnuclear Particle
Evidence of a new subnuclear particle -- an exotic meson -- has been discovered by a team of physicists from the University of Notre Dame and six other institutions. Long theorized, the particle had been undetected until now, said Neal Cason, professor of physics at Notre Dame and a cospokesman on the project. The elementary particle physics group at Notre Dame -- professors Cason, William Shephard, John LoSecco and James Bishop -- and 47 others are investigators in this research, which has been published in the Sept. 1 issue of Physical Review Letters. "Our observation of the exotic meson is significant to understanding the basic forces at work between the elementary particles," Cason said. "Comparing our results with current theoretical models will allow us to begin the detailed understanding of these forces." The experiment, titled E852 and conducted at Brookhaven National Laboratory on Long Island, is reported in the dissertation of Notre Dame doctoral student David Thompson. Five other Notre Dame graduate students are among the 51 investigators in the research. "This is a very important discovery," said Ted Barnes, a theoretical physicist at Oak Ridge National Laboratory and professor of physics at the University of Tennessee. "Theorists have predicted the existence of the exotic meson since the late 1970s, but E852 may have found the smoking gun for their existence. It's a benchmark that will set the mathematical scales for future experimentation and theoretical study." A meson is a very unstable, medium-mass elementary particle with a short life span that is similar to but smaller than a proton or neutron. All three are composed of the most basic elementary particle, the quark. Protons and neutrons are made up of three quarks, while ordinary mesons are composed of one quark and one antiquark. "Over the years, we've observed and catalogued mesons, with much of the work being done here at Notre Dame," said Cason. "What we've been searching for is a new form of a meson -- the exotic meson." The building blocks of one type of exotic meson are a quark, an antiquark and gluon, yet another elementary particle that "glues" together the quark and antiquark. Using high-energy particle beams at the Brookhaven accelerator, Cason said, "We discovered a meson that we know is not made up of a quark and antiquark, which means it must be an exotic meson. There are a number of different kinds of exotic mesons and we're now going to begin work to determine which kind this is." Mesons and exotic mesons "are not a part of our everyday life," Cason said. "Because they are unstable, you cannot make higher forms of matter with them." However, the discovery of the exotic meson is significant because it will allow physicists to expand their understanding of nature at its most fundamental level, Cason said. "When we search for matter like this (the exotic meson), what we're really doing is looking for the fundamental forces between matter," Cason said. "As far as we know, there are only four fundamental forces in nature -- the gravitational, the electrical, the strong and the weak forces. This research will help us better understand the properties of the strong force." The research began in 1989 and was funded by the High Energy Physics and Nuclear Physics Divisions of the National Science Foundation and the Department of Energy through Brookhaven. Other institutions participating in the collaborative project are Brookhaven, the University of Massachusetts at Dartmouth, Northwestern University, Rensselaer Polytechnic Institute, and Moscow State University and the Institute for High Energy Physics in Russia.
--------
456-> Children Who Breathe Second-Hand Smoke At Home Have Lower Levels Of "Good" Cholesterol, Study Finds
DALLAS, Sept. 2 -- Children already in danger of developing heart disease because of high cholesterol blood levels face a "triple jeopardy" if they live in smoke-filled homes, according to a study appearing in today's American Heart Association journal Circulation. The study, the first of its kind to look at blood fats and second-hand smoke in children (ages 2 to 18) with elevated cholesterol, found that passive smoke lowers by about 10 percent the level of the child's HDL. HDL, the "good" cholesterol, protects against heart attacks. Children with an inherited cholesterol disorder already have a higher risk of developing heart disease. Exposure to second-hand smoke at an early age lowers HDL. In addition, smokers' offspring more often become smokers themselves, says Ellis J. Neufeld, M.D., Ph.D., and his colleagues at Boston Children's Hospital Neufeld and his co-workers made a preliminary report on their research at the American Heart Association's 1994 Scientific Sessions in Dallas. The findings suggest that escaping a smoky environment could raise children's HDL by 10 percent -- equal to, or better than other risk-reducing interventions. "It's hard to make HDL go up 10 percent. Diet and exercise can help, but we'd predict that ending exposure to passive smoke would be at least as effective as these measures," says Neufeld, director of Clinical Hematology at Children's Hospital. Children in the study were considered at high risk because of cholesterol abnormalities -- either total cholesterol above 200 mg/dl (considered high in children), HDL levels that were unusually low or family history of heart disease. They had been referred to a Children's Hospital clinic for treatment of their cholesterol disorders. Twenty-seven percent of the 103 children came from households of cigarette smokers. Those exposed to tobacco had HDLs averaging 38 milligrams per deciliter (mg/dl) of blood, while HDLs averaged 43 mg/dl among those who didn't have to inhale smoke-fouled air. There are 27.4 million young Americans under 19 with cholesterol levels above 170mg/dL (comparable to a level of 200mg/dL in adults). "So many thousands of these youngsters can conceivably benefit from removing the smoke in their environment," he says. Passive smoke's effect was not attributable to demographic characteristics of the smoking households, knowledge of cholesterol, parents' attitudes or physiological factors, the authors add. Because all those in the study had abnormal blood cholesterol levels, the conclusions can't be applied to all children, the researchers point out. Their study's impact is limited by its relatively small size and by the fact that no tests were conducted for chemical components of tobacco smoke. Also, the investigators say their study's design did not allow them to prove that reducing passive smoke exposure would raise children's HDL levels. The study accounted for body mass index (an indicator of obesity), age, sex, exercise and dietary fat intake. Co-authors of today's report with Neufeld were Michele Mietus-Snyder, M.D.; Alexa S. Beiser, Ph.D., Annette L. Baker, R.N., M.S.N., and Jane W. Newburger, M.D., M.P.H. Circulation is one of five scientific journals published by the American Heart Association, which has its national headquarters in Dalla 
--------
457-> Researchers Develop Training Method To Help Reduce Asthma Attacks
ATHENS, Ohio -- Many people with asthma aren't able to detect a problem with their breathing until the asthma attack becomes severe. But a new training method developed by researchers at Ohio University could one day help asthma patients detect an attack as early as 30 minutes before its onset. Self-management of asthma includes the ability to detect resistance to air flow that is caused by constricted air passages. But research suggests that many people with asthma are unable to detect this breathing difficulty in time to stop the attack. Researchers at Ohio University have developed a training method that helps asthma patients improve their perception of air flow resistance. In a study of 45 asthma patients who took part in the training, researchers found that participants had fewer asthma attacks because they detected the problems earlier and took medication before the onset of an attack. "Breathing is so natural to us, we do it without thinking, and that's true for asthma patients as well," said Harry Kotses, professor of psychology at Ohio University and co-author of the study. "If people with asthma can learn to be sensitive to changes in resistance to air flow, they might be able to detect the early stages of an asthma attack and stop it before serious breathing difficulty occurs." Asthma, the most common chronic childhood illness, affects nearly 15 million Americans, 5 million of whom are under the age of 19. According to the Centers for Disease Control and Prevention, asthma accounted for an estimated 198,000 hospitalizations and 342 deaths in 1993. During an asthma attack, air flow into and out of the lungs is restricted by inflammation and swelling of the bronchial tubes and by bronchial narrowing caused by smooth muscle contraction. An attack can be triggered by exercise, infection, respiratory irritants, stress or an allergy to things such as pollen, dust mites or animal dander. The illness usually is controlled by steroids that reduce inflammation of tissues in the airway, by bronchial dilators that relax constricted muscles, or both. Because an asthma attack is costly to the patient in terms of health risk and hospital cost, physicians emphasize prevention through self-management. An attack can happen any time, Kotses said, and it's important that asthma patients learn to judge the illness' warning signs and take preventative measures early. For the study, researchers interviewed 20 men and 25 women ages 18 to 24, all Ohio University undergraduate students. Each had been diagnosed with asthma by a physician and used prescribed medication for the illness. Before undergoing training, study participants were interviewed about the frequency and severity of their asthma attacks. Sixteen had at least four asthma attacks a month, 20 had two or three attacks a month and nine had fewer attacks. During the study, asthma patients were asked to breath through nylon mesh screens. Each screen had a different weave -- some allowed for greater resistance to air flow and some for less resistance. Participants judged the level of difficulty they experienced while breathing through each of the screens. At the beginning of the study, some participants said that widely woven screens caused more air flow resistance than those more tightly woven, which added support to theories that asthma patients are unable to determine air flow resistance accurately. But by the end of the study, most participants were able to identify correctly those screens that presented the most problems. "It is possible that change in air flow obstruction associated with asthma occurs so gradually that it goes unnoticed until it is severe," Kotses said. "But the wide range we observed in ability to predict asthma suggests this is not the case. Some of our subjects reported ability to forecast occurrence of asthma by 30 minutes or more. A primary benefit of perception training may be that it increases the length of the warning period a patient has prior to the onset of an attack." Although self-management of asthma has been part of asthma control for many years, the idea of adding perception training is new, Kotses said. Many of the study participants reported that breathing through the different mesh screens was very similar to an actual asthma attack, which suggests this method may be useful in a perception training program. "The fact that our subjects were able to detect the onset of an attack earlier than before is very promising, but now we want to study the method using a larger group of asthma patients and examining them over a longer period of time," Kotses said. The study, published in a recent issue of the journal Psychosomatic Medicine, was co-authored by Thomas Creer, a former professor of psychology who retired in 1996, and Cynthia Stout, a former psychology graduate student, both from Ohio University. - 30 - Contact: Harry Kotses, 614-593-1080; hkotses1@ohiou.edu.Written by Kelli Whitlock, 614-593-0383; kwhitlock1@ohiou.e 
--------
458-> Oak Regeneration In Some Ohio Forests Is Failing, Researchers Find
ATHENS, Ohio -- Oak trees in some Southeastern Ohio forests are failing to naturally reproduce, even in fertile areas, according to a new Ohio University study. This could mean that without human intervention, oak-dominated forests in the area may be overtaken by different tree species, causing an ecological change unprecedented in modern times. Scientists studied oak regeneration in several mixed-oak forests in Southeastern Ohio, a type of forest that is common throughout Central Appalachia and the mid-Atlantic states. Recent studies at Ohio University and elsewhere had indicated that the number of oak seedlings in these forests was low compared to the number of mature oaks in the forest canopy, also called the overstory. Forest ecologists had theorized that oak regeneration may not be as serious in areas high in light and low in moisture, conditions that are amiable to oak growth. But a study presented at the annual meeting of the Ecological Society of America, held Aug. 11-14 in Albuquerque, N.M., seems to contradict that theory. "It has been thought that, barring any major disturbance such as fire or biotic influences such as an insect infestation, oak may be experiencing reasonable regeneration on sites of high light and low moisture," said Brian McCarthy, an associate professor in the Department of Environmental and Plant Biology at Ohio University and lead author of the study. "Interestingly, when we brought the light, moisture and regeneration data together, there was no obvious trend toward improved oak regeneration on well-lit, dry sites," he added. "Some forest managers had hoped that there might be a refuge or a niche where oak could still survive in the forested landscape, but our studies suggest that oak regeneration doesn't look hopeful anywhere." The cause for alarm, McCarthy said, is that if oak seedlings aren't present in sufficient numbers, the mature oaks in the overstory will be replaced with trees that are faring well in the understory, such as maple or American beech. "The entire biological web of species that live in these types of forests are adapted to living in an oak forest," McCarthy said. "If there is a major change in the habitat, there could be system-wide effects on all the species of insects, birds and mammals that live there, possibly even to the point that some species of animals or plants could become locally extinct." This concern is a driving force behind McCarthy's study, which was part of the first phase of a larger project by the Northeastern Forest Experiment Station of the United States Forest Service (USFS) in Delaware, Ohio. About 30 scientists are studying more than 1,000 acres over four sites in Ohio to evaluate the effect of prescribed fire on the regeneration of oaks and other hardwood tree species. "It's believed that fire differentially kills back thin-barked saplings of species like maple, which is one of oak's competitors in the forests we are studying," McCarthy says. "Repeated fires might provide oak with a window of opportunity in which it has the competitive upper hand. If the oaks can get ahead of the maples in the midstory of these forests, they might stand a chance of getting to the overstory." For this study, McCarthy, Ohio University graduate student Scott Robinson and forest service collaborators examined the patterns of hardwood regeneration in 108 plots in four stands of a mature mixed-oak forest in Southeastern Ohio. The area studied gets as much as 10 to 15 percent of the available sunlight and has moderately dry soil. McCarthy collected data for the site condition study in 1995, a year before the sites were burned. His preliminary studies of areas that were burned in 1996 and earlier this year suggest that the burn project is having the desired effect -- more sunlight is reaching the forest floor, which could be good news for oak seedlings. "Although we're still analyzing the data, I would expect to see a significant increase in light in the understory," he said. "But we will need to maintain this high-light condition for several years before we begin to see any effect on oak regeneration." The USFS project, which began in 1995, is a long-term effort and is funded by the United States Department of Agriculture.- 30 - Contact: Brian McCarthy, 614-593-1615; bmccarthy1@ohiou.edu.Written by Kelli Whitlock, 614-593-0383; kwhitlock1@ohiou.e 
--------
459-> Research Finds Some Antihypertension Drugs May Help Prevent Cell Damage
ATHENS, Ohio -- Three of the most widely prescribed drugs used to treat hypertension may do more than reduce blood pressure in people who take them. They also may help prevent a type of cell damage caused by too much oxygen in the blood, according to a new study by researchers at Ohio University. "Antihypertensive drugs are the second most frequently prescribed drug in the United States. Clearly, if you have a significant portion of the population taking these drugs, it's necessary to study the drugs' effects -- positive and negative -- on the body," said Peter Johnson, professor of chemistry and biomedical sciences at Ohio University and co-author of the study. Studies of the drugs -- captopril, hydralazine and terazosin -- found that, in some cases, the medications enhanced a protection mechanism the body employs when cells come under oxidative stress, a process caused by the production of free radicals released during the metabolism of oxygen. Free radicals are chemical byproducts of normal aerobic activities and can damage a cell's membrane, proteins and DNA.	A healthy body reacts to free radicals by producing antioxidant enzymes, which neutralize the free radicals before they can harm cells. When the production of free radicals is elevated, as is the case with hypertensive patients, a cell's ability to release these protective enzymes is affected, Johnson said. For the studies, the researchers gave high doses of the drugs to two groups of rats -- one group with high blood pressure and the other with normal blood pressure levels. In the majority of the animal studies, each of the drugs helped to stimulate the expression of these antioxidant enzymes, which enables the body to protect its cells from oxidative damage. But in a few cases, the drugs produce the opposite effect, inhibiting the body's production of these protective enzymes. "Each of the drugs we studied seems to have an effect on antioxidant enzyme level expression, but the effects are different from drug to drug," Johnson said. "More surprisingly, the effects were different in different groups of animals," which could mean that a drug that causes no problem in one animal may present problems in another. More than 50 million Americans have hypertension, or high blood pressure, and are treated with dozens of drugs. Most antihypertension medications have different, primarily non-threatening, side effects that range from water retention to skin irritation. But Johnson's studies suggest some of these drugs also affect cells in a way not studied before. "We weren't really surprised to find that captopril caused a change in antioxidant enzyme expression," Johnson said. "The drug is now being used by some physicians in heart attack recovery therapy because people suspect it may be an antioxidant itself." Researchers were surprised, however, to find that the other drugs in the study -- hydralazine and terazosin -- also had an impact on enzyme expression. In some cases, the drugs produced an increase in enzyme activity, which heightens the body's response to oxidative stress. But in others, it inhibited that protective process. "This is the first time that these two commonly prescribed drugs have been shown to affect antioxidant enzyme activities," Johnson said. "It's something physicians need to be mindful of, because if something in the body already is out of balance because of hypertension, these drugs could make things even more out of balance." The work was published in a recent issue of the journal Biochemical Pharmacology and was co-authored by Karen S. Cabell, a medical student in the College of Osteopathic Medicine and Lin Ma, a graduate student in chemistry, both at Ohio University. - 30 - Contact: Peter Johnson, 614-593-1744; pjohnson1@ohiou.edu.Written by Kelli Whitlock, 614-593-0383; kwhitlock1@ohiou.edu.
--------
460-> Males Don't Follow Intuition When It Comes To Listening To Rock Music
ATHENS, Ohio -- Males may be more likely than females to play rock music at potentially dangerous volumes, regardless of whether or not they like rock music at all, a new study at Ohio University suggests. A study of 250 Ohio University students ages 19 to 22 found that men may be influenced more by external circumstances, such as peer pressure, than they are by their own preferences for music. This pressure may influence their judgments about loudness to the point that they will play music they don't like loudly, said Donald Fucci, professor of speech and hearing at Ohio University and lead author of the study. "For women, it was straightforward -- if they said they didn't like rock music, they didn't like to hear it played loudly," Fucci said. "But the men couldn't seem to follow their own preferences." Studies of hearing loss in young people have suggested an increase in the cases of irreversible sensory hearing loss among people ages 18 to 21. This new study suggests males may experience more hearing damage because they may be succumbing to forces such as peer pressure, Fucci said. "Young adults frequently try to test their limits," he said. "It might be that boys are more likely than girls to do that, although we don't know that for sure." For the study, researchers asked the students to rate their preference for rock music as high, moderate or low. The people who rated their preference as either high or low were asked to listen to the rock song, "Heartbreaker" by Led Zeppelin, played at a range of volumes for a period of 10 seconds. While listening, participants were asked to indicate whether they thought a particular volume was too loud, or if they wanted the music played louder. "We found that even men who said they didn't like rock music rated it the same as those who liked it, which suggests that they may not be responding to their inner feelings about the music as much as women do," Fucci said. "It appears that women are more in tune with their emotions and their needs and are willing to follow those needs, at least in the case of listening to music." The audio industry often has been bla 
--------
461-> New X-Ray Generator To Improve Protein Crystal Research On Space Station
A collaborative effort by NASA, university researchers and industry has resulted in the development of a new X-ray generator to speed the collection of protein structure information from crystals grown aboard the International Space Station. Researchers grow protein crystals in space because the crystals typically grow larger and with greater purity in the near-weightless environment of low-Earth orbit, providing researchers better data for structure-based drug design. The X-ray device is a critical component of the X-ray Crystallography Facility, a payload planned for the International Space Station, being designed and developed by the University of Alabama in Birmingham's Center for Macromolecular Crystallography. Using the X-ray generator in the commercially developed X-ray Crystallography Facility will alleviate the need to return space-grown crystals to Earth for further analysis.  By measuring and mapping the crystal's structure in space, researchers will avoid exposing the delicate crystals to the rigors of space travel, and important research data will be available to scientists much faster. The X-ray generator, developed by Bede Scientific Instruments Ltd. in Durham, Great Britain, is a compact, lightweight, low-power X-ray device about the size of a small suitcase and is capable of generating high-brightness X-ray sources for protein crystal growth research.  The generator focuses X-ray beams approximately one-half millimeter in diameter on the targeted protein crystal, allowing researchers to analyze and model the three-dimensional structure of protein molecules in detail, previously only possible with sources using sixty times the power. Dr. Larry DeLucas, Director of the Center for Macromolecular Crystallography and a former Space Shuttle payload specialist, stated that having an X-ray facility aboard the Space Station will improve our understanding of effects of low-Earth orbit on crystal growth and contribute to accelerated drug development. "Providing a three-dimensional structure is what we're after," said DeLucas.  "Once we determine a protein structure, it provides a wealth of information regarding the mechanism of the protein and, in many cases, this information is used to design new and more effective pharmaceuticals.  This new X-ray facility will help to speed the process by allowing scientists to use the Space Station to grow the crystals and collect the X-ray data in space." Current X-ray crystallography facilities are about the size of anautomobile.  The new X-ray facility being developed for the Space Station willfit into a single space station rack -- about the size of a householdrefrigerator -- and will produce the same intensity of X-rays. Bede Ltd. built the new X-ray instrument in collaboration with the Center for Macromolecular Crystallography, which is under contract to NASA's Microgravity Research Program's Space Product Development Office at NASA's Marshall Space Flight Center, Huntsville, AL. A unique aspect of the X-ray crystallography facility is its commercial development approach.  The funding for further development of this facility will be provided by non-U.S. Government sources, thereby reducing the cost for taxpayers. DeLucas said, "I can't begin to tell you how much we are looking forward to continuing our work aboard the new Space Station.  This brings us one step closer to making the facility a reality.  With the X-ray facility onboard, we'll have a new and powerful potential tool to address many public health problems." - end -
--------
462-> Possible New Approach To Brain Tumors In AIDS Patients
COLUMBUS, Ohio -- Researchers may be close to developing an additional weapon for treating atype of rapidly growing, fatal brain tumor that often afflicts AIDS patients. The new approach, reported in the latest issue of the journal Blood, focuses on activating a proteinreceptor that stimulates cells to commit suicide. These specific tumors -- primary central nervous system lymphomas (PCNSL) -- have now beenshown by the researchers to express the receptor (called FAS) and to undergo cell death when thatreceptor is triggered. Since the brain itself does not appear to express this receptor, researchers may be able to trigger thereceptor on the tumor cells without damaging nearby normal brain tissue. These lymphomas are nowalmost universally untreatable and can kill a patient within two to four months after the condition isdiagnosed. These brain tumors almost always contain Epstein-Barr virus, a virus that normally remains dormant inmost normal people, held at bay by healthy lymphocytes called T-cells. But when the immune system isdamaged, or the number of T-cells has dropped substantially -- as is the case with AIDS patients -- thevirus activates, presumably leading to the brain lymphoma. Robert Baiocchi, a third-year medical student at Ohio State University, and Michael Caligiuri,co-director of the division of hematology and oncology and associate director for clinical cancerresearch for the university’s Comprehensive Cancer Center, led the work. They examined tissue taken from eight different AIDS patients who had died from these lymphomas.They discovered that all the tumors expressed FAS at very high levels. FAS is common in the rest of the body, especially the liver, but the normal brain appears to be free ofFAS. Caligiuri said that finding FAS in the brain tumors was an advantage. The blood-brain barriergenerally prohibits the passage of compounds from the brain into the circulatory system. “The brain is a chemotherapy sanctuary. This means we may be able to administer anti-FAS medicineswithin the brain that could stimulate the brain tumors to self-destruct, without harming normal brain orwithout traveling to other parts of the body that normally produce FAS,” he said. To test their ideas, Caligiuri and Baiocchi turned to laboratory animals known as SCID (severecombined immune deficient) mice. These mice lack functional immune systems of their own. Because ofthat, researchers can put normal human cells inside the animals. After about three months, the animalsdevelop actual human lymphomas with the Epstein-Barr virus that strikingly resemble the brainlymphomas seen in some patients with AIDS. In the mice, however, the tumors appear in the lymphnodes. In humans, the lymphomas appear in the brain. The researchers were then able to use anti-FAS compounds to trigger FAS which begin killing thehuman tumor that had developed in the SCID mouse. Baiocchi and Caligiuri next examined three fresh brain tumors from patients with AIDS and PCNSL andwere also able to show that when the tumors received anti-FAS therapy, those tumor cells died.Furthermore, the cell death begun by the anti-FAS treatment was improved by adding radiation.Currently, radiation is the only standard treatment available for PCNSL tumors. The researchers sawimproved tumor cell death when the immune stimulant interleukin 2 was used. The next step, Caligiuri said, is to grow these same tumors in the brains of rats that have deficientimmune systems, and then test if the animals’ blood-brain barriers isolate the treatment and protect theanimals’ other organs. “Our dream would be to give the brain gene therapy which would cause it to express what’s called FASligand, an anti-FAS molecule that binds to FAS and triggers specific cell death,” Caligiuri said, which inturn would have the possibility of destroying existing tumors. The research is supported by a grant from the National Cancer Institute. Baiocchi and Caligiuri began this work while at Roswell Park Cancer Institute in Buffalo, NY, butcompleted their work at Ohio State. Working with them there were Vijay P. Khatri, Matthew J.Lindemann, Mary E. Ross, Anthony J. Caprio, Thomas V. Caprio, Robert Fenstermaker and Zale P.Bernstein, all from Roswell Park. Guiliana Papoff and Giovina Ruberti, both researchers at the Instituteof Cell Biology in Rome, Italy, were part of the research team. #
--------
463-> Scientists Successfully Isolate Fish-Killing Organism Pfiesteria Toxin In Lab Tests
RALEIGH, N.C. -- Scientists are one step closer to identifying one of the major toxins produced by the fish-killing organism Pfiesteria piscicida, which has been blamed for killing millions of fish along the East Coast. In a series of experiments completed earlier this month, researchers at North Carolina State University, working in collaboration with the National Institute of Environmental Health Sciences (NIEHS) and the Marine Biotoxins Center at the National Marine Fisheries Service (NMFS), have for the first time successfully isolated and purified a water-soluble toxin component from Pfiesteria. Isolating the toxin component makes it possible for scientists to complete the task of identifying its chemical structure, so they can develop accurate tests to detect its presence in fish, humans or other mammals who may have been affected. "We expect to have the chemical identity of the toxin very shortly," says lead researcher Dr. JoAnn Burkholder, associate professor of aqautic botany at NC State. The toxin component isolated by the researchers is unlike any other known dinoflagellate toxin, Burkholder says. "It has a different mode of action and acts more rapidly than any we have previously seen. It also appears to be heat stable. In repeated tests conducted during one phase of the isolation procedure, we heated the toxin to 170 degrees Fahrenheit for two hours and it remained potent," she says. "And it's highly lethal to fish. When exposed to its purified form, fish became moribund in two to three seconds and died within three minutes." Tests also showed the toxin can damage mammalian neurological and pituitary cells. More testing is now under way to better understand the severity and duration of that damage. Burkholder presented the findings of the collaborative research in an invited talk this morning (Tuesday, Aug. 26) at the NIEHS Workshop on Hazardous Marine/Freshwater Microbes and Toxins, in Research Triangle Park. Leading environmental scientists from the United States and Canada are taking part in the two-day workshop. Burkholder and her colleagues at NIEHS and NMFS also have developed a promising new method for testing the toxicity of water collected at the scene of fish kills and related disease events. The method is called a reporter gene assay. It can quickly and reliably detect the presence of toxins -- even very low levels of them -- in water samples. The assay has been successfully tested in the lab. Months of field testing will now begin. "This assay will give researchers a much more concrete and accurate measurement method," Burkholder says. Pfiesteria piscicida and other Pfiesteria-like species are predatory, single-celled aquatic dinoflagellates found in coastal estuaries from Delaware to Alabama. At least four Pfiesteria-like dinoflagellates are currently known; Burkholder has found at least two of them in North Carolina's estuaries. Of the four, only P. piscicida has yet been given a formal scientific name. P. piscicida was first characterized and identified at the site of a fish kill in 1991 by Burkholder. (Burkholder's identification of the species was confirmed in independent tests by Dr. Karen Steidinger of the Florida Marine Research Institute in St. Petersburg, Fla.) Since 1991, P. piscicida has killed tens of millions of fish in North Carolina's shallow, nutrient-rich coastal waters. This year, Pfiesteria-like species also have been implicated in a fish kill on the Pocomoke River in Maryland. In some cases, Pfiesteria's toxins have been linked to human illnesses. Widely acknowledged as the world's leading expert on Pfiesteria-like dinoflagellates, Burkholder has published 17 peer-reviewed scientific studies on Pfiesteria-like species. Earlier this year, she received a prestigious Pew Fellowship in Conservation and the Environment in recognition of her research and educational outreach. The tests to isolate the Pfiesteria toxin were first conducted earlier this month by NC State and NIEHS researchers at NIEHS laboratories in Research Triangle Park. As a safeguard against error, the tests were repeated at NMFS, in Charleston, S.C. Results from the two sets of tests were consistent. Researchers collaborating on the experiments included: Burkholder, Howard Glasgow and Nora Deemer from NC State; Dr. Frank Johnson and Dr. Michael Snell from NIEHS; and Dr. John Ramsdell, Dr. Peter Moeller, Stewart Edmunds and Elizabeth Fairey from NMFS. -- lucas -- This release also is available on the NC State News Services Website at http://www2.ncsu.edu/ncsu/univ_relations/releases/current.html. For more information on Pfiesteria piscicida, or an on-line version of the research abstract (available later this week), check out Dr. JoAnn Burkholder's Website at http://www2.ncsu.edu/unity/lockers/project/aquatic_botany.
--------
464-> Zanzibar Monkeys Eat Charcoal To Counteract Toxins
Monkeys on the African island of Zanzibar have learned that ingesting charcoal will counteract the adverse affects of toxic substances in their diet, say Duke University and University of Wyoming scientists. UW Professor David Cooney, a chemical engineer with extensive research on the medical uses of activated charcoal, says he was asked to test samples collected in a study by Duke scientist Thomas Struhsaker, who observed the unusual habit of Zanzibar red colobus monkeys eating charcoal. Struhsaker was familiar with Cooney's research and with his recent book, "Activated Charcoal in Medical Applications." He sent Cooney leaf samples of the monkey's main dietary source, Indian almond and mango leaves, which are potentially toxic. He also sent charcoal taken from burned trees and charcoal lying near kilns, where it was produced for cooking. Cooney studied the adsorption ability of five charcoals from Zanzibar in hot water extracts steeped from the Indian almond and mango leaves. Adsorption is the ability of substances, in this case the toxins, to stick to the surface of a solid, such as charcoal. "For comparison, we also evaluated three commercial powdered activated charcoals," he says. "As expected, these charcoals acted best, yet the African kiln charcoals adsorbed surprisingly well. The findings support the hypothesis that the monkeys eat charcoal to reduce the harmful compounds, which have the potential to be toxic or interfere with digestion." Struhsaker says the young leaves of exotic trees, consumed by the monkeys living in gardens in this area of Zanzibar, are also high in protein and highly digestible. "This may explain why the birth rates and population densities of the colobus living in the Indian almond and mango habitat adjacent to the Jozani Forest are significantly higher than those in the ground water forest," he says. Cooney's book, "Activated Charcoal in Medical Applications," was published in 1995 as a comprehensive reference of research on medical uses of activated charcoal. His and other studies describe activated charcoal's effectiveness in treating overdoses and poisonings in humans and animals. The collaborative work by Cooney and Struhsaker has been published in two papers appearing in the International Journal of Primatology. A UW faculty member since 1981, Cooney is the author of more than 80 papers in refereed scientific journals. He served as head of the UW Department of Chemical Engineering from 1983-1990. His academic awards at UW include the Outstanding Graduate Teaching and Research Award and the Outstanding Undergraduate Teaching Award, both sponsored by Tau Beta Pi, the national engineering honorary.
--------
465-> Men Who Donate Blood May Reduce Risk Of Heart Disease, According To KU Medical Center Study
Story by Rosemary Hope KANSAS CITY, Kan. - Men who donate blood may reduce their risk of heart disease by up to 30 percent, according to a study led by David Meyers, M.D., professor of internal medicine and preventive medicine at the University of Kansas Medical Center. The study, "Possible association of a reduction in vascular events with blood donation," is published in the August issue of the journal Heart. The study supports the "iron hypothesis" which suggests that women are protected from atherosclerosis, or hardening of the arteries, because they have lower body stores of iron than men. Through menstrual blood loss, women have one-half the iron stores and suffer about one-half the heart attacks and deaths from heart disease as men of similar age. "What this means for men is - if you donate blood, in a sense you can become a virtual woman and protect yourself from heart disease," said Meyers. "We have identified another reason for blood donation, beyond altruism, for men." Subjects for the study were men and women, aged 40 or older, with no history of heart disease. They were drawn from the Nebraska Diet Heart Study, a 1985-1987 population-density-based and demographically representative study. The subjects were recontacted from 1992 to 1993 and surveyed about 39 items that included demographics, occurrences of heart disease or procedures, diet, cholesterol levels, smoking and blood donation. Of the 3,855 in the study, 655 reported donating at least one unit of whole blood in the preceding 10 years. Of the donor group, 9.77 percent reported "vascular events," defined as heart attack, stroke, angioplasty, bypass surgery and nitroglycerin use, compared to 17.72 percent of the non-donors. When the study group was divided into males and females, the benefit of blood donation was apparent only in the men. The benefit was negated in men by cigarette smoking. There was a much smaller benefit in reduced heart disease risk for women who donated blood. The observed reduction in vascular events can be explained in two ways, said Meyers. "Either iron depletion through blood donation truly affects atherosclerosis, or on the other hand, mainly healthy people who are at low risk of heart disease are blood donors." Meyers plans to conduct a randomized clinical trial of 4,000 men in the Kansas City area to determine which answer is correct. The results of the study may not prove that blood donation prevents heart disease, said Meyers. But the study does support the iron hypothesis, which suggests that stored iron in the body stimulates the process in which cholesterol is oxidized, an event that is thought to be involved in atherosclerosis. A smaller study published in March in the British Medical Journal supports the hypothesis also. This study reported that blood donation reduced the risk of heart attack by 86 percent among 2,682 Finnish men. "It could be a win-win situation," said Meyers. "Even if the iron hypothesis is proved incorrect, donating blood is still the right thing to do." Meyers' co-authors for the study are Daniel Strickland, M.S.P.H., Ph.D., Pierre Maloley, Pharm.D., and Jeanette Seburg, M.T.., all of the University of Nebraska Medical Center, Omaha; and Janet Wilson, M.T., and Bruce McManus, M.D., Ph.D., of the University of British Columbia, Vancouver, Canada. - KUMC - 
--------
466-> Scientists Discover Massive Jet Streams Flowing Inside The Sun
Scientists using the joint European Space Agency (ESA)/NASA Solar and Heliospheric Observatory (SOHO) spacecraft have discovered "jet streams" or "rivers" of hot, electrically charged gas called plasma flowing beneath the surface of the Sun.  They also found features similar to trade winds that transport gas beneath the Sun's fiery surface. These new findings will help them understand the famous sunspot cycle and associated increases in solar activity that can affect the Earth with power and communications disruptions.  The observations are the latest made by the Solar Oscillations Investigation (SOI) group at Stanford University, Palo Alto, CA, and they build on discoveries by the SOHO science team over the past year. "We have detected motion similar to the weather patterns in the Earth's atmosphere," said Dr. Jesper Schou of Stanford.  "Moreover, in what is a completely new discovery, we have found a jet-like flow near the poles.  This flow is totally inside the Sun.  It is completely unexpected, and cannot be seen at the surface." "These polar streams are on a small scale, compared to the whole Sun, but they are still immense compared to atmospheric jet streams on the Earth," added Dr. Philip Scherrer, the SOI principal investigator at Stanford.  "Ringing the Sun at about 75 degrees latitude, they consist of flattened oval regions about 17,000 miles across where material moves about 10 percent (about 80 mph) faster than its surroundings.  Although these are the smallest structures yet observed inside the Sun, each is still large enough to engulf two Earths." Additionally, there are features similar to the Earth's trade winds on the surface of the Sun.  The Sun rotates much faster at the equator than at the poles.  However, Stanford researchers Schou and Dr. Alexander G. Kosovichev have found that there are belts in the northern and southern hemispheres where currents flow at different speeds relative to each other.  Six of these gaseous bands move slightly faster than the material surrounding them.  The solar belts are more than 40 thousand miles across and they contain "winds" that move about ten miles per hour relative to their surroundings. The first evidence of these belts was found more than a decadeago by Dr. Robert Howard of the Mount Wilson Observatory.  The Stanford researchers have now shown that, rather than being superficial surface motion, the belts extend down to a depth of at least 12,000 miles below the Sun's surface. "In one way, the Sun's zonal belts behave more like the colorful banding found on Jupiter than the region of tradewinds on the Earth," said Stanford's Dr. Craig DeForest.  "Somewhat like stripes on a barber pole, they start in the mid-latitudes and gradually move toward the equator during the eleven-year solar cycle.  They also appear to have a relationship to sunspot formation as sunspots tend to form at the edges of these zones. "We speculate that the differences in speed of the plasma at the edge of these bands may be connected with the generation of the solar magnetic cycle which, in turn, generates periodic increases in solar activity, but we'll need more observations to see if this is correct," said DeForest. Finally, the solar physicists have determined that the entire outer layer of the Sun, to a depth of at least 15,000 miles, is slowly but steadily flowing from the equator to the poles.  The polar flow rate is relatively slow, about 50 miles per hour, compared to its rotation speed, about 4,000 miles per hour; however, this is fast enough to transport an object from the equator to the pole in a bit more than a year. "Oddly enough, the polar flow moves in the opposite direction from that of the sunspots and the zonal belts, which are moving from higher to lower latitudes," said DeForest. Evidence for polar flow previously had been observed at the Sun's surface, but scientists did not know how deep the motion extended.  With a volume equal to about 4 percent of the total Sun, this feature probably has an important impact on the Sun's activity, argue Stanford researchers Scherrer, with Dr. Thomas L. Duvall Jr., Dr. Richard S. Bogart, and graduate student Peter M. Giles. For the last year, the SOHO spacecraft has been aiming its battery of 12 scientific instruments at the Sun from a position 930,000 miles sunward from the Earth.  The Stanford research team has been viewing the Sun's surface with one of these instruments called a Michelson Doppler Imager that can measure the vertical motion of the Sun's surface at one million different points once per minute.  The measurements show the effects of sound waves that permeate the interior.  The researchers then apply techniques similar to Earth-based seismology and computer-aided tomography to infer and map the flow patterns and temperature beneath the Sun's roiling surface. "These techniques allow us to peer inside the Sun using sound waves, much like a doctor can look inside a pregnant woman with a sonogram," said Dr. Schou. Currently, the Stanford scientists have both identified new structures in the interior of the Sun and clarified the form of previously discovered ones.  Understanding their relationship to solar activity will require more observations and time for analysis. "At this point, we do not know whether the plasma streams snake around like the jet stream on Earth, or whether it is a less dynamic feature," said Dr. Douglas Gough, of Cambridge University, UK.  "It is intriguing to speculate that these streams may affect solar weather like the terrestrial jetstream impacts weather patterns on Earth, but this is completely unclear right now.  The same speculation may apply to the other flows we've observed, or they may act in concert.  It will be especially helpful to make observations as the Sun enters its next active cycle, expected to peak around the year 2001." - end - Images to support this story can be found at the following Internet address: http://pao.gsfc.nasa.gov/gsfc/newsroom/flash/flash.htm
--------
467-> Los Alamos Engineers Workin' On The Railroad
LOS ALAMOS, N.M., Aug. 26, 1997 -- Los Alamos National Laboratory engineers are applying their high-tech expertise to help engineers of another sort with an old problem: in a collaboration with the Association of American Railroads, Los Alamos is developing new alloys to extend the service life of railroad wheels. The research is tied to the largest Department of Energy railroad project ever conducted. DOE's Fernald Environmental Management Project in Ohio is scheduled to ship hundreds of tons of treated waste by rail to a disposal site in Utah. The AAR awarded Los Alamos $150,000 to begin the research. DOE Fernald matched the research grant. "If new alloys we help develop are accepted by the industry, it will affect rail wheels worldwide," said Dan Thoma, leader of the Laboratory's alloy development program. "Even a modest change in the life of the product can mean a savings of millions of dollars." "Los Alamos' unique equipment and metallurgical staff were the basis of the formation of this partnership," said Dan Stone of the AAR Transportation Technology Center. "And the Laboratory's relative proximity to the TTC's Pueblo, Colo., location helps ease problems with research planning, coordination and execution." When train wheels skid during braking, the tread of the wheels can reach temperatures over 1,600 degrees Fahrenheit. As soon as the train stops, the wheels cool quickly, causing a thin layer of steel to transform into a brittle, untempered form called martensite. The martensite causes shallow, widening cracks on the wheels, or spalling. Eventually, the wheel goes out of round and wrecks the surface of the tracks. The damage may lead to derailments. Because of spalling, the railroad industry must replace 75,000 wheels each year, at an annual cost of $70 million. These wheel defects also increase rolling resistance which increases locomotive fuel consumption. The industry estimates fuel costs rise about $50 per defective wheel, which means millions spent in total per year on extra fuel. Los Alamos will investigate alternative alloys that limit the formation of martensite or cause the steel to return to its crack-resistant form during rapid cooling. Researchers will investigate combinations of alloying materials, including chromium, silicon and cobalt. Although the railroad industry conducts large-scale research, Los Alamos' technical capabilities in metallurgy will allow rapid analysis and development of candidate alloys. "We have a complementary set of tools to do this research," said Thoma. One such tool is a device that can simulate the temperature changes and pressures that railroad steel goes through during braking. A "quench deformation dilatometer" can cool a sample 1,800 degrees per second and apply simulated loads, allowing Thoma to evaluate the thermal history of steel samples. "Even though it's been studied for years, steel is still an interesting material for research," said Thoma. "And alloy development is tied to the Laboratory's core mission, supporting maintenance and stewardship of the nation's nuclear weapons stockpile." Fernald contributed to support the research as an investment toward its massive environmental cleanup effort. For decades, Fernald refined raw uranium into metal used in production reactors at other Department of Energy sites to make plutonium and tritium for nuclear weapons. Now 473,000 cubic yards of waste pit materials and surrounding soils will be treated by a thermal-drying process. Then the treated waste will be loaded onto gondola rail cars for disposal at a licensed site in Utah. The cleanup will require shipping about 100 ore cars loaded with contaminated soil every 11 days for seven years. Los Alamos National Laboratory is operated by the University of California for the U.S. Department of Energy. -30- 
--------
468-> LSU Scientist On Team That Discovers Methane Ice Worms On Gulf Floor
BATON ROUGE -- LSU researcher Bob Carney was a member of a team of university scientists led by chief scientist Chuck Fisher of Pennsylvania State University who discovered what appears to be a new species of centipede-like worms that live on and within mounds of methane ice on the floor of the Gulf of Mexico. The ice worms, found in waters 1,800 feet deep, were viewed by scientists diving in Harbor Branch Oceanographic Institute's submersible Johnson Sea Link. Although scientists had hypothesized that bacteria might colonize ice mounds, called gas hydrates, this is the first time animals have been found living in the methane mounds. These hydrates are formed when water and natural gas, usually methane, come together where temperature is low and pressure is high, such as in deep ocean waters,and form a substance like dry ice. The discovery of dense colonies of one- to two-inch-long, flat, pinkish worms, called polychaetes, raises speculation that the worms may be a new species with a pervasive and as yet unknown influence on the energy-rich gas deposits. The worms had burrowed into a mushroom-shaped mound of methane seeping up from the sea floor. Using a research submarine on a National Oceanic and Atmospheric Administration-funded research cruise, scientists observed the worms using their two rows of oar-like appendages to move about the honeycombed, yellow and white surface of the icy mound. Carney, director of Coastal Marine Institute, said that "scientists would immediately have two questions. First, what are they living on? Logically, they are eating a film of methane bacteria. The second part of the question is more intriguing: If they are living off the methane, why aren't snails and small shrimp in the area also feeding off the methane?" "In the scheme of worms, these worms, Hesionidae, are large," Carney said. "They are very active. There are no other animals at that site. Though they are sitting on the side of a hydrated structure, the worms are not consuming the methane itself. They had drops of oil in their intestines. They may be scooping bacterial film off the rocks," he said. Harry Roberts, LSU coastal studies professor, was the first researcher to recognize the existence of solid methane outcrops on the floor of the Gulf of Mexico, Carney pointed out. Methane ice is usually buried deep in marine sediment. The Gulf of Mexico is one of the few places where hydrates can be found exposed on the ocean bottom, Carney said. Occasionally this seeping, solid methane bursts through in huge mounds, often six to eight feet across. Each new discovery of animal life on the Gulf floor raises questions, Carney said. Where did they come from? Why are they in this specific spot and not somewhere else? Why do some underwater communities live on radioactive rocks? How do the oil companies' deep-water drilling operations affect them? Minerals Management Service is charged with ensuring that colonies of fauna around seeps are not disturbed. MMS provides funding primarily to LSU and Texas A&M for ecological studies of seeps. "People think of LSU research in terms of coastal marshes and wetlands," Carney said, "and don't realize that LSU is also engaged in deep-water research." Geologically, the Gulf of Mexico "is a very exotic place. Ecologically, probably the most exotic places are the chemosynthetic communities about 100 miles off the coast of Louisiana, on the edge of the continental slope," Carney said. The one week expedition in July was carried out aboard the Harbor Branch research vessel Edwin Link and sponsored by the NOAA National Undersea Research Center at the University of North Carolina at Wilmington and the Minerals Management Service of the U.S. Department of the Interior. In addition to Carney and chief scientist Charles Fisher of Pennsylvania State University, principal investigators included Ian MacDonald of Texas A&M University, Steve Macko of the University of Virginia, and Alissa Arp and David Julian of San Francisco State University. -30-
--------
469-> Methods For Counting Airborne Bacteria Inadequate, Say Researchers
Current methods for detecting and counting airborne bacteria inenclosed buildings may be inadequate and understate the total number ofairborne organisms, say researchers from the University of Maryland andthe U.S. Environmental Protection Agency in the September 1997 issueof the journal Applied and Environmental Microbiology. Indoor air pollution has become a serious concern.  Newer, energyefficient buildings are usually sealed, recycling the air and increasing thenumber of bacteria in the environment.  An estimated 10 to 25 millionworkers in the United States show symptoms of "sick buildingsyndrome" (SBS) annually.  The role of airborne bacteria in SBS is stilllargely unknown but it is generally accepted that microorganisms areinvolved. In the study the researchers tested the effects of aerosolization onviability and colony-forming ability on several bacterial species.  Thebacteria were sprayed into glass containers and then total numbers werecounted by two different methods.  The first method was the methodtraditionally employed to determine indoor air quality where the thebacteria are cultured and the colonies formed are counted.  The other wasdirect staining and counting of viable bacteria.   The researchers foundthat less than 10 percent of the aerosolized bacteria were capable offorming colonies. "From these results it is concluded that the bacterial strains includedin this study did not respond to standard culture methods afteraerosolization," say the researchers.  "The plate [colony] count providesan estimate of only those few cells least affected by exposure to air."  (J.F. Heidelberg, M. Shahamat, M. Levin, I. Rahman, G. Stelma, C.Grim, and R.R. Colwell.  1997.  Effect of aerosolization onculturability and viability of gram-negative bacteria.  Applied andEnvironmental Microbiology 63:3585-3588.)
--------
470-> UF Researcher: Teens Who Drink Are More Likely To Be Sexually Active
Aug. 29, 1997 Writer: Cathy Keen Source: Daniel Perkins	(352) 392-2201 GAINESVILLE, Fla. --- Alcohol use is the best predictor of whether teen-agers are sexually active, regardless of their race or gender, a new University of Florida study finds. "One of the most effective ways to reduce teen-age pregnancy is to steer kids away from alcohol," said Daniel Perkins, a professor in UF's family, youth and community sciences department. "If we can target our prevention work at alcohol and engage kids in positive activities outside of school, we can decrease the odds they will be sexually active." Heavy alcohol use tripled the likelihood of teen-age sexual activity for white males, doubled it for Hispanic males and increased it by 18 percent for black males, the study found. For all females, alcohol use was the one risk factor that increased the probability of sexual activity by 10 percent or more. Research shows alcohol lowers inhibitions and interferes with people's ability to make sound decisions based on logic and thought, Perkins said. "If you're both drinking alcohol and a little out of it, it might seem like the right thing to do," he said. The study is based on a survey of more than 15,000 students between the ages of 12 and 17 in Michigan public schools in spring and fall 1994. It found that the average age at which teen-agers become sexually active is 14, said Perkins, who did the research with professors at Michigan State University and the University of Wisconsin. If the risk factors remain constant, the study found that a significantly higher proportion of black teen-age males were sexually active (79 percent) than Hispanic males (54 percent) and white males (37 percent). Similarly, black teen-age females were more likely to be sexually active (57 percent) than their Hispanic (38 percent) and white (33 percent) counterparts. "One possible reason for the high rates among African-Americans is, sexual activity involves less of a social stigma for them than for adolescents in other cultures," Perkins said. "Not only may it not be viewed as especially risky or taboo, but it may actually be considered normal or expected behavior. For Hispanics, it may be the influence of Catholicism on their culture that lowers the rates they engage in sexual activity." As with using heavy amounts of alcohol, getting low grades or experiencing peer pressure made teen-agers of both sexes and across all ethnic groups more likely to have intercourse, the study found. "Often what we see in early adolescence is that parents' involvement in school drops dramatically and they become too removed from their child's education," Perkins said. "Succeeding in class and after-school programs is important because it helps teen-agers to foster a sense of self that makes it easier for them to get through difficult times." Even though peer pressure plays a major role in teen-age decision making, it does not rule out the influence that parents can have, he said. "There is no doubt that teens turn to peers for advice on dating and other subjects, but if they have a really difficult question to ask in terms of their future -- like whether to go to college or pursue a career -- they're going to turn to their parents," Perkins said. Low church attendance and viewing God as unimportant in one's life increased the likelihood of sexual activity for white and Hispanic males, but not for black males. With females, lack of religious participation and viewing God as unimportant in one's life were risk factors for whites and blacks, but not for Hispanics, Perkins said. "The results of our study suggest that parents, programs and communities should focus their efforts on trying to decrease the risk factors and increase opportunities for adolescents to build the skills necessary to deal with difficult situations," he said. "For example, if you're a mom or dad, maybe making that extra effort to attend church services or allowing your child to participate in youth groups at church would be helpful. You could also encourage your teen to get involved in extracurricular activities that allow them to build their skills." -30-
--------
471-> Experts: Public Will Accept Irradiation In Wake Of Meat Recall
WEST LAFAYETTE, Ind. -- The Hudson Foods hamburger recall may be just what it takes to convince Americans that it's time to accept irradiation as another technique to safeguard their food supply, two Purdue experts say. Irradiation is little used and a lot misunderstood, but it can destroy the microorganisms responsible for food-borne illnesses and extend the shelf life of perishable foods. It is an FDA-regulated food preservation method, and currently it is allowed on foods such as spices, pork, poultry, and some fruits and vegetables. The FDA is considering approval for red meats. "It's really hard to process raw meat without getting some contamination on it, but if it's irradiated, the bacteria are killed," says April Mason, Purdue University Cooperative Extension Service assistant director and a foods and nutrition specialist. "Irradiation is one more safety precaution. It's not in lieu of other safety precautions, such as proper cooking, but irradiation destroys the organism before it reaches the consumer." Richard Linton, Purdue Extension specialist in food safety, says, "Cooking and irradiation are perhaps the only existing ways today to get rid of microorganisms on food." An instance where irradiation would've been particularly helpful, Mason explains, was last spring when microbial organisms on strawberries and raspberries -- foods that often aren't cooked -- caused an outbreak of food-borne illness. It also might have avoided the Hudson Foods recall of 25 million pounds of red meat, including hamburger patties, that may have been contaminated with E. coli, a microorganism that can cause illness and even death in those who consume it. A 1993 E. coli outbreak in the Pacific Northwest, in which hundreds of people were sickened and half a dozen children died, still lingers in people's memories. Food- borne illnesses are never far from the headlines, making Americans question the safety of their food supply. But consumers are reluctant to embrace irradiation because it is a technology they know little about and don't understand. George Pauli, director at the FDA Office of Pre-Market Approval, Division of Product Policy, says irradiating food doesn't make it radioactive, as some people believe. Pauli says the source of radiant energy is controlled and limited to cobalt 60 and cesium 137. "It's known that they can't make the food radioactive," he says. Different levels of irradiation are used on different foods, and those regulations may vary from country to country, Pauli says. Mason says all irradiated foods must be labeled with "radura," the international sign for irradiation, and must say that the food has been treated with radiation. So any consumer who's still hesitant to eat irradiated food can avoid it. Linton says, "If I had a crystal ball that could predict the future, I'd say the Hudson hamburger incident may lead to consumer acceptance of irradiation in the next four or five years." Mason agrees and adds: "Data show that consumers will accept food irradiation when they learn about it and taste irradiated food." She also says the recent E.coli outbreak may push along the approval process for irradiation of red meat. Pauli says the petition for irradiation of all red meat was received in July 1994. Since then, the petitioner's data have been studied to determine what effects irradiation may have on hamburger and other types of red meat. Three main areas studied are: whether any chemical changes occur that can cause toxicity, how the microbial profile changes, and whether the meat's nutrient value is affected. "The request is for all red meat to be approved at once," Pauli says, "but if we can do some ahead of others, then we may." Pauli says it's impossible to predict if and when approval may occur. After his staff members develop a recommendation, they must provide a written explanation of the reasoning behind their decision. When a final decision is reached, it and the rationale supporting it must be published in the Federal Register. Although a decision is effective immediately, 30 days are allowed for objections to be raised. "The decision must be legally and scientifically sound," Pauli says. "We must make sure nothing is overlooked." In the meantime, Linton recommends thoroughly cooking meat, keeping hands and cooking utensils clean, and avoiding cross- contamination. He says 1 tablespoon of bleach per gallon of water is a good sanitizer for food preparation areas. Some over-the-counter cleaning solutions are OK, he says, but consumers should read label directions carefully. ACS code/970829 Ag Mason.irradiate/9708f39 Sources: April Mason, (765) 494-8252; e-mail, masona@cfs.purdue.edu Richard Linton, (765) 494-6481; e-mail, lintonr@foodsci.purdue.edu George Pauli, (202) 418-3090 Writer: Andrea McCann, (765) 494-8406; e-mail. mccann@aes.purdue.edu
--------
472-> Yeast Gene May Hold Key To Universal Aging Mechanism
CAMBRIDGE, MASS. -- Researchers in the Department of Biology at the Massachusetts Institute of Technology may not have discovered the fountain of youth, but they have recently demonstrated that a yeast gene, SGS1, plays a crucial role in determining the life span of yeast cells. The biologists' research, reported in the August 29th issue of Science magazine, suggests scientists may be able to identify -- and perhaps, one day, to control -- a universal aging mechanism. The potential for discovering such a mechanism, at least among humans, arises from the fact that the SGS1 yeast gene has a DNA code that corresponds structurally to the human WRN gene. Yeast is an attractive organism for aging research because of the potential for researchers to isolate mutant cells with altered life spans. Mutations in WRN result in Werner's Syndrome, a disease with symptoms resembling a fast-forward aging process. The researchers predicted that experimental mutation of SGS1 genes would produce symptoms of aging in yeast cells. "We wished to determine the role, if any, of SGS1 in yeast longevity," stated the authors, David A. Sinclair, Kevin Mills, and Leonard Guarente, in their article, "Accelerated Aging and Nucleolar Fragmentation in Yeast SGS1 Mutants." From that simple beginning flowed a world of possibilities. Their groundbreaking work developed from research on aging processes in both yeast and human cells. What is common to both is a finite life span, and there are characteristics of aging found in old cells of each type. People suffering from Werner's Syndrome offer a scientifically compelling illustration of human aging, since mutations in the WRN gene had already been shown to cause premature aging. Their symptoms, which begin in early adulthood, include graying and loss of hair, osteoporosis, cataracts, atherosclerosis, loss of skin elasticity, Type II Diabetes Melitus, and a propensity for certain cancers. Adding a note of poignant urgency, Leonard Guarente, professor of biology at MIT, attached a pair of photographs to the original research paper. One showed a girl of fifteen; the other, the same girl at forty, her hair straggly and gray; her skin wizened and her eyes drooping unevenly, as if she were twice her real age. Werner's Syndrome sufferers appear to be twice their real age. Aged yeast cells, too, appear to be twice as old as they are in chronological time. What's more, they show up microscopically as enlarged cells with reduced capacities such as sterility. EARLIER RESEARCH Earlier research, published in the journal Cell in May 1997, measured yeast aging by determining the number of daughter cells that a mother cell can produce before dying. Mother and daughter yeast cells are differentiated microscopically on the basis of size -- mothers are larger than daughters. As mother cells grow older, they undergo a number of changes: an increase in cell size and slowing of the cell cycle; loss of mating potential; and a decrease in the ability of old mother cells to produce small daughter cells with full life span potential. The article in Cell, by Brian K. Kennedy and nine other authors, including Drs. Sinclair, Mills and Guarente, demonstrated that genes SIR2, SIR3, SIR4 and UTH4, determine life span in yeast. When these genes were deleted from a yeast strain, life span was significantly shortened. When they were overexpressed, the life span of mutant yeast extended way beyond that of the wild-type (i.e. un-mutated) strain. The research described in Cell showed that the gene products encoded by SIR2, 3, and 4 move from the telomeres to the nucleolus, thereby promoting longevity," said Professor Guarente. The article in Science reports further developments in the biologists' study of aging. The discovery of the action of SGS1, with its homologue in WRN, the rapid-aging gene, suggests we may one day discover what triggers and what slows the aging process itself. In their summary of the Science article, the MIT biologists wrote, "Our data show that deletion of SGS1 causes premature aging in yeast on the basis of three phenotypes: (i) the average life span of SGS1 cells is about 40 percent of wild type, (ii) SGS1 cells prematurely assume the aging-associated sterility, while mutations in other yeast genes do not result in a shorter life span, or do not exhibit the age-specific phenotype of sterility, and (iii) the Sir protein silencing complex redistributes from teleomeres to the nucleolus in old SGS1 cells, as observed in old wild type cells." The last part of their summary "harks back to the earlier paper. We also found that the effects of mutating SGS1 caused normal aging to occur at an accelerated pace," said Professor Guarente. "The finding raises the possibility of locating a general aging mechanism.  That would be important because we can study the aging process in a simple organism like yeast in order to learn general principles of aging," Professor Guarente said. In fact, the authors found that old SGS1 cells, mutant or old wild-type, display a novel change, fragmentation of the nucleolus. "Our findings indicate a particular cellular structure, the nucleolus, may be the Achilles heel as cells get old. The nucleolus contains highly repeated copies of the ribosomal DNS (rDNA). This repeated nature of the rDNA may render it less stable than the rest of the genome and thereby make it vulnerable to the fragmentation that we see in old cells. We think this fragmentation of the nucleolus is a cause of aging," said Professor Guarente. The research described in the current issue of Science opens the way for future study of the aging process. The next phase of investigation will include, said Professor Guarente, "one, establishing how general this mechanism of aging is in higher organisms, such as humans, and two, answering the question, can we find a way to slow down the fragmentation of the nucleolus as a way to slow down aging?" David Sinclair is supported by the Helen Hay Whitney Foundation and Kevin Mills by a National Institutes of Health predoctoral training grant. The Guarente lab is supported by a National Institutes of Health grant. -END-
--------
473-> Major Earth Science Spacecraft Reaches Critical Milestone
The first of NASA's Earth Observing System (EOS) Spacecraft, EOS AM-1, has reached a critical milestone with the delivery of its last science instrument, allowing completion of module testing and integration of the instruments and the spacecraft.  The last instrument arrived on Aug. 25. EOS AM-1 begins a new generation of Earth science - one that studies the Earth as a global system.  EOS will carry a complement of five synergistic instruments.  "We're absolutely thrilled to reach this milestone," said Dr. Robert Price, Director of NASA's Mission to Planet Earth Program Office at the Goddard Space Flight Center, Greenbelt, MD.  "We're now well on our way to having the spacecraft ready for its June 1998 launch." The next critical step for EOS AM-1 is to complete systems tests which validate the ability of the integrated spacecraft to withstand the harsh environment of space and to work with its ground system.  Following that, the spacecraft will be delivered to Vandenberg Air Force Base, CA, for launch processing. The EOS AM-1 spacecraft is being assembled and tested by Lockheed-Martin at its Valley Forge, PA, production facility. The EOS series spacecraft are the cornerstone of NASA's Mission to Planet Earth (MTPE) Enterprise, a long-term coordinated research effort to study the Earth as a global system and the effects of natural and human-induced changes on the global environment. EOS AM-1 will use this unique perspective from space to observe the Earth's continents, oceans and atmosphere with five state-of-the-art instruments with measurement capability and accuracy never flown before.  This unique approach enables scientists to study the interactions among these three components of the Earth system, which determine the cycling of water and nutrients on Earth. "EOS AM-1 will study simultaneously clouds, water vapor, aerosol, particles, trace gases, terrestrial and oceanic properties, the interaction between them and their effect on atmospheric radiation and climate," said Dr. Yoram Kaufman, EOS AM-1 project scientist.  "Moreover, EOS AM-1 will observe changes in Earth's radiation energy budget, together with measurements of changes in land/ocean surface and interaction  with the atmosphere through exchanges of energy, carbon, and water.  Clearly comprehending these interactive processes is essential to understanding global climate change," he said. A polar-orbiting spacecraft, EOS AM-1 is scheduled for launch in June 1998 aboard an Atlas-Centaur IIAS launch vehicle from Vandenberg AFB.  Because the AM series emphasizes observations of terrestrial surface features, its orbit is designed to cross the equator at 10:30 a.m., when cloud cover is minimalized. The Cloud's and the Earth's Radiant Energy System (CERES) instrument will perform measurements of the Earth's "radiation budget," or the process in which the Earth's climate system constantly tries to maintain  a balance between the energy that reaches the Earth from the Sun, and the energy that goes from Earth back out to space.  The components of the Earth system that are important to the radiation  budget are the planet's surface, atmosphere, and clouds. The Multi-Angle Imaging Spectroradiometer (MISR) will measure the variation of the surface and cloud properties with the view angle.  Meanwhile, the Moderate-Resolution Imaging Spectroradiometer (MODIS) will measure atmosphere, land and ocean processes, including surface temperature of both the land and ocean, ocean color, global vegetation, cloud characteristics, temperature and moisture profiles, and snow cover.  The Measurements of Pollution in the Troposphere (MOPITT) instrument is an infrared gas-correlation radiometer that will take global  measurements of carbon monoxide and methane in the troposphere.  The Advanced Spaceborne Thermal  Emission and Reflection Radiometer (ASTER) will measure cloud and vegetation properties, surface mineralogy, soil properties, surface temperature, and surface topography for selected regions of the Earth. The CERES, MISR, and MODIS instruments are provided by the United States; MOPITT by Canada; and ASTER by Japan.  Several hundred scientists from the U.S. and abroad have been preparing to take full advantage of EOS AM-1 observations to address key scientific issues and their environmental policy impacts. EOS is managed by Goddard for NASA's Mission to Planet Earth strategic enterprise, Washington, DC. -end- EDITOR'S NOTE:  For more information on EOS, access the EOS AM Project Homepage at URL:                   http://eos-am.gsfc.nasa.gov 
--------
474-> Materials Engineers Usher In Age Of Complex, 'Self-Organizing' Polymers
ITHACA, N.Y. -- Having mastered the world of simple polymers, materialsengineers will now turn their attention toward complex, "self-organizing"polymers.  And this will have a profound effect on our lives -- perhapswith the potential of keeping airplane wings free of ice, according to aCornell scientist in the latest edition of the journal Science (Aug. 29,1997). "This is the beginning of a new age in polymer research," said ChristopherK. Ober, associate professor of materials science and engineering in theCollege of Engineering, Cornell University.  "Right now, we use simplepolymers like plastic in our everyday life; it's nothing special anymore.But with new, complex polymers, we could have materials where, for example,the surfaces may be designed to be markedly different from the polymerinterior.  Another example is a super-strong polymer with a water-repellentsurface that could be used for an airplane wing that doesn't ice up.  Andwe're taking the first steps into that new age." Ober says that in the new age of complex, self-organizing polymers made byborrowing the self-processing behavior and complex functions of naturalpolymers, different types of products are beginning to emerge.  Complexpolymers are now seen as useful for films and surfaces, replete withmultiple, self-growing layers, each with different functions.  He adds thatthrough spontaneously grown cylinders within a polymer structure,technology could use such cylinders for molecular-scale wires -- wires assmall as 100 angstroms in diameter.  "We can do this by controlling themolecular geometry of the polymer," he said.  "With these new types ofpolymers, we are beginning to build in the same complexity as biologicalsystems." Murugappan Muthukumar of the University of Massachusetts at Amherst, EdwinL. Thomas of the Massachusetts Institute of Technology, and Ober publishedthe invited article in Science,  called "Competing Molecular Interactionsand the Formation of Ordered Structures on Different Length Scales inSelf-Organizing Polymeric Materials."  This article is among six in aspecial section on microstructural engineering of materials. Funding for this research into complex polymers has been provided by theOffice of Naval Research Laboratory, the Air Force Office of SponsoredResearch and the National Science Foundation. The research was carried outby Jianguo Wang, Cornell postdoctorate associate in materials science andengineering, and Guoping Mao, Cornell senior researcher in materialsscience and engineering. Sophisticated use of self-organizing materials, which include liquidcrystal, block coploymers, hydrogen-bonded complexes and many naturalpolymers, may hold the key to developing new structures and devices in manyadvanced technological industries.  Now, synthetic structures are designedwith only one structure forming process in mind, Ober said.  With complex,self-organizing polymers, molecular-scaled, multilayered devices can bebuilt with each layer -- for example on a film -- for a purpose. "Imagine growing different layers for different functions," said Ober."This has possible applications for biotechnology, sensor development, evensmart surfaces.  An example where complex polymers could be used would besensors made using this technology, where we might soon be able to monitorblood properties or other biological functions.  Some day it might bepossible to produce such microelectronics sensors directly from a complexpolymer in a single processing step." -30-
--------
475-> University of Florida Researchers Hope To Shed Light on Questions Brewing Over Caffeine Consumption
By Melanie Fridl Ross GAINESVILLE, Fla.---Tobacco and nicotine are under fire and going up in flames. Now coffee and caffeine are the latest substances to be put under the addiction microscope. University of Florida researchers are studying the substance's physical and mental effects, which could have broad implications for optimizing human performance, says University of Florida clinical psychologist Jon Kassel. Kassel and his colleagues at UF's College of Health Professions are administering 8-ounce cups of coffee -- which may or may not contain varying levels of caffeine -- to regular coffee drinkers ages 18 to 65 in a study examining caffeine's role in determining mood and performance. After imbibing the beverage, they complete questionnaires and conduct simple performance tasks. "There is a healthy debate right now as to how significant caffeine habituation is," said Dr. Allen Neims, professor of pharmacology, therapeutics and pediatrics at UF's College of Medicine. "The coffee hour is a big social event. When you visit someone's house they offer you a cup of coffee. Are you taking it to avoid withdrawal symptoms or are you taking it because you like the fresh feeling it gives you? Or are you taking it out of social custom?" At first glance, the current interest in caffeine research could have coffee klatchers clutching their cups. But never fear: Physicians aren't dispensing with the morning cup of joe or the chocolate bar just yet. Caffeine consumption has certainly never been designated a social ill, though people do become caffeine-dependent, and regular users can experience mild withdrawal symptoms when they abruptly halt their daily habit. Kassel, an assistant professor in the department of clinical and health psychology at UF, said his team hopes to understand what it is about caffeine that is so rewarding for people. "Such information could someday lead to more effective treatments for those who want to quit or give up their dependence on caffeine," he said. The timing couldn't be better. Although caffeine has always been in our midst, the American appetite for it seems to be growing. "Caffeine is the world's most commonly used mood-altering drug, and it deserves more study," said Dr. Roland Griffiths, a professor in the departments of psychiatry and neuroscience at the Johns Hopkins University School of Medicine. "In low doses it increases feelings of well-being, the ability to concentrate and energy levels. At high doses, it produces jitteriness, restlessness, anxiety and insomnia. "Caffeine is so ubiquitous in our culture and so widely accepted that exposure to it is almost universal, and it is habitual," he added. "So many people are caffeine- dependent that many don't recognize the extent to which their preference for various foods and beverages is actually being guided by the underlying pharmacology of caffeine, instead of what they think are simply taste and food choices. So it's a subtle effect." Caffeine is widely consumed in coffee, tea, cocoa, soft drinks and chocolate. It also is a component in hundreds of prescription and over- the-counter drugs, ranging from analgesics to cold medicines. Researchers are quick to emphasize regular caffeine use should not be confused with the abuse of life-threatening drugs such as cocaine or nicotine, or heavy alcohol consumption. "Caffeine is a drug, but it has nowhere near the kinds of risks associated with conventional drugs of abuse," Griffiths said. "Nonetheless, it is a very important compound to study further." Most published studies have shown caffeine has its biggest effects on performance and mood when people are bored and tired, Neims added. "In a sense it revitalizes you -- the so-called 'pause that refreshes,' " he said. "It's as much a social issue as it is a pharmacologic one: The issue merits political, social and economic debate as much as it deserves scientific scrutiny. "Harvard psychobiologist Peter Dews studied the whole issue of habituation, and he said, just remember how we evolved, from creatures who spent most of the time either running away from something that wanted to eat you, or chasing something you wanted to eat. Every so often you'd find safety in a cave to sleep and procreate. Your epinephrine was pumping the rest of the time. Now all of a sudden here we are expected to come to work at 8, leave at 5, and work steadily throughout the day. Is it any surprise we found it a necessity to invent the coffee break?" --------------------------------------------------------------------------------	Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.html
--------
476-> Lewis Spacecraft Encounters Difficulties; Solar Arrays Unable To Generate Full Power
NASA's Earth-orbiting Lewis spacecraft has entered a spin that has disrupted the spacecraft's power-generating capability, raising the potential of the loss of the mission. Lewis was launched successfully on Aug. 22 at 11:51 p.m. PDT from Vandenberg Air Force Base, CA, aboard a Lockheed Martin Launch Vehicle (LMLV-1).  Built by TRW Space & Electronics Group, Redondo Beach, CA, Lewis is part of NASA's Small Spacecraft Technology Initiative. Initial operations and check-out of Lewis were proceeding satisfactorily until telemetry received at 6 a.m. EDT today (Aug. 26) at the mission's Chantilly, VA, control center indicated that the spacecraft was spinning at approximately two revolutions per minute.  Preliminary indications are that excessive thruster firing had occurred on one side of the spacecraft, causing it to spin when it should be stable on all three axes. The solar arrays on Lewis were unable to generate full power due to the spinning motion, and the batteries were discharged below operational levels.  Four subsequent attempts to contact the spacecraft were unsuccessful. "The excellent performance of the launch vehicle put Lewis into an optimal circular parking orbit that provides us with a minimum of three weeks to try to resolve this anomaly," said Samuel Venneri, Chief Technologist at NASA Headquarters in Washington.  "In addition, Lewis carries several autonomous systems onboard that raise the possibility that it can correct itself and recharge the batteries.  NASA and TRW are working hard to assess and better understand the situation, in order to establish a recovery plan and try to resume the mission." Outfitted with advanced technology Earth-imaging instruments and subsystems intended to push the state-of-the-art in scientific and commercial remote sensing, Lewis features remote sensing instruments designed to split up the spectrum of light energy reflected by Earth's land surfaces into as many as 384 distinct bands.  Potential commercial applications include pollutant monitoring, analysis of endangered species habitats, estimation of forest and agricultural productivity, soil resources and crop residue mapping, and assessments of environmental impacts from energy pipelines. The total cost to NASA of the Lewis mission, including its launch vehicle and one year of orbital operations, is $64.8 million.  NASA incurred an additional cost of $6.2 million for storage and maintenance of the spacecraft during a one-year delay due to launch vehicle issues. Lewis is part of NASA's Mission to Planet Earth enterprise, a long-term research program designed to study the Earth's land, oceans, air and life as a total system. -end-
--------
477-> Wildlife Rabies Won't Cross Vaccination Barrier Zones In New York, Vermont
ITHACA, N.Y. -- The northward spread of raccoon rabies can be halted byvaccination barrier zones, veterinarians and wildlife biologists at theCornell University College of Veterinary Medicine are predicting. A preliminary assessment of vaccine trials in New York, Vermont and Ohio,where oral vaccines are dropped from aircraft into raccoon rabies-freeareas, points to the barrier zone strategy as the most promising way toprevent further spread of the disease, the Cornell experts say.  But thevaccination barrier should be extended across northern New Hampshire andMaine, they recommend, before treating East Coast states that already areinfected with wildlife rabies. "The vaccination barriers appear to be holding," said Donald H. Lein,D.V.M., Ph.D., director of the Diagnostic Laboratory at the CornellUniversity College of Veterinary Medicine, where the anti-rabies campaignfor the Northeast is based.  "We're ready to establish the same kind ofbarriers in Maine and New Hampshire.  This problem calls for a regionalapproach, because sick raccoons don't stop at state lines." Or at international borders, either.  That's why Ontario and other Canadianprovinces are interested in aiding the U.S. anti-rabies effort, said LauraL. Bigler, Ph.D., coordinator of the Cornell vaccination program.  Aparallel effort to vaccinate Canadian foxes has all but eliminated foxrabies from southern Ontario, Bigler reported.  Ontario and Quebec haveprovided financial and in-kind assistance to the Cornell project in hopesof keeping raccoon rabies from spreading across the U.S.-Canada border andinfecting Canadian raccoons. The Cornell wildlife rabies control program uses an oral rabies vaccine,Raboral, that was fully approved earlier this year by the U.S. Departmentof Agriculture's Center for Veterinary Biologics.  Capsules of the vaccineare concealed in flavored baits that are dropped from aircraft ordistributed by hand in populated areas.  Besides raccoons, the same vaccinehas been shown to control rabies in coyotes as well as red and gray foxes. Cooperation of several federal, state, county and provincial agencies wasrequired to initiate the rabies-control programs in strategic regions ofNew York and Vermont.  Beginning in 1995, Cornell developed a regionalrabies-control strategy for raccoons in the Northeastern United States. A vaccination zone also has been established in Ohio, said Bigler, whoassisted the effort in that state.  "But additional zones are required inMaine and New Hampshire to complete the barrier strategy.  Then we canbegin the second phase, gradually moving the vaccination zones southwardinto infected areas to attempt to eliminate this disease altogether," shesaid. Raccoon rabies was first diagnosed in the United States in Florida in 1947.The viral disease made a great leap northward in the late 1970s, when anestimated 3,500 raccoons were transported from Florida to Virginia.  Sincethen, raccoon rabies has spread to parts of every eastern state, from Maineto Florida. Although coyote rabies is found in Mexico and fox rabies occurs in Canada,neither country has reported the raccoon variant of rabies, Bigler noted,and the Appalachian Mountains serve as a natural barrier to contain raccoonrabies to the East.  Consequently, the elimination of raccoon rabies from arelatively small area, the East, may be possible with vaccination, she said. Compared with the cost of treating rabies in the United States, anestimated $200 million to $1 billion a year, the cost of preventing raccoonrabies is much less but it is not inconsequential, Lein said. "The vaccine baits are expensive.  That's why we're fine-tuning our programby using the smallest possible number of baits per square mile andvaccinating annually, in the fall instead of twice a year to keep theoverall costs as low as possible.  We also need to test different baits tosee if there are any 'raccoon favorites,' while also collecting informationabout how far apart the baits can be placed.  In the long run, we predictthat a coordinated, unified program to eliminate raccoon rabies will bemuch less expensive than individual state and provincial initiatives thatare performed in isolation," Lein said. Lein, the Cornell Diagnostic Laboratory director, called for congressionalaction to appropriate federal funds through the Animal Damage Control unitof the USDA's Animal and Plant Health Inspection Service (APHIS).  Thatunit, in cooperation with USDA Veterinary Services, universities, producerorganizations, federal and state agencies, already administers eradicationprograms for other diseases that impact people, domestic animals andwildlife, such as brucellosis, tuberculosis and pseudorabies, Lein observed. "USDA-APHIS-ADC should be granted the authorization and fiscal resources toproceed to carry out their mandate to control this disease withestablished, coordinated programs such as the Cornell control program forraccoon rabies," Lein said.  "Vaccination of wildlife will protect people,pets and livestock from this fatal disease." -30- 
--------
478-> Berkeley Lab Scientist Designs Self-Assembling Composite Materials At Nanometer Scale
BERKELEY, CA -- Nature has used self-assembling materials forstructures measured in nanometers (billionths of a meter) for hundredsof millions of years -- as components of living cells -- but humanattempts at nanoscale manufacture have been confined mostly to buildingstructural materials a few atoms or molecules at a time. That state ofaffairs may be on the verge of change. Douglas Gin of the Materials Sciences Division at the Ernest OrlandoLawrence Berkeley National Laboratory, Assistant Professor of Chemistryat UC Berkeley, has devised a general technique for engineeringnanocomposites that begins with the self-assembly of synthetic startingmaterials. Early in the twentieth century chemists began coaxing simplematerials to assemble themselves into microscopic structures such aslayered films and liquid crystal phases, but remarkable as they were,these structures lacked the sophistication of natural composites. Teeth,bones, and shells demonstrate how cleverly nature assembles differentmaterials into a variety of useful composites at the cellular level.Bone, tough but not brittle, consists of layers of collagen proteinincorporating crystals of inorganic calcium phosphate; the samematerials in a different ratio, with only a few percent protein, yieldthe hardest material produced by living things, tooth enamel. Not proteins but polymerizable liquid crystals form the skeleton ofDouglas Gin's unique new composites, matrices containing stacks ofhexagonally packed tubes whose diameter and spacing is measured innanometers. These ordered tubes contain a chemical precursor insolution, which can be converted to solid filler material after thearchitecture of the liquid-crystal matrix has been locked into place bypolymerization. Unlike the sort of liquid crystals found in digital displays, whichchange in response to temperature or an electromagnetic field, Gin useslyotropic liquid crystals; in addition to changes in temperature, theserespond to additives and changes in the chemical solution in which theyare immersed. "The design of unique lyotropic liquid crystals is the key toeverything that follows," says Gin. Basically, he works with chemicalsknown as polymerizable surfactants. "Like laundry soap, they're made ofamphiphilic monomers" -- molecules, each of which has a hydrophilic(water-loving) end and a hydrophobic (water-fearing) end. When theamphiphilic molecules of laundry soap form a droplet in water, all theirwater-loving heads point outward and their water-fearing tails pointinward -- where they may surround a glob of grease or dirt. Thetechnical name for a soap droplet is "micelle;" by adding more and moremonomers, spherical micelles can self-organize and lengthen intocylinders. Instead of submerging his monomers in water, Gin reduces the amountof water in his system and designs monomers to form "inverse"cylindrical micelles with their water-loving heads inward. Meanwhile thewater-fearing tails on the outside of the tubes seek each other'scompany, and the tubes pack themselves into hexagons, the tightestpossible geometric packing arrangement. After the hexagonal architectureis locked in place, says Gin, "We can do ordinary synthetic-organicchemistry inside the channels." Using two different kinds of monomers and two different fillerprecursors, Gin and his colleagues have already demonstrated two novelself-organizing nanocomposites with unique properties. In one techniquethe liquid-crystal matrix has been formed in a solution containing aprecursor to poly(para-phenylenevinylene) -- a light-emitting,electrically conducting polymer, more often called PPV -- which fillsthe tubes. When Gin turns up the heat, the precursor converts to PPVinside the tubes to form what is effectively a bundle of long, discrete,exceedingly fine wires. His group has made uniformly oriented films ofthis material up to eight centimeters wide, yet only 30 to 100 micronsthick. Nanoscale materials often show markedly different properties fromthe same materials in bulk, and PPV is no exception: GinÕs hexagonalmatrix of PPV has over twice the fluorescence, per unit volume, of PPVin bulk. In related work, Gin is studying an entirely different liquid-crystalsystem, which uses a different monomer to build the hexagonal-tubeframework and a different filler precursor, tetraethyl orthosilicate, ina solution of water and ethanol. The sol 
--------
479-> Psychiatric Symptoms May Signal Brain Damage From Diet Pills
Users of widely prescribed diet pills may suffer irreversible loss of brain serotonin nerve terminals, possibly resulting in symptoms of anxiety, depression, cognitive and sleep problems, suggests the first author of a newly published report on fenfluramine side effects. National Institute of Mental Health researcher Una McCann, M.D., and colleagues, report on their review of 90 animal studies on serotonin neurotoxicity and primary pulmonary hypertension from fenfluramine and its chemical cousin dexfenfluramine, in the August 27 issue of the Journal of the American Medical Association. An estimated 50 million people have taken the drugs, often in combination with phentermine (hence "fen/phen"), an amphetamine-like diet drug that counteracts the fenfluramines' tendency to induce drowsiness. The study cautions that if the animal findings apply to humans, the brain damage "would be expected to occur in almost everyone taking a dose sufficient to achieve weight loss." "I think there is cause for concern that people who take fenfluramines are at risk for a host of problems," said McCann, chief of anxiety disorders research in the NIMH Biological Psychiatry Branch, Bethesda, MD. "A dose comparable to that prescribed to reduce weight in humans causes neurotoxicity in monkeys." "It might be justifiable for someone who is morbidly obese and hence at risk for serious health problems, but not for a person who just wants to lose a few pounds for cosmetic reasons," explained McCann. "Many people who try diet pills quickly regain their weight after they stop taking the drugs, so they might be tempted to continue taking them. We won't know the long-term risks of these drugs until controlled studies are completed in humans." In one study reviewed, monkeys' brains continued to show signs of damage 17 months after taking a course of the drug. Much like the branches of a tree, neurons contain extensions called axons that transport messenger chemicals like serotonin and form synapses -- connections with other neurons. Fenfluramines damage serotonin-secreting neurons by pruning these axons, which do not grow back in monkeys, although studies show that they do in rodents. And since human brains are more like those of monkeys, any such damage in humans would also likely be permanent, according to McCann. "However, the neurotoxic potential of fenfluramines in humans has not been systematically evaluated," write the researchers. Moreover, "the functional consequences of brain serotonin neurotoxicity are largely unknown," even though the neurotransmitter is thought to be important "in a variety of brain functions, including cognition and memory and the regulation of mood, anxiety, impulsivity, aggression, sleep and neuroendocrine function." In fact, McCann cites case reports that some users have experienced psychiatric disorders, which, she points out, tend to be under-diagnosed in clinical practice. Studies also document that fenfluramines increase the risk for developing primary pulmonary hypertension, a rare, but incurable and life threatening illness. The researchers advise doctors to be vigilant for both behavioral and cardiopulmonary side effects, and that patients be apprised of the risks and benefits of fenfluramines for weight loss. Also participating in the study were: Lewis Seiden, Ph.D., University of Chicago; Lewis Rubin, M.D., University of Maryland; George Ricaurte, M.D., Ph.D., Johns Hopkins University. The study was supported by the NIMH Intramural Research Program and grants from the National Institute on Drug Abuse (NIDA). NIMH and NIDA are components of the National Institutes of Health, an agency of the U.S. Department of Health and Human Services.
--------
480-> Female Fruit Flies Pay A High Cost For Mating But Not For Egg-Laying, According To University Of Georgia Geneticist
ATHENS, Ga. -- When it comes to reproductive fitness, it seems that mother knows best -- at least when mother is Drosophila melanogaster, the common fruit fly. In a new analysis of earlier data, two scientists have found that the act of mating is far more harmful to females than the act of egg laying. The differences are so striking, in fact, that the study may give clues to how females help control their own reproductive fitness, according to a University of Georgia geneticist who is co-author of the research, to be published in the journal Evolution. "We propose that when females are in control, the costs to their reproductive fitness is minimal," said UGA's Dr. Daniel Promislow. "On the other hand, when males are in control, the costs are substantial." Co-author of the paper is Dr. Marc Tatar of the University of Minnesota. Scientists have long known there is a tradeoff between reproduction and survival in the animal kingdom, but only recently have new studies in evolution begun to focus on issues of male versus female control. The tradeoff between reproduction and age-specific survival has been widely studied, but Promislow and Tatar in their new analysis focus on the fitness cost of reproduction rather than the survival cost. Fruit flies are an especially fecund subject for such studies because of their mating habits and short lifespan, which covers from 30 to 90 days. Males and females engage in an elaborate mating ritual, during which males vibrate their wings in a "courtship song" and actually lick the females they choose. Copulation can last anywhere from a few minutes to several hours (depending on the species), during which the male injects into the female seminal fluid that included sperm and fluid from an organ called the accessory gland. "It gets interesting at this point, because some sperm and the accessory gland fluids are stored in organs called spermathecae," said Promislow. "And the function of the accessory gland proteins appears to be to displace sperm from previous males or prevent the storage of sperm from future matings." This chemical arms race has serious consequences for the females, who are subjected in this case to reproductive costs imposed by the males. This sperm competition, in fact, appears to occur at the expense of female survival. Both mating and the receipt of accessory gland fluid lead to an "almost immediate depression of female survival" and thus causes a great reduction in reproductive value. Egg production, which is controlled largely by the female through feeding and other environmental strategies, also reduces female survival, but only relatively late in life when its effect of reproductive fitness is minimal. The distinction between male- and female-controlled reproductive activities may seem fine, but the potential effects on evolutionary history are considerable. Promislow and Tatar base their new model on earlier work done by Dr. Linda Partridge and Dr. Kevin Fowler. That work examined tradeoffs between egg production, mating and the receipt of products from male accessory gland fluid from fruit flies. Also important was work by Dr. Tracy Chapman, who determined that the mating cost of reproduction was influenced by the receipt of the male accessory gland fluid. The work of Dr. Larry Harshman and Tim Prout added to the study, since they first suggested that the main cell products of accessory gland fluid may be involved in sperm competition. Interestingly, Promislow and Tatar found that the fitness costs of mating or the receipt of accessory gland fluid are substantial when a population size is decreasing but modest under conditions of population growth. "We also found that fitness costs of egg production, however, are not strongly influenced by the rate of increase in the population," said Promislow. While the evidence for female-controlled versus male-controlled reproductive fitness seems clear enough in the laboratory, it remains unknown whether or not the same is true in the natural world. Promislow and Tatar acknowledge that the difference in fitness costs of mating "might be an artifact of how flies are treated in the laboratory." For example, fitness costs of mating might be lower in the field than in the laboratory if females in the field encounter males less often than when they are confined in vials. At the same time, fitness costs of egg production may be greater in nature than in the laboratory if adult nutrients are abundant in the laboratory and scarce in the field. As well, females' abilities to avoid predators in the natural world may be affected by egg load. Still, the new work makes clear that a full understanding of the evolution of life history strategies must incorporate behavioral and even physiological interactions between males and females. "At the very least, we need to start distinguishing the costs that are under the female's control from those that aren't," said Promislow. -30-
--------
481-> NIH's Genbank Database Logs Billionth Base Milestone Reflects Explosive Progress Of DNA Research
(Bethesda, MD)- The National Library of Medicine, one of the National Institutes of Health,announced the achievement of a major milestone in molecular biology and the Human GenomeProject: the addition of the one billionth base to the NIH's GenBank DNA sequence database.This achievement reflects the explosive progress of molecular biology in understanding the geneticblueprint and paving the way for exciting breakthroughs for science and medicine in the 21stcentury. Said Donald A.B. Lindberg, M.D., director of the National Library of Medicine: "The future timeof fully understanding human genetics is fast approaching. This work is greatly speeded by suchcontributions from around the world-and by the study of genetic observations from plants,microorganisms, and animals. Congratulations to all who have shared these priceless geneticdiscoveries." DNA is the molecular "book of life," containing all the instructions necessary to build a livingorganism, whether an AIDS virus, a rice plant or a human being. These instructions take the formof a long, twisted, ladder-like DNA molecule that forms one or more chromosomes. Fourmolecular subunits, called bases and represented by the letters A, T, G and C, are arranged inmatched pairs that form the rungs of this molecular ladder. It is the sequence of these four lettersalong the length of the DNA molecule that determines all of our inherited biological characteristics. The GenBank database now contains nearly 10 percent of the human genome, as well as genesequences from more than 25,000 other species. GenBank is accessed by some 40,000researchers every day at the Web site http://www.ncbi.nlm.nih.gov/. GenBank is built andsupported by the National Center for Biotechnology Information (NCBI), a division of the NationalLibrary of Medicine. "As GenBank grows and becomes ever more comprehensive," said David J. Lipman, M.D., theCenter's director, "its value to the research community grows as well. And this deeperunderstanding of biology will lead to new opportunities in biotechnology and breakthroughs inhealth care." NCBI is also responsible for two other biomedical information systems recently in the news:PubMed and the Cancer Genome Anatomy Project (CGAP). PubMed, which provides freeWeb-based access to the NLM's MEDLINE database of medical literature, was demonstrated byVice President Gore at a press conference June 26th. CGAP, a database of scientific informationabout cancer genes, was launched by the Vice President and the Director of the National CancerInstitute, Dr. Richard Klausner, at an August 1st press event. More information about NCBI and GenBank is available through the Web site, via e-mail toinfo@ncbi.nlm.nih.gov, or by telephone at 301- 496-2475. # # # # #
--------
482-> Researcher Calls For More Careful Use Of Biological Controls
Using introduced plants or animals to attack undesirable species, though a valuable     tool for agriculture and conservation, can cause widespread damage to native     organisms. Too little attention is paid to that potential "dark side" when     biological-control projects are approved in the United States, says an authority on     plant-insect interactions at the University of California, Davis. Donald R. Strong, a highly respected UC Davis professor of evolution and ecology,     examines new evidence of "biocontrol gone haywire" in the Aug. 22 issue of the     journal Science. Strong reviews a report in the same issue from the University of Nebraska, Lincoln,     that a Eurasian weevil widely released in the United States and Canada has     sometimes reduced its target population -- non-native thistle plants that overrun     livestock grazing areas -- but also turned its appetite to five native thistle species. Some of the native plants' seed production has been cut by 86 percent, dramatically     hurting the plant's ability to reproduce. The weevil also appears to be pushing aside     native picture-wing flies, which normally feed on the native thistles' flower heads. And the weevil's distribution has expanded substantially, both naturally and through     introductions that continue today. Since it was first released in 1968, the Eurasian     weevil has been found in 24 states from California to New Jersey, and every     Canadian province except Alberta. Strong writes that the collateral attacks should come as no surprise: They have     occurred in similar biocontrol projects, and there was evidence before the weevil     releases began that the Eurasian bugs would like North American cuisine. Carefully planned biological control, Strong writes, can provide great economic     benefit, reduce the use of chemical pesticides, and even protect native species against     non-native predators or competitors. However, he said in an interview, too few     biocontrol projects get the requisite care. "This is a huge policy issue for the United States," Strong said. "There's tremendous     pressure from the agriculture industry -- and the industries that supply agricultural     biological controls -- to find new agents, release them, and then go find more, without     adequate study of their effects. "It is important for us to start a broad public discussion about the conservation and     environmental issues surrounding biological control." In the Science article, Strong says it's essential to establish experimentally that the     proposed control agent has an extremely limited "host range" -- that its food     preferences will keep it focused on its intended target, not native species. "Biological control is an important arrow in the quiver of pest management, perhaps     the only arrow in some cases of pests of grave concern," Strong writes in conclusion.     "However, willy-nilly biological control without regard for environmental costs" can     clearly have serious consequences. Media contacts:     -- Donald R. Strong, UC Davis Bodega Marine Laboratory, (707) 875-2211,     drstrong@ucdavis.edu.     -- Sylvia Wright, News Service, (916) 752-7704, swright@ucdavis.edu. Additional source:     -- Mary Louise Flint, director of integrated pest management education and     publications, UC Davis, (916) 752-7692, mlflint@ucdavis.edu.
--------
483-> Hopkins-HHMI Researchers Discover A Cause And Develop Test For Familial Colorectal Cancer -- A Gene Test Is Now Available For New Mutation
Researchers at The Johns Hopkins Medical Institutions and the Howard Hughes     Medical Institute (HHMI) have identified the first known genetic mutation that causes     familial colorectal cancer (FCC). The mutation causes the cancer through a     completely novel mechanism once considered harmless, and is present in over     one-half million Ashkenazi Jews, making it the most common cancer-related mutation     now known. Using this discovery, researchers have developed a simple blood test to     identify the mutation. Their findings are reported in the September 1, 1997, issue of     Nature Genetics. FCC accounts for between an estimated 15-50 percent of all colorectal cancers, but     until now its genetic basis has been a mystery, according to Bert Vogelstein, M.D.,     Clayton Professor of Oncology, HHMI investigator, and co-director of the research.     The mutation occurs in a cancer-causing gene called APC, which was previously     identified by the same Hopkins researchers and had been linked to a less common     form of hereditary colon cancer known as familial adenamatous polyposis (FAP). The researchers believe that those who have this APC mutation have an estimated     20-30 percent lifetime risk of developing colorectal cancer. "Though they are at     increased risk for the disease, it can be detected at an early and curable stage through     regular diagnostic screening tests such as sigmoidoscopy and colonoscopy," says     Frank Giardiello, MD, associate professor of medicine. Genetic counseling should be     provided to all patients tested for the APC mutation, says Giardiello. The Hopkins team says the newly identified APC mutation and the way it functions     are unique. "The mutation itself is harmless. It does not actually change the function of     the gene through the loss or insertion of genetic material, as is the case with most     cancer-related genetic mutations," says Kenneth Kinzler, Ph.D., associate professor     of oncology and co-director of the study. "Instead, what we've found is a subtle     alteration in the genetic code that causes DNA instability and leads to hypermutability,     or a cascade of mutations in surrounding sequences. These subsequent mutations are     what actually causes the cancer," says Kinzler. Genetic variations such as these, often referred to as polymorphisms, have long been     known to researchers, but Vogelstein says they were thought to be junk pieces of     DNA that had no bearing on disease. "The new research suggests that many of these     polymorphisms will have to be re-examined in future studies to see if they also cause     hypermutability," he says. The researchers first identified the mutation in two unrelated individuals with benign     colon tumors and family histories of colon cancer. They went on to study 766     Ashkenazim, believing the genetic similiarity of this group might provide insights into     the causes of FCC. In fact, they found the mutation in over 6 percent of those     studied. The researchers then studied blood and tissue samples of 211 Ashkenazi Jewish     colon cancer patients. They found that one in six of those patients who developed     cancer prior to age 66, and one in eight of those who developed colorectal cancer at     any age, had the mutation. The mutation was found in nearly one-third of Ashkenazi     patients with a family history of colorectal cancer. Patients with FCC generally have one or two family members with colon polyps or     cancer and typically develop colon tumors in their fifties and sixties. While FCC is     believed to account for a larger percentage of total colon cancers occurring in the     U.S., it is often difficult to distinguish it from non-hereditary colon cancer. "Until now,     its genetic basis has been a puzzle," says Vogelstein. Although this study and the test are specific to the Ashkenazi Jewish population, the     investigators say it provides important clues about familial colorectal cancer among in     the general population as well. "Studying specific populations make the discovery of     genetic mutations easier. These findings then serve as a paradigm for the general     population," Kinzler says. "This is the first example of the kind of mutations that can     cause FCC. It will have an important impact on cancer research because it proves     that even a subtle alteration--something we used to think was inconsequential--can     cause a predisposition to cancer. Now, we must go back and take a second look at     things we may have ignored in past," he adds. More than 130,000 cases of colon cancer are diagnosed in the U.S. each year. At     least 15 percent, and perhaps up to half, of these cases are thought to have a     hereditary component. FCC is the most common hereditary form. Familial     Adenomatous Polyposis (FAP) and Hereditary Non-Polyposis Colon Cancer     (HNPCC), two other inherited syndromes well defined by Hopkins researchers in     prior studies, account for another 3-5 percent of colon cancers. The remaining cases     occur sporadically, with no familial or inherited genetic link, among the general     population. More than 95 percent of the estimated six million U.S. Jews are Ashkenazi. There are     over 11.2 million Ashkenazi Jews worldwide, and the researchers estimate that more     than 680,000 carry this new mutation. Testing for this specific mutation among this     population is currently available at Hopkins. People of Ashkenazi Jewish heritage     (typically those Jewish people whose decendents originally lived in Eastern Europe)     with at least one first degree relative (a parent, sibling or child) who has had colon     cancer and who are interested in more information about the gene test can call     410-955-4041. The gene test costs $200. In addition to Vogelstein, Kinzler and Giardiello, other participants in this study     include, Steve J. Laken, B.A., Gloria Petersen, Ph.D., Stephen B. Gruber, M.D.,     Ph.D., and Stanley Hamilton, M.D., from Hopkins; Carole Oddoux, B.A., and Harry     Ostrer, M.D., from New York University Medical Center; and Heather Hampel,     B.A., Arnold Markowitz, M.D., David Klemstra, M.D., Suresh Jhanwar, M.D.,     Ph.D., Sidney Winawer, M.D., and Kenneth Offit, M.D., from Memorial Sloan     Kettering Cancer Center. The research was funded by the Clayton Fund, the Lucille P. Markey Foundation in     Cellular and Molecular Medicine, the National Foundation for Jewish Genetic     Disease, the Society of Memorial Sloan Kettering Cancer Center, and the National     Institutes of Health. # # # Due to licensing and research funding arrangements, the research described here is     expected to financially benefit the Johns Hopkins University as well as the authors.     Such arrangements are managed by the University in accordance with its conflict of     interest policies.
--------
484-> Role Of Cytokines In Treating Heart Disease Unveiled By Penn Scientists
Researchers from the University of Pennsylvania Medical Center and other institutions     are starting to amass solid evidence to explain how a popular heart medication works     on a molecular level. Specifically, the scientists investigated the role of cytokines     (bodily proteins that regulate inflammation) in explaining the effectiveness of     amlodipine, a widely prescribed calcium-channel blocker for patients with heart     failure. "A better understanding of the relationship between cytokines and amlodipine     will hopefully open the door to develop more effective therapies for congestive heart     failure, a condition that affects about three million Americans," says Emile R. Mohler,     III, MD, director of vascular medicine at Penn. Mohler presents his findings today at     the European Congress of Cardiology in Stockholm Sweden. Cytokines, an area of active research on many fronts, are proteins that regulate the     intensity and duration of the inflammatory response. People suffering from heart     failure, as well as many other diseases, have higher levels of two such proteins--tumor     necrosis factor-alpha (TNF-alpha) and interleukin-6 (IL-6)--circulating in their blood.     "Inflammation is quite prevalent in heart disease, and amlodipine somehow dampens     this inflammatory process," explains Mohler. Researchers currently believe that the release of cytokines may affect the function of     heart tissue by initiating programmed cell death in the myocardium. Over the course of     26 weeks, Mohler and his team found that amlodipine given to heart patients lowered     their plasma levels of IL-6. "I think the intriguing aspect of these results is that amlodipine may have a beneficial     action in heart failure patients by reducing cytokines, although this has to be explored     further in follow-up studies," says Mohler. The research team postulated that cytokine levels may also have some prognostic     value for treating heart disease. Using a statistical model, Mohler and his colleagues     found that congestive heart failure or death was more likely to occur in patients with     higher levels of IL-6. "By measuring cytokines it may help us to identify those patients     who may respond better to therapy," he says. "For example, if cytokine levels tend to     be lower, your chances of living longer with heart failure may be better." Dr. Mohler's findings appear in the July 1997 issue of the Journal of the American     College of Cardiology. This work was funded by the National Institutes of Health and     Pfizer Corp. Dr. Mohler can be reached at 215-662-9016 until Aug. 22, 1997, after which time     he leaves for Sweden. He returns Aug. 29. The University of Pennsylvania Medical Center's sponsored research ranks fifth in the     United States, based on grant support from the National Institutes of Health, the     primary funder of biomedical research in the nation. In federal fiscal year 1996, the     medical center received $149 million. In addition, for the second consecutive year,     the institution posted the highest growth rate in research activity--9.1 percent--of the     top-ten U.S. academic medical centers during the same period. News releases from     the medical center are available to reporters by direct E-mail, fax, or U.S. mail, upon     request. They are also posted to the center's home page (http://www.med.upenn.edu)     and EurekAlert! (http://www.eurekalert.org), an Internet resource sponsored by the     American Association for the Advancement of Science.
--------
485-> 'Space-Capsule' Computing Concept May Unlock Petaflops Power, UD Researchers Report
August 25, 1997--A new computing concept--patterned after successful space     missions--may soon help University of Delaware researchers complete the     architectural blueprint for a supercomputer 1 million times more powerful than the     most advanced personal computer now on the market. Capable of processing 1 million billion commands or "floating point operations" per     second, the world's first "petaflops" machine may feature superconducting     microprocessors, three-dimensional holographic data storage, advanced     semiconductor memory and optical interconnections. But first, researchers must figure     out how to compensate for the fact that the machine's processing chips will work     much faster than its memory. The space-capsule computing concept should help bridge this technological gap, says     Guang R. Gao, director of UD's growing Computer Architecture and Parallel     Systems Laboratory (CAPSL) and a leading expert on the "multi-threaded program     model," a processing strategy gaining increasing attention from high-performance chip     and system designers. Gao introduced his research team's latest findings during the     national Hybrid Technology Multi-threaded (HTMT) Architecture workshop, held at     UD July 20-21. How does the concept work? The key, Gao says, is to prepare "parallel     computational threads--essentially, many independent instruction pathways--within     the machine's lower-level memory hierarchy." The brain of a multi-threaded petaflops     computer, a series of processors powered by superconducting materials that lose all     resistance to electricity when deeply chilled, would execute many different tasks in     turn, Gao explains. Unfortunately, these superconducting processors might run into     problems when gathering information from many different sites within the computer's     deep-memory hierarchy, such as the optical memory unit or the dynamic random     access memory (D-RAM) region. Different types of data therefore must be converted     into a single "capsule" or parcel of information, Gao says. In other words: "You stock your capsule with all the information needed by the     processors before launching it into the superconducting region," Gao says. "If you     launch the information without preparing it first, the execution of tasks will almost     certainly be interrupted while the processor fetches what it needs from different sites."     After all, "if the Mars rover had been sent into space without all the proper     equipment," Gao notes, "that mission would have been a disaster!" For handling large, non-regular problems ranging from real-time weather forecasting     and biochemical modeling to simulations of complex systems such as aircraft, a     petaflops computer may prove essential, says Kevin B. Theobald, one of a half-dozen     graduate students and postdoctoral associates in Gao's lab. Gao's work "is a critical     path element in the success of the HTMT project," says researcher Thomas Sterling     of the Jet Propulsion Laboratory (JPL) in Pasadena, Calif., principal investigator for     the HTMT project and one of three visionaries to propose a petaflops machine in     1995. Resulting from a study funded by the National Science Foundation and the National     Aeronautics and Space Administration (NASA), the HTMT project is now     sponsored by the Defense Advanced Research Project Agency (DARPA), the     National Security Administration (NSA) and NASA. Gao's lab will receive $800,000     over the next several years to develop the architectural blueprint for a petaflops     computer. Along with UD, the HTMT project includes the California Institute of     Technology and JPL, the State University of New York at Stony Brook, Notre     Dame University, Princeton University, and government and industry labs. The UD team members are system-design veterans who previously developed a     high-performance, multi-threaded, multi-processor system known as EARTH     (Efficient Architecture for Running Threads)--a project directed by Gao at McGill     University in Montreal, where he taught before joining the UD faculty in 1996. The     EARTH platform is built atop a 20-node, 40-processor parallel machine called     MANNA (Massively parallel Architecture for Numerical and Non-numerical     Applications), contributed by the GMD-First computer firm of Berlin, Germany.     Doctoral student Andres Marquez, who helped design the memory system for the     MANNA, is now part of the UD team and one of the lead designers for the HTMT     project, Gao notes. The EARTH system also can run on the IBM SP-2 parallel computer, thanks to     support from C.J. Tan and others at IBM's T.J. Watson Research Center. Tan,     senior manager in charge of IBM's Deep Blue chess project, will be speaking at UD     on Oct. 21.
--------
486-> Astronauts Verify Restoration Of Electrical Power On Mir And Prepare For External Space Walk
Mir 24/NASA 5 Status ReportMission Control Center, Korolev, RussiaMonday, August 25, 1997, 2:00 p.m. EDT Aboard the Mir Space Station, Mir 24 Commander Anatoly Solovyev, Flight Engineer Pavel Vinogradov and U.S. astronaut Mike Foale began the process of verifying the restoration of electrical power from the solar arrays of the Spektr module today at the same time they began final preparations for an external spacewalk next week. Solovyev and Vinogradov told Russian flight controllers that a test of the connectors mated to a special “hermaplate” on Spektr’s hatch showed voltage from the arrays running through the connectors, which were attached last Friday during an internal spacewalk inside Spektr. And, ground controllers acknowledged that an additional 40 amps of electricity were flowing into the Kvant-2 module following the hookup of an adapter cable to route newly found power from the Spektr through the Kristall module into Kvant-2. But commands sent to the solar arrays to try to slew, or move them into a better orientation to face the sun, were not successful. The cosmonauts and ground controllers are assessing possible options to try to recover the pointing capability of the arrays. One of the 11 power cables mated to the hermaplate on Friday was designed to reestablish pointing capability of the arrays. It could take a few days before it known for certain how much power was recovered from the internal spacewalk operation. Current plans call for continuing work to power up the Kvant-2 module, followed by the Kristall module, then for the cosmonauts to direct electricity to the Priroda module. Video shot last Friday by Vinogradov of the interior of Spektr during the internal spacewalk is not expected to be downlinked until Wednesday at the earliest. The cosmonauts also spent part of their day trying to troubleshoot a problem with the device in which oxygen-generating candles are burned in Kvant-1 to produce oxygen for the Mir as a backup system. It has been used for the past several days to generate oxygen while the Elektron unit in Kvant-1 has been shut down to conserve power. Russian flight controllers ordered the cosmonauts to reactivate the Elektron in Kvant-1 even though it has been running a little warmer than desired, but after turning the system on, it shut itself down. This is not an uncommon occurrence when an Elektron unit is reactivated after having been shut off. Further analysis by Russian flight controllers continues. The Elektron may ultimately be reseated on its cold plate fixture in Kvant-1 to improve cooling for the unit. In the meantime, the cosmonauts are expected to conduct a maintenance procedure to replace parts in the solid-fuel oxygen candle burning device so it can be used again as a backup. In addition, Solovyev and Foale reviewed flight data file documents for an upcoming external spacewalk sometime during the first week of September. The spacewalk is designed to conduct a detailed inspection of possible leak sites on Spektr as the result of the June 25 collision of a Progress resupply ship and the Mir. Foale has been approved for on-orbit training for the spacewalk, but NASA officials have not yet given him the green light to proceed with the spacewalk itself. A final go-no go decision will be made at a joint readiness review between Russian and U.S. officials early next week. Foale has begun the 15th week of his long duration mission aboard the Mir. He is due to be replaced by U.S. astronaut Dave Wolf in late September. Wolf will be launched aboard Atlantis on the STS-86 mission, the seventh flight to dock with Mir.
--------
487-> UNH Researchers Using Lowly Lichens To Gauge The Effects Of Air Pollution On Vegetation
DURHAM, N.H. -- University of New Hampshire researchers think some of the Earth's smallest organisms can tell us some big things about what we're doing to our planet. That's why Barry Rock, UNH associate professor of natural resources, and graduate student Katrina Maloney focus part of their research on lichen, which can be found on rocks, trees -- even roof shingles. Lichen -- plants which are a combination of alga and fungus -- are good bio-indicators of changes in air quality because they absorb what's in the air -- for better or worse, says Maloney. An area with plentiful lichen, for example, means air quality is acceptable; those areas devoid of lichen have high levels of sulfur dioxide, lead or other air pollutants. Maloney and Rock will be among the scientists taking part in the New England Regional Climate Change Impacts Workshop, scheduled for Sept. 3-5 and sponsored by the university's Institute for the Study of Earth, Oceans and Space. Representatives from the six New England states and upstate New York, which share one general climatic region, are being invited to attend. The workshop is part of a federal initiative to define the nation's research agenda in the area of climate change. Results from this and 15 other workshops across the country will be brought to the National Workshop on Climate Change Impacts set for November in Washington, D.C. Maloney explains that her lichen research is yet another gauge of climate change. Lichen do not absorb anything from their "hosts," such as rocks or trees. Like plants, they manufacture sugars through photosynthesis, Maloney explains, "but they also absorb what's in the air and store it." An area's air quality is determined by the presence or absence of lichen and, Maloney adds, even what kind of lichen is present is important. It comes in three shapes: crustose, a crusty form that sits tightly against rock or tree; folise, more foliage like; and fruticose, shrubby, with 'fingers' pointing up. Crustose lichen generally is more tolerant of air quality changes, says Maloney, while fruticose, with more surface area, is the most sensitive. Why is lichen important? Not only does it serve as an air quality indicator, it also is an important part of nutrient recycling in the forest and an important food source for caribou in the tundra. It might take years for lichen to absorb enough sulfur dioxide, for example, to kill it, so Maloney's work has focused on finding ways to gauge damage before the lichen disappears. "We're trying to develop an early warning system," she says. "We'd rather find the damage sooner than later, and avoid a lichen desert."
--------
488-> Ulcer Sufferers Gain New Diagnostic Option Mayo Medical Labs First Test Center To Offer New Test
ROCHESTER, MINN. -- An exciting medical advance is allowing ulcer sufferers to breathe a sigh of relief. Until now, biopsy of the stomach lining has been the only certain way to diagnose an active infection which is believed to be a primary cause of peptic ulcer disease. Today the Meretek UBT(tm) Breath Test for H. pylori with Pranactin(tm) diagnostic drug provides a safe, painless, accurate and cost-effective way of determining the presence of this infection. Mayo Medical Laboratories (MML) is the first test center licensed by Meretek to offer this new procedure. H. pylori (Helicobacter pylori) infection is a primary cause of peptic ulcer disease, which causes pain and expense to millions of patients and their healthcare providers each year. Accurate and direct detection of active H. pylori infection is the first step toward diagnosing the cause of painful symptoms and curing peptic ulcer disease. Previously, this required an endoscopic procedure in which the sedated patient swallowed a tube with a light at its end and samples of stomach lining were obtained. The new test can be administered right in the physician's office, replacing the need for biopsy, a procedure that is invasive, costly and uncomfortable. "Accurate detection of an active H. pylori infection is crucial for selecting the right treatment for patients with indigestion or upper abdominal pain," said Dr. Michael Camilleri, gastroenterology consultant and professor of medicine and physiology at Mayo Clinic. Treatment of peptic ulcer disease usually involves prescribing antibiotics. Patients who are diagnosed with the H. pylori infection will have this condition treated, and many will experience an end to their painful stomach symptoms. Accurate diagnosis and appropriate treatment of patients with positive tests will also prevent people without ulcers from indiscriminate antimicrobial treatment which may result in development of resistance to antibiotics from unnecessary use. The Meretek UBT(tm) is as accurate as endoscopy with biopsy in detection of H. pylori infection. In addition, because the test assesses the entire stomach area as opposed to selective, random tissue, the chances of missing an infection are greatly reduced. Finally, it is a direct detection method, unlike serology, which detects antibodies to the bacterium in the blood, but cannot always reliably determine if a patient is currently infected. The patient drinks a clear, tasteless solution which is non-radioactive and uses only naturally-occurring compounds. The drug solution contains carbon-13 enriched urea and water. In the presence of an active H. pylori infection, urease hydrolyzes the carbon-13 enriched urea to form ammonia and carbon-13 enriched carbon dioxide, which is detectable in the patient's breath samples. Breath samples are collected from the patient before and after the physician administers the Pranactin(tm) diagnostic drug solution. The collected samples are then sent to Mayo Medical Laboratories for analysis. Mayo Medical Laboratories (MML) is the reference laboratory of Mayo Clinic, located in Rochester, Minn. MML has supported community-based laboratory medicine for over 25 years with reference testing services of high value, accountability and quality. Mayo's staff of nationally recognized laboratory experts, and Mayo Clinic's 1,400 physicians and scientists provide consultation on test selection, utilization and result interpretation. MML's reference services complement and support laboratory services at a local and a regional level. Meretek is a specialized healthcare company engaged in the development of simple, non-invasive, non-radioactive breath tests using safe diagnostic drugs. The company holds exclusive licenses to patents involving non-radioactive breath test technologies. Meretek is headquartered in Nashville, Tenn., with research and development facilities in Houston, Texas, and breath test centers in Nashville and Houston.
--------
489-> Dentists Warned To Look Out For Oral Piercing
CHICAGO - Body piercing is becoming more popular these days, and as people run out of body parts to impale, many are turning to the mouth, lips and tongue as suitable places for jewelry. However, according to a case study published in the July issue of the Journal of the American Dental Association (JADA), dentists need to be aware of this growing trend and the risks to patients that oral piercing carries. Professors at the West Virginia University School of Dentistry report on a 20-year old male who came to the clinic with wisdom tooth pain and swelling of the left jaw associated with multiple site piercings. Sheila Price, associate professor, School of Dentistry, Department of Diagnostic Services, WVU, reported that this reaction is common among people who have had oral piercings. "Common symptoms after piercing include pain, swelling, infection, increased salivary flow and gingival (gum) injury," she reports. Oral piercing often involves the lips, cheeks, tongue, uvula or any combination of these sites, with the tongue being the most commonly pierced intraoral site reported. "The most profound aspect of the intraoral piercing procedure is that anesthetic is not used," Dr. Price said. In most cases the person conducting the piercing will clamp the area while the needle is inserted into the tissue. The case study also indicates that after piercing is completed, oral jewelry in the form of studs, hoops or barbell-shaped devices are used. However, her report points out the severe risks that are associated with oral piercing and advises dentists to be aware of these risks when their patients with oral piercings come in for treatment. The risks reported include: airway obstruction after swallowing jewelry; prolonged bleeding; chipped or cracked teeth after biting one of the pieces of jewelry; scar tissue formation; speech impediment and jewelry that blocks the x-ray. "Piercing oral structures presents a high risk of infection because of the vast amounts of bacteria in the mouth," Dr. Price writes.
--------
490-> Circle Complete -- River Blindness Project Begins Final Stage
EAST LANSING, Mich. -- Nearly 20 years ago, a group of young scientists stepped off a plane at a remote airport in the Sudan to begin an ambitious program to rid that African nation and the rest of the world of a horrific disease known as river blindness. Next week, some of those scientists will return to the Sudan to "complete the circle," to finish a program many thought would never reach this point and to finish off a disease that claims millions of victims every year. "We are now on the road to treatment and our ultimate goal of total disease control," said Charles Mackenzie, chairperson of Michigan State University's Department of Pathology, who was among those "young scientists" who started the eradication program nearly two decades ago. On Sept. 2, dignitaries from around the world will gather in Khartoum for the APOC/NOTF Workshop, a conference that will officially begin the final drive to end the disease, which also is known by the name onchocerciasis. (APOC is an acronym for African Program for Onchocerciasis Control; NOTF is the National Onchocerciasis Task Force.) "This will mark the official commencement of the major treatment program and, of course, the conclusion of many months of planning and collaboration," Mackenzie said. Among those participating in the conference will be Mackenzie; representatives from the Atlanta-based Carter Center, which has been involved in the eradication program; officials from APOC and NOTF, including task force chairperson Mamoun Homeida, a Sudanese physician and nationally recognized tropical medicine expert; and many others, including representatives of other nations ravaged by the disease and organizations that have donated millions of dollars to help battle the disease. Onchocerciasis is a devastating disease in which parasites get beneath the skin, causing unbearable itching and discomfort. The parasites eventually make their way to the victim's eyes, causing blindness. The disease is called river blindness because it is spread by the black flies that breed in rivers. It's estimated that as many as 20 million people throughout Africa, Latin America and the Middle East are infected with onchocerciasis. Of those, nearly a million suffer serious sight impairment and a quarter-million are blind. One reason health officials are optimistic the disease is on the verge of eradication is the development of a drug called Ivermectin. Developed by the Merck Co., the drug has been incredibly effective in treating parasitic disease in animals and has now been deemed safe for human use. If all goes according to plan, Mackenzie said onchocerciasis could be a memory within a decade. One drawback of the medication: Onchocerciasis victims must take the drug for a number of years for it to work. "We must treat everyone who is infected once a year for probably eight or nine years," Mackenzie said. "This means getting the pills to about 2 million people, virtually all of whom live in the furthest reaches of the Sudan." No easy task, especially in a nation that has been ravaged by, among other things, a civil war that has dragged on for nearly 30 years. "In addition, the area is compromised by the lack of communications, the absence of any road system of any significance, and the sheer size of the country -- it's the biggest in Africa," Mackenzie said. "All these factors make the challenges of getting the new treatment to those needing it great indeed." It's estimated that about 2 million Sudanese are infected with onchocerciasis. About 11 million live in the east Africa nation. MSU has long been involved in the river blindness battle. Mackenzie, who actually joined the fray when he was on faculty of the London School of Hygiene and Tropical Medicine, along with MSU professors Jeffrey Williams and James Bennett have long been a presence in the Sudan. Risking war, land mines and even scorpion stings, Mackenzie and company have all become quite familiar with the Sudanese landscape, traveling to remote villages, teaching people how to take the medication and evaluating its effectiveness. They have also worked closely with Sudanese health care officials, helping them to distribute the much-needed medication. "We've conducted much research in the characteristics of the disease, the search for new drugs and the development of an integrated delivery system in the primary health system of the Sudan," Mackenzie said. "Happily we now are able to complete the circle, return to the infected people and give them treatment with real hope of controlling the disease and alleviating their suffering." Just last year, Mackenzie engaged in a bit of shuttle diplomacy, helping bring the country's warring factions together in an effort to battle onchocerciasis. "We managed to help get the two sides to meet and we were all great friends," he said with a grin. "A cease fire was in place for a while, but, unfortunately, the hostilities have since started up again."
--------
491-> Mir Spacewalk Complete -- Power May Be Restored On Monday, Says NASA
Mir 24/NASA 5 Status ReportMission Control Center, Korolev, RussiaFriday, August 22, 1997, 3:00 p.m. EDT Mir 24 Commander Anatoly Solovyev and Flight Engineer Pavel Vinogradov conducted an internal spacewalk inside the depressurized Spektr module of the Mir space station today, reconnecting 11 power cables from the Spektr’s solar arrays to a new custom-made hatch for the Spektr. The operations should provide additional power for the Mir’s other modules once power-up procedures are completed early next week. Solovyez and Vinogradov began their spacewalk by placing their spacesuits on internal oxygen flow at 5:59 a.m EDT, after a brief delay caused by a small leak in the left hand spacesuit glove worn by Vinogradov. After repressurizing the transfer node of the Mir, Vinogradov swapped out his glove for a new one and the spacewalk proceeded on schedule. The hatch to Spektr was opened by Vinogradov at approximately 7:10 a.m. EDT with the Mir out of communications range of Russian flight controllers. Vinogradov floated into the darkened module feet first to begin the job of connecting the power cables to the special hatch plate. Solovyev joined Vinogradov in Spektr later, helping him inspect several areas behind panels where Russian engineers believe leak points may be present as a result of the June 25th collision of a Progress resupply ship and the Mir. No obvious signs of damage to the module were reported. Vinogradov described the Spektr as being in generally good shape, with a few “white crystals” floating around, possibly from soap or shampoo and a thin layer of frost on experiment counters, which have been exposed to the vacuum of space for the last two months. Solovyev and Vinogradov finally left Spektr, closing the hatch at 10:30 a.m. EDT to officially end the spacewalk. In all, Spektr’s hatch was left open for three hours and 16 minutes. In addition to the repair work, the cosmonauts also retrieved a vacuum cleaner and several other unspecified items from inside Spektr and took documentary video of the new electrical connections and the interior of the module. Throughout the repair work, U.S. astronaut Mike Foale remained inside the Soyuz capsule attached to the Mir in constant communication with the cosmonauts and ground controllers. After Solovyev and Vinogradov reentered the transfer node to complete the spacewalk, Foale, speaking in English, congratulated the spacewalkers and ground support personnel saying, "We did everything we set out to do and more. Well done, everybody." It was Solovyev’s 10th spacewalk in five expeditions to the Mir and the first for Vinogradov, who arrived on the Mir August 7th. An external spacewalk is planned for the first week in September by Solovyev and either Foale or Vinogradov to conduct a more extensive survey of the external damage to Spektr. Foale has been given permission by NASA officials to begin on-orbit training for the spacewalk, although a final decision on his actual participation won’t be made until a joint U.S.-Russian readiness review is conducted around Labor Day. Foale has begun the 15th week of his long duration mission aboard the Mir. He is due to be replaced by U.S. astronaut Dave Wolf in late September. Wolf will be launched aboard Atlantis on the STS-86 mission, the seventh flight to dock with Mir.
--------
492-> Researchers Discover How Tuberculosis Bacteria Invade Cells
St. Louis, Aug. 22, 1997 -- The bacterium that causes tuberculosis uses a surprisingly underhanded trick to invade cells, researchers at Washington University School of Medicine in St. Louis announced today. The strategy is clever and effective -- and it may one day prove to be the disease's downfall. Understanding how the bacterium invades cells may be an important first step toward developing a vaccine to prevent tuberculosis, says Jeffrey S. Schorey, Ph.D., an instructor of medicine and lead author of a paper in the August 22, 1997, issue of Science. Although such a vaccine could be developed only after many more years of study, researchers are excited about the new insight into the common and deadly microbe. "This study helps us understand what's special about this bacterium and what makes it such an effective pathogen," says Eric J. Brown, M.D., co-author of the paper. Brown is a professor of medicine and of cell biology and physiology at the School of Medicine. Tuberculosis is a growing global menace that kills more people than any other infectious disease. Three million people die from it each year, and as many as one-third of the world's population is infected with Mycobacterium tuberculosis, the bacterium that causes the disease. Researchers have long known that M. tuberculosis makes its living by preying on macrophages, the immune system warriors that usually consume bacteria. The bacterium enters a macrophage and apparently multiplies until the cell ruptures, releasing more bacteria to attack other macrophages. Schorey, Brown and colleagues conducted test-tube studies with M. tuberculosis and a few of its close relatives including M. leprae, which causes leprosy, and M. avium, which frequently infects AIDS patients. The researchers found that all three bacteria share a special trick for finding and invading cells. They grab a protein discarded by the immune system and use it to lure the macrophages to their death. Normally, when a bacterium enters the body, the immune system responds by tagging the bug with certain proteins that alert the macrophages. Any macrophage (literally "big eater") that detects the proteins will attach itself to the intruder and try to consume it. Tagging a bug requires a highly choreographed interaction of many proteins, including one called C2a. When combined with another protein, C2a forms a potent enzyme that plays a major role in labeling intruders. After the job is done, C2a breaks off from its partner and floats in the blood with no known function. Humans may have no use for discarded C2a, but it's apparently invaluable for the disease-causing mycobacteria. Schorey's experiments demonstrated that the bacteria grab onto the protein and use it to create a new label that helps bacteria adhere to the macrophage. The protein also seems to work like a pass key that gives the bacteria easy entrance to the cells. The researchers found that adding infinitesimal amounts of the protein to test tubes containing bacteria and macrophages greatly increased the number of infected cells. Previous studies have described other invasion techniques used by mycobacteria, but the C2a strategy stands out for one major reason: It's used only by the types of mycobacteria that cause disease. "This is why we think C2a is important for the virulence of these bacteria," Schorey says. The next important step is to find the bacterial molecule that interacts with C2a, Schorey says. He and his colleagues also plan to move beyond test-tube studies to observe mycobacteria in immune-compromised mice. If researchers can find the molecule that binds to C2a, and if the results of animal studies echo the findings from the test-tube studies, this new invasion mechanism could form the basis for developing a novel vaccine, Schorey says. ### This research was supported by the National Institutes of Health.
--------
493-> Scientists Generate A Mouse With Duchenne Muscular Dystrophy
ST. LOUIS -- For the first time, scientists have developed a mouse with realistic symptoms of Duchenne muscular dystrophy, a devastating muscle disease that usually kills patients by age 20. This work should greatly advance the search for better treatments, the researchers say. "The only effective way to develop new therapies is to test them in an experimental animal with symptoms of the disease," says Joshua R. Sanes, Ph.D., who led the team. Sanes is a professor of anatomy and neurobiology at Washington University School of Medicine in St. Louis. The mouse, described in the Aug. 22 issue of Cell, develops muscle wasting and heart disease and dies by early adulthood. "This is the first animal suitable for studying the effects of Duchenne on both skeletal muscle and the heart," says R. Mark Grady, M.D., an instructor in pediatric cardiology and lead author of the paper. "That's important because these children would die of heart failure as young adults even if their muscles were cured. So it would be a mistake to look for a treatment for just the muscle symptoms."   Duchenne muscular dystrophy is the most common disorder of muscle, affecting mostly boys. Between 20 and 30 out of every 100,000 boys born in the United States this year will develop Duchenne, and 3 out of every 100,000 have it right now. There currently is no effective therapy, though steroids sometimes are used to slow the relentless progression of the disease. Symptoms usually begin between the second and fifth birthday, when a child starts to fall and have difficulty getting up. By late childhood or early adolescence, the muscles become so weak that crutches give way to a wheelchair. Because the muscles needed for breathing also are destroyed, patients eventually need a ventilator and often die from respiratory disease. The disorder results from a defect in the gene for an enormous protein called dystrophin, which forms part of the scaffold in muscle fibers. Scientists who want to study the consequences of dystrophin deficiency in an experimental animal have had to rely on a mouse called mdx, which has a natural mutation in the gene. But mdx mice have fairly normal muscles and no apparent heart problems, and they don't get progressively sicker or die young. One possible explanation involves another muscle protein called utrophin, which is very like dystrophin. Mice might contain enough of this protein to stabilize muscle when dystrophin isn't there to do the job. But the larger muscle fibers of humans would deteriorate in the absence of dystrophin, even when utrophin levels were normal. Grady began testing this idea in 1996 by removing the utrophin gene from a mouse, creating a creature that also had few symptoms. But when the team bred this utrophin-deficient mouse with the mdx mouse, they obtained the mouse described in Cell. Lacking both utrophin and dystrophin, this animal ends up in the same predicament as children with Duchenne. Its symptoms include decreased activity, a waddling gait, stiff limbs, curvature of the spine and death by early adulthood. The researchers used a variety of tests to determine the underlying causes. By viewing stained muscle samples under the microscope as the mice matured, they found that the muscle degenerated and partly regenerated and degenerated again, replacing itself with connective tissue. So the mouse had the same type of muscle-wasting as children with Duchenne. Electrophysiological tests showed that the muscles of the double mutant were not nearly as strong as those of normal mice or mice that lacked only utrophin or dystrophin. In fact, they generated only about half as much force when their nerves were stimulated. Further tests showed that this weakness resembled that seen in the muscular dystrophies, which involve muscle defects, rather than in the neuropathies, where muscle-controlling nerves are damaged, or the myasthenias, where connections between nerve and muscle are defective. The researchers also observed damaged muscle cells in the hearts of double mutants that were not present in the hearts of the other mice. By injecting dye that stains leaky cells, they determined that some of the heart cells were dying. So the double mutant develops severe heart disease, like patients with Duchenne. The mouse now can be used to learn more about the mechanisms of Duchenne. "It also will greatly facilitate research directed at finding an effective therapy for the disorder in humans," says Ronald J. Schenkenberger, director of research and patient services administration at the Muscular Dystrophy Association. The work also suggests a new strategy for treatment. "Other researchers recently showed that you can make mdx into a symptom-free mouse by making it synthesize huge amounts of utrophin," Sanes says. "But the double mutant shows that just removing the normal, small amount of utrophin makes mdx very sick. So turning up the human utrophin gene by just a modest amount might make Duchenne patients rather healthy." Learning how to turn up a gene that already is functioning should be easier than developing gene therapy techniques to replace the faulty dystrophin gene, the researchers say. "If you could take a boy with Duchenne and make him as healthy as an mdx mouse, that would be a great triumph," Sanes says. Grants from the Muscular Dystrophy Association and the National Institute of Neurological Disorders and Stroke supported the research. Grady RM, Teng H, Nichol MC, Cunningham JC, Wilkinson RS, Sanes JR. Skeletal and cardiac myopathies in mice lacking utrophin and dystrophin: A model for Duchenne muscular dystrophy. Cell 90, 729-738, Aug. 22, 1997. Note: Another paper describing the production of a mouse lacking both dystrophin and utrophin appears in the same issue of Cell. That research team is headed by Kay Davies, Ph.D., University of Oxford, England.
--------
494-> Roadsides Benefit From Wastes, UF Researchers Say
GAINESVILLE--Roadside dumping may be the best way to keep state highways beautiful and safe, says a team of University of Florida researchers. Litterbugs they aren't, however. The waste they want to see spread alongside Florida highways is made up of organic material. "The goal is to make roadsides a friendly environment to establish grass and at the same time get rid of waste products in an environmentally friendly way," said turfgrass researcher Grady Miller, of UF's Institute of Food and Agricultural Sciences. Miller and his colleagues were charged by the Florida Department of Transportation with finding a way to improve roadside soil. The improved soil would help grass grow, and grass helps to stabilize roadways. The researchers turned to cities and counties, which produce mountains of nutrient-rich organic wastes. Rather than use up precious landfill space with the wastes, the cities were glad to put the material at the disposal of the UF researchers. Miller said the material cannot be used on crops because it sometimes contains metals or glass. "There's no better location than roadsides," Miller said. "They're everywhere." In general, roadside soil is too sandy to hold nutrients or water, making it difficult for grass to grow well. Importing topsoil and adding commercial fertilizer helps but is prohibitively expensive. So the researchers turned to organic wastes. "The roadside is a very harsh condition in which to grow turf," Miller said. "The organic wastes add nutrients and hold water, making conditions more favorable for grass to grow." The compost has an added advantage over commercial fertilizer, said researcher Bob Black, in that it releases nitrogen slowly. With commercial fertilizer, there's a quick flush of growth after the initial application but no sustained nourishment of the soil and grass. Black said motorists cruising with their windows down might get a whiff of the compost after it's dumped from trucks, but once it's spread, the odor dissipates quickly and no one has complained. In field studies along an interstate in Broward County and a four-lane in Hernando County, the researchers are studying how the organic material aids the establishment of new grass. Along two-lanes near Steinhatchee and Melrose, they're using the compost as top dressing and looking at how it boosts the growth of the grass already there. In UF's state-of-the art Turfgrass Envirotron, where grasses from all over the world are monitored in three computer-controlled greenhouses, they are comparing the growth of roadside turf samples using both commercial fertilizer and the organic wastes. In all the samples, the grass nourished with organic wastes is faring better, Miller said. "We're seeing dramatic improvement in turf growth," Miller said. DOT landscape architect Gary Henry said roadside vegetation is necessary because it ensures the structural integrity of the roadbed by preventing soil erosion and keeping asphalt from crumbling. He said the news that roadside composting looks promising is welcome. "Importing topsoil and adding fertilizer is very costly, so this alternative will be a big help," Henry said. "This will save money, improve the grass and eliminate a landfill problem by reusing a material that still has some value. "It's a win-win-win situation," Henry said. -3 
--------
495-> Gold-DNA Combination May Lead To New Ways To Detect Diseases
Evanston, Ill. --- Researchers at Northwestern University have combined gold and DNA in an innovative way that should lead to new techniques for detecting many types of diseases. Screening for genetic and pathogenic diseases -- that is, those transmitted through heredity and those transmitted by microorganisms -- may be done using the new material, according to one of its inventors, Chad A. Mirkin, professor of chemistry at Northwestern. Research results reported in today's issue (Aug. 22) of Science magazine show that the procedure has a consistently high level of accuracy. "This process is likely to be faster, cheaper and more selective than existing diagnostic tools," Mirkin said. The new material is a probe made up of gold nanoparticles combined with oligonuceotides, strands of artificial DNA. Placing strands of a target DNA into a solution of the gold-DNA probes induces a chemical reaction that can be seen as a change in color from red to blue if genes linked to a particular disease are present. This color change can be readily sen en n the presence of bodily fluids such as urine or saliva. Currently, diagnosis of such diseases frequently requires the use of radioactive phosphorus or sulfur tracers in the probes. This requires specially trained personnel, creates disposal problems and uses material with short shelf lives. Using the new gold-DNA probes eliminates those problems, because no radioactive materials are used, and the solution is stabilized to give it the longer shelf life needed for a useful diagnostic tool. The new findings expand on earlier research by the Northwestern group, which develped the process for tailoring the optical, electrical, mechanical and structural properties of the gold-DNA combination material. Nanoparticles have a diameter one-billionth of a meter, so small they can't be seen with conventional microscopes. Mirkin, a materials chemist, and his colleague, Robert Letsinger, chemistry professor emeritus, have been developing the technique for several years. Letsinger is a pioneer in the fabrication of artificial DNA. In addition to Mirkin and Letsinger, co-authors of the Science paper are post-doctoral assistant Robert Elghanian and graduate students James J. Storhoff and Robert C. Mucic. In addition to medical diagnosis, the new material could be used for analysis in forensics, mass screenings for pathogens in clinical or laboratory settings and detection of biological weapons, Mirkin said.
--------
496-> Report Addresses Questions Over Wolves In Adirondacks
In an effort to inform the 130,000 people living in New York's Adirondack State Park where wolves may soon be sharing the landscape, the Wildlife Conservation Society (WCS) released a report today (Aug. 21) answering many of the commonly asked questions by residents about the big canines. Citing the best available published information on wolf behavior and ecology, the 85-page report examines a wide range of concerns by farmers, hunters and homeowners living in the six- million-acre park. "As conservation groups, government agencies and landowners debate the feasibility of restoring wolves to the Adirondacks, it remains clear that without public support, they have little chance of survival," said the report's author Angie Hodgson, a WCS biologist. "Our goal in releasing this report is to inform and advance the debate over wolf recovery and reintroduction." The report shows that park residents fear wolf interactions with livestock, humans and the native deer population. However, Hodgson found that states with wolves had minimal livestock losses. For example, Minnesota's 2,200 wolves killed only 74 cattle out of a population of 232,000 last year. According to the U.S. Fish and Wildlife Service, there has never been a documented, serious human injury caused by a healthy, wild wolf since records have been kept. Questions still remain whether the deer population can sustain predation from both wolves and humans, since wolves would directly compete with deer hunters, many of whom lease hunting rights from the park's private landowners (more than half of the Adirondack park remains in private hands). Other topics included the difference between wolf reintroduction and natural re- colonization, the costs of wolf restoration, and changes in land use where wolves occur. ### COPIES OF THE REPORT AVAILABLE UPON REQUEST 
--------
497-> 'Flare' For Fire Research Leads To New Detector
WEST LAFAYETTE, Ind. -- Purdue University engineers have developed a new type of fire detector that senses temperature to detect flames, and that has several advantages over conventional smoke detectors. "One advantage of this device is that it doesn't have to be 'looking' directly at the flame to 'see' it," says Jay Gore, a professor of mechanical engineering at Purdue who specializes in combustion research. "It can pick up reflections from a fire off the walls, so it can directly survey a multiple-room enclosure for fire from a single location. This gives it a very fast response time compared to a smoke detector, which doesn't go off until smoke has traveled to it -- a delay that can be several minutes." Because the new detector is very sensitive, Gore says, it may first be used in large warehouses, but it also will benefit the home. Gore and Yudaya Sivathanu, a Purdue research scientist, developed the new detector with the help of a two-year research grant from the Center for Fire Research at the National Institute of Standards and Technology (NIST). Because the new device uses fiber optics to detect radiation from a fire, optical fibers could easily be run from a central detection unit to each room in a multistory building, Gore says, providing "blanket" coverage. Also, the Purdue device would benefit those people who periodically turn off their smoke detectors to avoid a false alarm. The Purdue engineers say their device would cut down on false alarms because it doesn't respond to common household occurrences, such as a hot plate or an overcooked hamburger. The prototype detector is bulky, but Sivathanu has established a small business, En'Urga Inc., at Purdue's Business and Technology Center to develop the detector for industrial and commercial use within the next three to five years. Sivathanu presented information on the new detector Aug. 15 at the Second International Conference on Fire Research and Engineering in Gaithersburg, Md. The device, which detects the characteristic light given off by an uncontrolled flame, could be hooked into a telephone or personal computer to automatically notify the fire department and give off audio safety instructions when a fire starts, Gore says. "If the device were connected to a personal computer, as we have it in the lab, the computer can be programmed to repeat safety instructions to people in the house, such as 'Stay close to the floor,' or 'Crawl to the nearest door,'" Gore says. "This can be very helpful in an emergency, when people may be panicking, but it is especially important for small children who are frightened by scary, loud alarms. It could be very calming to hear a parent's voice, even if it is coming from the computer. "I believe that in the next few years, the home PC will control the home security and safety systems and that a fiber optic communication network will carry such signals in addition to voice and data. This detector could be easily integrated into such a communications network." The wavelengths of light that the detector picks up are in the near infrared -- in other words, heat. "The idea of using heat to detect fires is not new, but we have applied a unique discrimination algorithm to the process to eliminate false alarms," says Gore, whose previous research on different types of flames helped NIST researchers in their analysis of oil well fires in Kuwait. Over the past two years, as they were developing the detector, Sivathanu, Gore and their graduate students examined the near-infrared radiation given off by several "standard" types of fires. These type of fires cover a wide range of combustible materials. "We have analyzed flames based on the way the intensity of the light fluctuates as they burn," Gore explains. "For example, we may see a peak in intensity every tenth of a second, and then the pattern is repeated. That type of fluctuation frequency is characteristic of an uncontrolled fire." Once a flame has been detected, a sophisticated computer program analyzes the fluctuations in its near-infrared intensity -- its so-called infrared signature -- and determines whether to sound an alarm. While infrared signature analysis has been used by the military in a variety of ways, using it for fire detection is a new application. "We have 'taught' the detector not to respond to common household flames such as candles, gas stoves and cigarette lighters," Sivathanu says. "It also does not respond to fluctuations from hot plates, solar radiation or fluorescent light, which are different than those from uncontrolled flame. "We also installed a corrective filter when we learned that the detector went off when someone waved their hand quickly in front of a hot plate placed in direct view of the detector. We still have a problem with the alarm going off from a fireplace, which is an uncontrolled flame, but we are developing ways that may make the device 'blind' to certain spots in the room. Conventional smoke detectors also go off from smoke from fireplaces." Another bug to be worked out of the new detector is its difficulty in picking up smoldering fires, an area where smoke detectors also are slow to respond because of the time it takes for the smoke to reach the detector. "The intensities obtained for smoldering fires are too low for our detector to successfully discriminate them from background noise," Gore says. "However, new, more sensitive infrared technologies are now available that might boost this capability in our detector." Sivathanu and Gore have received a new, three-year grant from NIST for research that will focus on detecting the far-infrared radiation emitted from a fire, the type of radiation associated with smoldering. Sources: Jay Gore, (765) 494-1452; e-mail, gore@ecn.purdue.edu Yudaya Sivathanu, (765) 494-9364; e-mail, sivathan@ecn.purdue.edu Writer: Amanda Siegfried, (765) 494-4709; e-mail, amanda_siegfried@uns.purdue.edu Purdue News Service: (765) 494-2096; e-mail, purduenews@uns.purdue.edu ABSTRACT Experimental and numerical evaluation of a near-infrared fire detector Ying-Jie Zhu, Andrew Lloyd, Yudaya Sivathanu, Jay Gore - Thermal Sciences and Propulsion Center, School of Mechanical Engineering, Purdue University Near-infrared fire detectors work on the principle of detecting fires based on a statistical analysis of the apparent source temperature of fires. The apparent source temperatures are estimated from the radiation intensity incident on the fire detector at two near-infrared wavelengths. However in some instances, the fires are not in the direct view of the detector, and most of the radiation which is incident on the detector reaches it after multiple reflections from the walls of the building. An experimental and numerical study of the effects of these reflections on the temperatures inferred by a near-infrared fire detector are presented. The experimental evaluation was conducted using three open and two smoldering fires. The results show that the near-infrared fire detector is capable of discriminating open fires from reflected radiation. However, for smoldering fires, the intensities obtained from reflected radiation are too low to be successfully discriminated from background noise. Numerical evaluation of the performance of the near-infrared fire detector in cylindrical and rectangular enclosures were conducted utilizing a photon tracing algorithm in conjunction with the discrete probability function method. The numerical evaluation confirms that the detector can successfully detect fires from reflected radiation if its sensitivity is sufficiently high.
--------
498-> A New Index Of Earthquake Risk Ranks Boston Equal To San Francisco
Boston 39; San Francisco 37; St. Louis 36; Jakarta 39; Mexico City 38; Tokyo 54. No, they're not winter temperatures. These numbers represent the overall earthquake risk faced byresidents of each city. The higher the number, the greater the risk. The numbers were computed using a new Earthquake Disaster Risk Index, which aims to provide asimple and understandable measure of earthquake risk. It was developed by Rachel Davidson, adoctoral student in civil engineering at Stanford, and applied to 10 cities for her doctoral thesiscompleted last month. "We've gained a lot of knowledge in the study of earthquake hazards, but there is a big gap inimplementing it. We need a new tool to communicate what we know about earthquake risk," Davidsonsays. According to the index, Bostonians face an overall earthquake risk comparable to San Franciscans,despite the lower frequency of major earthquakes in the Boston area. The reason: Boston has a muchlarger percentage of buildings constructed before 1975, when the city incorporated seismic safetymeasures into its building code. Such an index can be useful for governments and international aid organizations as they allocateresources among various cities. Multinational companies might find it useful when deciding where tolocate new factories. Insurance companies could use the index to help diversify their portfolios. If suchan index became widely recognized, it might give cities an added incentive to reduce their ratings,Davidson argues. "The Northridge earthquake of January 1994 and the Kobe earthquake of January 1995 have broughtto our attention the unacceptable levels of risk our urban communities are facing," says Haresh C.Shah, professor emeritus of civil engineering and Davidson's thesis adviser. "It has become clear thatthe old paradigm of evaluating risk and developing mitigation strategies needs a fresh and innovativelook. Rachel's work, for the first time, makes it possible for various decision makers to understand therisk of potential disaster that their communities face and how it compares with what other communitiesaround the world are facing." Gil Jamieson, the chief of risk assessment in the mitigation directorate of the Federal EmergencyManagement Agency, says that the index will be an important tool to support federal, state and localdecision makers. It will aid in determining where mitigation resources should be targeted in relation tothe greatest risk. The federal agency is currently promoting the idea of "disaster-resistant communities."The concept rests on the idea that through public and private partnerships and a system of incentives,risk can be reduced at the community level. Before this approach can be put into operation, however,officials need a method to characterize and quantify the risk that each community faces. Davidson'sindex could serve as the prototype for such a method, Jamieson says. The index includes a number of factors in addition to the estimates of the size and frequency ofearthquakes likely to strike a given city. Specifically, it takes four additional factors into account: Exposure ­ the size of the city, number of inhabitants and the activities that it supports.      Vulnerability ­ how resistant a given area is to earthquake damage.      External context ­ how damage to the city affects people and activities in the surrounding area,     the country and the world.      Emergency response and recovery ­ how well a city is organized to respond to emergencies of     the magnitude expected and its consequent capability for reducing an earthquake's impact. Each of these factors is further broken down into subcategories. Exposure, for example, consists of thesize of the physical infrastructure, distribution of inhabitants, the size of the urban economy and thesocial-political system. Vulnerability is made up of the likelihood of physical damage; the odds thatinhabitants will face death, injury or serious disruption of their lives; the expected economic costs froman earthquake; and the degree of disruption of a city's social-political system. The next step in constructing the index was identifying indicators that accurately represent the differentsubcategories. For example, Davidson combined several indicators to come up with an overall hazardrating, including the largest earthquake likely to strike a town in the next 50 years, the intensity ofground shaking the quake is likely to produce and the percentage of the urbanized area of the city withsoft soil. For exposure, she used population, number of housing units and size of the local economy.For vulnerability, she included the age of the seismic code in force in the city and the history ofpopulation growth. For emergency response and recovery, she chose an assessment of the quality ofemergency planning and the number of hospital beds per 100,000 residents. "It's important that the individual indicators accurately reflect the factors that they represent," Davidsonsays, "otherwise the EDRI will not be believable." These individual indicators are then given different weights, depending on expert judgment of theirrelative importance, and are combined into indices for each factor. The individual factors are thensimilarly combined to provide an overall index. The comparisons produced by the initial application of Davidson's index might come as something of ashock to the inhabitants of Boston. She calculates that Bostonians have about the same earthquake riskas San Franciscans. The hazard of a major earthquake is significantly higher in San Francisco than inBoston, but Boston, with street after street lined with buildings that were constructed without anyseismic measures, is substantially more vulnerable to earthquake damage. St. Louis has about the sameoverall level of risk as well because of the greater vulnerability of its infrastructure. Of the 10 cities that she indexed, Tokyo, at 54, was the riskiest by far. It has a hazard level equivalentto San Francisco, but its level of exposure is much higher and external factors ­ the adverse impact thatdisrupting the city would have on the entire country, for example ­ are also well above those of theother cities. Davidson cautions against putting too much emphasis on her initial ratings. "The quality of the data, likethat on emergency response planning and enforcement of building codes, is not as good as I wouldlike," she says. Also, the weights that she has assigned to the different factors could use fine-tuning bysurveying a number of experts in the field to get their opinions, she adds. In addition to improving the quality of the index, Davidson would like to see the basic approach appliedto other natural hazards, such as hurricanes, floods and tornadoes. If that was done, then the individualindices could be combined into an overall, multi-hazard index. "I think that a multi-hazard index would be most useful to the government as a guide for how to deploytheir emergency response efforts," she says. If Davidson's approach is widely adopted, residents of the world's major cities will have a much betteridea of how well, or how poorly, their governments are protecting them from natural hazards. -30- By David F. Salisbury
--------
499-> Harvard Researchers Report P53 Doppelganger -- New Gene Hints At Family Behind Previously Singular Tumor Suppressor
BOSTON--August 20--The famous p53, considered the single most important tumor suppressor gene, is single no more. Researchers at Harvard Medical School, working in close collaboration with French scientists, have discovered a novel gene that closely resembles p53, a critical factor in tumor development that is mutated in 60% of all human cancers. The new gene, called p73, is deleted in at least one type of cancer and resides in an area of the genome that researchers worldwide have for years scoured for suspected tumor suppressor genes. The researchers are publishing their discovery and an initial analysis of p73 in the August 22 Cell, but cancer researchers across the country and abroad are already testing whether it is altered in other human tumors. It is too early to tell whether p73 will come to rival the central role in cancer genetics that 20 years of research have established for p53, or whether it will become the target of industrial drug design, as is p53. But the similarity of p73 to its famous relative, as well as other findings, make it an intriguing gene, says Frank McKeon, associate professor of cell biology at Harvard Medical School, who conducted this study with Daniel Caput of the pharmaceutical company Sanofi Recherche in Labege Cedex, France. Although dozens of groups are studying p53--the Medline database lists more than 9000 citations since 1977--none of them ever spotted its brother. And the authors are not long-standing participants in the high-powered field of tumor genetics. Caput first discovered p73 serendipitously while pursuing research into growth factors called cytokines. To analyze it, he quickly teamed up with McKeon, who had studied genes involved in DNA replication and cell division. The researchers knew they were on to something because the gene resides in the very tip of chromosome 1. This area is missing in many cancers, including those of the skin, colon, breast and liver, as well as neuroblastoma, a childhood cancer that--while relatively rare--has yielded much insight into the molecular workings of cancer cells. "P73 lies in one of the most interesting hot spots for putative tumor suppressors," says McKeon. "This has been a suspicious area for cancer for a long time." He cautions, however, that this danger zone probably contains many genes and that only future work will clarify if and how p73 contributes to disease. While it has long been known that the tip of chromosome 1 is missing in these cancers, researchers wonder why affected people cannot compensate for the loss simply by using genes on their second chromosome 1. McKeon, Caput, and colleagues do not fully understand this paradox, but they found that the p73 gene gets expressed from one chromosome only, possibly that of the mother. This finding suggests that having one faulty copy of p73 might suffice to lose all function. It also forges a connection to the separate field of genetic imprinting, which studies why and how organisms permanently "silence" certain genes just because they derive from a particular parent. And the research suggests a possible approach to future treatments: trying to awaken a silenced gene may prove easier than trying to supply a damaged gene by gene therapy, says McKeon. When the researchers analyzed p73, they found that it is a sibling, but no twin of p53's. Its overall structure is similar, as are important regions of the gene--those enabling the p53 protein to bind DNA, to stick to other p53 proteins, and to activate particular genes. p73 also contains the fateful ten or so amino acids that are most frequently mutated in p53, predisposing the carrier to cancer. Finally, p73 behaves like p53 in some of the experimental tests routinely used to study tumor suppressor genes. But that is where the resemblance ends. Unlike p53, p73 does not respond when the cell's DNA sustains damage from ultraviolet light, the researchers report. This is important because the major function of p53 that is currently known is to sense DNA damage and put the cell cycle on hold while enzymes restore the DNA. If the damage is irreparable, p53 commits the cell to destroy itself. These functions have earned p53 the sobriquet "guardian of the genome," and p73's failure to react to DNA damage suggests that its main functions, at least in part, lie elsewhere, McKeon says. His group is working to delete the gene in mice and indeed, early indications of that work suggest that p73 acts in the development of the brain and the immune system. By contrast, mice lacking p53 show almost no embryological defects. Next, McKeon's group and others will try to understand exactly what p73 does. They will ask what role p73 plays in the gradual process that scientists believe leads from an initial disturbance of the cell's internal controls through a series of exacerbating mutations to full-blown, metastatic cancer. Will the arrival of p73 dethrone p53 as the most prominent cancer gene? On the contrary, says McKeon, "I think p73 makes p53 much more interesting." Part of the reason is that p73 and p53 seem to interact. Another part may lie in evolution. McKeon suspects that a primitive p73-like gene may have evolved first, a generalist that served many functions in the growth and maturation of prehistoric cells. From this, p53 might later have evolved as a specialized offshoot concerned solely with tumor suppression. McKeon points to work by other researchers suggesting that key genes quadrupled in number at the time vertebrate animals arose. This strategy might have been a way for nature to realize biochemically the demands of the increasing complexity of species. Based on these observations, McKeon says, there should be two more, as yet undiscovered, siblings of p53, hinting at an entire network of related proteins that interact and regulate each other. The search, he adds, is on. Annie Yang, a student in McKeon's laboratory, is a co-author on the Cell paper.
--------
500-> Quiet Down: Adolescents Suffering From Noise-Induced Hearing Loss, University Of Florida Research Shows
By Victoria White GAINESVILLE, Fla.---For the typical teen-ager, graced by the taken-for-granted health of youth, hearing loss might seem as remote as Alzheimer's disease--a problem to be faced decades from now, if ever. But University of Florida research shows that 17 percent of middle- and high-school students already have lost some ability to hear. And the problem will keep getting worse if they don't protect themselves from the piercing decibels of loud music, motorcycles, target-shooting and other assaults on their ears. "They probably haven't noticed that they have lost the ability to hear very high pitches, such as that of a dog whistle," said Alice Holmes, associate professor of communicative disorders in UF's College of Health Professions.  "It isn't affecting their day-to-day life yet. But the more they are exposed to loud noises, the more damage will be done. As time goes by, they will have increasing difficulty understanding conversation. They may wind up being candidates for hearing aids." Can't trust such dire talk from an ivory tower researcher--or a parent with a headache? Plenty of rockers, including The Who's Peter Townshend and most of the heavy metal group Metallica, will testify that they don't hear so well anymore. Excessive noise has permanently damaged the cochlea, tiny hair-like receptors in the inner ear that are instrumental in transmitting sounds to the brain. Holmes' team screened 342 middle and high school students in Gainesville. Schools typically test younger children to check for hearing problems that escaped attention during toddler years. But it's long been assumed that there were no worries for middle- and high-schoolers. "There has been very little research on this age group," Holmes said. The students, ages 10 to 20, underwent pure-tone screening in both ears. Test administrators asked them to indicate when they heard a beep. The beeps were 20 decibels loud at pitches ranging from 1,000 to 6,000 hertz (cycles per second). "One thousand hertz is equivalent to about a middle C on the piano, and the tests went up in pitch from there," Holmes said. Seventeen percent of the students did not hear one or more of the sounds in at least one ear. They were most likely to fail at the highest pitch tested. Two students did not hear any of the tones in either ear, and five students failed all frequencies in one ear but passed in the opposite ear. "These results should serve as a warning that today's young people, who often have their headphones or car stereos cranked up high, are at great risk for losing some of their hearing in the coming years," said Holmes, who published her research earlier this year in Language, Speech, and Hearing Services in Schools, a journal of the American Speech-Language-Hearing Association. "But the good news is that noise-induced hearing loss is preventable. We can educate children about how to protect their ears. And if we screen more people, we can detect problems when they are mild, and urge stronger precautions for those who appear particularly susceptible to losing their hearing." Without screening, most people suffering early hearing loss do not realize it. "It's very common for someone who has a high-frequency hearing loss to comment that 'I hear fine, people are just mumbling,'" Holmes said. Susceptibility to noise-induced damage varies considerably. "You can go into a factory and find two people who have worked side by side with the same noise exposure and one of them will develop a severe hearing loss and the other one won't," Holmes said. "It might be genetics, but we don't really know. This area is wide open for more research." Holmes recommends wearing earplugs or other sound protection when mowing the lawn, working with noisy equipment, riding a motorcycle or attending a rock concert. "Today there are earplugs available that are like comfortable little sponges," Holmes said. "You won't even know they're there." People who like to hunt or shoot target practice also need to take precautions. Holmes' research showed that students who use firearms were more likely than others to have lost  some hearing ability. "A good rule of thumb is, if you're in a noisy environment and you have to significantly raise the level of your voice to be heard, that noise is loud enough that it risks hurting your ability to hear," Holmes said. ****************************** Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html For the UF Health Science Center topic/expert list, point your browser to http://www.health.ufl.edu/hscc/experts.h 
--------
501-> Acquiring Herpes Late In Pregnancy Brings Special Dangers To The Newborn
While there is never a good time to acquire a herpes infection, contracting the virus late in pregnancy can prove catastrophic for the newborn child, with a high risk of severe brain damage or death from neonatal herpes. "Contracting the herpes virus during pregnancy -- especially in the last trimester -- is worse than having herpes going into pregnancy," cautioned Dr. Zane A. Brown, professor of obstetrics and gynecology at the University of Washington. Brown and colleagues publish results of their study in the Aug. 21 issue of The New England Journal of Medicine.  Funding is from the National Institutes of Health. The researchers studied 8,538 pregnant women who received prenatal care at University of Washington Medical Center in Seattle or at Madigan Army Hospital in Tacoma, Wash., between 1989 and 1993. Based on antibody testing in early pregnancy and again at the time of labor, they found that 2 to 3 percent of the women acquired some form of herpes during pregnancy, and that the acquisition was about equally divided among the three trimesters of pregnancy. The danger to infants exists whether the mother has HSV-1 (oral herpes, the type that produces cold sores) or HSV-2 (genital herpes). The increased risk to the baby when the virus is acquired late in pregnancy comes because there is insufficient time for the mother to form antibodies to the virus (which takes four to eight weeks) and pass them to the baby before starting labor. With earlier infection, antibodies are passed through the placenta, giving the baby some degree of protection. Without antibodies, the child is highly susceptible to acquiring the virus in the birth canal. With its "naive" immune system, explained Brown, the baby has few resources to fight the virus. Infected babies don't show symptoms for five to 21 days. "Once the baby is symptomatic," said Brown, "it's too late to avert damage, and we're much less likely to contain the infection. Babies have no defenses." Unlike gonorrhea or syphilis, herpes is not a reportable infection, noted Brown, so there are no national statistics. Estimated rates of neonatal herpes vary throughout the country; in the Northwest, it occurs once in about 2,000 live births; about half of those infants die or suffer brain damage. "It's treatable, but often undetected, "Brown said. "Mother and baby have usually left the hospital, and the first symptoms are just listlessness and irritability. A couple of days later, there are seizures, but by that time, significant brain damage has occurred. "In women, there may be no recognizable symptoms," said Brown. "Until now, it was thought that the primary infection brought numerous lesions, headache and flu-like symptoms. But such cases are the tip of the iceberg. About two-thirds of women don't have any idea that they've just gotten herpes; therefore, they're at risk to transmit it to their babies. We have to have some way of diagnosing the mother who's susceptible, and test her partner as well. Even if you can't prevent her from acquiring the infection, at least you know she is at risk." With routine testing for herpes, said Brown, doctors would know whether to recommend Caesarean delivery to bypass the virus-laden genital tract. Since the baby is at some risk even when it has herpes antibodies from the mother, knowledge of her status would prompt avoidance of some labor and birthing procedures, like forceps or vacuum delivery that may cause tiny skin breaks through which virus could pass. Routine testing would also allow care providers to offer counseling on avoiding transmission of herpes between partners. "If you're one of the 20 percent of women who are negative for both HSV-1 and HSV-2," said Brown, "we would recommend that your partner be tested. For example, if he had cold sores (from HSV-1), we would counsel against oral-genital sex during pregnancy." Brown and his colleagues are calling for regular blood testing for herpes at the first prenatal visit, similar to the testing done to detect other infections and medical problems. They are conducting additional research to evaluate the value of such a program. "We know when the infection with the virus occurs and when the infection poses the greatest risk to the baby," said Brown. "The question is, can we intervene effectively to lower the risk? We would like to see all pregnant women tested routinely, as they are for German measles and syphilis.&# 
--------
502-> Mutated Gene Causes Death Of Nerves In Brain; Identification Of First Glutamate Receptor Linked With Neurodegeneration
A gene responsible for the degeneration and death of certain nerve cells in the brain has been cloned, yielding information that may be useful for further studies of such neurodegenerative diseases as Alzheimer's and Parkinson's, investigators from the Howard Hughes Medical Institute at The Rockefeller University and from The Johns Hopkins School of Medicine report in the Aug. 21 Nature. The gene carries instructions to make a receptor for chemicals called neurotransmitters, which nerve cells use to communicate. The discovery, from mouse studies, marks the first time scientists have identified and directly linked a mutant gene in the glutamate receptor family to the death of brain cells. Because of the mutation, the resulting faulty receptor acts as if a neurotransmitter always is present--even when none of the chemical is there. This false detection causes the nerve cells to die. "The mutations in the d2 glutamate receptor gene may play a role in changing the metabolism of the adult nerve cells to reactivate a program of cell death that normally occurs only during natal development. If we can reveal more about this process and understand it, it may be possible to slow the process down or stop it and preserve the neuron," explains Nathaniel Heintz, Ph.D., professor and head of the Laboratory of Molecular Biology at Rockefeller and an investigator at Howard Hughes. During fetal development, programmed cell death is used to sculpt the final number of cells in the mature brain. About twice as many cells begin the process of developing into brain nerves than are needed in an adult brain. Consequently, many of the cells activate a biochemical program to commit suicide, known as an apoptotic death, because they receive certain chemical signals. "We think that the surveillance mechanisms that monitor the normal metabolism of neurons are much like those monitoring the cell-division cycle in other types of cells. In neurodegenerative diseases, these mechanisms may activate the apoptotic cell death pathway as a normal response to the severe dysfunction of neurons. Our discovery of the d2 glutamate receptor gene mutation helps us to understand how this gene functions in normal neurons, but the $64,000 question remains: 'How does its altered function trigger cell death?'" says Heintz. Heintz and his colleagues would like to pursue studies of two possible explanations related to the mutant receptor's function and the initiation of cell death. The glutamate receptor is part of a biochemical relay system that transports signals between cells. When glutamate binds to the receptor, located in the outer membrane of the neuron, the receptor allows charged molecules, usually calcium ions, to enter the cell and pass the signal along. The first possibility of how the mutation causes cell suicide is simply that death ensues from the direct action of the receptor increasing the amount of ions coming into the cell. Other studies have shown that unusually high levels of calcium ions can enter the cell in response to increased activation of glutamate receptors, as occurs in stroke. These ions are critical in causing cell death. However, no direct pathway linking calcium ions to programmed death has yet been discovered. The second possibility is that the mutation alters the signaling properties of the receptor, and that the resulting aberrant signals are critical in the initiation of cell death. The receptor mutation occurs because of the substitution of two of the four nucleic acids used to build the gene, located on chromosome 6 of lurcher (Lc) mice. This switch changes the instructions carried by the gene and consequently, the receptor protein it makes. The mutation causes the death of Purkinje neurons in the cerebellum, the brain structure that controls all aspects of coordination and fine motor control in mature animals. Heintz's coauthors included Jian Zuo, Philip L. De Jager, Weining Jiang, Ph.D., at Rockefeller, and Kanji A. Takahashi and David J. Linden, Ph.D., at Johns Hopkins. The National Institute for General Medical Sciences, part of the federal government's National Institutes of Health, funded the research, with support from the National Institute of Mental Health, the McKnight Foundation, the Derelbiss Fund and the National Alliance for Research on Schizophrenia and Depression. Rockefeller began in 1901 as the Rockefeller Institute for Medical Research, the first U.S. biomedical research center. Rockefeller faculty members have made significant achievements, including the discovery that DNA is the carrier of genetic information and the launching of the scientific field of modern cell biology. The university has ties to 19 Nobel laureates, including the president, Torsten N. Wiesel, M.D., who received the prize in 1981. Recently, the university created five centers to foster collaborations among scientists to pursue investigations of Alzheimer's Disease, of biochemistry and structural biology, of human genetics, of sensory neurosciences and of the links between physics and biology. ### Journalists: Do you want to receive news from Rockefeller University by e-mail or fax? Let us know via e-mail or fax. Also, if your name or address or the contact at your organization needs to be changed, send us the correct information. Check out our other news at: www.rockefeller.edu/NEW.html. RU news also can be found on EurekAlert!: www.eurekalert.org.
--------
503-> New Microchip Could Mean Improvements In Auto Industry
A specialized microchip developed at Simon Fraser University could improve the way air bags deploy in crashes, calculate the punishment runners inflict on their knees, even build a better computer mouse. There's a huge market for the thumbnail-sized innovation which measures acceleration, motion and vibration. The automobile industry alone uses 100 million similar devices each year. However, prototypes of the SFU chip have proven to be 1,000 times more sensitive than current devices and could, for example, significantly improve the control of cars when skidding, or how they ride on shock absorbers. "Current devices cost $5 to $8, when purchased in volume, but ours can be manufactured for under a dollar," reports Albert Leung, professor and director of SFU's school of engineering science, who developed the device -- a micromachined thermal accelerometer -- and led the university research project. Leung first scribbled down his design for the better chip in 1984 on an airplane on the way to a successful job interview at SFU. In 1995, he found time in his busy research and teaching schedule -- and the scrap of paper -- and began to develop the device with professor John Jones, graduate student Maria Pascal and research assistants Eva Czyzewska, Jiaming Chen and Bill Woods. "Project Hot Air" is what they dubbed their work when they began two-and-a-half years ago. The name refers to the hot air bubble at the heart of the microchip and the reaction of many skeptics who told them it was impossible. The SFU group has applied for a worldwide patent and is expecting significant benefits, but is waiting for the patent before publishing its research. The university industry liaison office provided prototype development and continues to be very involved. "We hope the technology will be transferred to private industry," says Leung. "where sufficient research and development budgets can take advantage of the full commercial potential." The micromachined thermal accelerometer was unveiled in Ottawa this week, where it earned the Canadian Semiconductor Design Association award. CONTACT: Albert Leung, 291-4194/4371Bruce Mason, media/pr, 291-3035Media/pr's web site: http://www.sfu.ca/mediapr 
--------
504-> A 'CAT Scan' Of Mount Rainier Detects Quake Hazards
Geologists have long known that Mount Rainier, the largest volcano in the Cascades, looms as a potential risk to the communities around it. There is strong geological evidence that several times over the last 6,000 years massive landslides, and accompanying mudslides, have buried the surrounding area. Now University of Washington researchers have made the first detailed study of the possible trigger for such a devastating event, a large earthquake centered in the volcano's backyard. The study, the first three-dimensional look into the interior of Mount Rainier and its surroundings, leads UW research scientist Seth Moran to speculate that a potential earthquake hazard exists in the southeastern corner of Mount Rainier. In 1974 an earthquake of 4.8 on the Richter scale, the largest ever recorded in the national park, was centered on Ohanapecosh on Route 123, the site of a park visitors' center and campground. "We are definitely observing a systematic change in the geology beneath the surface in the area of the 1974 earthquake," says Moran. It is possible, he says, that this change represents a buried fault that could be long enough to generate a magnitude 6 earthquake. But Moran has down-graded another potential hazard, a 35 mile-long linear zone of concentrated earthquake activity lying just to the west of the volcano, called the Western Rainier Seismic Zone. If the earthquakes in this zone are occurring along a single continuous fault, says Moran, a magnitude 6.5 to 7 earthquake would be possible. But after studying his underground 3-D images, Moran has concluded that there is no sign of a continuous fault near the zone. At the most, he says, there are small faults capable of generating a magnitude 5.5 earthquake. "This means that the hazard posed to Mount Rainier by the zone is relatively small." Locating buried active faults is vitally important because earthquakes close to the mountain "pose a much greater threat" to Mount Rainier than those that are more distant, says Moran, whose research was the basis for his recently completed doctoral dissertation. The 7.1 magnitude temblor near Olympia in 1949 did not affect Mount Rainier; neither did the 6.5 in 1965 between Tacoma and Seattle. And there is strong evidence that in 1700 the volcano was unaffected by the magnitude 8 to 9 quake several miles out in the Pacific. Moran made the 3-D images using a technology known as seismic tomography. The technique is similar to CAT scan imaging of the body's internal organs. But instead of sending X-rays through the body, researchers record waves of energy from earthquakes. Seismometers pick up a quake's signature in the form of a P (for primary) wave, something like a shock wave that radiates out from a temblor's epicenter. The speed of the P wave indicates whether the rock is very hard, like granite, in which case the wave is fast moving, or soft, like sandstone, in which case the wave is slower. As the patterns of P waves build up through successive earthquakes, scientists are able to produce a computerized portrait of the sub-surface structure, with different densities displayed in varying shades of color. Moran assembled his portrait by adding 18 seismometers, mostly to the east of Mount Rainier, to the 15 permanent stations around the volcano. "This makes a big difference in our understanding of Mount Rainier," says Moran. Another geological puzzle has been whether earthquakes occurring within the volcano itself may be a result of the mountain actively disintegrating. "We know that earthquakes occur directly beneath the summit. What we don't know is why," says Moran, in part because their precise depths have been difficult to determine. However, the 3-D images indicate for the first time that the quakes are likely located deep below the mountain -- perhaps a half to one mile below sea level. This suggests that the earthquakes are probably not caused by the volcano falling apart from the inside. Instead, Moran thinks that the earthquakes may be caused by hot fluids circulating in the ground beneath Mount Rainier. Despite the quality of the 3-D images, "the depths of the earthquakes beneath the summit are still somewhat uncertain," notes Moran, because there is no seismograph at the summit to provide the needed data. "At this point, my guess is that there is no direct relationship between these particular earthquakes and hazards at Mount Rainier," says Moran. The historical record shows only two examples of earthquakes triggering landslides on volcanoes. The first was the 1980 eruption of Mount St. Helen's, which began as a large landslide that occurred at the same time as a 5.2 magnitude earthquake directly beneath the volcano. The second was at On-take in Japan in 1984, a landslide apparently triggered by a magnitude 6.8 earthquake located about six miles southeast of the volcano. The last great landslide on Mount Rainier happened about 500 years ago, and it generated a mudflow that enveloped what is now Orting, northwest of the mountain. Although there is no evidence this was caused by an earthquake, one thing is certain, says Moran, "earthquakes are potential triggers for landslides." ### Moran can be contacted at (206) 685-3398, or moran@geophys.washington.edu
--------
505-> Frequency Of Family Meals May Prevent Teen Adjustment Problems; Teens Less Likely To Do Drugs, More Motivated In School
CHICAGO -- Volumes have been written and spoken about how to keep teenagers out of trouble. But the answer, according to a study presented at the American Psychological Association's (APA) 105th Annual Convention, may be as simple as eating meals together as a family more often. Psychologists Blake Sperry Bowden, Ph.D., from the Cincinnati Children's Hospital Medical Center and Jennie M Zeisz, Ph.D., from DePaul University categorized 527 teenagers as either well-adjusted or not well-adjusted and then looked at the number of times per week that they ate dinner together with their families at home. The adjusted teens -- who were less likely to do drugs, less likely to be depressed, more motivated at school and had better peer relationships -- ate with their families an average of five days a week compared to the nonadjusted teens who only ate with their families three days a week. Clearly family mealtimes are strongly related to adjustment, but exactly what aspect of the event -- the sharing, the stories teens tell about their day or hear from others in the family -- helps prevent adjustment problems for them hasn't been pinpointed. But, say the authors, family mealtimes, it would appear, play an important role in helping teens deal with the pressures of adolescence. Presentation: "Supper's On! Adolescent Adjustment and Frequency of Family Mealtimes" by Blake Sperry Bowden, Ph.D., Cincinnati Children's Hospital Medical Center and Jennie M. Zeisz, Ph.D., DePaul University. Session 2220, August 16, 1997, Sheraton Chicago and Towers, River Exhibition Hall (E-5). (Full text available from the APA Public Affairs Office.) The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists. APA's membership includes more than 151,000 researchers, educators, clinicians, consultants and students. Through its divisions in 50 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare.
--------
506-> Newly Discovered Human Protein Provides Important Target For Cancer Therapy
(Cambridge, MA) The discovery of a key molecule linked to the immortalization of human tumor cells provides an important new target for anti-cancer drug design. Researchers led by Dr. Robert A. Weinberg of the Whitehead Institute for Biomedical Research have isolated and cloned the gene for the long-sought catalytic subunit of human telomerase, a molecule believed to play a major role in the transition from normal to cancerous growth. "The telomerase enzyme is an ideal target for chemotherapy because this enzyme is active in about 90 percent of human tumors, but inactive in most normal cells," Dr. Weinberg says. "Pharmaceutical companies have screened thousands of compounds to find agents capable of blocking telomerase. Now that we know the identity of the catalytic subunit, drug development should move much faster." Dr. Weinberg, principal authors Drs. Matthew Meyerson and Christopher Counter, and their colleagues from the Whitehead Institute, the Massachusetts Institute of Technology, Massachusetts General Hospital, Merck Research Laboratories, and McMaster University in Ontario, Canada, describe the new telomerase subunit gene, hEST2 (human Ever Shorter Telomeres 2), in the August 22 issue of Cell magazine. They report that this telomerase gene is expressed at high levels in primary human tumors (11 of 11 tumor samples studied, including 2 breast tumors and 4 ovarian tumors), but undetectable in most normal human tissues, including breast, ovary, heart, brain, placenta, liver, skeletal muscle and prostate. Achieving Immortality The normal function of telomerase in the body is to help maintain the ends of chromosomes in reproductive cells (cells that produce eggs and sperm) and in certain immature progenitor cells that give rise to other body tissues. Telomerase activity is not detectable in most mature cells. Switching off telomerase during development can be likened to setting a stopwatch. This stopwatch keeps track of the number of cell divisions that occur in any one population of cells over a person's lifetime. Normal cells have a finite replication potential; they can divide only so many times and then they die. In contrast, cancer cells divide and multiply without limit. Evidence collected by many laboratories indicates that the clock or counting mechanism relies on specialized bits of DNA, called telomeres, at the ends of each human chromosome. In the absence of telomerase enzyme, these specialized end-structures grow shorter with each round of cell division. Eventually, the shortening process reaches a critical stage; the chromosomes become unstable and any further cell division leads to cell death. (This limited allowance for cell divisions may be a significant factor in normal human aging.) "Cancer cells find a way of switching telomerase activity on, which gives them a tremendous competitive advantage," Dr. Weinberg says. "They have the potential for continuous reproduction in the body or in cell culture--they become immortalized. We want to learn how cancer cells regenerate telomerase function and, at a more fundamental level, how all cells switch telomerase off and on." Ideal Target for Chemotherapy The telomerase enzyme is a complex structure containing multiple proteins and an RNA molecule (RNA is a chemical cousin of DNA and, in this case, acts as a template for the production of new telomere segments). Previously, researchers in other laboratories had identified the genes responsible for producing human telomerase RNA and one telomerase-associated human protein, but careful studies of these genes revealed that neither could explain the regulation of telomerase activity: expression of the genes does not correlate with observed levels of telomerase activity in normal or cancerous cells. Finding the critical catalytic subunit that actually transcribes telomerase's RNA template into DNA proved to be an elusive goal. "The main difficulty in isolating telomerase proteins has been that even when telomerase genes are turned on full blast, the quantity of telomerase in a human cell is vanishingly small," Dr. Weinberg says. To overcome this problem, the Weinberg lab developed a genetic ploy using yeast. They created novel yeast mutants with specific defects in their ability to replicate telomeres. Shortly thereafter, both the Whitehead researchers and a team led by Drs. Joachim Lingner and Thomas Cech of the University of Colorado, Boulder, and Dr. Victoria Lundblad of the Baylor College of Medicine in Houston, Texas, independently converged upon the same discovery: a key protein in the telomerase complex. "Our studies and those of the Colorado/Baylor group proved without doubt that the new protein was the catalytic subunit of yeast telomerase," Dr. Counter says. Using the sequences of the yeast telomerase protein and a comparable telomerase protein from a single-celled protozoan (discovered by the Colorado/Baylor group), the Whitehead reseachers quickly isolated the human gene. The order of the building blocks of all three proteins is remarkably similar. In addition, the Whitehead studies revealed a strong association between the presence of the hEST2 message and telomerase activity; both are present in immortal transformed cells and absent in mortal normal cells. "This suggests that hEST2 expression might underlie the activation of telomerase that occurs during cellular immortalization," Dr. Meyerson says. "Blocking hEST2 expression or activity could halt or slow the progression of malignant tumors." In fact, say Meyerson and Counter, the foundation for an anti-telomerase drug may already exist. The three known catalytic subunits of telomerase (from humans, yeast, and a protozoan, respectively) belong to the same general family of molecules as the reverse transcriptase enzyme produced by the HIV virus that causes AIDS. Several of the most commonly used AIDS drugs, including AZT, are reverse transcriptase inhibitors. "The beauty of this finding is that we already know a great deal about the structure of reverse transcriptase inhibitors," Dr. Counter says. "We have a good starting point for developing anti-telomerase drugs." This work was supported in part by the National Cancer Institute of the United States, the National Cancer Institute of Canada, the Damon Runyon-Walter Winchell Cancer Research Foundation, the MIT-Merck Postdoctoral Fellowships Program, the Howard Hughes Medical Institute, and the Human Frontier Science Program. Dr. Weinberg is a founding Member of the Whitehead Institute for Biomedical Research, an American Cancer Society Research Professor, and the Daniel K. Ludwig Cancer Research Professor at MIT. Drs. Meyerson and Counter are post-doctoral fellows in the Weinberg lab. The authors of the Cell paper are: Dr. Matthew Meyerson of the Whitehead Institute for Biomedical Research and the Department of Pathology, Massachusetts General Hospital Dr. Christopher M. Counter of the Whitehead Institute for Biomedical Research Mrs. Elinor Ng Eaton of the Whitehead Institute for Biomedical Research Dr. Leif W. Ellisen of the Massachusetts General Hospital Cancer Center Dr. Philipp Steiner of the Whitehead Institute for Biomedical Research Mrs. Stephanie Dickinson Caddle of the Whitehead Institute for Biomedical Research Mrs. Liuda Ziaugra of the Whitehead Institute for Biomedical Research Dr. Roderick L. Beijersbergen of the Whitehead Institute for Biomedical Research Mr. Michael J. Davidoff of the Department of Human Genetics, Merck Research Laboratories Dr. Qingyun Liu of the Department of Human Genetics, Merck Research Laboratories Dr. Silvia Bacchetti of the Cancer Research Group, the Department of Pathology, McMaster University Dr. Daniel A. Haber of the Massachusetts General Hospital Cancer Center Dr. Robert A. Weinberg of the Whitehead Institute for Biomedical Research and the Massachusetts Institute of Technology
--------
507-> Patented Laser Device Detects Blood Disorders Near-Instantly
ALBUQUERQUE, N.M. -- A revolutionary handheld laser device that in a few moments can detect and then track disorders of the blood has been patented in prototype by scientists at Sandia National Laboratories and the National Institutes of Health. The scanner, which makes blood samples part of the laser generation process, immediately detects sickle-cell anemia as well as nanometer-scale changes in cell structure like those imposed by the AIDS virus. The device, called a biocavity laser, also is better able to distinguish between cancerous and non-cancerous cells than pap smear tests, which analyze visually only relatively small numbers of cervical cells. The biocavity device also should allow observers to monitor unrestricted cell growth -- cancer -- and cell death (apoptosis) as these processes take place. (Apoptosis -- cell suicide -- is thought to eliminate unwanted human tissue and to aid proper growth of organs, limbs, and neurons.) For victims of terrorist biological or chemical attacks, the transportable unit is expected to greatly reduce the time needed to analyze dangerous materials invading the blood stream. Diagnosis could be made on the spot, thus facilitating treatment when speed is crucial. Widespread adoption of the device would end delays for patients in obtaining results from blood tests, when blood taken by a nurse is shipped to a lab for analysis. Princeton University physicist Robert Austin in Science described the biocavity laser as "really an innovative technology." Using it, says Paul Gourley, device project manager at Sandia, "It's possible to take a blood sample containing millions of cells and extract information about each cell in a few minutes. The results are quantifiable. If no cell is cancerous, we get a standard light signal. A cancerous cell gives a bright flash at different wavelengths." The work is funded by Sandia's Laboratory-Directed Research and Development program, which funds speculative defense-related projects, and by the US Department of Energy. Preliminary interest has been expressed by blood and cell analyses companies, and by pharmaceutical companies, says Gourley. Lab-on-a-chip combines semiconductor and biological material The device combines semiconductor and biological material to function as a kind of lab-on-a-chip, bringing fluids into a microlaboratory and reading results on the spot. Gourley originated it with his brother, physician Mark Gourley at the National Institutes of Health, with assistance from Anthony McDonald, a Sandia technician. (Note: Mark Gourley is now at the Washington Hospital Center in Washington, D.C.) It employs a laser device called a VCSEL -- a vertical-cavity surface-emitting laser-- that originates millions of tiny laser beams from an area roughly the size of a postage stamp. VCSELS were pioneered by Sandia's Gourley, together with his Labs' colleague Tim Drummond, in the mid 1980s. How the device works Instead of creating beams that pass through blood cells and then yield data, researchers insert blood samples into the laser itself to become part of the generation process of the VCSEL laser beams, altering them as they are formed. Above a specialized semiconductor, a coated glass mirror forms one end of the laser generating area. In the glass, through etched microgrooves each 1/10 the width of a human hair, a blood sample is pumped. The unique design allows blood components -- red or white blood cells, or invading particulates -- to become part of the lasing process. The components of the blood in effect modify the lasing light as it is created in the tiny laser cavity, thus permitting output light to be analyzed in a spectrometer to detect changes in cell sizes and shapes. Because the light reflects many times through a given sample -- a consequence of the lasing process -- the deviation in image created by the blood particle is magnified, greatly increasing the chances of positive, errorless identification. What it sees A sickle-shaped red blood cell is clearly distinguishable from a normal, more spherical cell. The components of a white blood cell, held inside the cavity, can be analyzed to see how it reacted to organisms or drugs in the blood, thus aiding in the design of new drugs. "After microsurgery to cut a white cell open and let out its proteins, we can see the extent of the material in a cell. Activated lymphocytes will show a larger volume and index of refraction change," says Gourley. Because the readout relies on light-emitting semiconductors, in most usages the cells do not have to be killed and stained -- the most typical laboratory procedure. Instead, researchers can watch changes in cells as they occur -- in "realtime." "The microcavity laser is basically a tool to study cell structure changes," says Gourley, "and could even be used for sequencing DNA." Present methods of analyzing living cells involve flow cytometers, which merely shine a laser light through one cell at a time. Power and cost In wafer form, the device is activated by a laser microscope about the size of a telephone receiver that acts as an energy source and reads output from the biocavity laser like a supermarket scanner reads bar codes. To make a commercial biochip, quarter-sized electrical power sources already exist and bulky optical components would be replaced by an optical fiber, says Gourley. A small, no-frills system can distinguish between cells in a sample and offer a spectral analysis (without image) on a laptop computer for a cost between $5,000 to $15,000, Gourley estimates. A more complete setup for laboratory research to scan a laser over a surface or pump materials such as large quantities of blood through it would cost about $70,000. A comparison of biocavities with more conventional lasers A brief note here comparing bioocavity lasers, VCSELs and ordinary lasers: Conventional lasers require mirrors set opposite each other to reflect light back into the generating substance -- a crystal or gas -- placed between them, to create still more light. Lasers made from semiconductors use their sharply cleaved ends as mirrors -- light reflects because of the difference in speed of light in silicon and air, just as a glass window reflects images though it lets other light pass through. In the VCSEL, the semiconductor is not cleaved to provide a reflective surface. Rather, it is made by depositing alternating layers of tailored alloys. The layers are formed at exactly the distance from each other needed to reflect "in-phase" light, so the beam's efficiency is very high. (In-phase means that the maximums and minimums of the created light occur at the same time, creating a powerful effect.) The beams also are created in a far smaller generating volume than the typical semiconductor laser, and many more beams can thus be created to light an area. In the medical device, the top layer of gallium aluminum arsenide and aluminum arsenide are replaced with the glass slide whose microgrooves carry blood. The lasing beams are varied by the quality and components of the blood through which they pass, and by the glass from which they are reflected. Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national security, energy, and environmental technologies and economic competitiveness. # Visuals available: yes Media contact: Neal Singer, 505-845-7078 nsinger@sandia.gov Tech contact: Paul Gourley, 505-844-5806 plgourl@sandia.gov Sandia National Laboratories' World Wide Web home page is located at http://www.sandia.gov. News releases, fact sheets, and news tips can be found at http://www.sandia.gov/media/whatnew.htm. The Sandia Lab News Online Edition is at http://www.sandia.gov/LabNews/LabNews.html.
--------
508-> Preventing Perinatal Infections -- For Pennies
In a study of nearly 7,000 pregnant women, cleansing the birth canal with an inexpensive antiseptic solution dramatically reduced post-birth infections, hospitalizations and deaths, according to a study supported by the National Institutes of Health (NIH). The research report was published in the July 26, 1997 issue of the British Medical Journal.  The study was funded by the National Cancer Institute (NCI) and the National Institute of Allergy and Infectious Diseases (NIAID). "We found that washing the birth canal with a very safe solution -- 0.25 percent chlorhexidine in sterile water -- at eachvaginal examination before delivery, and then wiping the babies with the solution after delivery, significantly reduced postpartum infectious problems in both mothers and babies," says co-author Paolo Miotti, M.D., M.P.H., a pediatrician and medical officer in NIAID's Division of AIDS. "Perhaps most significant was our finding that infant deaths related to sepsis, or bacteria in the bloodstream, were reduced three-fold among babies in the intervention phase of the trial." Chlorhexidine has a long track record of safety, and the investigators noted no adverse reactions to the solution amongmothers or babies. "The low-cost, simplicity and safety of this approach suggests that it may have a role in reducing illness and death associated with perinatal bacterial infections, which exact a considerable toll among women and neonates, especially in the developing world," comments the study's field director, Taha E. Taha, M.D., Ph.D., of JohnsHopkins University.  "Significantly, the cost of the antiseptic solution used in this study, and the cotton to apply it, was less than 10 cents per patient, making this a feasible approach for the most resource-poor settings," adds co-author and senior investigator, Robert J. Biggar, M.D., of NCI. Although encouraged by these findings, the investigators stress that further research is needed in a randomized study to confirm the results. In the study, the investigators enrolled a total of 6,965 women at a busy hospital in Blantyre, Malawi.  The study was divided into control and intervention phases.  During the first two months of the trial -- a control phase -- women received the usual prenatal care provided at the hospital, and underwent the typical delivery procedures.  In the subsequent three months -- the intervention phase -- women received standard care plus birth canal washes with the chlorhexidine solution administered by a nurse midwife.  Babies born in the intervention phase were wiped with pads soaked with the solution immediately after delivery.  The final month of the study was a control month and no chlorhexidine solution was used. In all, 3,635 women giving birth to 3,743 babies were enrolled in the intervention phase of the trial, and 3,330 women giving birth to 3,417 babies were enrolled in the control months. *****Benefits to Babies and Mothers***** Compared to control infants, infants born in the intervention phase of the study were 22 percent less likely to die; three times less likely to die from sepsis; 12 percent less likely to be admitted to thehospital for any reason; and 2.3 times less likely to be admitted for sepsis. Among mothers receiving the chlorhexidine intervention, hospital admissions related to delivery were reduced by 27 percent and admissions related to post-partum infections were reduced three-fold. Dr. Miotti notes that additional studies of vaginal cleansing to prevent perinatal infections will be needed before the approach can be considered standard care.  Although the investigators speculate that the benefits seen in the intervention arm of the trial were due toreduction in pathogens in the birth canal, they did not have the facilities in this study to document infections before and after treatment with the chlorhexidine solution.  Future studies may involve taking vaginal swabs before and after cleansing with chlorhexidine and testing them for pathogens such as Group B streptococcus, which arerecognized causes of neonatal sepsis. The current report is the second from a study in Malawi that evaluated the effects of birth canal cleansing.  Previously, the researchers reported that the 0.25 percent chlorhexidine solution did not reduce the overall rate of HIV transmission from mother to infant. It did, however, reduce HIV transmission when a woman's membranes were ruptured for more than four hours prior to delivery (See Biggar RJ, et al. Lancet 1996;347:1647-50). "This study, designed in the context of HIV prevention, demonstrates that HIV-related research often has positive spin-offs relevant to other diseases as well," comments Anthony S. Fauci,M.D., NIAID director. NCI and NIAID are components of the National Institutes of Health (NIH).  NCI is the principal federal agency working to prevent cancer and help patients live longer and healthier lives.  NIAIDsupports research on AIDS, malaria and other infectious diseases, as well as allergies and asthma.  In addition to the current study, NIAID supports numerous other research to prevent perinatal infections, including efforts toward understanding the mechanisms by whichbacteria infect newborns, and developing and testing maternalvaccines to protect newborns against infections acquired in utero or during delivery.  NIH is an agency of the U.S. Department of Health and Human Services. ### Press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov, and on the NCI home page at http://www.nci.nih.gov. Reference:Taha TE, Biggar RJ, Broadhead RL, Mtimavalye LAR, Justesen AB,Liomba GN, Chiphangwi JD and Miotti PG.  Effect of cleansing the birth canal with antiseptic solution on maternal and newborn morbidity and mortality in Malawi: clinical trial.  British Medical Journal 1997;315:216- 
--------
509-> UF Researchers Build A Runway As A Landing Zone For Lightning Bolts
Writer: Karen Meisenheimer Source: Vladimir Rakov	(352) 392-4242E-mail: rakov@admin.ee.ufl.edu GAINESVILLE, Fla. --- After designing and building their own runway, equipped with typical lighting, signs and surface area, University of Florida engineers now plan to wreak electrical havoc on their new creation by causing lightning to strike it. The provoked bolts of electricity will help researchers study the effects of lightning strikes on existing runway lighting systems and develop new protective measures. The 300-foot experimental runway, built at UF's lightning research facility at Camp Blanding near Starke, is a fraction of the size of a typical runway. Part of its surface is paved with asphalt and the other part with concrete. The Florida Department of Transportation's Aviation Division is sponsoring the study, asking UF scientists to recommend improved standards for lightning protection. Officials are concerned not only with the expensive damage caused by lightning, but also with the potential danger to pilots, especially at small airports. "At most small airports, there are no personnel and runway lights are operated by the pilots with remote control," said Vladimir Rakov, associate professor of electrical and computer engineering at UF and lead investigator of the project. "If someone tries to land at night after lightning has knocked out the power, what happens next will depend on how much fuel the pilot has left." During Florida's peak summer thunderstorm season, researchers will launch rockets into dark, threatening skies from various positions on the runway. Each rocket will trail a grounded thin wire coated with Kevlar, a strong material used in things such as bulletproof vests. When a rocket initiates lightning, the bolt of electrical current follows the wire down to the runway through a lightning rod attached to the launcher. Before launching, engineers measure the electrical field at ground level to determine if a sufficient electrical charge has accumulated in the clouds. "It's true that tall objects are more likely to be struck by lightning," Rakov said. "We just create a temporary tall object by shooting the wire toward the clouds." The two surfaces, as well as two lighting systems, were designed to simulate different airport conditions, said Ralph Ellis, an associate professor of civil engineering at UF who was responsible for the design and construction of the model runway. He said the installation conforms to current Federal Aviation Administration (FAA) standards. Design and construction of the project took about one year, said Ellis, whose team included faculty and students from UF's civil engineering department. Two runway lighting systems are accepted by the FAA, Rakov said. With one, each light is placed on a stake in the ground with its transformer and the power cable buried in a trench along the runway perimeter. The more expensive system calls for each light to be mounted on a metal can housing the transformer. The power cable is placed in protective PVC piping before it's buried in the soil. Most small Florida airports use direct buried cables and stake-mounted lights, Rakov said. Both lighting systems were installed for UF's project to determine if one is better at surviving lightning. The FAA currently requires all airports to use a specific lightning protection procedure designed to draw the lightning away from the electrical circuit. It consists of a bare copper wire buried 4 inches above the power cable and attached to vertical rods installed around the entire circuit. The required wire, called a counterpoise, is connected to each light fixture and to the power source grounding system. But, Rakov said, such a configuration could make things worse. "There is no consensus on if it's protecting or not," Rakov said. "This is the first thing we'll find out. We'll test the FAA standard, and then we'll install an alternative protection system and test again to see if it does any better." -30- Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-9092.
--------
510-> USC Robot Explorers Find Enigmas On The Ocean Floor
The surface of Mars is not the only alien environment being probed by scientists with the aid of faithful robotic explorers.  For years, "lander" modules designed by University of Southern California scientist William Berelson and built in USC shops have gathered data at the bottom of harbors, seas and oceans all over the earth. Dr. Berelson, an associate research professor of earth sciences in the USC College of Letters, Arts and Sciences, is now pondering twin puzzles posed by his latest undersea explorer missions, both with significant implications for humans: * Why does the bottom of Los Angeles Harbor process wastewater nitrogen at only a fraction of the efficiency of the sea bottom off Melbourne, Australia, which is otherwise extremely similar in measurable characteristics?  (The answer to this may help clean up Los Angeles harbor, as well as protect Australian waters.) * Why did the deep waters of the Pacific Ocean suddenly become significantly more acidic approximately 3,500 years ago?  (The answer may be tied to the carbon cycles linked to global warming.) Berelson began designing his submersible landers, technically called "benthic flux chambers" ("benthic" means "of or referring to the ocean floor environment"), in 1981.  He first successfully deployed a lander in 1983, in the ocean off Los Angeles.  USC technicians have built many others since then. The landers are all designed to descend to the ocean floor and form a seal, trapping a volume of ocean water in contact with a small patch -- a little less than a square yard -- of submarine soil. The devices contain instrumentation to probe biochemically, on site, the way the soil, and the complex community of animals, plants and micro-organisms living in this soil, process various important elements and minerals.  They also can inject measured quantities of known substances into the sealed area to study what happens to them at the sea bottom. A good example of the kind of analysis Berelson's landers can provide is a recent study the scientist conducted in Port Phillip Bay, Australia, off the city of Melbourne. Human activity on land sends the nitrogen compound ammonia (NH3) into offshore waters in many forms -- treated sewage, agricultural and landscaping runoff containing fertilizers, and others.  Such waste nitrogen can produce dense, foul-smelling algae blooms and other undesirable consequences in the water. The ocean bottom can play an important role in nitrogen cycling in the ocean, because the community of micro-organisms living there can -- in some places at least -- convert ammonia and other nitrogen compounds into environmentally benign nitrogen gas. But Berelson found that ocean floors vary widely in their ability to convert nitrogen compounds.  The sea floor of Port Phillip Bay was extremely efficient at carrying out this conversion.  In many bay sites tested by the landers, all or almost all of the ammonia that entered the benthic sediments was being recycled. Berelson is able to say that the benthic reactions in Port Phillip Bay are unusually efficient because he has measured the same reaction in other areas, including the Adriatic Sea, San Francisco Bay and Los Angeles Harbor. "In Los Angeles Harbor, lander measurements showed a much lower efficiency.  Instead of 80% to 100% of the ammonia entering the sea bottom being recycled, as we found in Port Phillip Bay, we found zero to 40% being recycled in Los Angeles Harbor," Berelson explains. Berelson says the huge difference is mysterious because the two areas are otherwise quite similar.  The sea bottoms in both places receive about the same amount of carbon, in the form of a "rain" of dead plant and animal material.  The populations of marine animals "irrigating" the sea bottom are similar.  The size and type of sediments are similar.  So, too, are the waters' temperature, their salinity, and the amount of dissolved oxygen available at the sea bottom. Port Phillip Bay is a much larger area than Los Angeles Harbor, and the parts of the bay receiving the most pollution were found to have the least ability to recycle nitrogen waste.  "This finding still leaves the question of what's causing the difference," Berelson says.  "If we knew that, we might be able to improve conditions in both Los Angeles Harbor and Port Phillip Bay." Berelson's Port Phillip Bay research was part of a study funded by Australian authorities.  A report based on his research is under review by the Estuarine, Coastal and Shelf Science Journal. Berelson has uncovered another submarine enigma in the deep waters of the central Pacific.  In a recently completed study, to be published in the next edition of the journal Deep Sea Research, Berelson and a team of collaborators examined the fate of the element carbon on the ocean floor. Carbon falls to the bottom in various forms.  Most arrives as organic material, in the form of the soft tissues in the dead bodies of plants, animals and micro-organisms, and as calcium carbonate, the limy material in animal bones and mollusk shells.  Calcium carbonate, also known as calcite, slowly dissolves in the waters of the deep ocean, "like an Alka-Seltzer? tablet in a glass of water," as Berelson puts it. But in many places on the ocean floor, calcite accumulates because the rate of "rain" of new particles is greater than the rate at which old particles dissolve. In a series of  measurements based on lander data, Berelson and his team established that in recent geologic times, beginning 3,000 to 4,000 years ago, the rate of accumulation abruptly slowed. Using sophisticated measurements of trace levels of radioisotopes in bottom sediments, the group established that the slowing wasn't due to fewer new calcite particles raining down:  that amount has remained constant over at least the last 10,000 years or so. Another analysis ruled out another possible explanation -- that the slowing resulted from an increase in the amount of soft-tissue organic, non-carbonate carbon falling in the rain of particles from above, and that the greater quantity of carbon would speed the dissolution of calcite. Elimination of those two possibilities implied that the composition of the bottom water itself changed markedly about 3,500 years ago, becoming significantly more acidic and, hence, better able to dissolve calcite. Berelson is looking now for an explanation of what might account for such a change.  That date, 3,500 years before the present, is not associated with any obvious geological change, such as the end of an ice age.  Possibilities include a slowdown in the transport mechanism that circulates deep ocean water around the world, or  some stimulus that might have led to greatly increased production of organic carbon somewhere else in the world, "upstream" of the Pacific equatorial study zone.  But why either change might suddenly have taken place 3,500 years ago remains a mystery. The answer could prove important.  Knowing how such a large-scale change in the ocean's metabolism of the key element carbon could have occurred may help us to understand how the greatly increased introduction of fossil-fuel carbon in recent times will affect the air and oceans. Berelson's team on the carbon experiments included researchers from Lamont-Doherty Earth Observatory, Oregon State University, North Carolina State University, the Woods Hole Oceanographic Institution, the University of Hawaii, the University of Rhode Island, and the University of Miami (Fla.).  The National Science Foundation funded the research. Berelson believes his landers will provide more clues - and pose more puzzles.  "The use of robotic equipment to study the biogeochemistry of the sea floor fascinates me.  The results tell us not only about the way the ocean works today, but how the ocean and the planet's climate have behaved in the past." Berelson, a participant in USC's Wrigley Institute for Environmental Studies, is playing a leadership role in development of the institute's coastal oceanography program. EM.BERELSON.ME-USC-AUG. 18, 1997 EDITOR:   Dr. Berelson is a resident of Los Angeles (90036).  For more information, call him at (213) 740-5828 or send email to berelson@usc.ed 
--------
511-> NSF Awards Recognize Comprehensive Reform Of Undergraduate Education
University of California-Irvine leaders have decided thattheir existing mathematics and science curriculums are no longeradequate to prepare students to meet the needs of modern society. From that seemingly simple and straightforward proposition,U.C.-Irvine is about to embark on an ambitious strategy tomodernize its teaching.  The university will infuse technologyinto all teaching, forging partnerships with professionalassociations, and create a series of interdisciplinary curricula. These ground-breaking changes and institutional commitmentled the National Science Foundation to include U.C.-Irvine among19 colleges and universities to receive monetary awards in thesecond year of the agency's Institution-Wide Reform ofUndergraduate Education (IR) initiative. "U.C.-Irvine has made the kind of commitment tocomprehensively restructure, not merely tinker, at the margins ofreform, which is what the IR initiative is about," said Luther S.Wiliams, who heads NSF's education and human resourcesdirectorate. The UC-Irvine initiative is among many of the progressivechanges being made by two and four-year institutions that NSF isrecognizing through awards of up to $200,000 in the second yearof the IR initiative. Florida A&ive.M University, for example, is an awardee fordeveloping a multidisciplinary science course for non-sciencemajors and creating a faculty professional development initiativethat emphasizes effective use of technology. At Millikin University, a small school in Decatur, Ill.,introductory science courses and related labs will link the studyof biology, chemistry, physics and mathematics to otherscientific and technological disciplines.  The school will alsorequire students to teach a class in local K-12 schools. "The problems of the future will be very complex and theywill require interdisciplinary approaches and solutions," NormanFortenberry, who heads NSF's division of undergraduate education,points out.  "At too many institutions, there is not a mechanismfor faculty to work with their counterparts in other disciplines,nor to team-teach across disciplines." NSF launched the IR initiative in 1996 to rewardinstitutions that have made significant improvements in thequality of undergraduate education and are now prepared tointroduce sweeping changes to extend those innovations to benefitall students.  The changes reflect the institutions' response tothe new demands faced by undergraduates to succeed in a highlytechnological society. Williams said the IR initiative addresses serious nationaldeficiencies in undergraduate education that were highlighted ina report, "Shaping the Future: New Expectations for UndergraduateEducation in Science, Mathematics, Engineering and Technology."NSF published the report last summer. The IR awards complement another NSF initiative, theRecognition Awards for the Integration of Research and Education(RAIRE), which provided $500,000 grants to 10 research-intensiveuniversities for their commitments to blending their research andeducation programs.  RAIRE recognizes the prior achievements oflarge research universities, says Williams, while the IRintiative is open to all institutions that enroll undergraduatestudents and focuses on planned new programs to improve educationin math, science and engineering. -NSF- Attachment: Awards for Institution-wide Reform of UndergraduateEducation Awards for Institution-wide Reform of Undergraduate Education Alverno College:  The women's college in Milwaukee is expandingthe  quantitative reasoning requirement for all students beyondthe introductory level, including non-math and science majors. Brooklyn College - City University of New York:  The school's"across the curriculum" project systematically links quantitativeskills through core course in math, natural sciences and socialsciences. Broward Community College:  This two-year Florida college's newExploration Center will have an integrated math, science,engineering and technology curriculum with multi-course projectsand interaction with business and govenment agencies. City College - City University of New York:  The school isincreasing the engagement of faculty in undergraduate educationthrough new reward structures, formal training in curriculumdesign and mentoring and support systems. Colorado School of Mines:  The school is in the fourth year of acurriculum reform process, currently implementing a uniqueundergraduate engineering curriculum that will include new texts,lab experiments and multimedia materials. Colorado State University:  A two-year project will overhaulmath, science and computing skills for non-science majors.  Multidisciplinary, lab-based core courses have clearly defined linksbetween the impact of science and technology on society and theessential role of non-science disciplines. Drexel University:  Drexel is building faculty-wide teachingdevelopment activities based on successful programs inmath/science integration with engineering, widening the effortinto investigative, problem-solving bioscience curriculums. Hampshire College:  The Massachusetts institution's expandedInquiry Project Courses include an original research project toexpand student skills in critical thinking, quantitativereasoning, collaborative research and communications. Massachusetts Institute of Technology:  M.I.T. is developingdiscipline-specific communications instruction and practice intoits technical and scientific undergraduate programs, recognizingthat scientists' and engineers' professional success depends uponhow they communicate to wide audiences. Milikin University:  The Illinois university is fundamentallychanging introductory science courses across disciplines toincrease student understanding of the linkages between them, andapplying this knowledge to solve problems in the local community. New York City Technical College - City University of New York:The revision of core mathematics and science courses includesidentifying connections among the courses and developingexperience-based problems that enhance student skills in criticalthinking. Portland State University:  A Science Cornerstone Project ofinterdisciplinary courses is designed to achieve improved scienceliteracy among students majoring in fields outside science, math,engineering and technology. Sinclair Community College:  The Dayton, Ohio college isemploying new methods to align curriculum format to moderndelivery systems and addressing new ways to align curriculumoutcomes with the requirements of the modern work place. Southwestern College:  The Kansas school is structuring researchprojects to address real problems.  Freshmen students conduct anacross-the-curriculum project in water quality, formulatinghypotheses and designing experiments, then generating proposalsfor research by the next freshman class. Trinity College, Connecticut:  Philosophy course labs are beingdeveloped to model those found in science departments to focus onstudents' problem-solving skills.  Cross-disciplinary techniquesin math and science associated with philosophy to improve mathand science literacy within a humanities setting. University of California - Irvine:  Major curriculum changes inmath, computer science and engineering (and engineeringliteracy), along with a new infusion of educational technologyand multidisciplinary curricular committees are part of aCampuswide Reform Initiative. University of Delaware:  Interdisciplinary faculty teams arecreating freshman and sophomore-based Foundation Courses inscience and engineering to increase analytical skills, bettercommunication, teamwork and resource utilization. Worcester Polytechnic Institute:  Addressing concerns of studentsthat introductory science and mathematics courses have littlerelation to one another, WPI has begun a system of peer-assistedcooperative learning, open-ended group course projects andintegrated computational and instructional technolo 
--------
512-> Evolution Re-Sculpted Animal Limbs By Genetic Switches Once Thought Too Drastic For Survival
Extremely powerful genes that govern the shape of an embryo from the earliest stages of development have been tinkered with by nature over the course of evolution to create the enormously wide range of animal forms, scientists report in the August 14 issue of the journal Nature. Homeotic, or Hox genes specify the identity of segments along the embryo's body axis and regulate the formation of major structures in every animal studied. But because laboratory mutations in these genes can cause monstrosities--such as a fly with legs where its antennae should be--many scientists doubted that natural variation of homeotic genes could underlie the incremental, survivable changes that accrued over eons as animals gradually evolved improved body parts. Today's finding marks the first time that changes in the control of homeotic genes have been shown to underlie an evolutionary trend leading to novel body structures. Nipam Patel, assistant professor of organismal biology and anatomy in the University of Chicago's Howard Hughes Medical Institute, and Michalis Averof, currently at the European Molecular Biology Laboratory in Heidelberg, showed that changes in the pattern of activity of two Hox genes in crustaceans are linked to the relatively sudden evolutionary development of useful, distinctive feeding limbs called maxillipeds (literally jaw-feet) where swimming or walking legs once were. The finding is a landmark in the new field of evolutionary developmental biology, or "evo-devo," as its proponents call it, in which scientists study the patterns of gene expression in embryos to peer backward in time. In the past few years, researchers have made remarkable progress in identifying genes that specify gross changes in body shape early in development. But others have argued that any naturally arising variants in such genes would quickly die. "The question has always been did evolution actually fiddle with this stuff to generate diversity of body plan?" says Patel. Many scientists looked to insects for natural homeotic gene variation, Patel explained, because insects have such diverse body plans. "But it turns out that much of their diversity arises after this step in development," he said. "The diversity comes not so much from controlling where in the embryo the homeotic genes are initially expressed, but how other genes respond to them." Instead, Patel and Averof turned to crustaceans. They collected a wide range of specimens--13 separate species from nine different orders--many of them at the Smithsonian Field Station in Belize. "Crustaceans have far more variation than insects in their body plan," Patel said. "If that's surprising, it's because people only think of the two or three closely related kinds of crustaceans we eat." The researchers used an antibody that labels the proteins made by two closely linked homeotic genes, Ubx and abdA, to show in which segments of the embryo the genes are turned on. The Ubx-abdA genes--like other homeotic genes, including the one that can cause a fruit fly to grow a leg out of its head--orient the embryonic tissues as to where they lie in the body. In the case of that particular fly mutant, if the homeotic gene called Antennapedia is turned on in the head segment, "the cells that bud off from the fly's head think, 'oh, we're sitting in the thorax, we're supposed to grow into a leg,'" Patel explained. In crustaceans, if Ubx-abdA is turned on in a segment, it tells the limb buds they lie in the part of the thorax that should grow locomotory legs. The researchers found variation in the pattern of segments in which Ubx-abdA is turned on, and that pattern corresponded with anatomic changes that traced ancestral relationships and evolution. "In primitive kinds of crustaceans, we found Ubx-abdA is turned on in the first thoracic segment and is 'on' from there back to the tail," Patel said. "In these animals, there's a marked difference between the appendages of the head and the thorax--the head has tiny appendages used for pushing food into the mouth, and the thoracic appendages are long and feathery for swimming." But in more advanced crustaceans, the first segment in which Ubx-abdA is turned on lies farther back along the body. In these animals, the first few thoracic segments have appendages that look like those of the head. These maxillipeds are not just misplaced jaw parts but have new capabilities because they are attached to the powerful muscles and the nervous system of the thorax. Crustaceans that have them include the decapods--shrimp and lobsters and their relatives. "If you watch, animals with maxillipeds can feed in a different way," Patel said. "They can walk and hold and move their food at the same time. This has clear implications for the organism and can be an advantage, depending on environment." Patel said the finding legitimizes the comparative genetics of early development as a tool for studying evolution. "This variation is what everyone had hoped to find for this class of genes," he said. "They hoped you would find a change in morphology that mirrored what was happening with respect to expression of the gene. They weren't finding that in insects, but in crustaceans we show a very striking example of this correlation." The research was funded by the Howard Hughes Medical Institute and the Carnegie Institute.
--------
513-> "Super Aspirin" Holds Long-Term Benefits For Some Patients Who Undergo Balloon Angioplasty
While innovative techniques and catheters, including coronary stents, have dramatically improved success rates for nonsurgical coronary revascularization, complications following balloon angioplasty remain an important problem associated with mortality. An intravenous "super aspirin" called abciximab (ReoPro™, Centocor, Inc., Malvern, PA) administered in the catheterization laboratory before an angioplasty can prevent platelets from sticking to arterial walls and reclogging vessels after the procedure. Results of a multicenter study published in the August 13 issue of The Journal of the American Medical Association (JAMA) demonstrate a favorable effect on long-term outcome and survival in selected patients treated with ReoPro™. In an editorial that accompanies the study, David L. Fischman, MD, associate professor of medicine, division of cardiology, Jefferson Medical College, Philadelphia, and associate director, cardiac catheterization laboratory at Thomas Jefferson University Hospital, recognizes the vast advantages of ReoPro™ but points out that patient profiles, drug costs and other interventional alternatives are issues to consider when deciding who should receive this "super aspirin." In his editorial, Dr. Fischman notes that the multicenter study, which is a three-year follow-up to an initial study of ReoPro™, led by Eric J. Topol, MD, of the Cleveland Clinic Foundation, Ohio, shows that the benefits of ReoPro™ are greatest in the highest risk patients with acute heart attack or medically unstable angina. "The Topol study suggests a remarkable 60 percent reduction in mortality at three years in this select group treated with ReoPro™ compared with the group treated with placebo," said Dr. Fischman. While pretreatment with ReoPro™ is highly effective, its average cost is estimated at $1,350 per patient dose. "The cost of this drug should bring significant attention to the question of who should receive it," said Dr. Fischman. "The issue of cost-effectiveness is vital to understanding whether or not ReoPro™ should be used in lower risk patient populations." Dr. Fischman suggests that further investigation is necessary to address this issue. "Future development of oral agents similar to ReoPro™ promises to further expand the use of these agents to a broader spectrum of patients with ischemic heart disease," he said. Michael P. Savage, M.D., associate professor of medicine, division of cardiology, Jefferson Medical College, and director of the cardiac catheterization laboratory at Thomas Jefferson University Hospital, contributed to the editorial.
--------
514-> New Gene May Intensify Breast Cancer Growth
Bethesda, MD - Scientists in the National Human Genome Research Institute (NHGRI) at the National Institutes of Health (NIH) have discovered a new gene that is pivotal to a crucial metabolic pathway linked to the growth and progression of human breast cancer. The gene appears to be expressed at abnormally high levels in tumor cells of most breast cancer patients, more than half of cases examined so far. The researchers report their findings in the August 15 issue of Science. In many cancers, but especially breast cancer, tumor cells accumulate extra copies of genes that give the cancer a growth advantage. The new gene is one such amplified gene. The gene, previously unknown, is linked to the estrogen response pathway. The scientists expect further study of the gene to help reveal the basic biology of tumor cells, especially those responsive to steroid hormones. This group of diseases includes not just breast and ovarian cancer, but prostate cancer as well. The NHGRI researchers found the gene, which they call AIB1 (amplified in breast cancer-1), by searching the long arm of chromosome 20 for genes whose expression and copy number are elevated in breast cancer. The gene is expressed at lower levels in normal human tissue. AIB1 is the most recently identified member of a gene family known as SRC-1 (steroid receptor coactivator), all of which interact with genes for steroid hormone receptors, ultimately enhancing tumor cell growth. "It's another example where information that we have about other members of this gene family allows us to infer that this may be very important in breast biology, regulating not just steroid growth response but possibly other growth response pathways. It could eventually be a target for therapeutics. It will certainly be a target for significant additional biologic studies to understand its action," said Dr. Paul Meltzer, the senior author of the paper, and a faculty member of the NHGRI's Division of Intramural Research, at the NIH. The finding is too new to have an immediate impact on breast cancer therapies. "At this early stage, we're really thinking more in terms of the fundamental cell biology of breast cancer. We think this gene is probably part of the engine that drives the growth of some breast cancers, and we're trying to understand how that works," said Dr. Jeffrey Trent, a co-author of the paper and head of the NHGRI laboratory where the gene was cloned. The researchers have also begun to design the first clinical studies using the gene as a marker to find out how it affects the course of breast cancer. "Do the patients who make a lot of the message from this gene respond differently to therapy, do they have a different clinical outcome, are their tumors different, do they develop at a different age or at a different rate" We don't have answers to any of those questions yet, but we are actively seeking the answers," said Trent. "A lot is known about how steroid receptors work, but the wiring of how they send their signals has been imperfectly understood. There are a lot of different genes which seem to be part of this system. We suspect that this one is a particularly important part of the wiring system in the breast cancer cell that transmits the signal from steroids like estrogen that says 'grow,'" Meltzer said. "It gives us a important new window into the cell biology of breast cancer that emphasizes the importance of this particular kind of gene to the growth of cancer cells in a significant number of patients. And that's going to be an extremely interesting thing to investigate." Previously, other genes found to be amplified in breast cancer have led to clinical tests and trials of therapy. AIB1 may turn out to be a new candidate for similar development, Meltzer noted. NHGRI oversees the NIH's role in the Human Genome Project, an international research effort to develop tools for gene discovery. 
--------
515-> Study Finds Five Football Players Died In 1996 Season, Nine Paralyzed
CHAPEL HILL -- Five high school football players died from injuries suffered on the playing field during the 1996 season, according to a new University of North Carolina at Chapel Hill study. Another 12 -- including one professional and one college player -- died, but their deaths came from heart failure and other conditions not directly linked to football. "Of the five direct deaths, four resulted from injuries to the brain and one from a blow to the chest from a helmet," said Dr. Frederick Mueller, professor and chair of physical education, exercise and sport science at UNC-CH. "We found two heatstroke deaths in 1996," Mueller said. "During the 1995 season, there were four heatstroke deaths, which made no sense since proper precautions should prevent all such deaths." Chairman of the American Football Coaches' Committee on Football Injuries, Mueller directs the National Center for Catastrophic Sports Injuries, located on the UNC-CH campus. Each year, the center issues reports on deaths and severe injuries from amateur and professional sports. Reports are based partly on newspaper stories from around the United States, along with information from the National Collegiate Athletic Association, the National Federation of State High School Associations and about 150 volunteers who monitor sports accidents. Nine young men were permanently paralyzed last year, including six in high school and three in college, Mueller said. Five high school players suffered head injuries, which resulted in brain damage with some permanent disability. "Coaches need to remind players continually to keep the head out of football," Mueller said. "No player should make initial contact with his head when blocking and tackling." Shortened practices and non-contact drills during which players do not wear helmets also help prevent heatstroke and reduce accidents, he said. Coaches should allow players as much water as they want and call regular cooling-off breaks. Mueller attributed the drop in deaths directly caused by football to rule changes adopted in 1976 that prohibited using the head as the first point of contact during blocking and tackling. In 1968, 36 young men died after injuries in practice or games. In 1970, eight players died from heatstroke. Before 1955, no deaths from becoming overheated were recorded among football players. Mueller said the reason may be that few schools and homes had air conditioning before then, and boys and young men likely were better able to tolerate the heat. Parents should ensure that youngsters who want to play football have a physical examination and that their coaches know and teach safe playing techniques, the UNC-CH professor said. They also should ask whether insurance and medical assistance are available in case of injuries. The annual survey of football deaths and injuries began at Yale University in 1931, moved to Purdue University in 1942 and has been at UNC-Chapel Hill since 1965. It is sponsored by the American Football Coaches Association, the National Collegiate Athletic Association and the National Federation of State High School Associations. 
--------
516-> Duke Researcher Finds Some Tropical Farming Practices Have Surprising Consequences
ALBUQUERQUE, N.M. -- A Duke University doctoral student in botany has found that a type of shifting cultivation long practiced on the Indonesian island of Borneo can boost fertility of tropical soils, but apparently only at a cost to tree biodiversity. Deborah Lawrence has made her findings during five years of research at a remote Dayak village whose inhabitants periodically clear 2-acre patches of land for rice farming or rubber and fruit tree cultivation. In between cultivating these patches, the Dayaks allow them to revert to native shrubs and trees during 20 year long "fallow" periods. These fallow and active farming sites, in turn, are nested within a matrix of "primary" forest land that has never been cleared for farming -- forming a mosaic of differing land uses. In a report prepared for presentation Monday at the Ecological Society of America's annual meeting, Lawrence described her recent analyses of soils and trees within seven grown-over fallow sites that had not been cultivated for 10 years, and three other never-disturbed primary forest sites. Her research was supported by the National Science Foundation, the World Wildlife Fund, the National Security Education Program and the Garden Club of America. Lawrence's previous studies in the same area have shown that the Dayak method of shifting cultivation actually makes soils more fertile than those in undisturbed primary forest. Those results themselves are "surprising," she said in a recent interview at Duke, because they contradict negative perceptions of "slash and burn" methods that the Dayaks themselves employ to clear land. In her newest study, Lawrence found that -- especially when she combined all her data from all her sites -- tree biodiversity was "negatively correlated" with soil fertility. In other words, the less carbon, calcium, magnesium, nitrogen, phosphorus and potassium she found in the soil, the more varieties of trees she found growing in a given study plot. Each of those elements is an essential nutrient, Lawrence said. Carbon is the building block for all organic life, while nitrogen and magnesium both contribute to the photosynthetic process that uses sunlight to create plant sugars. Phosphorus is essential for energy production. Calcium is used to make plant cell walls. And potassium contributes to plant water regulation. When she separated the fallow site data from that for the primary forest sites, Lawrence found some interesting differences. Not only was there more tree diversity in the never-disturbed woodlands, she said, but to some extent, the relationship between biodiversity and soil fertility was actually reversed when primary forest plots were analyzed alone. With increasing fertility, diversity increased in primary forest, whereas it decreased in periodically-cultivated plots. "It's as if cultivation takes the soil over some critical threshold where nutrients increase to the point that they then actually limit diversity in a negative way," said Lawrence, who is specializing in biogeochemistry and community ecology. Her latest findings offer mixed signals for the prospects of reclaiming former tropical rain forests that have been cleared of their trees. On the one hand, she said, they corroborate a paradoxical finding of other scientists. Tropical rain forests may grow the world's most diverse array of plant life. But conditions are so delicately balanced there that the soils actually contain relatively few nutrients. That means that subsistence farmers who clear tracts of the rich forests in the hopes of a quick return in bountiful row crops are quickly disappointed. They then must move on to destroy additional rain forest, leaving behind soil too depleted to grow anything but scrub grass. But Lawrence's findings also suggest that Borneo's Dayaks have found a way to manage rain forest land much more productively by alternating various parcels between rice production, tree gardening, and decades-long resting periods. "It's a broad mosaic of uses, much richer in species than any other land use system around," she said. "It's certainly richer than tree plantations or oil palm plantations or clove plantations or pulpwood plantations. But, within this land use system itself, there's no doubt that there's a decline in diversity and that it will probably continue." By improving the soil's fertility, though, Dayak methods may actually create the conditions for the long process of generating the next rain forest, Lawrence added. All that would be needed would be seed from nearby remaining patches of primary forest. "It means that we don't have to bring fertilizers in to get the forests to come back," she said. "We just have to leave them alone and make sure there are seed sources." Fluent in Indonesian, Lawrence collected an oral history of the changing uses of each patch of land in her study area by gaining the Dayak's trust over a five-year period. She would ask farmers how many times they had "opened" a given patch for cultivation, knowing that there were intervening fallow periods of approximately 20 years. She also asked the farmers what they remembered about their parents and grandparents use of various tracts. "I think that by going back three generations you can get a rough but pretty reliable estimate about how many times a patch was used," she said. Land in her study area around the Dayak village of Kembera has been in continuous though shifting cultivation for at least 200 years. ### 
--------
517-> Where Fossils Fear To Tread: Scientists Follow Genes To An Ancient Ancestor
FOR IMMEDIATE RELEASE 8/13/97 CONTACT: Sean Carroll, (608) 262-6191, sbcarrol@facstaff.wisc.edu MADISON - Some 600 or 700 million years ago, before animal life made a sudden evolutionary shift and diverged into nearly all the major animal divisions we know from fossils, primitive animals were inventing the genes that would make it all possible. No one knows what it looked like. There is virtually no clear fossil evidence. But now scientists believe they have found a way - using genes preserved in and common to modern animals - to look past the fossil record to our most distant common ancestors. Writing this week (Aug. 14) in the journal Nature, and following up on a series of recent papers, molecular biologist Sean Carroll of the Howard Hughes Medical Institute at the University of Wisconsin-Madison, Neil Shubin from the University of Pennsylvania, and Cliff Tabin of Harvard Medical School, sketch out a radical new way of looking back in time. "The fossil record prior to the Cambrian is so scant nobody knows the origin of animal life," said Carroll. But now "we're drawing a picture of something no one has ever seen." Carroll is one of a growing number of scientists now using the techniques of modern molecular biology to look into the murky waters of distant evolutionary biology. They are looking so far back that there are virtually no fossils or other physical clues to what the Earth's earliest animals were like. But Carroll and others are now finding powerful evidence that an ancient common ancestor - a worm-like animal from which most of world's animals subsequently derived - invented a set of body-building genetic machinery so successful and malleable that it has survived to this day. "This is stunning," said Carroll. "Nobody thought that this animal was so sophisticated. We're talking about the common ancestor of all the most successful animals on Earth." What is so striking, according to Carroll, is that the genes used to grow appendages - legs, arms, claws, fins and antennas - were operational at least 600 million years ago, and that the genetic machinery is very similar in all animals past and present. What makes animals different, what differentiates a crab from a mouse or a fruit fly from an eagle, is simply how those genes are expressed, he said. Until the advent of genetic techniques and recent work that has shown that animals, as embryos, share the same genetic machinery that governs body architecture, the only recourse for understanding how animals evolved different kinds of appendages was in the realm of comparative anatomy. And appendages, said Carroll, have been used as classic examples of independent evolution. But now Carroll and his colleagues argue that the problem of developing limbs, be they claws or wings, was solved just once a very long time ago, and that the genetic mechanism is still at work. "Everybody thought the wheel was invented again and again and again," Carroll said, "but there was a single solution and everything is a modification of that." That argument is supported, said Carroll, by the discovery of the same appendage-making genes in six broad divisions of the animal kingdom, including vertebrates, insects and fish. The discovery, made in Carroll's lab, was reported last May in the Proceedings of the National Academy of Sciences. "We found the same mechanism in all of these divisions of the animal kingdom. The architecture can vary tremendously, but the genetic instructions are the same and have been preserved for a very long period of time," he said. The idea that a common set of genes is responsible for building appendages not only simplifies evolutionary history, but helps explain the great burst of evolutionary activity known as the Cambrian explosion. This "evolutionary big bang" took place in the world's oceans more than 500 million years ago when new animals appeared at breakneck speed. "The reality is that animals with appendages took off and dominated the Earth," at that time Carroll said. "It was like an arms race" with animals that could swim faster, grab tighter and fight with greater effect dominating the ocean environment and conquering new ones like the land. During the Cambrian, animals got bigger and more diverse, but those changes did not require new genes. The techniques being pioneered by Carroll and others are opening a new window to the past, said Carroll: "It's doing paleontology without fossils." ### - Terry Devitt, (608) 262-8282, trdevitt@facstaff.wisc.edu 
--------
518-> PAL-2 Computer Promises Dramatic Improvements In Image Processing
Writer: Randolph Fillmore Sources: Gerhard Ritter or Joseph (352) 392-1212 GAINESVILLE, Fla. --- A pizza-box size desktop computer as fast as 9,000 Pentium processors soon will dramatically speed and improve everything from airport luggage checks to mammograms, using a mathematical computer shorthand developed at the University of Florida. Known as PAL-2, for Parallel Algebraic Logic, the computer also will bring about equally dramatic drops in the cost of image processing, said Gerhard Ritter, professor of computer engineering and mathematics and director of UF's Computer Vision and Visualization Research Center. Ritter, along with fellow UF researcher Joseph Wilson, developed and pioneered the mathematical theory known as image algebra that makes the technology possible. "When we began developing image algebra, we wanted to provide the military and the commercial market with an image processing capability that would significantly reduce the cost of the next generation of high-speed image and signal processors," Ritter said. "By the year 2000, thanks to image algebra and the PAL-2 chip, the cost of powerful imaging computers will come down from today's half a million dollars to about $4,000." The chip design for an evolved PAL-2, a 4-by-5-inch multi-chip module, is being tested now. Like PAL-1, it will have military applications but also will have a huge effect on the world of commercial image processing. "The first PAL-2 chips will be made this year," said Ritter. So what does the new chip mean in terms of real work? A huge image processing task, such as matching millions of finger prints in a national database -- a task that today takes an hour -- will take a 60 seconds with PAL-2.  Airport security will be able to X-ray quickly and effectively every piece of luggage, not just carryons.  Medical image processing -- mammography, telemedicine, cytology, robotic vision and even document image processing -- will move at lightning speed with greater clarity and accuracy. The development of image algebra began at the University of Florida in 1984. Several image algebra programming languages have been created since then. The current version works with the PAL-1, an attached work station accelerator that has been used for sometime by the military. Image algebra is a mathematical theory that simplifies and shortens lengthy computer commands previously written in long algorithms. When image algebra's more time-efficient commands are  applied to the super-fast PAL-2 computer chip, the shortcuts will allow a computer to perform up to 10 billion operations per second. Ritter compares the difference in calculation speed with what was realized when the world switched from ancient and cumbersome Roman numerals to the Indo-Arabic numbers we use today. "Image algebra is an algebraic notation for specifying computer vision and image processing algorithms," said Ritter. "It is based on well-defined and well-known mathematical systems and grew out of a need by the U.S. Air Force Systems Command for a common image processing language." Because the basis of image algebra is a mathematical theory that makes it  independent of any future computer architecture or language, Ritter said, its longevity and continued evolution is assured. Also, he said, it can be programmed on any computer platform. "Image algebra is living mathematics," said Ritter. "It is not a 'thing' but a body of knowledge, so it will continue to develop."		-30- 
--------
519-> NASA Selects Replacement Instrument For Hubble Telescope
NASA has selected a proposed scientific investigation that includes the development of a new spectrograph for the Hubble Space Telescope (HST), Associate Administrator for Space Science Dr. Wesley T. Huntress, Jr., said today (August 12).  The estimated cost of the new instrument is about $25 million. NASA will work with Dr. James C. Green, University of Colorado, Boulder, to negotiate a contract for the new instrument, called the Cosmic Origins Spectrograph (COS).  The new spectrographic instrument is planned for installation on the HST by Shuttle astronauts during the fourth servicing mission scheduled for late in 2002. "The new instrument's capabilities will be a major enhancement to Hubble's spectrographic capabilities at ultraviolet wavelengths," said Dr. Edward Weiler, HST Program Scientist, Washington, DC.  "This state-of-the-art spectrograph will be a premier Hubble instrument for most of the first decade of the next century.  It will allow astronomers to study the very early Universe and the creation of the heavy elements during the first period of star formation billions of years ago." Plans call for the COS to be installed into the HST instrument bay in place of COSTAR, the instrument that was successfully installed in 1993 and corrected early instruments for the telescope's optical aberration.  More recent instruments include the correction in their design and COSTAR no longer will be needed. Ball Aerospace Corp., Boulder, CO, is the prime hardware contractor for  COS. - end - 
--------
520-> Stress From Plate Collisions Travels Through Continents, Says University Of Michigan Geologist
EDITORS: A color slide of a limestone deposit sampled in the U-M study is available on request. ANN ARBOR---When continental plates come together to form mountain ranges, the impact from the collision bends microscopic grains in rocks more than 1,200 miles away, according to an article published in this week's issue of Science. "Classic plate tectonics theory maintains that all activity is concentrated at the plate margins, but our evidence shows that seemingly quiet mid-continent areas are highly sensitive recorders of plate tectonic activity," said Ben A. van der Pluijm, University of Michigan professor of geological sciences. When examined under a microscope, calcite grains in limestone samples, collected by van der Pluijm and his colleagues at more than 70 North American mid-continental locations, all showed the characteristic bending or deformation pattern produced in rocks under shearing stress. Intensities of stress recorded in the limestone samples varied directly with distance from the Appalachian and Rocky Mountain ranges. "These grains of calcite are like stress gauges placed in the Earth long ago," said van der Pluijm. "Since each deformation pattern corresponds to a specific stress level and orientation, these patterns preserve a permanent record of the effects of plate collision and mountain-building over long periods of geologic time." Published in the Aug. 8 issue of Science, the research was conducted by van der Pluijm; John Craddock, associate professor of geology at Macalester College; U-M undergraduate student Brita Graham and U-M graduate student John H. Harris. Stresses in continental plate interiors---a region long ignored by geologists---could provide new insights on tectonic processes, such as basin formation and fault reactivation, and offer critical input for computer modeling of plate dynamics, according to van der Pluijm. U-M researchers collected samples from limestone deposited between 500 million and 200 million years ago---a period of time when the North American mid-continent often was covered with shallow seas. Samples were taken at regular intervals along two transects or straight lines. One sampling line extended from the Rocky Mountains in Wyoming into Minnesota. The second line, which replicated results from a previous study, originated in the Appalachian Mountain range in Tennessee and extended into Indiana. "Surprisingly, deformation patterns from both transects were identical, even though the Appalachian range on the eastern side of the North American continent differs dramatically in age and style of mountain formation from the Cordilleran range on the western side," van der Pluijm said. "Mountain belts appear to act as 'stress filters' absorbing any variations in plate margin conditions before transmitting stress into plate interiors." While the orientation of the calcite grain stress indicators did not change along either transect, the level of stress recorded decreased steadily with distance from the mountain range. Stress levels recorded in Wyoming nearest the Rockies, for example, were about five times greater than those recorded in western Minnesota. "Our data show that mid-continent areas are not quiet and tectonically dead, as geologists believed," van der Pluijm said. "Transmitted stresses were associated with a host of geologic phenomena, including motion and earthquakes along ancient faults created long before recent mountain-building occurred." The research project was funded by the Pew Charitable Trust, the Blandin Foundation, the Huron Mountain Wildlife Foundation and the National Science Foundation. U-M senior Brita Graham participated in the project through the U-M College of Literature, Science, and the Arts' Undergraduate Research Opportunity Program, which facilitates undergraduate involvement in faculty research.
--------
521-> 'Yogi' Rock Found On Mars Similar To Rocks Underneath 'Yogi' Berra Stadium, Geologist Says
UPPER MONTCLAIR, N.J. --   "Yogi," the rock that the Sojourner rover investigated on Mars,  is remarkably similar to the rocks underneath recently dedicated "Yogi"  Berra Stadium on the Montclair State University campus, a university geologist says. "'Yogi'  appears be more earth-like than anticipated, according to the preliminary analyses,"  said Dr. Gregory Pope of MSU's Earth and Environmental Studies Department. "NASA geologists indicate that 'Yogi' is a fine-grained homogenous basalt. This if very much like the rock that underlies the University campus and can be found in the former quarry where Yogi Berra baseball stadium is being constructed. "'Yogi' looks unlike any of the Martian meteorites recovered on earth," Pope said. "In chemical composition, it falls into the realm of 'terrestrial basalts,' which would group it with similar volcanic rocks such as the Watchung basalt of Montclair or the Columbia flood basalts of Washington state. These are the very dark, solid rocks that come from runny lava emanating from fissures and fractures. 'Yogi' has plenty of dark minerals and only a little silica (like quartz) typical of basalt. "NASA says that basalt is the most common rock found in the inner solar system, and makes up major portions of the surfaces of Mercury, Venus, the Moon, as well as part of Mars and parts of Earth. That 'Yogi' falls within the range of Earth basalts is very interesting, if only for the remarkable coincidence." Pope said that "the similarities are such that if 'Yogi' -- the rock, not the baseball legend who lives here in Montclair -- was lurking out on the edge of the baseball stadium parking lot, I doubt we would notice much of a difference." Pope noted that both the 'Yogi' rock on Mars and the rocks underlying MSU's baseball stadium "come from volcanic flows that resemble those from Hawaii or Iceland. The Martian rock, however, is probably at least 10 times as old as our local variety, and could be a lot older than most rocks you could find on earth." Pope added that 'Yogi' differs from neighboring rocks on the Martian surface. "'Barnacle Bill' is an andesite, a completely different volcanic rock, with more silica, more like what would be found on tall volcanic cones like Mt. St. Helens, Mt. Rainer or Mt. Fuji, but still different in rock chemistry from similar rocks on earth," he said. "That 'Barnacle Bill' and 'Yogi' are near each other is interesting," Pope said. "Sagan Station is located on what appears to be a Martian floodplain. Perhaps the stones were carried by floodwaters which left them side-by-side. Martian floods were on a scale probably unprecedented on Earth. The only floods we have to compare are the catastrophic glacial lake bursts in Idaho and Washington at the end of the last Ice Age." Pope said that he found the similarities between rocks on the two planets intriguing. "It's very satisfying to translate what one studies on earth to relevant features on another planet. Mars is still very alien and hostile to life as we know it, yet has many familiar characteristics deriving from familiar processes. Regardless of whether we confirm if life ever existed on Mars, we have found a connection between the two planets." Pope noted that a graduate student with whom he is working, Glenn Calabrese, is involved in a study of what the Martian "soil" might be. "We are both eagerly awaiting more data from NASA on this," Page said. "Most geologists have used Antarctica, with its dry, cold, climate, as an analog for Martian soil-forming conditions. Calabrese thinks that Australia, with its ancient desert surface, deep weathering and highly oxidized soil might be a better choice. Of course, a lack of organics and water would make a major difference. But, if the rocks are any indication, the similarities may be more than we expected."
--------
522-> Fluoride Molecules Detected In Space
THE JOHNS HOPKINS UNIVERSITY OFFICE OF NEWS AND INFORMATION 3400 N. Charles Street Baltimore, Maryland 21218-2692 Phone: (410) 516-7160 / Fax (410) 516-5251 ---------------------------------------------------------------- August 7, 1997 FOR IMMEDIATE RELEASE CONTACT: Emil Venere Emil@jhu.edu ASTRONOMERS DISCOVER FLUORIDE MOLECULES IN INTERSTELLAR SPACE Not only is our water supply fluoridated, but so too,apparently, is our galaxy. A team of astronomers from the United States and Germany,led by Johns Hopkins astrophysicist David Neufeld, has discoveredtrace amounts of hydrogen fluoride gas in the near vacuum ofinterstellar space, using a satellite built and launched bythe European Space Agency and operated by ESA with NASA's participation.Although approximately 100 different kinds of molecules have been detectedin interstellar space over the past 30 years, the discovery ofhydrogen fluoride marks the first time that a molecule containingfluorine has been detected in an interstellar gas cloud. It is also thefirst time that a new interstellar molecule has been detected byobservations at far-infrared wavelengths. The discovery will be reported in an article that is toappear in October in the Astrophysical Journal Letters. The astronomers searched for hydrogen fluoride moleculeswithin a giant cloud of interstellar gas located near the centerof the Milky Way galaxy, using ESA's Infrared Space Observatory satellite,which was launched in November 1995. The new observations were carried out inMarch 1997 with the Long Wavelength Spectrometer, one of four instruments onboard ISO. Looking in the far-infrared region of the electromagnetic spectrum,the astronomers observed the telltale signature of absorption by trace amountsof hydrogen fluoride gas. "Because the Earth's atmosphere is completely opaque tofar-infrared radiation, the observations that we carried out arepossible only from space," said Neufeld, a professor in the Johns?ŠHopkins Department of Physics and Astronomy. "The ISO satellitehas opened up an exciting new window on the universe by allowingus to observe at far-infrared wavelengths." In concentrated liquid form, hydrogen fluoride -- orhydrofluoric acid as it is known when dissolved in water -- isfamiliar to laboratory chemists as an extremely dangerous andcorrosive acid that dissolves glass and severely burns humantissue. The ISO's sensitive spectrometers enabled the astronomersto detect hydrogen fluoride in interstellar space even though itsconcentration was less than one part per billion. The characteristic wavelength at which hydrogen fluoridemolecules absorb radiation is about one two-hundredth of an inch,much larger than the wavelength of visible light but far smallerthan the wavelengths typically used for radio and televisioncommunications. The gas cloud in which hydrogen fluoride molecules werediscovered lies about 20,000 light years from Earth, in thesouthern constellation Sagittarius. Known to astronomers asSagittarius B2, the gas cloud is composed primarily of hydrogenmolecules. As in other clouds of interstellar gas, theenvironment in Sagittarius B2 is extreme by earthly standards, with temperatures less than minus 370 degrees Fahrenheit, andpressures more than one hundred trillion times smaller than theatmospheric pressure on Earth. "This discovery gives us the opportunity to study thechemistry of fluoride molecules in the frigid conditions thatcharacterize the near vacuum of interstellar space," Neufeldsaid. "One of the key questions is how these molecules wereformed. Our analysis suggests that the hydrogen fluoride wedetected was produced by direct chemical reactions betweenfluorine atoms and hydrogen molecules. Unlike most atoms,fluorine atoms are extremely reactive and attack the relativelyinert hydrogen molecules that are the principal constituent ofthe interstellar gas. The result is hydrogen fluoride." The other members of the team that made the hydrogenfluoride discovery are professors Jonas Zmuidzinas and ThomasPhillips of the California Institute of Technology, and Dr. PeterSchilke of the Max-Planck Institute for Radio Astronomy in Bonn,Germany. The participation of Neufeld, Zmuidzinas and Phillips asguest observers on the European satellite was supported by theNational Aeronautics and Space Administration. Further information is available from Professor Neufeld at(410) 516-8582, or by e-mail at neufeld@pha.jhu.edu. His Web address is http://www.pha.jhu.edu/~neufeld.
--------
523-> U.S. Could Feed 800 Million People With Grain That Livestock Eat, Cornell Ecologist Advises Animal Scientists
MONTREAL -- From one ecologist's perspective, the American system of farming grain-fed livestock consumes resources far out of proportion to the yield, accelerates soil erosion, affects world food supply and will be changing in the future. "If all the grain currently fed to livestock in the United States wereconsumed directly by people, the number of people who could be fed would benearly 800 million," David Pimentel, professor of ecology in CornellUniversity's College of Agriculture and Life Sciences, reported at the July24-26 meeting of the Canadian Society of Animal Science in Montreal.  Or,if those grains were exported, it would boost the U.S. trade balance by $80billion a year, Pimentel estimated. With only grass-fed livestock, individual Americans would still get morethan the recommended daily allowance (RDA) of meat and dairy protein,according to Pimentel's report, "Livestock Production: Energy Inputs andthe Environment." An environmental analyst and longtime critic of waste and inefficiency inagricultural practices, Pimentel depicted grain-fed livestock farming as acostly and nonsustainable way to produce animal protein.  He distinguishedgrain-fed meat production from pasture-raised livestock, callingcattle-grazing a more reasonable use of marginal land. Animal protein production requires more than eight times as muchfossil-fuel energy than  production of plant protein while yielding animalprotein that is only 1.4 times more nutritious for humans than thecomparable amount of plant protein, according to the Cornell ecologist'sanalysis. Tracking food animal production from the feed trough to the dinner table,Pimentel found broiler chickens to be the most efficient use of fossilenergy, and beef, the least.   Chicken meat production consumes energy in a4:1 ratio to protein output; beef cattle production requires an energyinput to protein output ratio of 54:1.  (Lamb meat production is nearly asinefficient at 50:1, according to the ecologist's analysis of U.S.Department of Agriculture statistics.  Other ratios range from 13:1 forturkey meat and 14:1 for milk protein to 17:1 for pork and 26:1 for eggs.) Animal agriculture is a leading consumer of water resources in the UnitedStates, Pimentel noted.  Grain-fed beef production takes 100,000 liters ofwater for every kilogram of food.  Raising broiler chickens takes 3,500liters of water to make a kilogram of meat.  In comparison, soybeanproduction uses 2,000 liters for kilogram of food produced; rice, 1,912;wheat, 900; and potatoes, 500 liters.  "Water shortages already are severein the Western and Southern United States and the situation is quicklybecoming worse because of a rapidly growing U.S. population that requiresmore water for all of its needs, especially agriculture," Pimentel observed. Livestock are directly or indirectly responsible for much of the soilerosion in the United States, the ecologist determined.  On lands wherefeed grain is produced, soil loss averages 13 tons per hectare per year.Pasture lands are eroding at a slower pace, at an average of 6 tons perhectare per year.  But erosion may exceed 100 tons on severely overgrazedpastures, and 54 percent of U.S. pasture land is being overgrazed. "More than half the U.S. grain and nearly 40 percent of world grain isbeing fed to livestock rather than being consumed directly by humans,"Pimentel said.  "Although grain production is increasing in total, the percapita supply has been decreasing for more than a decade.  Clearly, thereis reason for concern in the future." -30- EIGHT MEATY FACTS ABOUT ANIMAL FOOD >From "Livestock Production: Energy Inputs and the Environment" By David Pimentel -- WHERE'S THE GRAIN?  The 7 billion livestock animals in the United Statesconsume five times as much grain as is consumed directly by the entireAmerican population. -- HERBIVORES ON THE HOOF.   Each year an estimated 41 million tons ofplant protein is fed to U.S. livestock to produce an estimated 7 milliontons of animal protein for human consumption.  About 26 million tons of thelivestock feed comes from grains and 15 million tons from forage crops.For every kilogram of high-quality animal protein produced, livestock arefed nearly 6 kg of plant protein. -- FOSSIL FUEL TO FOOD FUEL.  On average, animal protein production in theU.S. requires 28 kilocalories (kcal) for every kcal of protein produced forhuman consumption.  Beef and lamb are the most costly, in terms of fossilfuel energy input to protein output at 54:1 and 50:1, respectively.  Turkeyand chicken meat production are the most efficient (13:1 and 4:1,respectively).  Grain production, on average, requires 3.3 kcal of fossilfuel for every kcal of protein produced.    The U.S. now imports about 54percent of its oil; by the year 2015, that import figure is expected torise to 100 percent. -- THIRSTY PRODUCTION SYSTEMS.   U.S. agriculture accounts for 87 percentof all the fresh water consumed each year.  Livestock directly use only 1.3percent of that water.  But when the water required for forage and grainproduction is included, livestock's water usage rises dramatically.  Everykilogram of beef produced takes 100,000 liters of water.  Some 900 litersof water  go into producing a kilogram of wheat.  Potatoes are even less"thirsty," at 500 liters per kilogram. --  HOME ON THE RANGE.  More than 302 million hectares of land are devotedto producing feed for the U.S. livestock population -- about 272 millionhectares in pasture and about 30 million hectares for cultivated feedgrains. --  DISAPPEARING SOIL.  About 90 percent of U.S. cropland is losing soil --to wind and water erosion --  at 13 times above the sustainable rate.Soil loss is most severe in some of the richest farming areas; Iowa losestopsoil at 30 times  the rate of soil formation.  Iowa has lost one-halfits topsoil in only 150 years of farming -- soil that took thousands ofyears to form. -- PLENTY OF PROTEIN:  Nearly 7 million tons (metric) of animal protein isproduced annually in the U.S. -- enough to supply every American man, womanand child with 75 grams of animal protein a day.  With the addition of 34grams of available plant protein, a total of 109 grams of protein isavailable per capita.   The RDA (recommended daily allowance) per adult perday is 56 grams of protein for a mixed diet. -- OUT TO PASTURE.  If all the U.S. grain now fed to livestock wereexported and if cattlemen switched to  grass-fed production systems, lessbeef would be available and animal protein in the average American dietwould drop from  75 grams to 29 grams per day.  That, plus current levelsof plant-protein consumption, would still yield more than the RDA forprotein. -30- --------------------------------Cornell University News Service324 Judd Falls RoadIthaca, NY 14853607-255-4206 phone607-255-5373 faxmailto:cunews@cornell.eduhttp://www.news.cornell.edu 
--------
524-> U.S. Geological Survey Supports Fish Lesion Research
"We are extremely concerned about this issue, especially in light ofthe fish kill which began Wednesday (Aug.6) near the mouth of the PocomokeRiver," said USGS Chief Biologist Dennis Fenn.  "Our scientists have theexpertise to examine a broad range of fish health and disease distributionissues.  Working with the State of Maryland, other federal agencies andarea university researchers, we will try to determine the causes of thefish lesions and the extent of the problem throughout the Chesapeake Bayarea." Funds are available for studies by colleagues at the University ofMaryland-Eastern Shore and for the USGS Fish Health Laboratory at Leetown,W.Va. Scientists at these locations will collaborate with the State ofMaryland and other research partners on the fish lesion problem.  "Leetownscientist, Dr. Vicki Blazer, will focus on the question of possiblesuppression of fish immune systems, which could make fish more vulnerableto disease," said Dr. Fenn.  The research team at the University ofMaryland will also collect fish samples and broaden the scope of theirmonitoring efforts to include other Eastern Shore river systems. With the start of the new fiscal year in October, the USGS will commitadditional funds to expand these studies and for landscape-scale studiescoordinated by biologists at the USGS Aquatic Ecology Laboratory inLeetown, to take a broader view of the bay. "We want to examine thecomplexities of the Chesapeake Bay ecosystem, looking at bay-wide fishhealth, lesion occurrence and potential links to land use, water qualityand stream flow patterns," said Dr. Fenn. "We will continue to work closelywith the State of Maryland and other partners to help devise a strategy forprotecting and preserving the Chesapeake Bay, one of our nation's mostvaluable natural resources." Biologists participate in a bureauwide interdisciplinary ChesapeakeBay Ecosystem program, which began in May, 1996, and is closely coordinatedwith the Chesapeake Bay Program, a multi-agency effort for Bay restoration.The objectives of the ecosystem program are to better understand the effectsof natural and human-induced activities on the water quality andliving resources of the Bay and provide resource managers with informationthat is based on sound scientific investigations. Management implicationsof the scientific findings are provided so resource managers may evaluatethe effectiveness of different nutrient-reduction strategies on waterquality and the living resources in the Bay. The USGS has participated inthe Chesapeake Bay program since 1983. * * * USGS * * * For more information on USGS work in the Chesapeake Bay, checkhttp://chesapeake.usgs.gov/chesbay/stream flow on the World Wide Web. 
--------
525-> NIH Grant Allows UT Southwestern Researchers To Study Fast Biochemical Reactions
DALLAS ― August 12, 1997 ― Imagine mixing tiny amounts of proteins and other biological molecules in a thousandth of a second and then studying the reactions that take place in a tenth of a second. A National Institutes of Health (NIH) grant has enabled UT Southwestern Medical Center at Dallas researchers to purchase equipment that makes possible sensitive measurements of the fastest biological processes. The NIH awarded a $180,000 Shared Equipment Grant to seven UT Southwestern investigators to obtain state-of-the-art rapid mixing and optical monitoring instruments, available to only a few medical centers in the country. The competitive funding is given to scientists who show they can make full use of a sophisticated and expensive laboratory instrument. "No one of us could justify spending that kind of money to purchase this equipment for any individual project, but a shared facility of this kind is a wonderful asset to our research," said Dr. Elliott Ross, professor of pharmacology and holder of the Greer Garson and E.E. Fogelson Distinguished Chair in Medical Research. "These instruments let us look at the rates and progress of fast biochemical reactions. By fast, I mean from less than one  millisecond to five seconds. This means that we can study the details of how these reactions happen and the chemical nature of their intermediates. For instance, when a light flashes, how fast does the amplifying biochemistry in your retina record that information? How does it work? With this machine, you can actually determine the rates of those reactions," he said. The instrument is based on four computer-controlled syringes. The syringes independently ― and very quickly ― mix  reagents by injecting them into a series of three tiny mixing chambers, each only 15 microliters in volume (five ten-thousandths of an ounce). After mixing, the instrument can do two types of analyses. In the first, called stopped-flow, the reaction mixture is driven into a small quartz chamber, where several different optical techniques can be used to follow the course of the reaction. In the second, called quench-flow, the reaction is stopped at precise times, and the mixture is collected for chemical analysis. The versatility of the new instrument is crucial for its shared use. Stopped-flow absorbance measurements -- looking at colored reaction intermediates -- can be used to follow complex enzyme reactions. Stopped-flow circular dichroism, which monitors molecular shape, can follow the rapid folding of a protein into its active conformation. Stopped-flow fluorescence can measure the binding of proteins to each other, changes in their structures and many other parameters. Quench-flow is used when no optical probe is available. To obtain such versatility, the UT Southwestern researchers worked with the manufacturer, BioLogic S.A., of Grenoble, France, to combine and adapt the necessary components. Specifications on the final order were six pages long and included several custom-designed items. One UT Southwestern scientist sharing this machine, Dr. Margaret Phillips, assistant professor of pharmacology, will use it to study reactions catalyzed by several enzymes in trypanosomes, the parasites that cause sleeping sickness and Chagas' disease. Dr. Julian Peterson, professor of biochemistry, will use stop-flow spectroscopy to study the functions of P450s, a large class of enzymes that can degrade drugs, synthesize hormones and inactivate toxins. Dr. Philip Thomas, assistant professor of physiology, and Dr. Elizabeth Goldsmith, associate professor of biochemistry, will use circular dichroism to study how proteins fold and how regulators of enzyme action change the structure of their enzyme targets. Ross and his group study signaling proteins that convey information from drug and neurotransmitter receptors to intracellular regulatory proteins. They will use quench-flow measurements to determine how stimulatory and inhibitory signals combine on the millisecond time scale to organize incoming signaling pathways. "We are trying to measure these individual processes and how they are regulated," Ross said. "Determining the real turn-on and turn-off rates and what regulates the speed of these reactions  has not really been done before. "Where and when a response turns on and turns off is essential information. For instance, when you read, you are taking in a lot of light, but it's the cut-off between black and white that is important; when you hear a voice, the changes convey the information." Ross said that stop-flow instruments have existed for 30 years, but previous ones were inefficient. They were too slow ― the fastest could not measure reactions faster than about 20 milliseconds ― and they required too much reagent, often 1,000 times more than is needed now. "Five years ago, I wouldn't have dreamed of doing this kind of experiment because the equipment wasn't up to it," he said. "We couldn't possibly make enough enzyme or get enough sensitivity." Other UT Southwestern researchers sharing in the grant are Dr. Joseph Albanesi, associate professor of pharmacology; Dr. James Stull, chairman of physiology and holder of the Fouad A. Bashour Chair in Physiology; and Dr. Clive Slaughter, associate professor of biochemistry and Howard Hughes Medical Institute investigator. Ross said the researchers on the grant will have priority use of the equipment, but other NIH-funded UT Southwestern scientists will be able to use the instruments as well. ### This news release is available on our World Wide Web home page at http://www.swmed.edu/news/newspubs.htm/
--------
526-> El Nino Returns, Could Upset Nation's Weather
WEST LAFAYETTE, Ind. -- The weather pattern known as El Nino is re-emerging in the Pacific Ocean, and that could bring a change in weather for next winter, and perhaps for the next few years. The near record-setting cold seen in parts of the Midwest off and on for the past few years could be replaced by unseasonable warmth. Ken Scheeringa, acting state climatologist for Indiana, stationed at Purdue University, says that the last major El Nino 15 years ago caused memorable changes in our weather. Early predictions by the National Weather Service say that this El Nino is even more severe than the 1982-83 episode. "It appears that El Nino is roaring back, and this one is showing signs it could become more intense than the one in 1982-83," he says. "That year parts of the central United States had a Christmas day in the 60-degree range." The effects of El Nino are always the most apparent near Christmas, and the name "El Nino" refers to the Christ child. "What we're in now is the opposite of an El Nino," Scheeringa says. "In the Midwest we're feeling the influences of a weather pattern known as 'La Nina.' With this the ocean surface temperatures are cold, and since the end of last year and the beginning of this year we have been in a predominately cool weather pattern. That's why parts of the country have seen such cool temperatures this past winter and into the spring. That appears to be changing, perhaps in a very intense way." According to Scheeringa, the El Nino weather pattern could bring unusually warm and dry weather to the Midwest, especially in the winter months. El Nino weather patterns occur every few years, most recently during the winters of 1994-95 and 1987-88. The last major El Nino occurred during the winter of 1982-83. That winter, storms caused damage in California and the Gulf States resulting in an estimated 100 deaths and more than $2 billion damage. Dayton Vincent, professor of atmospheric sciences at Purdue, says there is some disagreement among researchers about what causes El Nino, but there some characteristics that all weather scientists agree on. Vincent says two events happen nearly simultaneously to create the weather pattern known as El Nino. "Water over the eastern Pacific, especially just south of the equator, becomes much warmer than normal during December and January," he says. "The second occurrence is that low-level winds from the region stretching from the western Pacific to east of the International Dateline become more westerly or, at least, less easterly than normal. This actually causes upwelling in the ocean circulation, and warmer waters come to the surface over the central Pacific to join those already over the eastern Pacific." According to Vincent, wind changes in the lower atmosphere and in the Pacific Ocean cause a change in upper atmospheric circulation patterns. It's this upper atmospheric weather pattern, near jet stream levels, that ultimately influences weather in the United States, he says. "It's well established that the southeastern part of the United States will see more cyclonic activity, and the northern Great Plains and south-central Canada will have more high pressure, so there are fewer storms and less rainfall," Vincent says. "In the Midwest, we lie in a zone that makes it difficult to tell if El Nino affects our weather. This spring we've had a lot of storms to the south while northern Minnesota and northern Michigan had better than normal weather. This could well be associated with the beginning El Nino conditions." CONTACTS: Scheeringa, (765) 494-8105; e-mail, kenneth.l.scheeringa.1@purdue.edu; Vincent, (765) 494-3290; e-mail, dvincent@meteor.atms.purdue.edu Compiled by Chris Sigurdson, (765) 494-8415; home (765) 497- 2433; e-mail, sig@ecn.purdue.edu
--------
527-> More Studies Show That Hard Core Smokers May Be Using Nicotine To Manage Depression, ADHD, Anxiety Or Bulimia
ANN ARBOR---You still see them huddled over their cigarettes in public doorways, despite 30 years of increasing social pressure and education about health risks. Why can't they quit? "There is mounting evidence that smoking is becoming increasingly concentrated in people at-risk for major depressive disorders, adult attention deficit hyperactivity disorder (ADHD), anxiety disorders and bulimia or binge-eating. People with these conditions or co-factors often use nicotine to help manage their symptoms," according to Cynthia S. Pomerleau, a researcher with the University of Michigan Substance Abuse Research Center and the Nicotine Research Laboratory in the U-M Department of Psychiatry. "Many of those who have given up smoking in the past appear to have been the 'easy quits' or casual adult smokers," she added. "Health practitioners interested in helping patients with co-factors to quit need to develop new kinds of smoking interventions tailored to the special needs of these difficult-to-treat, at-risk populations." Pomerleau's findings are reported in a literature review in the April issue of Addiction. Smoking has dropped in the U.S. adult population from 40 percent in 1965 to less than 29 percent in 1990. Despite the decline, Pomerleau said that smoking rates may level out at about 15 percent to 20 percent of the adult population. "Nicotine produces temporary, small but reliable adjustments in a wide variety of cognitive and behavioral functions. Administered via smoking, nicotine quickly enters the brain where it affects neural regulators such as norepinephine, dopamine and serotonin, and can either sedate or stimulate depending on the timing, dosage and other factors," Pomerleau explained. When smokers with co-factors such as depression or binge-eating try to quit, their symptoms are exacerbated or unmasked by the absence of nicotine and persist well beyond the usual two- to three-day nicotine withdrawal period. Consequently, they are more likely to relapse than smokers with no co-factors. Pomerleau cited a substantial accumulation of research to support her conclusions, including: ---A 1986 study of diagnostic subgroups that included 217 psychiatric outpatients and 411 non-psychiatric patients in a comparison group found that 47 percent of the 34 patients with anxiety disorder and 49 percent of the 45 patients with major depressive disorder smoked compared with 30 percent of the comparison group. ---A 1994 study conducted by Pomerleau and colleagues that found that 42 percent of men and 38 percent of women diagnosed with ADHD were current smokers---nearly twice the rate of the standard population. Also the "quit ratio" was 29 percent for the ADHD patients who had ever smoked compared with 48 percent in the general population. ---A 1991 study of 1,007 young adults found that---compared with individuals who had no psychiatric disorder---the rate of nicotine dependence was twice as high in adults with any anxiety disorder; three times as high in adults with major depression; and more than four times as high in individuals with the two disorders combined. ---A 1992 study of 1,800 women about to enter the U-M reported that less than 10 percent of the non-dieters and casual dieters smoked compared with nearly double that in the young women who reported behaviors and attitudes associated with a clinical diagnosis of bulimia nervosa. Similarly, a 1986 study of 646 10th-grade females found that 28 percent of bulimics and 32 percent of the purgers smoked regularly compared with 18 percent of the normal females. Health professionals helping smokers with co-factors to quit smoking may have to treat the depression, anxiety, ADHD or binge-eating behaviors first or simultaneously, Pomerleau said. "A 1995 study found that Prozac helped smokers with depression to quit but it had no effect on smokers who were not depressed," she said. "It is possible that some of these patients wouldn't need nicotine replacement treatment once they received appropriate medications or psychotherapy for their underlying conditions." Pomerleau also suggested that more research be conducted regarding the potential therapeutic use of nicotine products---transdermal patches, nasal sprays or gum---to treat ADHD and conditions such as Parkinson's and Alzheimer's diseases. "We need more data on the possible toxic effects of nicotine to weigh against its possible therapeutic effects. "Finally, we need to consider the potential needs of children of smokers with co-factors," she said. "Recent twin studies suggest that the heritability of smoking is at least as high as that of alcohol, with significant genetic contributions to initiation, age of onset, amount smoked and likelihood of quitting. It may be that some families are predisposed to both smoking and depression. "There also is good evidence of assortative mating in smokers---the tendency to find each other, marry and have children, with the nature and severity of problems experienced by smokers with co-factors being magnified in succeeding generations. Prevention efforts and early identification and treatment of the co-factor itself may be needed in these children.&#3 
--------
528-> Huntington's Disease Findings Pave Way For Potential Cure
New York, N.Y., August 8, 1997- Nearly 20 years ago, Columbia University researchers observed brain cell changes in Huntington's disease patients. Today, the significance of those changes has finally been explained--and the new findings may lead to a treatment or cure for the progressive, degenerative brain disease. In the August 7 issue of Cell, Dr. Gillian Bates of the Division of Medical and Molecular Genetics, Guy's Hospital, London; Dr. Stephen W. Davies of the Department of Anatomy and Developmental Biology, University College London; Dr. Hans Lehrach and Dr. Erich Wanker of the Max Planck Institute for Molecular Genetics in Berlin, and colleagues have described the changes with unprecedented clarity. The cellular and biochemical mechanisms they have discovered could be a starting point for the development of new drugs that could interrupt the progress of Huntington's disease or prevent it in people at risk. The gene for Huntington's disease (HD) was discovered in 1993 through the collaborative efforts of six research teams led by Nancy S. Wexler, PhD, Higgins Professor of Clinical Neuropsychology at the College of Physicians and Surgeons of Columbia University in New York and President of the Hereditary Disease Foundation in Santa Monica. Under the direction of Wexler, the Foundation has formed the Cure Huntington's Disease Initiative to accelerate progress from research to therapy. Symptoms of Huntington's disease include abnormal movements, moodiness, depression, slurring and loss of speech, and, finally, mental incompetence, incontinence, confinement, and unremitting decline over 10 to 20 years. This progressive degenerative brain disease affects about 30,000 Americans; 150,000 more have a genetic risk for developing the illness. The cause is a mutation in a gene located on chromosome 4: Instead of having molecule groups that repeat a small number of times, they repeat 40 or more times and produce a defective form of the huntingtin protein. The defective protein interacts with brain cells, though exactly how has not been known. In 1979, researchers from the Columbia University College of Physicians and Surgeons in New York viewed HD changes in biopsied human brain cells and described the damage as clumps, fibers, and masses in the cell nucleus. The Bates and Davies group and a second international team of investigators have now, nearly 20 years later, explained what the Columbia researchers found. Using new "transgenic" mice developed by Dr. Bates to contain a disease-causing fragment of the human HD gene, the researchers saw in the nucleus of each mouse brain cell a rough, grainy, circular, sometimes fiber-fringed structure that strikingly resembled structures seen by the Columbia University researchers in the brain cell nuclei of people with HD. The Bates group labeled them neuronal intranuclear inclusions (NII). Analysis using monoclonal antibody technology not available in 1979 revealed that NIIs were aggregates (clumps) of huntingtin protein. The protein entered the cell nucleus through pores in the nuclear membrane. The NII were present in the brain cell nuclei of mice with symptoms very similar to HD and absent in non-transgenic control mice. "This radically changes our framework for thinking therapeutically," says Dr. Wexler, who is also the president of the Hereditary Disease Foundation in Santa Monica. "Is there a way to prevent the protein from clumping, to break up clumps once they've formed, to keep it out of the nucleus or to attack the mysterious signals that start the process? "In early development, when everything is normal, the protein is swimming in the cytoplasm like Odysseus sailing in his boat," she explains. "He hears the siren song of Circe and ends up marooned in the nucleus instead of going home." Dr. Wexler is "ecstatic" about these findings and optimistic that they will lead researchers in the direction of an effective treatment. At the moment, a blood test can detect the HD gene, but there is no cure and no effective treatment. In a second study in the current issue of Cell, an international group led by Eberhard Scherzinger of the Max Planck Institute announce that they have found a way to recreate the protein clumps in a test tube, which will make it much easier to develop new therapies that prevent the clumping. The Bates research was supported in part by the Hereditary Disease Foundation. Founded by Dr. Wexler's father, Milton Wexler, the foundation's goal is to provide intellectual stimulus and financial support for basic scientific research aimed at uncovering the causes of Huntington's disease and related genetic and neurological disorders. The Hereditary Disease Foundation also seeks to advance the treatment of these incurable and devastating illnesses. The foundation's Cure Huntington's Disease Initiative will support further research into medications effective in treating HD.
--------
529-> Mars Pathfinder Results Generating New Picture Of Mars As Mission Moves Into Extended Operations
August 8, 1997 Douglas IsbellHeadquarters, Washington, DC(Phone:  202/358-1753) Diane AinsworthJet Propulsion Laboratory, Pasadena, CA(Phone:  818/354-5011) RELEASE:  97-174 MARS PATHFINDER RESULTS GENERATING NEW PICTURE OF MARS AS MISSION MOVES INTO EXTENDED OPERATIONS NASA's Mars Pathfinder spacecraft -- a novel mission to send an inexpensive lander and roving prospector to the surface of Mars -- has concluded its primary mission, fulfilling all of its objectives and returning a wealth of new information about the red planet. The robotic lander, which continues to explore an ancient outflow channel in Mars' northern hemisphere, completed its milestone 30-day mission on Aug. 3, capturing far more data on the atmosphere, weather and geology of Mars than scientists had expected.  In all, Pathfinder has returned 1.2 gigabits (1.2 billion bits) of data and 9,669 tantalizing pictures of the Martian landscape to date. "The data returned by the Sagan Memorial Station and Sojourner has been nothing short of spectacular, and it will help provide a scientific basis for future Mars missions, including a sample return, for years to come," said Dr. Wesley Huntress, NASA associate administrator for space science.  "The Pathfinder team's "can do" attitude not only was critical to overcoming several complex technical challenges during development and cruise, but has carried through the uncharted territory of operating a solar-powered lander and mobile rover on the surface of a planet millions of miles from Earth." "This mission demonstrated a reliable and low-cost system for placing science payloads on the surface of Mars," said Brian Muirhead, Mars Pathfinder project manager at NASA's Jet Propulsion Laboratory (JPL), Pasadena, CA.  "We've validated NASA's commitment to low-cost planetary exploration, shown the usefulness of sending microrovers to explore Mars, and obtained significant science data." A new portrait of the Martian environment has begun to emerge in the 30 days since Pathfinder and its small, 23-pound rover began to record weather patterns, atmospheric opacity and the chemical composition of rocks washed down into the Ares Vallis flood plain.  The rover's alpha proton X-ray spectrometer team, led by principal investigator Dr. Rudolph Rieder, has been ableto analyze the first-ever in-situ measurements of Mars rocks. "We are seeing much more differentiation of volcanic materials than we expected to see," said Dr. Matthew Golombek, Mars Pathfinder project scientist at JPL.  "The high silica content of one of the rocks we've measured, nicknamed Barnacle Bill, suggests that there was more crustal activity -- heating and recycling of materials -- early in Mars' history than we thought."       Similarly, atmospheric-surface interactions, measured by a meteorology package onboard the lander, are confirming some conditions observed by the Viking landers 21 years ago, while raising questions about other aspects of the planet's global system of transporting volatiles such as water vapor, clouds and dust, said science team leader Dr. Timothy Schofield.  The meteorology mast on the lander has observed a rapid drop-off in temperatures just a few feet above the surface, and one detailed 24-hour measurement set revealed temperature flucuations of 30-40 degrees Fahrenheit in a matter of minutes. In addition, sweeping, color panoramas of the Martian landscape, created by the Imager for Mars Pathfinder team and principal investigator Peter Smith, are revealing clear evidence that the surface of Mars has been altered by winds and flowing water. Sojourner, a robust rover capable of semi-autonomous "behaviors," captured the imagination of the public, which followed the mission with great interest via the World Wide Web.  Twenty Pathfinder mirror sites, constructed by JPL web engineer Kirk Goodall and managed by Pathfinder webmaster David Dubov, recorded 565 million hits worldwide during the period of July 1 -- August 4.  The highest volume of hits in one day occurred on July 8, when a record 47 million hits were logged, which is more than twice the volume of hits received on any one day during the 1996 Olympic Games in Atlanta. The rover's performance has easily surpassed its designers' minimum expectations.  Engineers designed the roving vehicle's electronics, battery power and hazard avoidance features to see it through at least a week of safe roving, not knowing beforehand what conditions it might encounter on Mars.  After 30 days, the rover is still healthy and has traveled 171 feet in distance, circumnavigating the lander and taking 384 spectacular views of rocks and the lander. "Sojourner's capabilities to detect hazards and then act on its own to overcome those hazards have been remarkable," said Dr. Jacob Matijevic, Sojourner project manager.  "The technology experiments we have been able to perform with the rover's wheels have given us more information about the composition of the Martian soil, as well as rocks around the landing site.  Sojourner's durability in this frigid, hostile environment also is showing us that we are on the right track to building smarter, even more durable rovers for future missions." Pathfinder's primary objective was to demonstrate a low-cost way of delivering an instrumented lander and free-ranging rover to the surface of the red planet.  Landers and rovers of the future will share the heritage of spacecraft designs and technologies tested in this "pathfinding" mission. Part of NASA's Discovery program of low-cost planetary missions with highly focused science goals, the spacecraft used an innovative method of directly entering the Martian atmosphere.  Assisted by a 36-foot-diameter parachute, the spacecraft descended to the surface of Mars and landed, using airbags to cushion the impact. This novel method of diving into the Martian atmosphere worked like a charm.  "Every event during the entry, descent and landing went almost perfectly," said Richard Cook, Pathfinder mission manager.  "The sequences were executed right on time and well within our margins." Pathfinder landed right on the money, within 13 miles of the targeted landing site.  The landing site coordinates in Ares Vallis were later identified as 19.33 degrees North latitude, 33.55 degrees West longitude. The spacecraft's terminal velocity as it parachuted to the ground was higher than expected, said Rob Manning, Pathfinder flight system chief engineer.  "Interestingly, we estimated our descent on the parachute at about 134 miles per hour.  Software controlling the retro rockets recorded Pathfinder's speed at about 140 miles per hour at the time the rocket-assisted deceleration rockets fired." Pathfinder's performance in the Martian atmosphere will be of great value to Mars Global Surveyor, which will aerobrake through the Martian atmosphere to circularize its orbit when it reaches Mars on September 11.  The Pathfinder navigation team, led by Pieter Kallemyn of JPL, estimated that horizontal wind velocities in the upper atmosphere helped accelerate the spacecraft's descent velocity by about 20 to 25 miles per hour. After being suspended from a 65-foot bridle and firing its retro rockets, a 19-foot diameter cluster of airbags softened Pathfinder's landing, marking the first time this airbag technique has been used on another planet.  The spacecraft hit the ground at a speed of about 40 miles per hour and bounced about 16 times across the landscape for about six-tenths of a mile before coming to a halt.  The airbag seems to have performed perfectly and sustained little or no damage.  To top it off, the spacecraft even landed on its base petal, consequently allowing its thumb-sized antenna to communicate the successful landing to a jubilant team on Earth only three minutes after touchdown. Science data from the surface of Mars will continue to be collected and transmitted to Earth, then analyzed by scientists, as Pathfinder enters its extended mission.  The lander was placed in a two-day hibernation period earlier this week to recharge its battery after the conclusion of the primary mission, and the flight team now will begin to power the lander battery off each Martian night to conserve energy.  The rover's batteries remain in good condition, but are not rechargeable. The Mars Pathfinder mission is managed by the Jet Propulsion Laboratory for NASA's Office of Space Science, Washington, DC.  JPL is a division of the California Institute of Technology, Pasadena, CA. -end-
--------
530-> Robot Lawn Mower At UF Designed To Change Suburban Landscape
GAINESVILLE --- George Jetson, eat your heart out. A robot lawn mower called LawnNibbler,  developed at the University of Florida's  Machine Intelligence Laboratory, can cut your grass intelligently --  avoiding dogs, kids, trees and birdbaths -- while you're out on the golf course or taking the kids to soccer practice. "The LawnNibbler can provide a substitute for the majority of the work a person does caring for a lawn," said Kevin Hakala, the graduate student who designed and built LawnNibbler for  his engineering master's thesis, written under the guidance of Professor Keith L. Doty, laboratory director. "It will trim the grass in a defined area while avoiding obstacles such as trees, children, toys or pets. It uses two smart systems: one to tell it where it is and another to tell it what to avoid." Hakala said LawnNibbler promises to be  the first low-cost and efficient robot lawn mower. It  uses a radio wire buried  at the perimeter of its work area and a navigational beacon system using sonar  and infrared emitters and detectors to tell it where it is in its environment. "LawnNibbler uses signals to treat the buried wire as an obstacle that it cannot  cross," Hakala said. "It moves straight ahead until its sonar senses a beacon in  its work environment or an obstacle." Beacon or obstacle identified, LawnNibbler makes the appropriate turns and continues. Additionally, LawnNibbler can keep track of where it has already cut. LawnNibbler's navigation system scans its surroundings with sonar pulses. If a beacon in the yard "hears" the sonar, the beacon replies with an infrared light.  The infrared light also provides LawnNibbler with its obstacle avoidance mechanism. Just 24 inches high, 23 3/4 inches long,  12 3/4 inches wide and weighing 35 pounds, LawnNibbler uses a weed trimmer-like nylon cord that cuts a 6-inch swath. Hakala said that the mower,  driven by a rechargeable battery-powered electric motor and humming along at 1 foot per second, has the power to cover rough terrain and climb a 15-degree angle. "Robots of the future are becoming today's reality," said Hakala, who described his LawnNibbler's beacon navigation system as "cheap and accurate."  LawnNibbler, he added, is more intelligent and less expensive than earlier commercial models. "Previous attempts at robot lawnmowers  have been limited because of the absence of a navigation system," said Hakala. "Those robot lawnmowers only knew the boundary of their work area when they approached it.  They did not have the intelligence to know where they were in their environment. Because of the beacon navigation system, LawnNibbler knows where it is." Hakala added that the beacon systems  used by his LawnNibbler are a stepping stone to a future where robots will be able to sense their environment as humans do, by using landmarks. "LawnNibbler will likely have its market entry through industrial and commercial uses, mostly because of the  safety issues," said Scott Jantz, a UF engineering graduate student who worked on the LawnNibbler with Hakala. "Golf course care is an obvious application. LawnNibblers can go to work when no one is on the course. It could also be used in restricted industrial or military areas, or even in areas where foliage is contaminated and should not be touched by humans." With the outdoors under robotic control,  Jantz said, researchers are tackling another project to bring similar Jetson-esque technology to indoor tidying chores: "We're working on a vacuum cleaner." -30- Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-9092.
--------
531-> Lewis Satellite Ready To Demonstrate Finer Spectrum Of Earth Views
Douglas IsbellHeadquarters, Washington, DC              (Phone:  202/358-1753) Brooks McKinneyTRW Space & Electronics Group, Redondo Beach, CA(Phone:  310/814-8177) Rebecca GrayLockheed Martin Astronautics, Denver, CO(Phone:  303/977-6893) RELEASE:  97-172 LEWIS SATELLITE READY TO DEMONSTRATE FINER SPECTRUM OF EARTH VIEWS Outfitted with advanced technology Earth-imaging instruments and subsystems intended to push the state-of-the-art in scientific and commercial remote sensing, NASA's Lewis satellite is scheduled for launch at 2:51 a.m. EDT on August 10 from Vandenberg Air Force Base, CA. One of several focused, small satellite missions under development by NASA's Mission to Planet Earth enterprise, Lewis features remote-sensing instruments designed to split up the spectrum of light energy reflected by Earth's land surfaces into as many as 384 distinct bands.  In addition, Lewis carries the Ultraviolet Cosmic Background astrophysics instrument built by the University of California at Berkeley.  The satellite was built by TRW Space & Electronics Group, Redondo Beach, CA, for launch aboard a Lockheed Martin Launch Vehicle, under NASA's Small Spacecraft Technology Initiative. "Lewis has proven to be an invaluable groundbreaker in our efforts to infuse fast-track procurement methods and industry-driven technology development into all of NASA's future spacecraft," said Samuel Venneri, Chief Technologist at NASA Headquarters in Washington.  "This philosophy has since helped spawn the Agency's New Millennium program and, more importantly, has fostered a mindset of innovation and partnership with industry across all of NASA's technology field centers." The primary payload on Lewis consists of two complementary hyperspectral imaging radiometers.  The 384-band Hyperspectral Imager instrument built by TRW covers the spectral range from .4 microns to 2.5 microns.  It is based on a conventional airborne spectro-radiometer design integrated with new advanced technology components, making it the first high-resolution hyperspectral imager to be flown in space.  The Hyperspectral Imager can resolve objects on the ground as small as 16 feet (five meters) in its panchromatic band and 100 feet (30 meters) in its hyperspectral bands. The companion hyperspectral instrument on Lewis is called the Linear Etalon Imaging Spectral Array.  Built by NASA's Goddard Space Flight Center, Greenbelt, MD, it can "see" the Earth in 256 bands with 1,000-foot (300-meter) resolution, in the spectral region from 1.0 to 2.5 microns.  The Array's fundamentally new technology provides data in the same spectral bands as the Hyperspectral Imager while offering "factors-of-ten" reductions in size, cost and design complexity. The Hyperspectral Imager and the Linear Etalon Imaging Spectral Array accomplish theoretically equivalent measurements using different approaches.  The Imager takes a snapshot of a narrow "one-dimensional" stripe of the Earth and separates the incoming optical signal into its component spectral bands for a concurrent spectral observation.  It then uses the motion of the spacecraft over its ground track to build up the spatial image through successive snapshots.  Conversely, the new approach enabled by the Array technology involves a "two-dimensional" snapshot of 256 adjacent stripes of the image, with each stripe viewed in a different spectral band.  Using the motion of the spacecraft over the ground track, the Linear Etalon Imaging Spectral Array then takes 256 successive snapshots, thus building up the complete spectral signature of each of the image stripes. As a comparison, the primary imager on the current Landsat remote-sensing satellites views the Earth in just seven spectral bands with about ten times lower resolution (although it has some thermal band capabilities beyond those of the Hyperspectral Imager's image collection system).  A key area of potential scientific and commercial interest in Lewis is the idea of "data fusion," in which the unique new capabilities of Lewis are merged with the more mature Landsat data products to provide new insights. "The sensors on Lewis will allow environmental scientists to discriminate between different types of vegetation, and determine their health, with a fine precision only hinted at by previous space- and aircraft-based measurements," said Dr. Diane Wickland, program scientist in NASA's Office of Mission to Planet Earth.  "It also will enable much more accurate estimates of the run-off from spring snow melts, the distribution of surface minerals, and the composition of sedimentary discharges into coastal waters." Potential commercial applications include pollutant monitoring, analysis of endangered species habitats, estimation of forest and agricultural productivity, soil resources and crop residue mapping and assessments of environmental impacts from energy pipelines, Wickland said. NASA's Stennis Space Center, Stennis, MS, will be the Agency's focal point for commercial applications and technical support on Lewis, and will help distribute its data.  Stennis also will work with TRW on spreading the results of Lewis into secondary school classrooms and will support validation of Lewis data via an aircraft-borne hyperspectral instrument flown on a NASA Learjet. Another airborne imaging spectrometer instrument operated by NASA's Jet Propulsion Laboratory, Pasadena, CA, will support calibration and validation of measurements from Lewis and will help determine how the signals are changed when they pass through Earth's atmosphere. Named for the 19th century U.S. explorer Meriwether Lewis, the mission incorporates approximately 40 new technologies and state-of-the-art components.  Technologies developed by Goddard include miniaturized cryocoolers, new composite material structural components with an integrated thermal and structural design, faster data processors, lightweight propellant tanks, miniaturized star trackers, and exploitation of the Global Positioning System for space timekeeping, navigation and attitude control. Lewis technologies contributed by NASA's Langley Research Center, Hampton, VA, include a Recorder Interface Module that provides both primary and back-up interfaces between the Lewis data recording system, the science instruments, the on-board computer and the communication subsystem.  The Lewis Enhanced Attitude Control Experiment should lead to better future spacecraft attitude control systems that take into account the many disturbances a spacecraft experiences while in orbit, ensuring its science instruments remain accurately pointed.  The Cloud and Feature Editing Experiment will assist the Hyperspectral Imager by picking out areas of the Earth's surface that are covered by clouds, ensuring that only unobscured images of the Earth's surface are stored and transmitted to the ground for later analysis, doubling the useful capacity of the Hyperspectral Imager's image collection system. The total cost to NASA of the Lewis mission, including its launch vehicle and one year of orbital operations, is $64.8 million.   NASA incurred an additional cost of $6.2 million for storage and maintenance of the spacecraft during a one-year delay due to launch vehicle issues.  Lewis and its partner remote-sensing technology demonstration mission Clark were selected by NASA for development in June 1994.  The development of Clark has been paced by difficulties in readying some of its complex new technologies for flight, including its commercially provided high-resolution imager.  Clark is scheduled for launch in 1998. Under the direction of TRW and Lockheed Martin, an LMLV-1 booster will launch Lewis from Space Launch Complex 6 at Vandenberg.  All checkout and launch-control equipment is housed in a Launch Vehicle Control Van, a 40-foot vehicle located near Launch Complex 6. Further technical details on the Lewis spacecraft and some color image files of the spacecraft being prepared for launch are available on the Internet at the following URL:                     http://www.trw.com/seg/sats/SSTI.html Lewis is part of NASA's Mission to Planet Earth enterprise, a long-term research program designed to study the Earth's land, oceans, air and life as a total system. -end-
--------
532-> Compost Hounds Are Headed For Tummy Trouble, Cornell Veterinary Toxicologist Warns
ITHACA, N.Y. -- The "greening" of American backyards -- as more people turnto composting food scraps -- is turning some dogs a bilious shade of green.Certain microorganisms and the toxins they produce can sicken or even killdogs that get into the wrong compost pile, a Cornell University veterinarytoxicologist is warning. "We're seeing more and more cases of 'compost poisoning,' where thefermentation of meat, dairy products and other food in compost pilesproduces clostridial toxins that can be very nasty to a dog," said Larry J.Thompson, D.V.M., Ph.D., a toxicologist in the Cornell University Collegeof Veterinary Medicine's Diagnostic Laboratory. Samples sent to the Cornell Diagnostic Laboratory from throughout New Yorkstate and the Northeast give veterinarians an early warning about diseaseand toxicological trends in the animal population, and they now have arenewed concern about "garbage gut." "Particularly in warm weather, when animals ingest garbage with clostridialtoxins, we see severe vomiting, severe diarrhea, dehydration and sometimesdeath if garbage gut is not treated," Thompson said.  "As more peopleutilize compost for degrading biological materials -- if they're notjudicious about what they put in their compost and how they protect theircompost pile -- dogs and other animal can smell the meat and gain access tothe compost." Composts can be a microcosm of potentially harmful bacteria tomeat-foraging pets, according to  Patrick McDonough, Ph.D., amicrobiologist at the Cornell Veterinary Diagnostic Laboratory.  He pointedto Clostridium perfringens, Campylobacter jejuni, Yersinia enterocolitica,Staphylococcus aureus and some of the Salmonellae and Bacillus species asprime suspects. In any case, meat scraps have no business being in backyard composts, saidDan Cogan, a compost technology expert at the Cornell Waste ManagementInstitute. "It's true that meat can be composted in some of the high-tech, in-vesselsystems that are now in commercial use," Cogan said.  "But please don't trythis at home -- for a number of reasons, including the 'attractive-nuisance' problem with dogs and other animals.  Also, if you simply makesure your pile is enclosed on all sides, dogs won't be able to gainaccess." Most of the compost garbage-gut cases recorded at the Cornell VeterinaryDiagnostic Laboratory involve dogs, Thompson said, hoping to alert petowners to hazards in their own backyards and to encourage owners to monitorthe health of dogs that roam the neighborhood.  	"Dogs are not putoff by smells that offend us humans," he said, "and dogs -- more so thancats -- will eat garbage without hesitation.  It takes all kinds oforganisms to make a compost work, but a dog isn't one of them." -30- --------------------------------Cornell University News Service324 Judd Falls RoadIthaca, NY 14853607-255-4206 phone607-255-5373 faxmailto:cunews@cornell.eduhttp://www.news.cornell.edu 
--------
533-> University Of Florida Researchers: Stress Can Hasten Progression Of HIV
FOR IMMEDIATE RELEASE By Melanie Fridl Ross GAINESVILLE, Fla.---Stress can accelerate the progression of the early stages of HIV disease, report researchers from the University of Florida and the University of North Carolina at Chapel Hill.        	In fact, for every severe stress a patient reported in a six-month period, the risk of early disease progression doubled. And among those tracked for at least two years, higher severe life stress increased the odds of developing HIV disease progression nearly fourfold, researchers wrote in the June issue of the American Journal of Psychiatry.        	While other studies have suggested stress and depression can alter the body's ability to fight off illness, few have rigorously examined the role of emotional factors in the onset and course of immune-based diseases such as cancer and AIDS, says Dr. John M. Petitto, associate professor of psychiatry, neuroscience and pharmacology at UF's College of Medicine and the UF Brain Institute.         	"This study provides among the first evidence that severe life stress increases the likelihood and severity of early HIV disease progression," Petitto said.        	Researchers studied 93 homosexual men, ages 18 to 51, who tested positive for HIV but showed no symptoms of the disease when they entered the trial. They were recruited from rural and urban areas of North Carolina through state health departments, advertisements in gay publications and gay organizations, and word of mouth.        	To be eligible for the study, they could have no previous intravenous drug use as a risk factor for HIV, could not drink heavily or use recreational drugs and could not be taking medications affecting the immune system, such as antibiotics.	Participants, who were studied up to 42 months, were asked about more than 100 possible stresses at six-month intervals, including death of a mate, arrest, trouble with a boss, chronic financial difficulties or breakup of a love relationship.        	Researchers then assigned a "degree of threat" to the stress; in other words, the unpleasantness and uncertainty most people would experience given the same circumstances. For example, the long-term stress associated with the breakup of a committed relationship was based on the length of time the two were together, whether the patient lived with the person, whether the patient had control over the decision and other extenuating circumstances.        	In addition, to eliminate the chance that the stress of worsening disease might have influenced disease progression, researchers excluded disease-related stresses such as the onset of symptoms of AIDS-related complex, job loss due to dementia or a mate leaving because the disease worsened.        	The study showed that only severe stress had an influence; levels of stress common to everyday living did not seem to play a role in disease progression, Petitto said.        	Because HIV progresses at varying rates among patients, showing that stress can influence the course of illness could have implications for treatment, he said.        	"If we are able to identify factors that account for this disparity, that information could someday have implications for the treatment of HIV-infected individuals," Petitto said. "Further studies are required to shed light on the potential immune or other biological factors that may underlie the relationship between stress and disease progression." --------------------------------------------------------------------------------	Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html
--------
534-> Z Accelerator Output Climbs Closer To Fusion Levels
ALBUQUERQUE, N.M. --If the power and temperatures generated recently by Sandia's Z accelerator were graphed like stock prices, brokers would describe them as going through the roof and still climbing. The remarkable test results lay the groundwork to achieve sustainable fusion reactions, provide data to help test US defenses without physically exploding large-scale devices (the concept of so-called science-based stockpile stewardship), and advance basic scientific research. Z (formerly called PBFA-Z) is the most powerful generator of X-rays in the world. In the past ten months, the machine, located at Sandia National Laboratories, has more than quintupled its output from 40 to 210 trillion watts (terawatts). It took 25 years for a succession of Sandia accelerators to reach 40 terawatts. Z's output is now 60 times the world's usage of electrical power at a given moment. Rapid breakthroughs In the most recent development, Z in mid July achieved a temperature of 1.5 million degrees Celsius after languishing for many years at a mere 0.5 million degrees. Nuclear fusion requires temperatures from 2 to 3 million degrees. "The progress the Z-team continues to make is frankly astounding," says Gerry Yonas, Sandia vice president of Information and Pulsed Power Research & Technology Division. "Time and time again, the team has made theoretical projections, done experiments faster than expected, and made improvements along the way that gives even better results than predicted. This is world-class science and technology." Says Vic Reis, Assistant Secretary for Defense Programs for the US Department of Energy, "With this world-record result, the Z machine proves once again that the people at Sandia are up to the challenge of science-based stockpile stewardship. My heartiest congratulations!" Reis calls stockpile stewardship, to which the Z machine contributes, "perhaps the greatest scientific challenge of the next decade. It is our foundation for maintaining nuclear deterrence, as well as the basis for much of our arms control and nonproliferation objectives in the post cold war era. It clearly requires the best and the brightest." Stewardship requires studying the physics of nuclear explosions, and creating in miniature the effects of these explosions. Carl Ekdahl, program manager of the high-energy density physics program at Los Alamos National Laboratory, says, "It's wonderful work. Sandia researchers are way ahead of schedule. They fill a niche that no other facility in the world fulfills. My program is and will continue to be one of the largest users of Z for weapons physics." David Hammer, a physics professor at Cornell University, was quoted in the July 18 issue of Science: "I think it's spectacular what they [at Sandia] have done. The implications are only beginning to dawn on people." Says Jeff Quintenz, manager of the Inertial Confinement Fusion Program at Sandia's Pulsed Power Sciences Center, "There's a band in the spectrum - a profile of X-ray energies - that we are not able to adequately reproduce with today's X-ray generators. We lost that capability when we ceased underground testing. We need that band to certify our microchips are hardened against the effects of a nuclear explosion. These new results from Z bring us closer to producing the required output in the appropriate energy band." Sensors produce data to be used in Sandia's supercomputer -- the fastest in the world -- and in computers at Los Alamos and Lawrence Livermore national laboratories so that computer codes realistically can portray variations in the complex physics related to high-intensity emissions. Realistic data are needed to check the properties of materials, using an iterative series of prediction and experiment that close in on physical properties as yet unknown. These checks ensure that computers accurately model the physical world rather than produce logical but wrong conclusions. P> "The best part," says Don Cook, director of the Pulsed Power Sciences Center, "is that if fusion can be made to work in a very cost-effective way, there will not be future wars over oil in the Persian Gulf or anywhere else, and the injury to the environment caused by civilization will be reduced. Fond hopes, but these were, and are, some of the dreams of fusion scientists and engineers." Closer to high-yield fusion Sandia's inertial confinement approach uses massive bursts of electricity to superheat a miniature oven, called a hohlraum, that is about the size of a sugar cube. Numerical figures on Z's achievement are necessarily approximate because a change in any factor influences the others. But it could be said that Z now produces approximately 20 percent of the energy, 40 percent of the power, and 33 to 50 percent of the temperature to achieve high-yield fusion - a state in which much more energy is created than used. Of particular importance is temperature, because the pressure that drives the basic reaction increases as the fourth power of the temperature. While temperature is the hardest quantity for the Z accelerator to increase, "By optimizing the configuration of the hohlraum further, we believe we can increase its temperature still more," Cook says. "If all goes well with these tests on Z over the next several months -- and so far, we have exceeded all milestones -- at 1.7 million degrees, we will submit a formal request, first to design and then to build the next-generation X-1 accelerator." The next-generation machine's energy, power, and temperature outputs would be sufficient to create the fusion energy required to start the reaction in the accelerator. "In X-rays, this new machine would yield 1,000 terawatts of power, 16 megajoules of energy, 2 million to 3 million degrees Centigrade, and cost about $300 million," Cook says. One eventual use of the Z technique may be for a rocket propulsion system, says Sandia researcher Rick Spielman. "Z generates tremendous pulsed thrusts from a portion of the machine an inch high." Every time one drive pellet is burnt up, another would be dropped into place and lit. ------------------------------------------------------------------------ Why the breakneck breakthrough pace? The first breakthrough came when Sandia scientists realized that a nearly discarded forty-year-old technique -- the passage of a huge electric current through a wire cage the size of a thimble -- could produce dramatically more power in the form of X-rays if scientists greatly increased the number of thimble-wires -- from 30 to 300 -- through which the current passes. Within limits, the more wires available, the more uniform the magnetic field. The field evenly collapses at tremendous speed as the wires vaporize and become plasma. Atoms caught within the collapsing field speed up and then are braked suddenly to a stop - nowhere to go - as the uniformly shrinking magnetic field reaches a diameter about the thickness of a mechanical pencil lead. The sudden stoppage generates heat, much like the tires of a fast-moving car get hot when suddenly braked. While tire heat is generated at frequencies in the infrared range, the much faster deceleration of plasma in the shrinking magnetic field produces heat at higher radiation frequencies -- as it happens, in the X-ray range. While tweaking input energies and wire arrays could boost output even further than the 1.5 million degrees, the present arrangement is not certain to achieve fusion temperatures, says Cook. But by putting a very thin-walled gold cylinder inside the wire cage, Cook anticipates heat of approximately 1.7 million degrees, because of the heating effects of the imploding magnetic field and plasma striking the three-microns-thick walls of the cylinder. Says Cook, "The temperature goes up as the radiation container size decreases." If that works, "We'll want to do experiments to show we can get symmetry in produced X-ray flux -- adequate symmetry to drive a high-yield fusion reaction when scaled up to X-1 levels." Symmetry is important because without it, not all the energy arrives at the same location at the same time, thus diluting the impact. Successful conclusion of these experiments would mean that every contingency has been examined on the Z machine and found to be working correctly. At that point, a request to actually build the X-1 machine will be submitted to DOE. If granted, the Sandia team will move ahead on the road to fusion.
--------
535-> Study Of Graduate Record Exam Shows It Does Little To Predict Graduate School Success
ITHACA, N.Y. -- The Graduate Record Examination (GRE) does little topredict who will do well in graduate school for psychology and quite likelyin other fields as well, according to a new study by Cornell and Yaleuniversities. Of the three subtests of the GRE (verbal, quantitative and analytical) andthe GRE advanced test in psychology, only the analytical subtest predictedany aspect of graduate success beyond the first-year grade point average(GPA), and this prediction held for men only.  The verbal subtest andpsychology test predicted first-year GPA, but this prediction vanished bythe second year's GPA. "With these exceptions, the GRE scores were not useful as predictors ofvarious aspects of graduate performance, including ratings by primaryadvisers of analytical, creative, practical, research and teachingabilities by primary advisers and ratings of dissertation quality byindependent faculty readers," said Wendy M. Williams, associate professorof human development at Cornell University. Williams and her colleague, Robert J. Sternberg of Yale University -- bothexperts on measures and theories of intelligence -- reported their findingsin the June issue of American Psychologist (Vol. 52, No. 6, pp. 630-641). The researchers strongly suspect that the GREs may prove to lack validityin predicting performance in other fields as well. "We know from other researchers' work that the GREs also have failed topredict success in the field of physics, and we suspect that the GREs willfail to prove predictive for the humanities as well," Williams said. "Instead of relying so heavily on the GREs -- and many applicants aren'teven considered if their GRE scores are not in the top group -- we need todevelop and use tests that measure meaningful performances in specificareas.  The GREs, including the one specifically for psychology, do notassess many of the types of abilities required for succeeding as aprofessional psychologist," Williams said. She also pointed out that applicants from less privileged backgrounds, whoare not as likely to do as well on the GRE as applicants from goodpreparatory schools, lose out even though they may have the appropriateskills for the profession they desire.  "Graduate programs rely so heavilyon GREs to make their initial cuts, many well-qualified applicants who arestrong in the appropriate areas aren't even being considered.  This is ahuge disservice to the applicants, the graduate programs and society atlarge." The researchers set out to test the validity of the GRE, working within thebroader framework of the triarchic theory of human intelligence.  Thetriarchic theory distinguishes academic or analytical abilities fromcreative and practical abilities. "Academic-analytical abilities are used when one analyzes, compares andcontrasts, evaluates, judges or critiques," said Sternberg, who haspublished widely on the theories of intelligence.  "Creative abilities areused when one invents, discovers, supposes, hypothesizes or theorizes.Practical abilities are used when one applies, uses or implements." To assess the validity of GREs in predicting success or failure of graduatestudents, the researchers asked 40 faculty members of psychology at Yale toprovide ratings on five scales of the 166 graduate students they had hadsince 1980.  In addition, the researchers looked at GPAs of students intheir first and second years of graduate training and overall evaluationsof dissertations by outside, independent raters. When the researchers looked at GRE scores and GPAs, they did find amarginal relationship between the scores and grades in the first year ofgraduate study.  When they looked in more detail at the GRE subtests andthe genders separately, they found only one of them (the analytical testscore) successfully predicted more consequential evaluations of studentperformance (dissertation reader ratings) -- but this was only true formen.  For women, there was no prediction. "This study suggests the need to reflect on the use of tests before theybecome firmly -- and, as it sometimes seems, irrevocably -- entrenched.Too often, we believe, the use of a test becomes self-perpetuating, withoutserious attempts to verify its effectiveness," the psychologists wrote."We believe that our results underscore the need for serious validationstudies of the GRE, not to mention other admissions indexes, againstmeasures of consequential performances, whether of students or ofprofessionals." Next, Williams hopes to look at GRE scores of men and women in the socialsciences, natural sciences and humanities.  GREs are developed by theCollege Board of the Educational Testing Service. The study was supported in part by the U.S. Department of Education. -30- --------------------------------Cornell University News Service324 Judd Falls RoadIthaca, NY 14853607-255-4206 phone607-255-5373 faxmailto:cunews@cornell.eduhttp://www.news.cornell.edu 
--------
536-> Hubble Separates Stars In The Mira Binary System
CONTACT:  Donald Savage          NASA Headquarters, Washington, DC                                          (Phone:  202/358-1547) Tammy Jones          Goddard Space Flight Center, Greenbelt, MD          (Phone:  301/286-5566) Ray Villard          Space Telescope Science Institute, Baltimore, MD          (Phone:  410/338-4514) Megan Watzke          Harvard-Smithsonian Center for Astrophysics, Cambridge, MA          (Phone:  617/495-7463) Although the giant star Mira has been known for about 400years, astronomers have had to wait for NASA's Hubble Space Telescopeto provide the first ultraviolet images of the extended atmosphere ofthe cool red giant star and its nearby hot companion. By giving astronomers a clear view of the individual members ofthis system, Hubble has provided valuable insights into other types ofdouble star systems where the stars are so close they interact with oneanother. The separation between Mira and its companion is about 70 timesmore than that between Earth and the Sun, (equal to an angular size ofonly 0.6 arcseconds -- the apparent diameter of a dime at four milesaway) even smaller than the typically fuzzy ground-based telescopicimage of a single star as smeared out by Earth's turbulent atmosphere. Using the European Space Agency's Faint Object Camera aboardHubble, Margarita Karovska and John Raymond of the Harvard-SmithsonianCenter for Astrophysics, Cambridge, MA; Warren Hack of the SpaceTelescope Science Institute, Baltimore, MD; and Edward Guinan ofVillanova University, Villanova, PA, obtained both ultraviolet andvisible light images and spectra of the two separate stars in the Mirasystem.  The results appear in the June 20 Astrophysical JournalLetters. In ultraviolet light, Hubble has resolved a small hook-likeappendage extending from Mira in the direction of the companion, whichmight be material from Mira being gravitationally drawn toward thesmaller star.  Alternately, it could be material in Mira's upperatmosphere being heated due to the companion's presence. Hubble's visible-light images show that Mira has an odd,asymmetrical shape resembling a football.  This may be tied to dramaticchanges occurring during its expansion-contraction cycles, or to thepresence of unresolved spots on its surface.  Hubble allows astronomersto measure the star's size at about 60 milliarcseconds, correspondingto a diameter some 700 times larger than our Sun.  If Mira were at thecenter of our solar system, it would extend out more than 300 millionmiles, well beyond Mars' orbit and nearly two-thirds of the way toJupiter. Mira (officially called Omicron Ceti in the constellation Cetus)is the prototype for an entire class of stars known as "Mira-typevariables."  Although once like our Sun, Mira is now at the end of itslife, and has evolved into a cool red giant star that is highly variablein brightness.  Contracting and expanding every 332 days, Mira shedsvast amounts of material through its powerful "wind" of gas and dust. Mira's companion is a burned-out star called a white dwarf thatis surrounded by material captured from Mira's wind.  At a distance ofabout 400 light-years, Mira is the closest wind-accreting binary systemto Earth. Separating the spectra of Mira and its companion -- somethingastronomers previously have tried to do through indirect means -- is acrucial step for studies of physical processes associated with windaccretion in binaries. Mira was discovered on August 13, 1596, by Dutch astronomerDavid Fabricus, who mistook it for a nova because it later faded fromview.  He called it Mira, meaning "The Wonderful."  Astronomers laterrealized it was really the first case of a variable star. The Space Telescope Science Institute is operated by theAssociation of Universities for Research in Astronomy, Inc., for NASA,under contract with NASA's Goddard Space Flight Center, Greenbelt, MD. The Hubble Space Telescope is a project of international cooperationbetween  NASA and the European Space Agency (ESA). EDITORS NOTE:  The Hubble images of Mira are available tomedia representatives by calling the Imaging Branch at NASAHeadquarters at 202/358-1900.  Photo number is: (color) 97-HC-537 Image files in GIF and JPEG format and captions may be accessed on theInternet via anonymous ftp from oposite.stsci.edu in /pubinfo. GIF                   JPEGPRC97-26  Mira        gif/mira.gif          jpeg/mira.jpg Higher resolution digital versions (300 dpi JPEG) of the releasephotograph are available in /pubinfo/hrtemp: 97-26.jpg (color) and97-26bw.jpg (black & white). GIF and JPEG images, captions and press release text are available viathe World Wide Web at URL:http://oposite.stsci.edu/pubinfo/PR/97/26.html and via links inhttp://oposite.stsci.edu/pubinfo/Latest.html orhttp://oposite.stsci.edu/pubinfo/Pictures.html Space Telescope Science Institute press-release text and other information are available automatically when you subscribe to the STScI List Server.  To subscribe, send e-mail to "listserv@stsci.edu".  In the body of the message (not the subject line) type the words "subscribe pio Your Name".  For example, someone named Jane Doe would type "subscribe pio Jane Doe".  The system will respond with a confirmation of your subscription, and you will receive new press releases by e-mail. * * * *
--------
537-> Motor Memory: Skills Slip Most Easily In First Hours After Learning
They say practice makes perfect, but when it comes to skills involving movement and coordination, a more critical factor appears to be the simple passage of time. The first six hours after a motor skill—such as riding a bicycle—is learned comprise a window of vulnerability during which the skill can be impaired or even lost by attempting to learn a second motor task.  During those hours, researchers from the University of Maryland School of Medicine and Johns Hopkins University School of Medicine say, the central nervous system is consolidating a pattern of neural pathways that control performance of the task, moving them from one part of the brain to others in the process. Dr. Henry H. Holcomb, professor of psychiatry at the University of Maryland, and Dr. Reza Shadmehr, a biomedical engineering professor at Johns Hopkins, report their findings in the August 8, 1997 issue of Science.  What they’ve learned could change the way skills training is conducted in educational and industrial settings. "We wanted to know if the neural representation of a motor task change with time in the absence of practice," Holcomb said. Using positron emission tomography (PET) imaging to monitor changes in cerebral blood flow, the researchers taught study participants a new skill involving rapid, accurate movements of a motorized robotic arm. Imaging brain blood flow is a way of tracking neural activity. They found that during the critical first five to six hours, the neural links that form the brain’s internal model of the task shift from the prefrontal regions of the cerebral cortex to the premotor, posterior parietal and cerebellar areas. Even without practice, after five or six hours, the recipe for the task is virtually hardwired into the brain.  That’s why an adult who learned to ride a bicycle as a child can climb on a bike 20 years later and pedal away, Holcomb said. "The representation of a motor task is fragile immediately after learning it, but it becomes progressively more resistant to modification with the passage of time. After about five to six hours, a person’s retention and neural representation of a task is stable," he explained. "This paper demonstrates that time’s passage causes the brain actually to represent the task using different neural pathways," Holcomb added. "We believe that this shift in neural representation is an important aspect of memory consolidation." The study reported in Science laid the groundwork for the scientists' current research: using PET imaging to examine what happens in the brain when interference occurs during the window of vulnerability, before motor memory is consolidated. It was funded in part by the Whittaker Foundation, the National Institute of Mental Health and the Office of Naval Research.  
--------
538-> Remote Control Robot Breaks Rough Terrain Travel Record, Paves Path For Future Planetary Science Missions
Douglas IsbellHeadquarters, Washington, DC(Phone:  202/358-1753) John BluckAmes Research Center, Moffett Field, CA(Phone:  650/604-5026) Anne WatzmanCarnegie Mellon University, Pittsburgh, PA(Phone:  412/268-3830) A hardy traveler named "Nomad" recently set a record by traveling farther than any remotely controlled robot has before over rough territory.  The robot's four wheels logged more than 133 miles (215 kilometers) across Chile's rugged Atacama Desert from June 15 to July 31, during a field experiment designed to prepare for future missions to Antarctica, the Moon and Mars. Scientists from NASA's Ames Research Center, Moffett Field, CA, and Carnegie Mellon University's Robotics Institute in Pittsburgh performed experiments with Nomad for 45 days, conducting both technology demonstrations and scientific activities.  Nomad often worked on its own to avoid obstacles and, in a clear foreshadowing of the future duties of similar robots, it recognized meteorites planted in the desert as a test and may even have found a fossil. "The Atacama trek is a quantum leap for the planetary robotics culture, where the historical standard of travel has been yards, not miles," said principal investigator Dr. William L. "Red" Whittaker of Carnegie Mellon.  "Although the 'straight-line' distance on a map was only about 13 miles, Nomad had to weave through very difficult terrain, and it made numerous sidetrips for science and to test the meteorite sensors.  It is a pioneer laying a trail toward future planetary robots, who will be challenged for thousands of miles and years of operations, in bold missions like searching for signs of life." The 1,600-pound robot, developed at Carnegie Mellon and funded by NASA, validated the use of color stereo video cameras with human-eye resolution for geology.  A separate panospheric camera returned more than a million video panoramas from the Atacama, a cold, arid region located above 7,000 feet. "During different phases of testing, we configured the robot to simulate wide-area exploration of the Moon, the search for past life on Mars and for the gathering of meteorite samples in the Antarctic," said Dave Lavery, telerobotics program manager at NASA Headquarters, Washington, DC.  "Nomad met or exceeded all of our objectives for this project." "We want to give planetary scientists experience using mobile robots, so that they can develop the skills necessary for performing remotely guided investigations," added Dr. David Wettergreen, Nomad project leader at Ames. Nomad is about the size of a small car.  To maneuver through rough terrain, the robot has four-wheel drive and four-wheel steering with a chassis that expands to improve stability and travel over various terrain conditions.  Four aluminum wheels with cleats provide traction in soft sand.  For this terrestrial experiment, power was supplied by a gasoline generator that enabled the robot to travel at speeds up to about one mile per hour. "Nomad drove itself through about 12 miles (20 kilometers) of the 133 miles it traveled," said Dr. Mark Maimone, Nomad software and navigation lead at Carnegie Mellon.  "Autonomous driving is critical for planetary exploration because the communications delay between Earth and planets can be many minutes.  With autonomous driving, a robot can explore a much greater distance because it doesn't have to wait for a person to decide a safe route.  The rover is able to see obstacles and recognize them on its own," he said. Nomad's unique onboard panospheric camera provided live 360-degree, video-based still images of the robot's surroundings.  "Experimentation with the panospheric camera validated the use of immersive imagery for remote driving," Maimone said. The camera takes a 360-degree picture -- one frame per second -- and did so throughout the mission.  The high-resolution video camera focuses up into a hemispheric mirror similar to a store security mirror.  The video view includes all of the ground up to the horizon in the circle surrounding Nomad. "The camera is a new technology, and it gave members of the public as well as scientists a new way to drive with peripheral, or side vision," he explained.  "We sent the Nomad pictures to a theater at the Carnegie Science Center in Pittsburgh that has a 200-degree, semi-circular screen.  Fifty people at a time pushed a button to vote on whether the robot should look to the left, center or right." On June 25, NASA scientists were driving the robot remotely from their laboratory at Ames, more than 5,455 miles (8,780 kilometers) away, when the scientists in California found a rock that appeared to contain algae fossils. Using the rover's cameras, scientists noticed a light-colored, three-inch diameter rock with a darker, intricately shaped marking in a rock outcrop in the Chilean desert.  The rock was retrieved by Chilean scientists and was brought to Ames for scientific analysis. "The rock is sedimentary and was formed in an ancient sea bed.  However, the consensus is that this rock does not contain fossilized algae," said Dr. Nathalie Cabrol, the expedition's NASA science team leader.  The science team was excited to learn that the outcrop was an undiscovered geologic deposit from the Jurassic Period. "This experience is one of the most important of the science tests," Cabrol said.  "I am not sure that we can get much closer to what may happen with the research of interesting rocks on Mars and the related search for life in the coming Mars exploration program.  We are most likely to face this exact situation of selecting a rock because it looks interesting to us.  Once in the lab, we were unable to tell conclusively if there had been life in the rock at one time or not." "The first-level interpretation from the rover camera was close enough, fossil or not," she added.  "The team was able to reconstruct the geology of the site, often matching or at least getting very close to the conclusions of the back-up field team." The total cost of developing Nomad and conducting the desert trek is $1.6 million.  The project is funded by NASA with in-kind support from corporate sponsors and educational foundations. NASA and Carnegie Mellon are formulating plans to use Nomad to look for meteorites in Antarctica in 1998 and 1999. Further information about the Atacama desert trek, images and data are available from the Ames Intelligent Mechanisms Group at URL: http://img.arc.nasa.gov/Nomad Carnegie Mellon's Robotic's Institute also has a website at URL: http://www.ri.cmu.edu/atacama-trek -end-
--------
539-> Resistance To Leptin Contributes To Obesity
Insensitivity to the protein leptin, which helpsthe body regulate its fat stores, contributes to obesityin mice according to the first formal study of leptinintolerance, report scientists in the Aug. 5 Proceedingsof the National Academy of Sciences.  The findings alsoprovide clues about leptin's action in the nervoussystem and may help to explain some forms of obesitythat affect humans, including more than 50 millionoverweight adult Americans, the researchers note. "We knew obese mice and humans generally have highlevels of leptin in their blood, which suggested thatthe protein was not fully active.  Our new researchdirectly shows that resistance to leptin can causeobesity," explains senior author Jeffrey Friedman, M.D.,Ph.D., professor at The Rockefeller University and aninvestigator with Howard Hughes Medical Institute(HHMI). Some investigators have suggested that leptin'sprincipal role is to suppress the body's response tostarvation.  The new study also suggests that receivingextra leptin adjusts a mouse's 'set point' for the bodyweight to a lower-- but stable level --by reducing foodintake without  an accompanying decrease in energy use. "These data confirm that leptin plays an importantrole in the body's response to weight gain.  This resultsuggests that lean animals increase their production ofleptin to return their weight to the set point,"explains first author Jeffrey L. Halaas, B.S.,biomedical fellow at Rockefeller.  "Also, leptin acts toblunt the reduction in energy use that typically followsa reduction in the number of calories eaten." In previous studies, Friedman and his colleaguesdiscovered leptin and documented weight loss ingenetically obese and normal mice given daily injectionsof the protein for two weeks.  These early studiesrequired high dose injections of leptin.  In the currentstudy, much lower doses were effective in reducingweight when the hormone was delivered as a constantinfusion.  While receiving leptin, the mice ate less andhad a relative increase in their energy use compared tofasted mice.  Leptin, a product of the obese gene, ismade in fat and then is released into the blood stream,by which it travels to the brain. Obesity, defined as being more than 20 percentabove a healthy weight, affects one in three Americansand is a major risk factor for diabetes, heart disease,high blood pressure, stroke, sleep apnea, gallstones,some cancers and forms of arthritis, according to theNational Institute of Diabetes and Digestive and KidneyDiseases (NIDDK), part of the federal government¹sNational Institutes of Health.  NIDDK supported theresearch, along with the Robert J. Jr. and Helen C.Kleberg Foundation. In the new study, Friedman and his coinvestigatorsfrom Columbia University, St. Luke's-Roosevelt HospitalCenter, University of Melbourne and the Howard FloreyInstitute of Experimental Physiology and Medicine, foundthat three strains of obese mice, all with normally highlevels of leptin, are overweight because they havevarying degrees of insensitivity to the protein.  Theteam examined the effect of leptin given during a 30-dayperiod as infusions either into the fat tissue under theskin or directly into the fluid that bathes the brainand spinal column.  This innovative technique, calledICV infusion, was developed by coauthor Dr. Derek A.Denton of the Howard Florey Institute in Melbourne,Australia. Normal weight, lean mice receiving leptin by eithermethod lost significant weight and fat, with low dosesdelivered via ICV infusion having the same effects ashigh doses given as subcutaneous infusions into the fattissue.  For example, during ICV infusion, at a constantrate of 8 nanograms (ng) per hour, lean mice lost 15percent of their body weight, yet this dose had noeffect when given to other lean mice by the subcutaneousinjection. "The difference between the increased potency ofleptin in lean mice receiving the protein via ICVinfusion and those receiving subcutaneous injectionsshows that the central nervous system, in particular thehypothalamus, is an important site of leptin action,"says Friedman.  "Indeed, chronic ICV infusions of verylow doses of leptin replicate the weight-reducingeffects of much higher doses of leptin given byinjection.  The basis for this apparent difference isnot clear, but may suggest that the transport of leptinacross the blood-brain barrier, which allows leptin toenter the brain from the body's blood stream, may be animportant step in the body's processing of leptin'ssignal." Specifically, in normal, lean mice, injectingleptin subcutaneously at an infusion rate of 200 ng perhour, for example, led to an increase in blood levels,from 5 to 7 ng/milliliter, and resulted in a 5 percentreduction in weight.  A doubling of leptin levels led toa 9 percent reduction in weight, while a five-foldincrease in leptin levels yielded a 15 percent weightloss. Other lean mice receiving leptin through ICVinfusion rapidly lost fat, reaching their lowest weightby the eighth day of treatment and maintained it for theremainder of the 30-day infusion period.  The micereduced their food intake to its lowest level, a drop ofmore than 50 percent, by the third day, but their foodintake crept back to original levels by the eighth day.After the 30 days of ICV, the researchers replaced thecerebrospinal fluid and the mice quickly recovered theirweight by eating more food. To compare leptin's affects via injection and ICVinfusion among overweight mice, the researchers selectedstrains of mice with different types of obesity.  Onetype, the Diet Induced Obese (DIO) mouse, is lean whenfed regular mouse chow, but has an inheritedpredisposition to develop obesity when fed a diet inwhich 45 percent of the calories are from fat.  Thesecond strain, the New Zealand Obese (NZO) mouse, isoverweight because of the action of several genes.  Thethird kind of mouse, called Yellow Agouti (Ay), is obesedue to single copy of a mutant gene. In the leptin injection study, NZO and Ay mice didnot respond to subcutaneous leptin doses of 5 microgramsper hour, a 10 times greater dose than required toachieve a maximum response in the lean mice.  The DIOmice lost weight when give injections of leptin, butwere less sensitive than the lean mice.  Also, the DIOmice fed the regular diet had a greater response to highdoses of injected leptin than DIO on high-fat diets:losses of 83 vs. 30.5 percent of body fat.  In the ICVinfusion studies, NZO mice responded to low doses of 5ng per hour, but doses 100 times greater yielded modestweight loss in the Ay mice. "Because the Ay  mice required substantially higherdoses than that needed in lean and NZO mice for weightloss, leptin resistance in the Ay mice may result from adefect in the nerve pathway activated by leptin,"Friedman says.  "In NZO mice, a decrease in thetransport of leptin into the cerebrospinal fluid maycause the obesity." Friedman, Halaas and Denton's coauthors include:Naseem Fidahusein, B.S., at Rockefeller; Carol Boozer,D.Sc., at Columbia University School of Medicine and theObesity Research Center at St. Luke's-Roosevelt HospitalCenter; and John Blair-West, Ph.D., of the University ofMelbourne. Rockefeller began in 1901 as the RockefellerInstitute for Medical Research, the first U.S.biomedical research center. Rockefeller faculty membershave made significant achievements, including thediscovery that DNA is the carrier of genetic informationand the launching of the scientific field of modern cellbiology.  The university has ties to 19 Nobel laureates,including the president, Torsten N. Wiesel, M.D., whoreceived the prize in 1981. Recently, the universitycreated five centers to foster collaborations amongscientists to pursue investigations of Alzheimer'sDisease, of biochemistry and structural biology, ofhuman genetics, of sensory neurosciences and of thelinks between physics and biology. ###Journalists: Do you want to receive news fromRockefeller University by e-mail or fax?Let us know via e-mail or fax.  Also, if your name oraddress or the contact at your organization needs to bechanged, send us the correct information.  Check out ourother news at: www.rockefeller.edu/NEW.html.  RU newsalso can be found on EurekAlert!:  www.eurekalert.org.###### The Rockefeller University Office of Public Affairs Marion E. Glick, Director of CommunicationsJoseph Bonner, Assistant Director of CommunicationsLaura Smith, Communications Assistant Journalists Line: 212-327-7900, Fax: 212-327-78761230 York Avenue, 301 Caspary HallNew York, NY 10021-6399
--------
540-> Eddies And Echoes To Thwart Smugglers
RICHLAND, Wash. -- Smugglers, beware.  Pacific Northwest NationalLaboratory researchers have developed two portable detectionsystems that can detect quickly and accurately everything fromthe contents of a soda pop can to strategic metals used to makenuclear weapons. The Material Identification System and the Ultrasonic Pulse Echoinstrument, currently in use by the U.S. Customs Service and theDepartment of Energy's Hanford Site,  are being provided tocustoms inspectors in Eastern Europe and former Soviet Unionrepublics. "With both systems, we have taken basic measurementtechnologies--eddy current and ultrasound--and provided new,sophisticated applications that are extremely user-friendly,"said Pacific Northwest senior research scientist Richard Pappas. Although the devices have traveled separate development paths,they now are viewed as companion technologies and an effectiveone-two punch for border security. Material Identification System Development of the Material Identification System began in 1993. "A U.S. Customs official visiting Pacific Northwest wasimpressed by a demonstration of an eddy current device that wasable to tell the difference between nickels, dimes and othercoins," Pappas explained. "Because most metals, including thoseused for strategic purposes, are similar in appearance, it ishard, if not impossible, for border inspectors to visuallydetermine whether a metal is what it's purported to be. "U.S. Customs felt a device that could discriminate betweenmetals would be a useful tool for their inspectors," he added. With initial funding from DOE, Pappas and Pacific Northwestengineer Jim Skorpik completed the first Material IdentificationSystem several months later. The system is composed of a laptop computer with a plug-ininstrument card that operates a hand-held probe.  As the probeis passed over a piece of metal, the instrument card measuresthe flow of electrical currents through the metal.  Ease offlow--or, alternately, resistance--varies from one metal toanother.  Information gathered through this process is used bythe computer for comparison and reconciliation against anextensive U.S. Customs data base.  The computer lets the userknow whether the metal is, in fact, what is declared orpurported to be, and also indicates the most likely identity ofthe metal.  The inspector may search the data base foradditional information including the classification of the metaland regulations that apply. In addition to detecting strategic metals, which could be usedto make nuclear weapons, the Material Identification Systemhelps border inspectors determine if a shipment of metals hasbeen labeled fraudulently to avoid a higher duty fee. But applications are not limited to customs-related work.  Thesystem is used at the Hanford Site to inspect excessed equipmentbefore it is sold as surplus to the public.  This is aprecaution to help identify items that may impose special exportcontrols requirements on the person or organization purchasingthem. Ultrasonic Pulse Echo The Ultrasonic Pulse Echo instrument, based on ultrasoundtechnology, originally was developed by Pacific Northwest staffto inspect chemical weapon stockpiles in Iraq following the 1991Gulf War.  A hand-held device roughly the size and shape of alarge ping-pong paddle, the instrument houses a computer, islinked to a data library and sensor head, and can determine thecontents of a sealed container. The sensor, which transmits ultrasonic pulses and detects anyreturn echoes, is positioned on the outside wall of thecontainer.  As sound waves are transmitted, the return echoesbouncing off the other side of the container are analyzed interms of time-of-flight and amplitude decay to identify thecharacteristics of the contents and compare those featuresagainst information in the data library. In addition to characterization, the Ultrasonic Pulse Echo canmeasure how full a container is, and determine whether there areany cavities or hidden packages within the container that mighthold drugs or other smuggled goods. "This instrument and the Material Identification System arereliable and can provide information in a matter of seconds, butthey should not be viewed as end-alls," Pappas emphasized. "Border inspectors simply don't have time to conduct a search ofthe contents of  every vehicle passing through a border point. But if experience and intuition tell them a particular shipmentwarrants suspicion, they then could turn to these systems." The U.S. On-S 
--------
541-> Research With Gel May Help Chemical Analysis
Kansas State University News Services9 Anderson Hall, Manhattan, KS 66506-0117(785) 532-6415; fax - (785) 532-6418Cheryl May, director of news services, cmay@ksu.edu MANHATTAN - A special type of porous  liquid-glass that acts almost like a sponge may help soak up environmental  and biological problems in the future. Maryanne M. Collinson, electrochemist at Kansas State University is conducting a research project titled "Electroanalytical Applications of Organically Modified Sol-Gel Materials." Collinson said the materials that are created through the sol-gel process can be thought of as glasses at room temperature that have not been hardened by exposure to high levels of heat associated with creating actual glass. The "glass" used in their work is made out of a composite of both organic and inorganic materials. It also has several qualities that can be compared to a sponge. The gel is very porous with many channels and cases that can be used to trap reagents, which can be substances used to detect or measure other substances or to convert one substance  into another. When certain reagents are trapped in the gel, they are able to react with other substances in the solution and  change their properties, like turning a certain color - such as a transparent orange, green or yellow. Collinson said they are studying the gel itself and how it influences the physical and chemical properties of the different reagents placed into it. She said in the future, scientists may be able to use the gel to analyze very specific molecules in places that contain many different materials. "For example, one such application may  involve the measurement of pesticides in well water," Collinson said. "There are lots of things in well water and if we want to measure only one particular pesticide and no other pesticide or other agent in the water, the gel may be able to do that. Then we can say, for example, there is one part per billion of that certain pesticide in the water or give some other value." She said the more they learn about the gel, the more efficient they can make it at identifying specific molecules in complex solutions. Organic polymers are commonly used to trap molecules for analysis applications. These polymers have many good qualities, but are still imperfect, Collinson said. "We're trying to develop a more stable, more sensitive, more selective material than the organic polymers commonly used to analyze compositions," Collinson said. "We want  to optimize the properties of the gel we're working with, such as the pore  size and the overall structure of the gel, so it will be a better analytical  sensor than the current organic sensors used." She said the gels her research group is working on have high mechanical, chemical and thermal stability relative to the conventional organic polymers because of their rigid, highly cross-linked structures. She also said the gel is more optically transparent than the organic polymers so it is easier to study the components of what is in the gel. "Basically," she said, "we're combining organic and inorganic properties into one composite material so we can get the best of both worlds." To further her research, Collinson received a prestigious Faculty Early Career Development - CAREER - Award  from the National Science Foundation. The $244,000 award for four years was  granted in April 1996. Collinson has received three other grants from the  National Science Foundation totalling nearly $50,000, and a Young Investigator award from the U.S. Navy for $133,000. K-State's Vice Provost for Research, Tim Donoghue, said, "CAREER awards are intended to facilitate the early phases of the careers of the most promising scientists in the nation and are  therefore highly competitive. This is indeed a true honor to be so recognized." Since 1991, nine K-State young scientists have been chosen for special awards designed to help launch the early stages of a research and teaching career. Prepared by Bree Bisnette. For more information contact Collinson at (913) 532-1468. ------------------------------------------------------------- This has been a post from KSUSCI-L, an  electronic mailing list about science topics, utilizing expertise from Kansas State University sources. This is a low volume list, providing one or two news releases each month. KSUSCI-L is a service of Kansas State University News Services. Articles may be reproduced without permission, either electronically or in hard copy form. A selection of other news articles is available on our Web site at: http://www.newss.ksu.edu
--------
542-> Voyage Of Discovery: Rutgers Scientists Take Leading Role In Historic Deep-Sea Explorations
RUTGERS NEWSRutgers News ServiceRuth Scott, Director 732/932-7084Rutgers Contact: Harvey Trabb, Extension 615E-mail: htrabb@communications.rutgers.edu Woods Hole Oceanographic Institution Contact: Shelley Lauzon (508) 289-2270 (as of Aug. 4) IFREMERContact: Pierre Saliot (France):  33-1-46-48-22-40 July 28, 1997FOR IMMEDIATE RELEASE			EDITOR'S NOTE:  The two Rutgers professors mentioned in this story are due back from their expedition Aug. 1.  At that time, Dr. Lutz can be contacted by calling his office at (732) 932-8959, extension 200, and Dr. Vrijenhoek by calling (732) 932-6680, extensions 368 or 356.  Images of highlights of the expedition are downloadable from Rutgers' Media Relations Web site at http://uc.rutgers.edu/news. TO THE POINT:  Rutgers scientists take leading role in historic deep-sea explorations NEW BRUNSWICK/PISCATAWAY, N.J. -- At the same time the Sojourner rover explored the surface of  Mars, another scientific expedition -- this one going to the bottom of the North Atlantic Ocean -- gathered data that may help scientists get a better understanding of the origins of life on Earth and provide clues about how and where life might exist on other planets. The historic international expedition to the bottom of the sea focused on exploring the unique biology and geology of volcanic vents along the Mid-Atlantic Ridge near the Azores.  The expedition, involving two international teams of scientists, found one of the largest hydrothermal vent fields yet discovered in the Atlantic and also made the first joint dive using two submersibles from different countries working together in the deep sea. One team of scientists was led by two professors affiliated with Rutgers' Institute of Marine and Coastal Sciences at Cook College -- Robert Vrijenhoek and Richard Lutz.  The other scientific team was led by Yves Fouquet of IFREMER, the leading oceanographic exploration agency in France.  The scientists are from Colombia, France, Great Britain, India, Italy, Panama, Portugal, Russia and the United States. Vrijenhoek, director of Rutgers' Center for Theoretical and Applied Genetics, and Lutz, director of the Center for Deep-Sea Ecology and Biotechnology at Rutgers, served as co-chief scientists for the team based on the Wood's Hole Oceanographic Institution's research vessel Atlantis and diving in the submersible Alvin.  They cooperated with a multinational European Commission scientific team based on the French government agency IFREMER's research vessel L'Atalante and diving in the submersible Nautile. Most of the scientists on the Atlantis are marine biologists looking for new species of animals and collecting bacteria that may play a vital role in biomedical research, while most of  those on L'Atalante are geologists and geochemists studying hydrothermal fluids and minerals. During two exploratory dives, scientists on the French submersible, Nautile, discovered "Rainbow," one of the largest volcanic vent fields in the Atlantic, at a depth of 7,700 feet.  As prearranged, Alvin joined Nautile the next day to explore the field.  The joint Alvin/Nautile dive represents the first time that human-occupied submersibles from two nations worked together on the deep-ocean floor. Lutz described the rendezvous with Nautile as "a brief encounter in inner space, a tremendous stride toward international cooperation in the exploration of the last great frontier on earth." Following a second joint dive, the Atlantis headed south so that the team could dive at other vent sites along the Mid-Atlantic Ridge.  The scientists are expected to return from their voyage Aug. 1. The Mid-Atlantic Ridge is part of a 46,000-mile series of undersea mountain ranges that curve around the world along the edges of drifting continental plates, the scientists explained.  These edges are sites of frequent volcanic activity where hydrothermal vent fields are created as magma comes out of the Earth's molten interior and forms a crust.  Seawater pours into cracks that develop in the crust and is superheated by the magma to temperatures in excess of 600 degrees Fahrenheit.  The water erupts through vents in the crust in a process that forms eerie, hollow, cone-like chimneys as the minerals carried by the water precipitate out. At these vents, which are more than a mile below the surface, the minerals nourish extensive bacterial colonies.  The bacteria are at the bottom of a unique undersea food chain that includes exotic varieties of shrimp, mussels, worms and many previously unknown types of marine life. The primary goal of the Rutgers-led team of researchers is to use state-of-the-art genetic techniques to study the dispersal and evolutionary relationships of these unusual deep-sea organisms.  During the expedition, they prepared tissue samples and DNA extracts from specimens brought to the surface by Alvin.  How these organisms disperse from one tiny deep-sea oasis to the next has been a mystery to marine scientists since the discovery of these unusual ecosystems two decades ago. Genetic approaches can assess the similarity between populations at different localities and construct models of how the organisms disperse and colonize new habitats as they arise.  Additionally, the Rutgers team is using molecular techniques to place these unusual organisms on the tree of life. The environment at these vents is filled with hydrogen sulfide, which would be highly toxic to humans and most other forms of life on Earth.  Scientists believe that studies of the marine life that thrives in such an environment could lead to important medical breakthroughs insuch areas as cancer prevention and might be valuable in such diverse areas as chemical manufacture and environmental cleanup.  The studies could also help scientists devise methods to look for organisms that may live in similar environments on other planets. Funding for the Rutgers scientists' current expedition is provided by the National Science Foundation and the New Jersey Commission on Science and Technology. Both Lutz, a resident of CLINTON, and Vrijenhoek, who makes his home in WHITEHOUSE STATION, are veterans of many previous dives to the sea floor.  In 1992 they became the first American biologists to dive in the Japanese submersible Shinkai 6500 to study hydrothermal vents along the Mariana Trough in the Pacific.  The following year Lutz and his colleagues discovered evidence of unprecedented rates of biological and geological growth on the sea floor along the East Pacific Rise 500 miles southwest of Acapulco, Mexico.  The discoveries were hailed as being among the most important ever made under the sea. 970728-2
--------
543-> Researchers Cut Solar Cell Production Time In Half Without Losing Efficiency
ATLANTA, GE--Researchers have successfully cut in half the timeit takes to make a silicon solar cell without diminishing itsperformance, an achievement that should reduce the cost of solarenergy. Using rapid thermal processing (RTP), researchers at the GeorgiaInstitute of Technology have produced a solar cell with the sameefficiency rating -- 18 percent -- as one made by conventionalfurnace processing. They created the cells in 8 1/2 hours,compared with the 17 hours needed for a furnace-processed cell. In a separate process, researchers also  integrated  RTP withscreen-printing, an alternative method for applying the cell'smetal contacts, which slashed the processing time even further,to 1 1/2 hours. "If we can make the solar cells very fast compared to what'sbeing done out in industry today, that will obviously reduce theuse of chemicals, gases and manpower, and it will increase theproduction capacity and throughput," said Dr. Ajeet Rohatgi, aprofessor in Georgia Tech's School of Electrical & ComputerEngineering. "That can result in the significant reduction ofcosts." Rohatgi presented a paper on these results, titled "HighestEfficiency RTP Silicon Solar Cells by Rapid Thermal Diffusionand Oxidation," during the 14th European Photovoltaic SolarEnergy Conference and Exhibition in Spain, which ended July 4.The paper was written by Rohatgi, graduate student Parag Doshiand research engineer Sachin Kamra. The research was done under Georgia Tech's University Center ofExcellence for Photovoltaics Research and Education (UCEP),established by the U.S. Department of Energy and supported bythe Sandia National Laboratories. Proponents of photovoltaics -- the direct conversion of sunlightinto electricity -- say it offers a clean, sustainablealternative to traditional energy sources that arenon-renewable, create pollution and contribute to globalwarming. Despite major strides made in the last two decades,photovoltaic-generated energy remains about four times moreexpensive than energy produced from fossil fuels. At GeorgiaTech, researchers are exploring several ways to reduce that costwithout sacrificing performance. "My goal is to reduce the cell processing time to the range of ahalf-hour to one hour," said Rohatgi, who also is UCEP'sdirector. "People have tried this, but when they reduced thetime, the efficiency took a dive." Rapid thermal processing utilizes incoherent radiation as asource of optical and thermal  energy.  The  interaction of high  energy  photons with matter leads to thermal andphotophysical effects that significantly decrease the activationenergy for various semiconductor processes like diffusion, thusreducing the processing time and temperature needed to fabricatea solar cell. Conventional furnace processing lacks these highenergy photons and requires greater thermal cycle time andtemperature. Georgia Tech's rapid thermal process has three steps:  athree-minute rapid thermal diffusion that simultaneously formsthe front and back of a silicon solar cell; a five-minute rapidthermal oxidation (RTO) for the front emitter surface; and theapplication of metal contacts by evaporations andphotolithography. In current industrial production,  front and back diffusions aredone separately. Each step takes one to three hours, and thecells must be cleaned between each procedure. The solar cellthen goes back into a high-temperature furnace for a processcalled passivation, in which an oxide is grown on the frontsurface of the cell. Although passivation improves performance, many manufacturersdelete it to save money and increase output. Georgia Tech's RTOprocess offers a time-saving way to include this step. Forming the metal contacts by evaporations and photolithographyaccounts for over 80 percent of Georgia Tech's RTP process.Although these procedures give good resolution and conductivity,Rohatgi said commercial manufacturers often use screen printing-- an alternative method for adding the metal contacts to asolar cell -- instead. Screen-printing is quicker but producesless efficient cells. Georgia Tech researchers successfully integrated screen printingwith RTP in 1996 and have since raised cell efficiency from 14.7percent to 16.3 percent. They hope to increase it to 18 percent-- the same level already reached for cells produced by RTP andphotolithography -- with further modifications. These includeadding rapid thermal oxidation, a screen-printed aluminum backsurface field (to prevent the loss of light-generated carriersto recombination on the back), and surface texturing (to reducethe amount of light reflected off the front surface and trapmore light into the cell). "Today, industrial cells made with crystalline silicon are inthe range of 11 to 15 percent," Rohatgi said. " If we succeed inwhat we're doing, we will end up making cells that are close to18 percent, in less than one-half to one-third of the time." For the paper presented in Barcelona, researchers also usedmodeling and analysis to show how these same modifications couldimprove cells produced by RTP and photolithography. In lateJune, they produced a solar cell with 19 percent efficiency,which is the highest rating ever achieved with a low-cost, rapid(non-furnace) process. They'll release details this fall at the26th IEEE Photovoltaics Specialists Conference to be held inAnaheim, Calif. The key to transferring this technology to industry, Rohatgisaid, is developing a batch or continuous-processing machine tomake multiple cells, perhaps 500 to 1,000 an hour. Researchersare perfecting their techniques on machines that produce onlyone cell at a time, and they also work with cells that are 4square centimeters. The industry standard size is 100 squarecentimeters. One manufacturer recently developed RTP machines that can handlenine 100-square-centimeter cells at once, but Georgia Techresearchers are collaborating with partners in industry,government and other universities to build a machine that canincrease the output further. ### Georgia Institute of TechnologyResearch Communications Office223 Centennial Research BuildingAtlanta, Georgia 30332-0828 MEDIA RELATIONS CONTACTS: Amanda Crowell (404-894-6980) or John Toon (404-894-6986); Fax (404-894-6983); Internet:  or TECHNICAL CONTACTS: Dr. Ajeet Rohatgi(404-894-7692); Internet: VISUALS: Color slides of Dr. Rohatgi demonstrating the new process and a close-up of the cell produced.
--------
544-> Dealing With The Terrorist Threat: World's Top Bomb Squads Get 'Mitts-On' Training At Sandia's Operation Albuquerque
Disabling sophisticated bombs without getting hurt is what a small team of researchers at Sandia National Laboratories knows how to do best. Now Sandia is sharing its technology and expertise in the occult art of bomb disablement with members of the world's most elite bomb squads during an eight- day, hands-on training conference in Albuquerque. Operation Albuquerque '97, as the event is called, focuses on the science and methodology of bomb disablement, with emphasis on emerging technologies that keep "bomb techs" out of harm's way as they protect the public from criminals and terrorists whose devices grow more sophisticated and dangerous every day. Only members of the most advanced bomb squads are invited to participate. Sandia hosted the first Operation Albuquerque in 1994 after Chris Cherry of Sandia's Explosives Applications Department recognized a need to put tomorrow's bomb disablement technologies into the arsenals of the nation's busiest bomb squads. The first event received wide acclaim from its participants. This is the third Operation Albuquerque, and the list of invitees has become more cosmopolitan. Operation Albuquerque '97 is expected to include 48 bomb techs representing the police departments of major U.S. cities like New York, Chicago, Atlanta, Houston, and Los Angeles; state police departments; federal law enforcement agencies including the FBI and Secret Service; and anti-terrorist and law enforcement agencies from England, the Republic of Ireland, Canada, Norway, Germany, and Australia (host country for the 2000 Summer Olympic Games). Sandia, the Department of Energy, the National Institute of Justice, and the Albuquerque Police Department are sponsoring this year's event. To stay ahead of the increasingly sophisticated anti-tamper and explosives devices being encountered in the world today, Cherry and his team research and develop some of the world's most technically advanced and versatile "render- safe" technologies, along with reconnaissance technologies to help categorize complex, terrorist-type bombs and assess their potential threats remotely. Since 1992, Sandia has developed and licensed a family of bomb disablers for a variety of situations. Foremost among these is the Percussion Actuated Nonelectric Disrupter, which has become the primary tool used by bomb squads nationwide to disable conventional, handmade-type bombs remotely, says Cherry. The PAN Disrupter was instrumental in safely disabling numerous suspect devices in Atlanta during the '96 Summer Olympic Games. How Sandia's disrupters work cannot be disclosed for security reasons, but each is designed to disrupt a bomb's internal gadgetry so instantaneously that it never has a chance to detonate. During Operation Albuquerque, the PAN Disrupter and a variety of other Sandia disablers   with cryptic names like the "Black Box" and "Magic Cube"   will be deployed in realistic bomb disablement scenarios by small teams of bomb tech "players" as they practice using the technologies to defeat mock bombs, many of which are booby trapped or have small charges that go off if players accidentally trip the devices. "These aren't your run-of-the-mill pipe bombs," says Cherry. "The bomb techs who come here are concerned about more complex devices. Our goal is to give them the training they'll need to deal with the kinds of terrorist-type devices we think they'll encounter in the next 10 to 20 years." In past Operation Albuquerque scenarios, teams were dispatched to locate and defeat sophisticated bombs hidden in public places, such as at shopping malls and on the front seats of cars, and disable "body bombs" wired to hostages, for example. This year, participants will respond to more than 48 scenarios throughout Albuquerque. Following each round of scenarios, players and observers from Sandia and the FBI's Bomb Data Center will discuss and evaluate the teams' tactical approaches.
--------
545-> Prenatal Multivitamins Fail Industry Test For Folic Acid
BALTIMORE--Studies show that supplementing a mother's diet withfolic acid before and during pregnancy can reduce incidences ofneural tube birth defects in children. But researchers at theUniversity of Maryland School of Pharmacy, found poor folic aciddissolution in six prenatal prescription multivitamins theytested, raising questions as to whether or not absorption by thebody is complete. Stephen Hoag, Ph.D., assistant professor at the UM School ofPharmacy, says tests of nine prenatal prescription multivitaminsfound six products did not release at least 75 percent of theamount of folic acid listed on their labels in one hour, anindustry standard set in 1995. The report, written by Hoag and co-author Ralph Shangraw, Ph.D.,professor emeritus with the UM School of Pharmacy, and HanuRamachandruni, M.S., a graduate student in the pharmacy school,was published in the July-August issue of the Journal of theAmerican Pharmaceutical Association. "Typically vitamins, including folic acid, are more readilyabsorbed in the upper gastrointestinal tract, just beyond thestomach," says Hoag. "Not meeting the standard of dissolvingwithin an hour highlights a potential problem with theseproducts. The amount of folic acid available for optimalabsorption in the body could be inadequate." While dissolution of a substance does not guarantee absorption,the researchers say it is necessary for absorption to occur.Many of the products Hoag tested missed the minimum standard bya wide margin, two released less than 25 percent of the labeledquantity. Hoag and Shangraw say they will not name the products studiedbecause federal regulations and standards for nutritionalsupplements are changing and some manufacturers have improvedtheir products to insure proper dissolution before this researchwas published. The standards for folic acid dissolution aredeveloped by the United States Pharmacopeial Convention.Nutritional products meeting these standards can label theirproducts USP. "Folic acid is caught in evolving regulatory policies and isregulated by the FDA as a food, not a drug," says Shangraw."Only products that bear a health claim stating that increasedfolic acid intake before conception and during early pregnancyreduces the risk of having a baby with neural tube defects, arerequired to meet a USP folic acid dissolution standard. Althoughthe products tested contained 1 mg of folic acid, were clearlylabeled prenatal vitamins and sold by prescription only, theytechnically did not have to meet dissolution standards. It seemsreasonable that they should," says Shangraw. "For drugs it is standard to analyze blood levels to make surethe substance is absorbed. You must substantiate purity, safetyand efficacy with data in a drug application to the FDA. Butbecause nutritional supplements are regulated as a food, thestandards are different," says Hoag. "Scientifically we know about how drugs are absorbed by thebody, but there has been very little research intobioavailability from vitamin tablets or capsules," saysShangraw. Hoag and Shangraw say people should not stop taking theirvitamins. "Vitamins should preferably be taken with food andplenty of fluids. Any amount absorbed is beneficial, and no oneis sure what amount of folic acid is needed to reduce neuraltube defects," says Shangraw. -30-
--------
546-> Researchers Use Prehistoric Packrat Piddle To Refine Hydrologic Dating Techniques
LOS ALAMOS, N.M., July 24, 1997 - Researchers from Los Alamos National Laboratory, New Mexico Institute of Mining and Technology, and other organizations have discovered that packrats seem to save a little of everything - including clues in their urine that can help scientists more accurately determine the age of water and other materials. In a paper published today in the journal Science, Mitch Plummer, a researcher at New Mexico Institute of Mining and Technology, shows how he and colleagues from Los Alamos and other organizations used fossilized packrat urine from prehistoric dens to determine that deposition rates of chlorine-36 - a naturally occurring isotope of chlorine and an important chemical tag that can be used to determine the age of water - were substantially higher than previously thought for periods older than 11,000 years ago. In addition to giving researchers better data for dating hydrologic processes, the work also has helped Los Alamos scientists determine how water moves through Yucca Mountain, Nev., a proposed repository for high-level nuclear waste. Chlorine-36 is produced naturally in the stratosphere when atoms are bombarded by cosmic rays, high-energy particles that streak through space from beyond our solar system. This so-called cosmogenic production of chlorine-36 has varied over time due to fluctuations in the strength of Earth's magnetic field. When the field is weak, more cosmic rays can reach the upper atmosphere and more chlorine-36 is produced. Moreover, because Earth's magnetic field deflects cosmic rays toward the North and South Poles, chlorine-36 production rates decrease with distance away from the poles. Researchers can determine the rate at which chlorine-36 was deposited in the past by determining the ratio of chlorine-36 to regular chlorine atoms in materials that contain chlorine and then comparing that ratio to the age of the material. Plummer and his colleagues analyzed chlorine-36 to chlorine ratios in fossilized packrat dens from northwestern and southern Nevada. Packrat urine binds together the twigs, leaves, seeds, feces and other debris that the animals use to construct their dens, or middens. In desert areas, middens can be preserved for tens of thousands of years if protected from the elements by caves or rock overhangs. Packrats get their water by ingesting desert plants. The plants take in atmospheric chlorine-36 through rainfall. Consequently, packrat urine is a good indicator of chlorine-36 levels and can be used to help determine deposition rates of the cosmogenic isotope. To determine the age of the urine, Plummer and his colleagues were able to take packrat midden debris such as leaves and twigs and determine their age through carbon-14 dating - useful for dating organic materials up to 40,000 years old. Plummer and his colleagues were able to determine that the rates at which chlorine-36 was deposited at mid-latitudes during periods older than 11,000 years ago were nearly twice as high as previously thought. "One explanation for why chlorine-36 levels are higher during the period beyond 11,000 years ago is because of the position of the jet stream during the last glacial period," said Jake Turin, co-author of the paper and a researcher in Los Alamos' Environmental Science and Waste Technology Group. "In order for stratospheric chlorine-36 to be deposited on Earth's surface, it must enter the troposphere where it can be washed out of the atmosphere in rain. Mixing of the stratosphere and troposphere occurs most strongly at the jet stream. Apparently during this period, the jet stream had moved southward and this could account for the increased levels of chlorine-36 deposited at mid-latitude." Global climate change, then, could explain the larger-than-previously-expected levels of chlorine-36, levels higher than can be explained by variations in Earth's magnetic field, he said. June Fabryka-Martin, co-author and a researcher in Los Alamos' Environmental Science and Waste Technology Group, said the research has helped Los Alamos researchers working on the Yucca Mountain Site Characterization Project to better understand the hydrology of the mountain. Fabryka-Martin and her colleagues are using cosmogenic isotopes and computer models to understand how water moves through the rock layers that make up Yucca Mountain. Los Alamos researchers are using naturally occurring chlorine-36 and man-made chlorine-36 - referred to as "bomb-pulse" chlorine-36 - to identify paths through which water can flow into Yucca Mountain. The worldwide concentration of chlorine-36 substantially increased during atmospheric nuclear weapons tests conducted in the Pacific about 40 years ago, creating a unique bomb-pulse signature that has elevated levels of chlorine-36. Hence, water with the bomb-pulse signature is less than 50 years old. During Yucca Mountain site characterization work, Fabryka-Martin and her colleagues collected subsurface samples along a tunnel route that starts at the surface of Yucca Mountain and declines at a shallow grade to a depth of 200 to 300 meters below the surface. The 25-foot-diameter tunnel is part of the Exploratory Studies Facility in the mountain. They looked for samples with chlorine-36 levels that were higher than natural background levels. Elevated levels of chlorine-36 in samples could indicate the presence of bomb-pulse chlorine-36. Some of the samples had chlorine-36 levels that were lower than the bomb-pulse signature levels, but were higher than previously estimated background levels. These samples puzzled the scientists. However, since the packrat midden samples indicate that background levels of chlorine-36 for periods older than 11,000 years ago were more than twice as high as original background estimates, Fabryka-Martin now has a plausible explanation for the samples that didn't quite fit the bomb-pulse signatures, but didn't quite match the previously believed background-level signatures, either. Los Alamos National Laboratory is operated by the University of California for the U.S. Department of Energy.
--------
547-> Endocrine Disrupters: Dioxin Causes Reproductive System Defects
A toxic chemical that lurks in the environment for years causes a vaginal defect in unborn rats. The abnormality is a web of tissue that partially obstructs the vaginal opening and may impair the rats’ ability to reproduce. "If dioxin does that, what else might it be doing? Is it affecting the reproductive health of human beings?"  said Dr. Mary Dienhart,  a reproductive biologist from the University of Maryland School of Medicine. She presented research findings on August 5 to the Society for the Study of Reproduction annual meeting in Portland, Oregon. Dienhart is a member of a research team headed by Dr. Anne N. Hirshfield, professor of anatomy and neurobiology at the UM medical school. Working with Dr. Richard Peterson at the University of Wisconsin, they examined the offspring of pregnant laboratory rodents exposed to single doses of dioxin, a highly toxic chlorinated byproduct from the bleaching of pulp to make paper. It also is produced by many incineration processes. The dose was 1,000 times that of the typical environmental exposure of people in industrialized countries. Within less than a week after exposure, three out of four of the unborn female rats had developed the vaginal defect. The toxic chemical, known to be a disrupter of the endocrine system, persists in the environment. It enters the food chain and is accumulated in livestock and fish, where it is stored in fat, which is the major route of human exposure. Although the mechanism is not known, dioxin is known to cause changes in hormones and growth factors that could have profound effects on the growth and development of the reproductive system. "Hormones are signaling molecules; they tell genes when to turn on and turn off," Dienhart explained. "Development is a complex genetic program. If you interfere with it anywhere along the line, you could cause an entire cascade of events that could adversely affect reproductive health." Next, the Maryland researchers want to look at the molecular mechanism underlying the development of the vaginal defect, to determine if it is interfering with cell formation or programmed cell death. Their study of the developmental effects of dioxin was funded in part by the Bressler Foundation and the National Institutes of Health.  
--------
548-> World's Most Powerful Telescopes Team Up With A Lens In Nature To Discover Farthest Galaxy In The Universe
July 30, 1997 Doug IsbellHeadquarters, Washington, DC              (Phone:  202/358-1547) Tammy JonesGoddard Space Flight Center, Greenbelt, MD(Phone:  301/286-5566) Ray VillardSpace Telescope Science Institute, Baltimore, MD(Phone:  410/338-4514) Andrew PeralaW.M. Keck Observatory, Kamuela, HI(Phone:  808/885-7887) RELEASE:  97-162 WORLD'S MOST POWERFUL TELESCOPES TEAM UP WITH A LENS IN NATURE TO DISCOVER FARTHEST GALAXY IN THE UNIVERSE An international team of astronomers has discovered the most distant galaxy found in the universe to date, by combining the unique sharpness of the images from NASA's Hubble Space Telescope with the light-collecting power of the W. M. Keck Telescopes -- with an added boost from a gravitational lens in space. The results show the young galaxy is as far as 13 billion light years from us, based on an estimated age for the universe of approximately 14 billion years.  This would place the galaxy far back in time during the "formative years" of galaxy birth and evolution, less than a billion years after the birth of the universe in the Big Bang. The detailed image shows that bright dense knots of massive stars power this object.  Due to the firestorm of starbirth within it, the galaxy is intrinsically one of  the brightest young galaxies in the universe, blazing with the brilliance of more than ten times our own Milky Way. "We are fascinated to be witnessing the very early stages of the construction of  what could well become a massive galaxy like our own Milky Way," says Garth Illingworth of the University of California, Santa Cruz.  "This object is a pathfinder for deciphering what is happening in young galaxies, and offers a rare glimpse of the powerful events that transpired during the formation of galaxies." "We were excited by the possibility that we may have found a unique example of a galaxy in formation at the time of the earliest quasars," said Marijn Franx of the University of Groningen in the Netherlands. Predicted by Einstein's theory of general relativity, gravitational lenses are collections of matter (such as clusters of galaxies) that are so massive they warp space in their vicinity, allowing the light of even more-distant objects to curve around the central lens-mass and be seen from Earth as greatly magnified. The object is so far away, observing it in such detail would tax the capabilities of both Hubble and Keck without the magnification of the gravitational lens, provided by a foreground cluster of galaxies  that is much closer to us at five billion light-years. Due to a rare and fortunate alignment of the young galaxy behind the foreground cluster, astronomers gain a magnified view that is five to ten times better than Hubble alone can yield for an object at such a great distance.  A telltale sign of the lensing is the smearing of the remote galaxy's image into an arc-shape by the gravitational influence of the intervening galaxy cluster . The smeared image of the galaxy stood out because of its unusual reddish color.  "Such magnified galaxies had been observed before, but never with such a color.  The special color of the galaxy in the arc is due to absorption by the matter in the universe between us and the galaxy, and suggested to us that it was at a great distance," says Franx. The suspected remoteness of the lensed object was confirmed when the team of astronomers made spectroscopic observations with one of the twin 10-meter Keck telescopes on Mauna Kea, HI, to measure its redshift, and therefore its distance, based on the shifting of its light towards the red end of the visible light spectrum.  The resulting high redshift corresponds to a very early era when the universe was just beginning to form galaxies. Though candidates for still more distant objects have been proposed, they have not been confirmed spectroscopically.  The previous most-distant known object was the quasar PC1247+34. "Based on this image we can begin to make some conclusions about the early growth of galaxies," says Illingworth.  "The knots show that starbirth happens in very tiny regions compared with the size of the final  galaxy."  This helps clarify the astronomer's view of the formation of galaxies  as occurring  within a cauldron of hot gas, with knots of intense star formation, strong winds, and "mergers" -- collisions of the dense star-forming  knots. Using Keck's spectroscopic capabilities, the astronomers have also, for the first time, been able to measure the motions of the gas within such  a distant galaxy. The observations reveal gas flowing at nearly 500,000 miles per hour (200 km/sec), presumably accelerated by energy from supernova explosions going off like a string of firecrackers. "The strong winds that we observe suggest that galaxies may lose a lot of material when they are young and thereby enrich the empty space around them," says Franx.  "Many astronomers had speculated about the existence of such winds in such distant galaxies, and we now have an object where we can see them directly. It is striking that the most distant galaxy found to date is also the one that provides us the most detailed  picture of events in such distant galaxies." The Space Telescope Science Institute is operated by the Association of Universities for Research in Astronomy, Inc. (AURA) for NASA, under contract with the Goddard Space Flight Center, Greenbelt, MD.  The Hubble Space Telescope is a project of international cooperation between NASA and the European Space Agency (ESA).  The W.M. Keck observatory is operated by the University of California, the California Institute of Technology and NASA. - end - EDITOR'S NOTE:   Image files win GIF and JPEG format and captions may be accessed on the Internet via anonymous ftp from oposite.stsci.edu in /pubinfo GIF                JPEGGravitational Lens     gif/grlz492.gif    jpeg/grlz492.jpg Higher resolution digital versions (300 dpi JPEG) of the release photograph are available in  /pubinfo/hrtemp:97-25.jpg (color) and 97-25bw.jpg (black and white). GIF and JPEG images, captions and press release text are available via the World Wide Web at URL: http://oposite.stsci.edu/pubinfo/PR/97/25.htmland via links inhttp://oposite.stsci.edu/pubinfo/Latest.html    http://oposite.stsci.edu/pubinfo/Pictures.html
--------
549-> University Of Florida Surgeons Pioneer Procedure To Prevent Incontinence After Prostate Surgery
By Melanie Fridl Ross GAINESVILLE, Fla.---Using a technique akin to securing a hammock to a tree, UF surgeons have suspended the bladder within the abdomen to prevent urinary incontinence in men whose cancerous prostate glands have just been removed. Removal of the prostate, known as radical prostatectomy, is the established treatment for managing prostate cancer that has not spread. More than 300,000 patients were diagnosed with prostate cancer in 1996, said Dr. Perinchery Narayan, chairman of urology at UF's College of Medicine. Nearly half will undergo surgery. Incontinence plagues as many as 1 in 4 men after prostate surgery, in part because the bladder shifts to fill the 2- to 4-centimeter space left after the gland is extracted. "Normally we all exert tremendous pressure on the bladder when we cough, sneeze or bend over and straighten out, but there is equal pressure on the bladder neck," Narayan said. "When the neck of the bladder shifts slightly below the abdomen, as often happens after prostate surgery, the pressure of those activities gets transferred out, and patients may leak urine." Between 3 and 5 percent of patients will have incontinence so severe it requires them to wear pads. "The numbers are variable," Narayan said. "If you consider any incontinence at all, even a drop or two when the patient coughs or sneezes, the incidence may be as high as 25 percent of patients." Incontinence is more severe in patients older than  70 because their muscles are naturally weak. To combat the problem, UF surgeons have begun taking fibrous connective tissue from elsewhere in the body, wrapping it around the bladder and tying it to muscles lining the abdomen. The approach restores some of the normal anatomy and slightly compresses the neck of the bladder, said Narayan, who pioneered the 10-minute procedure a little more than a year ago. "A combination of a little compression and the sling effect lifting up the bladder prevents many patients from leaking urine," he said. "This appears to reduce the incidence and degree of incontinence. "Surgeons have tried a variety of techniques to prevent or correct incontinence," he added. "These include sparing some nerves that may be involved in maintaining continence and giving injections of collagen into the urethra. But still the problem continued. It's unpredictable prior to surgery as to who will develop incontinence. While the percentage with more severe problems may be low, these patients are very devastated by this problem." Furthermore, of the 30 men who have undergone the procedure, all were continent immediately after surgery, Narayan said. Normally, many patients experience temporary incontinence for up to three to six months after the operation. "The patients we've operated on have been really happy, and we've not seen other problems," said Narayan, who presented his findings at this year's American Urological Association meeting and continues to study and modify the procedure. "Over a year's follow-up, they are voiding well and are continent." --------------------------------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html
--------
550-> University of Florida Physicians Perform First "Mini" Bone Marrow Transplant
By Melanie Fridl RossShands Public Relations GAINESVILLE, Fla.---For what is thought to be the first time in Florida, University of Florida physicians have performed a "mini" bone marrow transplant using much less intensive chemotherapy and no radiation. The experimental procedure, performed at Shands at UF and reported at only four other centers worldwide, could be an alternative for thousands of cancer patients too old or too ill to withstand conventional transplantation. Larry Tucker, a 43-year-old Jacksonville resident fighting an aggressive form of lymphoma, was the recipient. Previous chemotherapy  failed to keep the disease in check. Doctors used potent drugs at half the usual doses to suppress his beleagured immune system, replacing it May 23 with powerful disease-fighting cells known as lymphocytes donated by his sister, said John Wingard, director of the bone marrow transplant program at Shands at UF. Tucker, who was discharged from the hospital June 20, will return as needed for repeated infusions of those cells. Physicians hope they will be the foundation for a new, more robust immune system. "In the past, we have relied mostly on the "atom bomb" approach to treating cancer -- blasting the tumor with drugs and radiation treatment," Wingard said. "We are calling this a "kinder and gentler" transplant. With this new procedure, we are trying to exploit the new immune system of the donor to fight against the cancer. "There are a number of patients who could potentially benefit from a bone marrow transplantation, but either because of their age or other illnesses they are excluded -- physicians fear aggressive regimens will be too tough and too toxic for them to endure," he added. In Florida, the situation is complicated by an aging population. Up to now, older adults who contract cancer unresponsive to first-strike treatments have discovered they have few options. Meanwhile, diseases like leukemia primarily strike the elderly -- the average age at diagnosis is 64, Wingard said. "Most patients who benefit from the current, most aggressive forms of treatment are very young," said Fred Weeks, a clinical fellow in medical oncology at UF's College of Medicine. "This is something we can offer the older patient with leukemia, particularly elderly patients with liver, heart or kidney disease who otherwise couldn't withstand high-dose chemotherapy. It's a very different way of thinking." In Tucker's case, physicians feared he would not tolerate a traditional transplant because he also has hepatitis, a lung infection and impaired lung function from previous chemotherapy treatments. Early tests show the transplant successfully took. Time will tell whether it is effective against the cancer. In recent years, physicians' understanding of the immune system has evolved. "We used to think of cancer to be like an infectious disease entity where we had to kill off every last cell up front," Weeks said. "But what we've seen with this approach is that even if people have relapsed we might be able to bolster their immune system with donor cells and eventually get them into remission. "The only way that could work, especially given the small number of lymphocytes from the donor -- about the amount in a pint of blood -- is that the immune system is a lot more powerful than we ever gave it credit." The novel treatment also is offered at the M.D. Anderson Cancer Center in Houston, and medical centers in Singapore, Israel and Italy. "We don't know ultimately if this is going to work; that's what we aim to find out," Wingard said. "But our study may show this to be very suitable for the large elderly population we have here in Florida." ---------------------------------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html
--------
551-> TB Prophylaxis Unnecessary in HIV-Infected People with Anergy, Study Suggests
HIV-infected patients at high risk for tuberculosis (TB) but without confirmed TB infection do not benefit from preventive treatment with a front-line TB drug, a study supported by the National Institute of Allergy and Infectious Diseases (NIAID) has found.  The study is reported in the July 31, 1997 issue of The New England Journal of Medicine. "Clinicians who care for people with HIV/AIDS should take note of this important finding," says NIAID Director Anthony S. Fauci, M.D.  "This study suggests that we can make more efficient use of TB prevention resources by focusing on HIV-infected persons with known TB infection or who have close contact with another individual with active TB." Although only 10 percent of healthy people infected with TB bacteria ever develop active TB disease, co-infection with TB and HIV dramatically increases this risk.  A number of studies have shown that daily treatment with the antibiotic isoniazid (INH) significantly reduces TB disease risk in persons known to be co-infected with HIV and TB. The tuberculin skin test, which involves injecting TB-derived proteins below the skin, is the only method available for diagnosing inactive, or latent, TB infection.  Palpable swelling at the site of injection occurs in most TB-infected people with healthy immune systems.  However, HIV-infected people with suppressed immune systems often exhibit anergy, a reduced or absent reaction to skin tests for TB as well as other infections.  In such persons, TB infection can be masked by a false negative skin test.  As a precaution against activation of a possible latent TB infection, in 1991 the Centers for Disease Control and Prevention (CDC) suggested that INH preventive therapy be given to anergic HIV-infected individuals at high risk for TB.  High-risk individuals include those who belong to groups, such as homeless persons and those who inject drugs, in which the prevalence of TB infection is at least 10 percent. To determine the effectiveness of INH prophylaxis in this population, investigators in NIAID's Terry Beirn Community Programs for Clinical Research on AIDS (CPCRA) divided more than 500 high-risk HIV-infected people with anergy into groups that received either daily INH or placebo.  They found that the number of cases of active TB disease that developed in each group during the six-month study period did not differ significantly. "Our findings suggest that giving INH to people in this group is probably not warranted," says lead author Fred M. Gordin, M.D., of the Veterans Affairs Medical Center in Washington, D.C.  "It would be more appropriate to reserve INH preventive therapy for HIV-infected persons who have a prior history of a positive TB skin test or who have been in recent contact with someone with active TB disease." In fact, revised guidelines for preventing TB and other opportunistic infections in HIV-infected individuals, developed by the U.S. Public Health Service (PHS) and the Infectious Diseases Society of America, (IDSA) recommend just that: daily INH for persons with positive TB skin tests and for those in close contact with someone known to have active TB. The PHS/IDSA Working Group considered the findings of Dr. Gordin and his colleagues in developing the guidelines, which were published in the June 27, 1997 issue of Morbidity and Mortality Weekly Report. "The low rates of TB in both the treatment and placebo groups (three cases out of 260 patients, and six cases out of 257 patients, respectively)," says Dr. Gordin, "indicate that TB may be under much better control than in 1991 when the CDC suggested that INH preventive therapy might be useful in anergic patients." Dr. Gordin adds that in addition to saving the considerable programmatic costs associated with administering prophylactic INH to anergic HIV-infected individuals, a more selective use of INH would allow many people to avoid the known toxic side effects of INH.  For example, about 2 percent of persons who take INH develop hepatitis. The CPCRA is a network of primary care physicians and nurses who work with NIAID staff to design and conduct community-based clinical trials in patients with HIV disease and AIDS.  NIAID currently funds 15 CPCRA units in 14 cities throughout the United States. NIAID is a component of the National Institutes of Health (NIH).  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies.  NIH is an agency of the U.S. Department of Health and Human Services. ### NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.g 
--------
552-> NASA Announces Revised Plan For Mir Staffing
July 30, 1997 Michael BraukusHeadquarters, Washington, DCPhone:  (202/358-1979) Rob Navias/Ed CampionJohnson Space Center, Houston, TXPhone:  (281/483-5111) RELEASE:  97-163 NASA ANNOUNCES REVISED PLAN FOR MIR STAFFING Astronaut Wendy Lawrence (Cmdr, USN) has been replaced by her backup, Dr. David Wolf, for the next long duration stay on the Russian Mir space station. The change will enable Wolf to act as a backup crew member for spacewalks planned over the next several months to repair the damaged Spektr module on the Russian outpost. Lawrence does not fit in the Orlan suit which Russian cosmonauts use for spacewalk tasks and never underwent spacewalk training.  Wolf fits in the Orlan suit. Lawrence will continue training in the backup role according to normal procedures, in the unlikely event that she is needed. To enable Wolf to complete spacewalk training at the Gagarin Cosmonaut Training Center outside Moscow, the launch of Atlantis on the next Shuttle-Mir docking mission, STS-86 in September, could be delayed approximately 10 days.  Wolf had been scheduled for launch in January on STS-89 as the prime crew member for the final long duration increment on the Mir. NASA will be conducting their normal safety reviews in preparation for the transfer of a U.S. astronaut to Mir as was done before the last shuttle docking mission.  This review will imclude an evaluation of all the events that have occurred aboard the Mir since the last docking mission.  That final determination is expected at the conclusion of the formal U.S. review process at the shuttle program Flight Readiness Review in September. NASA and Russian space officials have discussed a variety of options for backup spacewalk capability since the Spektr module was damaged in the collision of a Progress resupply craft on June 25.  It was jointly agreed by both sides that it would be mutually beneficial to have all three crew members on the Mir qualified for spacewalks in the event additional assistance is needed from the U.S. astronaut on the station. "The Russians usually only fly two people trained for spacewalks," said Frank Culbertson, Manager of the Shuttle-Mir Phase One program.  "Because of the number and the nature of spacewalks under consideration by the Russians to repair the Spektr, we have discussed at length the advantage of having another astronaut qualified for those tasks." Culbertson added, "The fact that Wendy does not fit in an Orlan suit is not unusual.  When first selected to fly on the Mir, it was absolutely normal that she would not be considered to be a spacewalk qualified crew member.  Only because of subsequent events have requirements on board the Mir changed.  As a result, the joint decision was made to have all three crew members on board qualified to handle spacewalking tasks." Lawrence was informed of the decision by Culbertson, who is in Russia for meetings with Russian space officials. Because of her knowledge and experience with Mir systems and with crew transfer logistics for the Mir, NASA will fly Lawrence on STS-86 in September which will deliver Wolf to the Russian station.  Wolf is fully trained on both Mir and Soyuz capsule systems. - end -
--------
553-> Research Team Gains Important Insights Into Dengue Fever; Disease Afflicts Tens Of Millions Annually And It's Moving Into The U.S.
ANN ARBOR---Researchers have a new understanding of the way dengue virus binds to human cells---and how to stop it from doing so. The mosquito-borne dengue virus causes dengue fever, a severe flu-like illness which the World Health Organization (WHO) calls "the most important and rapidly increasing arbovirus in the world." The disease is prevalent in Third World tropical regions and spreading to sub-tropical developed countries, including the United States. WHO estimates that 50 million cases of dengue (pronounced DEN-ghee) fever occur worldwide each year, including a potentially deadly form of the disease called dengue hemorrhagic fever. Most cases occur in children. A team of researchers from the University of Michigan and the University of Iowa have gained new insights into the way the virus attacks at a cellular level. Their findings will be published in the August issue of Nature Medicine. "Dengue is a very significant world public health problem which has largely been ignored in the developed world," said Rory Marks, M.D., a member of the research team and an assistant professor of internal medicine at the U-M. "There's no specific treatment for infection and no way to prevent progression to the more deadly forms of the disease. No vaccine is available or likely to become available anytime soon. "Programs to control dengue infection have focused on killing the mosquito responsible for transmitting the virus to humans," Marks said. "These measures were very effective in the past but appear to have failed in recent years. The mosquitoes appear to be winning this latest war." New approaches for the control of dengue virus infection---specifically aimed at aspects of dengue virus infectivity other than mosquito control---are urgently needed, Marks said. The research team has discovered the mechanism the virus uses to attach itself to cells it will infect---and they can block it from doing so in laboratory tests. "It provides something to work from to develop a potential treatment," Marks said. Marks points out that dengue fever is: --An enormous social and economic burden throughout much of the developing world. --Spreading to the developed world, including frequent epidemics within U.S. territory, in Puerto Rico. --Increasingly prevalent after the withdrawal of mosquito control programs. "It is controversial whether wealthy nations, particularly the United States, have a continuing responsibility for controlling diseases that mainly threaten developing countries," Marks said. In earlier studies, the researchers concluded that a particular dengue virus protein---called the envelope protein---is responsible for binding the virus to cells targeted for infection. Their latest work takes that a step further by showing that dengue infection occurs when the virus binds to a type of sugar molecule they identified as heparan sulfate, which is found on the surface of the target cell. Marks and his colleagues also prevented that binding from occurring---and inhibited the infection---through the use of a drug called Suramin, chosen because it mimics the structure of heparan sulfate. It's questionable whether Suramin ultimately will be used to treat dengue infections, Marks said. This, however, is the first demonstration that a pharmaceutical can effectively prevent infection by dengue virus, and it provides a basis for screening related compounds which may inhibit the virus safely and effectively. Dengue virus is one of a large family of viruses, called flaviviruses, many of which cause serious human diseases. These include yellow fever and hepatitis C viruses. Most flaviviruses have similar envelope proteins, and it is expected that they share the same basic mechanism for binding to cells. "We expect our work with dengue virus to also hold true for these other viruses," Marks said. # # # # # # Background on dengue fever from the World Health Organization --Dengue fever is a severe flu-like illness spread by mosquitoes. It's symptoms include fever, intense headache and eye pain, rash, diarrhea, and pain in the muscles and joints. There is no cure, but recovery typically is complete within 10 days. It is estimated that dengue fever afflicts 50 million people---mostly children---each year. --Dengue hemorrhagic fever (DHF) is a potentially deadly form of the infection. It can cause internal bleeding, circulatory failure, coma, and shock. An estimated half-million patients require hospitalization for DHF each year, of which 25,000 die. There is no cure, but basic medical care saves most patients. --The prevalence of dengue virus infection has increased dramatically in recent years. It is endemic in more than 100 countries in Africa, the Americas, the eastern Mediterranean, southeast Asia, and the western Pacific. Prior to 1970 , only nine countries had experienced epidemics of dengue hemorrhagic fever. By 1995, that number had grown to at least 41. --Two-and-a-half billion people---40 percent of the Earth's population---are at risk of dengue infection. --In 1996, the WHO called the resurgence of infectious diseases, including dengue infection, a global crisis that is crippling the socio-economic development of many Third World countries. --In 1995, the worst dengue epidemic in Latin America and the Caribbean in more than a decade struck at least 14 countries, causing more than 200,000 dengue fever cases and almost 6,000 cases of dengue hemorrhagic fever. --That same year, health officials confirmed the first case of dengue fever contracted from within the continental United States in a decade---in Hidalgo, Texas, with 30 additional cases later found in the same region. Sources of additional information Centers for Disease Control, Dengue Branch, Division of Vector-Borne Infectious Diseases, National Center for Infectious Diseases, San Juan, Puerto Rico; 809-766-5181. The CDC also operates the following dengue home pages: http://www.cdc.gov/incdod/EID/vol1no2/gubler.htm http://www.cdc.gov/incdod/publications/brochures/deng_q&a.htm World Health Organization, Division of Control of Tropical Diseases, Geneva, Switzerland; 4122-791-3221. WHO's dengue home page is at http://www.who.ch/programmes/ctd/diseases/deng/dengmain.htm
--------
554-> Working Full Time Does Not Deter Breast-Feeding
 UF RESEARCHER: WORKING FULL TIME DOES NOT DETER BREAST-FEEDING MOTHERS July 31, 1997	Writer: Cathy Keen	Source: Teresa Smith	(910) 777-3957 GAINESVILLE --- Women who return to the workplace after having babies are just as likely to breast-feed as their counterparts who stay home, a new University of Florida study finds. "Women who make it a priority to pursue careers in addition to motherhood are often well-educated, and we know that breast-feeding rates go up with higher education levels," said Teresa Smith, who did the research for her doctoral dissertation in sociology at UF. Smith asked 150 mothers who had just given birth at Forsyth Memorial Hospital in Winston-Salem, N.C., whether they planned to breast-feed or bottle-feed their infants. Sixty- one percent of the women expecting to work full time in the next few months intended to breast-feed, compared with 50 percent of those returning part time and 54 percent of those staying home. Breast-feeding rates were even higher for women who were the family's primary breadwinner or who shared this role with their husbands or partners. Seventy-eight percent of these mothers breast-fed, the study found. "Women with careers that allow them to be the primary earners in a household are probably especially well-educated and likely to have careers as opposed to jobs," she said. World Breast-Feeding Week is Aug. 1-7. Until now, little has been known how labor force participation affects breast-feeding, Smith said. "The lack of studies is surprising, considering that the recent dramatic increase in the number of mothers of small children in the work force has coincided with a decline in breast-feeding rates," she said. From a post-World War II low of less than 20 percent, the proportion of breast-feeding women in the United States rose dramatically between 1960 and the mid ‘80s to 60 percent of all mothers being discharged from the hospital, Smith said. However, by 1989, the share had dropped to 52 percent, she said. The UF study found women most likely to breast-feed were white, older, better educated and married or living with a partner. Women whose mothers supported breast-feeding chose that method 97 percent of the time, and women whose husbands or partners approved chose breast-feeding 84 percent of the time, Smith said. "Interestingly, living with a partner made a big difference," she said. "Women who were married or living with a man were much more likely to breast-feed than single women, even if the single woman had a partner. In fact, women who lived with their partners were more than twice as likely to breast-feed as those not living with a partner. Three-quarters of the women who selected breast-feeding gave their baby's health as the primary reason, while bottle-feeding mothers citied the convenience, Smith said. "With the benefits of breast-feeding so well-known, I wondered why women would choose a method that is second-best," she said. "I couldn't help but question whether our cultural views of the breast as primarily a sexual organ to fulfill men's pleasure are a factor." Women who have been strongly socialized to value breast-feeding, particularly if they were breast-fed themselves, would probably be less likely to see the breast as exclusively male territory and would be less likely to seek male permission to use their breasts to nourish a child, she said. Research has shown that human milk contains the best mix of proteins, lipids and other nutrients for developing infants, Smith said. Studies find that breast-fed infants have lower mortality rates, fewer ear infections and allergies and less gastro-intestinal illness than bottle-fed babies, she said. Smith would like to see breast-feeding promoted in public education campaigns, much like those for childhood immunizations and use of child safety seats in cars. But, she said, prospective parents interested in breast-feeding should learn about its value well before the mother gives birth. In the UF study, more than one-third of the mothers who chose breast-feeding made the decision before they became pregnant. -30- Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-90  Smith asked 150 mothers who had just given birth at Forsyth Memorial Hospital in Winston-Salem, N.C., whether they planned to breast-feed or bottle-feed their infants. Sixty- one percent of the women expecting to work full time in the next few months intended to breast-feed, compared with 50 percent of those returning part time and 54 percent of those staying home. Breast-feeding rates were even higher for women who were the family's primary breadwinner or who shared this role with their husbands or partners. Seventy-eight percent of these mothers breast-fed, the study found. "Women with careers that allow them to be the primary earners in a household are probably especially well-educated and likely to have careers as opposed to jobs," she said. World Breast-Feeding Week is Aug. 1-7. Until now, little has been known how labor force participation affects breast-feeding, Smith said. "The lack of studies is surprising, considering that the recent dramatic increase in the number of mothers of small children in the work force has coincided with a decline in breast-feeding rates," she said. From a post-World War II low of less than 20 percent, the proportion of breast-feeding women in the United States rose dramatically between 1960 and the mid ‘80s to 60 percent of all mothers being discharged from the hospital, Smith said. However, by 1989, the share had dropped to 52 percent, she said. The UF study found women most likely to breast-feed were white, older, better educated and married or living with a partner. Women whose mothers supported breast-feeding chose that method 97 percent of the time, and women whose husbands or partners approved chose breast-feeding 84 percent of the time, Smith said. "Interestingly, living with a partner made a big difference," she said. "Women who were married or living with a man were much more likely to breast-feed than single women, even if the single woman had a partner. In fact, women who lived with their partners were more than twice as likely to breast-feed as those not living with a partner. Three-quarters of the women who selected breast-feeding gave their baby's health as the primary reason, while bottle-feeding mothers citied the convenience, Smith said. "With the benefits of breast-feeding so well-known, I wondered why women would choose a method that is second-best," she said. "I couldn't help but question whether our cultural views of the breast as primarily a sexual organ to fulfill men's pleasure are a factor." Women who have been strongly socialized to value breast-feeding, particularly if they were breast-fed themselves, would probably be less likely to see the breast as exclusively male territory and would be less likely to seek male permission to use their breasts to nourish a child, she said. Research has shown that human milk contains the best mix of proteins, lipids and other nutrients for developing infants, Smith said. Studies find that breast-fed infants have lower mortality rates, fewer ear infections and allergies and less gastro-intestinal illness than bottle-fed babies, she said. Smith would like to see breast-feeding promoted in public education campaigns, much like those for childhood immunizations and use of child safety seats in cars. But, she said, prospective parents interested in breast-feeding should learn about its value well before the mother gives birth. In the UF study, more than one-third of the mothers who chose breast-feeding made the decision before they became pregnant. -30- Color or black & white photo available with this story. For information, please call News & Public Affairs photography at (352) 392-9092.
--------
555-> Snap! Crackle! Pop! Electric bug zappers are useless for controlling mosquitoes, says pest expert
If mosquitoes and other insects are taking a bite out of your summer fun, don't bother with one of those electric bug zappers, says a University of Florida pest control expert. "They are a total waste of money. Bug zappers will not control mosquitoes or other biting insects such as horseflies, dogflies or deerflies," said Jonathan Day, associate professor of entomology with the UF's Institute of Food and Agricultural Sciences. "They simply do not work as advertised. In fact, bug zappers actually make things worse by attracting more mosquitoes into your yard, and they end up killing thousands of beneficial insects that don't bother people." He said the devices have been on the market for more than 30 years, and prices range from $30 to more than $200 for those sold in upscale stores and catalogs. They all have an ultraviolet light that attracts bugs to an electric grid that electrocutes them. "When people buy one of these bug zappers, they want to see and hear bugs fry. That's one of the great attractions of these things. You hang them in your yard, and they really put on a show. As the bugs hit the electric grid, they arc. There are a lot of light flashes and snap, crackle and pop sounds. That's what people get for their money." While the UV light in these bug zappers draws a wide range of insects, mosquitoes and other biting insects are more attracted to the carbon dioxide exhaled by people and pets. They're also attracted to carbon dioxide that is passed through human skin. "The main reason bug zappers don't work is that mosquitoes are extremely sensitive to carbon dioxide," Day said. "They see the UV light in your yard, but once they pick up even the slightest trace of carbon dioxide from people, they change direction and zero in on the source of that odor. They are expert at detecting carbon dioxide at levels as low as 50 parts per million." Some zappers claim to interrupt the mosquito breeding cycles, and others promise to control pests over an acre or more. Both of these claims also are false, Day said. Even some of the new electric bug zappers that have been fitted with an octenol packet -- which he described as "the latest marketing gimmick" -- are virtually useless for controlling mosquitoes. Compared to the powerful attraction carbon dioxide has for mosquitoes, octenol is a minor chemical insect attractant and will not improve the overall performance or effectiveness of the device. Day said tests at the UF/IFAS Florida Medical Entomology Laboratory in Vero Beach show that thousands of beneficial insects -- not mosquitoes -- are the main victims of the electric devices. Out of some 10,000 insects destroyed by one bug zapper during a one-night test period, only eight were mosquitoes. He estimates 71 billion nontarget insects are zapped by these devices across the nation every year. Most are beneficial beetles, moths, ants and midges along with parasitic wasps that control other insect pests. "Sure, some people say the only good bug is dead bug, but they don't understand the relationship of insects to the overall ecosystem," Day said. "Whether it's for pollination or food for birds and other vertebrates, the vast majority of insects are beneficial. We would be in bad shape if we killed all of our insects." To ward off mosquitoes and other biting insects in the yard, Day recommends using an insect repellent containing an active ingredient called deet. He said it's the most effective repellent developed in the past 40 years. Wearing protective clothing or simply going indoors also are options for battling pesky insects. Since mosquitoes breed in standing water, Day recommends emptying bird baths, kiddy swimming pools and other water sources in your yard or adding a briquette with altocid to kill mosquito larvae. Neighborhood spraying programs by city or county governments produce temporary relief from mosquitoes, usually less than 24 hours, he said. Day also discounted the value and effectiveness of various ultrasonic devices. "There are ultrasonic devices to control or repel everything from cockroaches to rats, and none of them work. They're one of the biggest rip-offs on the market," he said. And, he added, citronella plants have no repellant benefit. "While citronella oil is a repellant, it must be reapplied frequently," he said. "Citronella candles contain the oil in the wax. As the wax burns off, citronella is released in the smoke. However, in order to derive any benefit from citronella candles, you have to stand in the smoke." Andrew Myers, vice president of administration for north Palm Beach-based Deejay Corporation, which manufactures and markets electric bug zappers under the Stinger brand name, said they stand by all the advertising claims on the box of their product.
--------
556-> Launch Of Ocean-Viewing Sensor Set For August 1
David E. SteitzHeadquarters, Washington, DC                     July 29, 1997(Phone: 202/358-1730) Allen KenitzerGoddard Space Flight Center, Greenbelt, MD(Phone:  301/286-8955) RELEASE:  97-161 LAUNCH OF OCEAN-VIEWING SENSOR SET FOR AUGUST 1 The launch of the Sea-viewing Wide Field-of-View Sensor (SeaWiFS), onboard the Orbital Sciences Corporation (OSC), Dulles, VA, SeaStar spacecraft, is scheduled for Aug. 1, 1997, from Vandenberg Air Force Base, CA.  The launch window opens at 4:17 p.m. EDT (1:17 p.m. PDT), with a ten-minute window available. The SeaWiFS project is part of NASA's Mission to Planet EarthEnterprise, a long-term, coordinated research effort to study the Earthas a global system.  Using the unique perspective available from space, NASA is observing, monitoring and assessing large-scale environmental processes, such as the oceans' productivity, focusing on climate change.  In line with Mission to Planet Earth's commercial strategy, government-industry partnerships such as SeaStar provide NASA with needed data and may lead to practical commercial data use such as the development of fishing maps and estimation of crop yields for farmers and commodities markets. "We're looking forward to this upcoming launch," said Dr. Mary Cleave, SeaWiFS Project Manager, at NASA's Goddard Space Flight Center, Greenbelt, MD.  "The data from SeaWiFS will be of great benefit to our understanding of global carbon cycling." Understanding the role of the oceans in the global carbon cycle -- the process by which carbon travels through the Earth's atmosphere, oceans, land and living organisms -- is essential to understanding climate change.  Phytoplankton, microscopic marine plants, remove carbon dioxide from the atmosphere for internal use.   Scientists are eager to understand this exchange of carbon dioxide and the role it plays in the global climate. The SeaWiFS instrument will study the carbon cycle by observing the world's oceans from space and measuring "ocean color."  The color of most of the worldÕs oceans varies with the concentration of phytoplankton, which contain chlorophyll, a green pigment.  Near coastlines, the color of the ocean is affected by chlorophyll, dissolved organic material and suspended sediments from rivers and lagoons.  By observing the color of different parts of the oceans, scientists can measure the amount of these materials in ocean water. "A SeaWiFS launch at this time will be particularly important given what appears to be a very intense El Nino event developing in the equatorial Pacific Ocean," said Dr. Charles McClain, SeaWiFS Project Scientist, of Goddard.  "SeaWiFS data will allow us to assess the global impact of the El Nino on marine ecosystems, including coastal waters off the U.S. West Coast." SeaWiFS represents a new way of doing business for NASA.  Rather than building, launching, and controlling a satellite to study an important aspect of the Earth's environment, NASA will purchase commercially available data from a privately built satellite and use the data for environmental research. The SeaWiFS Team has developed, and will operate, a data system that will process, calibrate, validate, archive, and distribute SeaWiFS data for research.  All other aspects of the mission -- satellite construction, launch, command and control and tracking -- are the responsibility of OSC.  NASA has contracted with OSC to provide, for five years, the raw satellite data which will be used for research purposes.  OSC will own the data rights for operational and commercial purposes. OSC has integrated the SeaWiFS instrument, built by Hughes Electronics at the Santa Barbara Remote Sensing, Goleta, CA, into its SeaStar satellite and will market the data for commercial and operational use following launch. SeaWiFS will be launched from a modified Lockheed L-1011 aircraft aboard an OSC Pegasus XL expendable launch vehicle.  The Pegasus XL will be released from the L-1011 at an altitude of 39,000 feet over the Pacific Ocean.  Following payload separation, an onboard hydrazine propulsion system will then raise the spacecraft to its final 440-mile (705-kilometer) circular orbit within approximately 20 days after launch. SeaWiFS can view the world's oceans every two days.  Since oceans cover 70 percent of the Earth's surface, SeaWiFS will provide information on a large part of the global biosphere.  SeaWiFS also will provide important information for fisheries and coastal zone management.  SeaWiFS data, which also are useful for viewing plants on land, can be combined with plant productivity data from other satellites, such as Landsat and other operational weather satellites, to measure the role of the biosphere in the total global carbon exchange. NASA's Mission to Planet Earth Program Office, located at Goddard, manages the SeaWiFS contract and is developing and will operate the research data system for NASA's Office of Mission to Planet Earth, Washington, DC. -end-
--------
557-> Second U.S. Space Station Component Begins Launch Preparations
Michael BraukusHeadquarters, Washington, DC                         July 25, 1997(Phone:  202/358-1979) James HartsfieldJohnson Space Center, Houston, TX(Phone:  281/483-5111) George DillerKennedy Space Center, FL(Phone:  407/867-2468) RELEASE:  97-160 SECOND U.S. SPACE STATION COMPONENT BEGINS LAUNCH PREPARATIONS The first of two pressurized mating adapters for the International Space Station arrived today at the Kennedy Space Center, FL, from manufacturer McDonnell Douglas in Huntington Beach, CA. A pressurized mating adapter is a cone-shaped connector that will be attached to Node-1, the space station's structural building block, during ground processing in Kennedy's Space Station Processing Facility.  Node-1 with the adapter attached will be the first element of the Station to be launched aboard the Space Shuttle in July 1998. The mating adapter will be the connection point between Node-1 and the U.S. financed, Russian-built Functional Cargo Block, which will be launched from Russia as the first Station element to be placed into orbit.  The adapter will house Space Station computers and various electrical support equipment and eventually will serve as the passageway for astronauts between the node and the cargo block. "PMA-1 brings with it the computers that are the intelligence for the node," said Glenn Snyder, Space Shuttle mission STS-88 payload manager.  "We're looking forward to testing with those computers." For processing at Kennedy, the adapter will undergo initial acceptance testing.  Then, in early September, it will be mated to Node-1 and a series of integrated tests will be conducted. "We're pleased that the first mating adapter is now at Kennedy," added John Elbon, test integration leader for McDonnell Douglas.  "It is the next of the three elements of flight hardware necessary for the STS-88 mission." The second adapter, the final element of the STS-88 mission, is expected to arrive at Kennedy this October.  It also will be attached to Node-1 in the processing facility.  This second adapter will serve as a Space Shuttle docking port during the construction and resupply of the Space Station. The asymmetrical open-ended cone-shaped pressurized mating adapters are about seven feet long, five feet in diameter at one end and nine feet in diameter at the other.  Each adapter consists of five individually machined and welded aluminum ring forgings, thermal insulation blankets and 52 fittings for electrical connections.  The outer covering is a double-wall aluminum sheet to protect the adapters from strikes by space particles. Space Shuttle Endeavour, carrying Node-1 with the two attached adapters, is targeted for launch in July 1998, approximately two weeks after the Functional Cargo Block is launched from Russia. -end-
--------
558-> Genetically Engineering Longer-Lasting Antibodies Could Lead To Better Therapeutic Drugs
DALLAS -- July 25, 1997 -- Delivering drugs to fetuses andfighting such diseases as cancer and autoimmunity may be greatlyenhanced by altering a common antibody so that it stays in theblood stream longer, according to researchers at UT SouthwesternMedical Center at Dallas. By taking a portion of the natural antibody IgG and usingprotein engineering techniques, the scientists found they couldisolate fragments that bound with higher affinity or force to the Fcreceptor, FcRn. This receptor is involved in regulating the levelof gamma globulin, the part of the blood containing mostantibodies, in many mammals. In rodents and humans, it also isbelieved to be part of the pathway that transfers antibodies acrossthe placenta from mother to child. The research, published in arecent issue of Nature Biotechnology, showed that manipulatingthe antibody extended its half-life in the circulation of mice. "We thought if we could increase the binding affinity of anIgG fragment for FcRn, then it would have a longer serumhalf-life than the endogenous (naturally occurring) IgGs," said Dr.E. Sally Ward, associate professor of microbiology and CancerImmunobiology Center researcher. "We mutated antibodyfragments called Fc fragments and selected ones that bound betterto FcRn." Antibodies are Y-shaped proteins with IgG being the mostcommon type. The long arm of IgG is the Fc fragment, which isthe non-antigen binding portion of the molecule and carries outtasks called effector functions. Because a very similar Fc receptor is found in humans,Ward said their research could be applicable to people. Since thealtered antibodies are more persistent in the blood, smalleramounts of therapeutic antibodies made with this technologywould be needed. Therefore, the necessity for repeated doseswould be reduced. This approach also could be used to isolatesmaller molecules that have high affinity for bonding to FcRn.These molecules could then be used to tag drugs. "If the drugs have a longer serum persistence, then it willbe cheaper and more economically attractive for patients," Wardsaid. "We also believe this tighter binding of the IgG fragment toFcRn will transfer antibody across the placenta moreefficiently." This means it may be possible to deliver therapeuticantibodies or drugs to fetuses in cases where the mothers have adisease such as AIDS, she said. The UT Southwestern investigators found that the mutantantibody fragment had a binding affinity for FcRn that is 3.5 timeshigher than the unaltered Fc fragment from which it was derived.In one strain of laboratory mouse, the amount of mutated antibodystill effectively circulating in the blood 20 days after injection ofIgG was four times greater than with the parent antibody. It wastwice as much in another strain. Other researchers involved in this study were Dr. VictorGhetie, associate professor of microbiology; Dr. Sergei Popov,assistant instructor of pharmacology; research fellows, JozefBorvak and Dr. Corneliu Medesan; former UT Southwesternresearch fellows  Caius Radu and Diana Matesoi; and Dr.Raimund Ober, a collaborator from The University of Texas atDallas. The study was funded by grants from the National Institutesof Health, the Welch Foundation and the Texas AdvancedResearch Program. ### This news release is available on our World Wide Web homepage at http://www.swmed.edu/news/newspubs.htm/
--------
559-> University Of Florida Orthopaedic Surgeons Test First Implant For Certain Knee Injuries
By Melanie Fridl RossShands Public Relations GAINESVILLE, Fla.---It's summer, and snow skiing is the furthest thing from most Floridians' minds. But Eric Bath can't stop thinking about his last dizzying run down a Colorado mountain. On his final day of vacation several months ago, Bath, of Gainesville, was racing to the bottom when he wiped out, injuring his right knee. "I went flying," he said. "Once I stopped rolling, I definitely knew I had popped something. I managed to get back to Gainesville, but by the time I got home, I was in a lot of pain and limping severely." Tests revealed he had a tear in the meniscus, a crescent-shaped shock absorber that prevents the ends of the bones forming the knee joint from rubbing directly against each other. Conventional arthroscopic surgery to remove the damaged portion would have spelled the end of his daily two-mile jogs and could have put him at risk for severe arthritis. Instead, Bath, 44, opted for an experimental procedure offered by University of Florida orthopaedic surgeons, who replaced the injured section with the first artificial mensicus replacement, made of cow collagen. "The collagen is organized to recreate the framework of a normal human meniscus," said Peter Indelicato, an orthopaedic surgeon at UF's College of Medicine and the study's principal investigator.  "We're studying whether the patient's own tissue will eventually grow and replace the bovine collagen and whether it will function normally at the end of that transformation process." Researchers are seeking approximately 200 patients at 12 medical centers nationwide, including the Cleveland Clinic, the Hospital for Special Surgery in New York, the University of Washington in Seattle and the Stedman Hawkins Clinic in Vail, Colo., where the research originated. The study is sponsored by ReGen Biologics Inc., of Redwood City, Calif. Study participants, ages 18 to 60, fall into two categories: those who have undergone partial removal of the meniscus but now complain of pain or discomfort in their knee, and those who have a torn meniscus and are facing surgery to remove it. They are randomly assigned to either receive the investigational implant or undergo traditional surgery to remove the meniscus. Following surgery, patients remain on crutches for six weeks and must undergo physical therapy. They will be tracked for at least two years. At the end of the first year, surgeons will perform arthroscopic surgery to view the implant and take tissue samples to assess whether the procedure has been effective. The meniscus is easily damaged with twisting or squatting, Indelicato said. Many times, a portion has to be removed in order to prevent further damage to the knee joint. As people age, the meniscus becomes more brittle, losing its elasticity. "At the age of 40 or 50, getting out of the car or squatting down to tie your shoe could be all that's necessary to tear the structure," said Indelicato, also team physician for the Florida Gators and former team physician for the Miami Dolphins. "After part of the meniscus has been removed, the knee becomes vulnerable to developing some arthritic changes," he added. "Anything that would increase the loading of the knee, such as a patient being overweight or the pounding of an intense jogging program, would accelerate this wearing out or arthritic process in the knee joint." Bath said if the implant doesn't work it will be removed. "I'm very physically active," he said. "That's why I wanted to go through this. I'm hoping the long-term benefits will outweigh any short-term inconvenience." ------------------------------------------------------------------ Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html
--------
560-> Ocean Fisheries Desperately Need New Management Structures
July 24, 1997 OCEAN FISHERIES DESPERATELY NEED NEW MANAGEMENT STRUCTURES While better scientific analyses may help reduce worldwideoverfishing and depletion of many ocean fish species, newmanagement systems must be instituted to shield global marinefisheries from the political pressures to over-fish,according to a team of scientists led by a researcher at theUniversity of California, Davis. In a paper appearing in the July 25 issue of the journalScience, the researchers suggest that the major cause ofoverfishing is political pressure to protect jobs and sustainshort-term profits by increasing the fish harvests.  Theeconomic justification for bigger harvests prevails, in part,because it is inherently difficult to predict future fishpopulations. "The challenge for the next century lies in crafting newlocal and regional institutions, not just in filling thescientific gaps," said Louis W. Botsford, a wildlife andfisheries biologist at UC Davis.  "The best hope for greatersustainability of fisheries is to insulate management frompressures for greater harvest, while attempting to reduceuncertainty through a comprehensive ecosystem view." Collaborating on the study with Botsford were Juan CarlosCastilla of the Pontificia Universidad Católica de Chile inSantiago, Chile, and Charles H. Peterson of the University ofNorth Carolina at Chapel Hill. Ocean fish provide an important source of food, accountingfor 19 percent of all animal protein eaten by humans.Furthermore, they are the basis for an industry thatemployees 200 million people worldwide and produces an annualcatch valued at $70 billion. But fisheries around the world, including many in the UnitedStates, are in trouble, note Botsford and colleagues.  Theypoint to a recent report by the United Nations Food andAgriculture Organization indicating that global fisheries inthe 1990s are leveling off at about 100 million tons caughtannually.  And nearly half of the individual commercial fishspecies are fully exploited, while another 22 percent areover-exploited.  Recent examples of overfishing include thecollapse of the cod and haddock populations off of the EastCoast of the United States and Canada. Perhaps this sorry state of affairs should come as nosurprise.  Marine ecosystems --ranging from coastal to deep-sea communities of fish, mammals, turtles, birds and plantlife -- are complex.  They are directly impacted not only byhuman enterprises, such as fishing and pollution-producingactivities, but also by large-scale fluctuations in weatherand climate.  Fisheries scientists have long been concernedwith annual changes in weather and physical oceanographicconditions, but in recent years they have come to realizethat periodic long-term changes also have profound influenceseven on fish stocks that are separated by great distances. One such example is the El Niño-Southern Oscillation, awarming of the waters in the eastern Pacific Ocean thatoccurs every five to 10 years.  (Scientists believe we are atthe beginning of another large El Niño.)  Another example isthe warming of waters off of Alaska in 1976, believed to havetriggered important biological changes that are still ineffect, including an increase in the Alaskan salmon catch anda drop in salmon catches from California waters. Clearly, the undersea worlds are a challenge to probe andeven more perplexing to wisely manage.  While betterunderstanding of the physical variabilities, such as thelarge-scale weather and climate shifts, will yield sounderinformation on which to base management decisions, thepolitical pressures on fisheries management still must bealleviated, Botsford stressed. "Most overfishing is due to the 'ratchet-effect,' whichoccurs when -- faced with the inherent uncertainties ofpredicting future fish populations -- fisheries managers bendto socio-political pressure to provide jobs and profits forthe fishing industry, leading to greater harvests of fishthan are prudent," he said. Structurally, fisheries management might be improved bygiving commercial fishers a greater vested interest in thelong-term health of the fisheries.  This could be done byoffering them individual transferable quotas or greaterinvolvement in fisheries management.  Botsford and colleaguesacknowledge that this would be more difficult at thecorporate level than in small-scale coastal fishingoperations.  It would be particularly difficult ininternational fisheries, where existing institutionalstructures and cultural differences don't encouragecooperation. The researchers suggest that several changes in the way marinefisheries are managed would improve sustainability, regardlessof improvements in marine science.  First, they urge adoptionof the precautionary approach to fisheries management, whichwould translate into lower levels of fish harvests unlessscientific evidence clearly demonstrates that higher catchrates are warranted. Secondly, Botsford and colleagues suggest establishing marinerefuges that are off-limits to fishing in order to protectportions of exploited fish populations and allow thosepopulations to rebuild themselves. And finally, they advocate more liberal use of closures andfishing moratoria to protect declining fish populations orstressed ecosystems before, instead of after, a fishpopulation collapses. The fisheries management study was funded by the PewCharitable Trust, the Center for Marine Conservation, theU.S. Global Ocean Ecosystems program and Sea Grant. Media contact:-- Louis Botsford, Wildlife, Fish and Conservation Biology,   (916) 752-6169-- Patricia Bailey, News Service, (916) 752-9843,   pjbailey@ucdavis.edu -------------------------------------------------More university news and an experts directory:http://www-news.ucdavis.edu/PubComm/-------------------------------------------------UC Davis News Service; Davis, California(916) 752-1930, newsservice@ucdavis.edu------------------------------------------------- 
--------
561-> Advanced Composition Explorer Set To Study Matter From Sun, Milky Way And Beyond
Donald Savage  Headquarters, Washington, DC                    July 23, 1997(Phone:  202/358-1547) Lynn JennerGoddard Space Flight Center, Greenbelt, MD(Phone:  301/286-0454) RELEASE:  97-157 ADVANCED COMPOSITION EXPLORER SET TO STUDY MATTER FROM SUN, MILKY WAY AND BEYOND The Earth is constantly being bombarded by a stream of accelerated particles arriving not only from the Sun, but also from interstellar and galactic sources.  The study of these energetic particles by NASA's Advanced Composition Explorer (ACE) observatory will contribute to the understanding of the formation and evolution of the solar system as well as the astrophysical processes involved. The space science observatory is scheduled for launch on a Delta II rocket at 10:39 a.m. EDT August 25, from Launch Complex 17at the Cape Canaveral Air Station, FL. "The Advanced Composition Explorer observatory is designed to sample the matter that comes near the Earth from the Sun, from the apparently, but not actually, empty space between the planets, and from the Milky Way galaxy beyond the solar system," said Don Margolies, ACE Mission Manager at NASA's Goddard Space Flight Center, Greenbelt, MD. "While previous missions have studied these particles, the instruments on ACE have a collecting power 10 to 1,000 times greater and will be at least 100 times more sensitive than anything we've ever flown," Margolies said.  "We will be able to study known phenomena in much greater detail than previously possible, and discover new ones to give us a better understanding of the interaction between the Sun, the Earth, and the galaxy." The Advanced Composition Explorer has six high-resolution particle detection sensors and three monitoring instruments.  It will sample low-energy particles of solar origin and high-energy galactic particles.  The observatory will be placed into an orbit at the L1 libration point, which is almost a million miles (or 1.5 million kilometers) away from the Earth, about 1/100 the distance from the Earth to the Sun. The ACE payload includes four brand-new, state-of-the-art spectrometers.  They are the Cosmic Ray Isotope Spectrometer; Solar Isotope Spectrometer; Solar Energetic Particle Ionic Charge Analyzer; Ultra-Low-Energy Isotope Spectrometer.  In addition, there are four spare instruments from other NASA missions that, with appropriate modifications, are being flown on ACE.  They are the Solar Wind Electron, Proton, and Alpha Monitor; Solar Wind Ionic Charge Spectrometer; Electron, Proton, and Alpha Monitor; and a Magnetometer.  An additional instrument, the Solar Wind Ion Mass Spectrometer, is a newly built copy of a previously flown instrument. Also onboard are two secondary instruments, the Spacecraft Loads and Acoustic Measurements, designed to measure spacecraft environments during the first five minutes of launch, and the Real Time Solar Wind experiment, which will provide real-time data to the National Oceanic and Atmospheric Administration (NOAA).  NASA and nine universities in the U.S. and Europe built the instruments. The ACE spacecraft's instruments and experiments will work together to add to our understanding of  solar events ranging from "solar storms" to the origin and evolution of solar and galactic matter. The scientific goal of the ACE mission is to measure accurately the composition of several different types of matter, including particles coming from the Sun, the very thin gas between the planets, the even thinner gas just outside the solar system, and matter from distant parts of the galaxy.  The particles that ACE measures are moving very fast, up to 3.5 million miles per hour, and are atomic and subatomic. ACE also has an Earth applications goal.  It will provide NOAA's Space Environment Center, Boulder, CO, with continuous real-time solar wind "space weather" information, which will give an advance warning (about one hour) of geomagnetic storms that can affect electric power grids, Earth-orbiting spacecraft, and radio communications on Earth. The 1,730-pound observatory was built by the Johns Hopkins Applied Physics Laboratory, Laurel, MD, where its instruments were integrated.  ACE was tested at the Applied Physics Laboratory and at Goddard. The science payload was provided under the direction of the Payload Management Office at the California Institute of Technology, Pasadena, CA.  Flight operations will be conducted from Goddard; the Science Center is located at Caltech.  The ACE mission is managed by the Explorer Program at Goddard for the Sun-Earth Connections Program in the Office of Space Science, NASA Headquarters, Washington, DC An ACE Project website can be found at the following URL: http://www.gsfc.nasa.gov/ace/ace.html - end -
--------
562-> New Aerospace Computer Will Revolutionize The Design And Construction Of Airplanes
Dwayne BrownHeadquarters, Washington, DC                     July 24, 1997(Phone:  202/358-1726) John BluckAmes Research Center, Moffett Field, CA(Phone:  415/604-5026) RELEASE:  97-158 NEW AEROSPACE COMPUTER WILL REVOLUTIONIZETHE DESIGN AND CONSTRUCTION OF AIRPLANES A NASA computer network tool promises great savings in time and money for airplane makers and the government by providing faster access to information to help shorten the aircraft design and test process by about 25 percent. Called "Darwin," the network will revolutionize the way airplanes are developed by using wind tunnels linked with computers that send nearly instant test results via a network to geographically separated companies and laboratories. Wind tunnels are chambers through which air flows during tests of airplane shapes.  In the tunnels, air is blown around airplane and rocket models to simulate flight.  "With Darwin, we're helping reduce the aerospace design cycle time by around a quarter, and we're providing information access to cut the number of independent design cycles," said Dr. David Korsmeyer, deputy project manager at NASA's Ames Research Center, Moffett Field, CA.  "Our purpose is to get results and data out of NASA wind tunnels faster.  Previously, such knowledge had to be derived by scientists and engineers in the days and months following wind tunnel tests," he said. The key to Darwin's success is its ability to funnel wind tunnel data into a server computer, and then send knowledge back to researchers in "near real time" -- within about 30 seconds to five minutes.  Darwin is similar to the Internet, but Darwin is not open to the public.  The system is able to link NASA, aerospace industry and academic centers that may be located thousands of miles from one another.  A computer program that many people use to browse the Internet from their home computers is used in the Darwin system. Pressure gauges, strain gauges and other instruments attached to the models take readings while air blows through wind tunnels during experiments.  Data streaming from the model instruments tell aerospace engineers how much lift, drag and maneuvering performance an airplane model can generate through different angles of flight, and at various speeds, altitudes and conditions. New knowledge about airplane designs gained during wind tunnel tests helps engineers to decide if their ideas are working, or if design changes must be made before expensive, full-size prototype airplanes are built. Aerospace models used in the tunnels often cost more than $1 million each because they must be exactly to scale, and they must be extensively instrumented.  Running a large wind tunnel can cost tens of thousands of dollars per hour, with the exact cost depending upon the tunnel, the number of personnel needed, as well as any special equipment required.  Engineers would prefer not to have to return to a tunnel for follow-up test cycles with modified airplane or spaceship models. "Engineers use supercomputers to try to predict how new designs will work before an airplane model is built.  That works fairly well for straight, level flight, but even that kind of analysis is not perfect.  What happens during take-off and landing is especially difficult to predict with supercomputers because air turbulence occurs.  The wind sneaks back around and does unexpected things," said Korsmeyer. "We're talking about eight-hour runs on the fastest computers on Earth to simulate wind flow over just a piece of the wing.  That's where wind tunnel testing comes in.  Testing a model in a wind tunnel, you get actual physics because you have real wind blowing over a wing," he explained. "Before we began to use large computer networks to deliver data, wind tunnel systems were very good at capturing data for later analysis, but they were not good at 'serving' the data," said Korsmeyer.  "Now, Darwin collects data, and it is translated into a useable form.  Darwin also can provide access to data for researchers where they want it.  The system can distribute data to many places at once, and it is secure," he added. "The kind of data Darwin can provide to researchers is in a standard format so people can easily understand the data.  In addition to the normal graphs and charts engineers use, they also can step through images like frames of a movie to see changes of colorized air pressure and wind speed.  You can see changes more easily than if you were to study each image individually," he said. -end- 
--------
563-> Computer Models Of The Heart Can Help Cure Cardiac Ills
THE JOHNS HOPKINS UNIVERSITYOFFICE OF NEWS AND INFORMATION3400 N. Charles StreetBaltimore, Maryland 21218-2692Phone: (410) 516-7160 / Fax (410) 516-5251 ---------------------------------------------------------------- July 25, 1997FOR IMMEDIATE RELEASECONTACT: Phil Sneidermanprs@jhu.edu COMPUTER MODELS OF THE HEART CAN HELP CURE CARDIAC ILLS The dog heart on Raimond Winslow's computer screen is beatingerratically. The diagnosis is severe arrhythmia, abnormal electrical activitythat could kill the dog within minutes. Winslow gave the dog thismalady by manipulating the numbers that created its heart -- athree-dimensional model that exists only inside the computer.Now, he changes a few numbers again, this time to adjust themicroscopic gates or ion channels that regulate electrical excitability incardiac cells. Moments later, the heart is beating in a slower, more regular fashion. For this computer-animated organ, "death" is no longer imminent. Human hearts can also benefit from this high-tech marriagebetween biology and computer technology, says Winslow, anassociate professor of biomedical engineering at The JohnsHopkins University. Using a highly detailed computer model thatmimics the way a heart works -- down to the sub-cellular level -- hestudies serious cardiac disorders and mathematically "tests" thedrugs that might cure them. He begins by translating the heart's physiological functions intonumeric formulas, using the latest data collected by biologists.Then, by making small changes in the model, he can see howcertain enzymes, proteins and other molecules make the heart beatproperly -- or improperly. Using this model, Winslow is looking for medicines that couldprolong the lives of millions of people suffering from congestiveheart failure. His experiments have already shown that certaindrugs used to control high blood pressure might also preventsudden cardiac death. Winslow and his key research partner, Denis Noble, have formed acompany, Physiome Sciences Inc., to pursue commercialapplications of this software and to market drug leads discoveredby the team. Noble, a professor at England's University of Oxford, developedthe first mathematical models of electrical activity in the heartmore than 30 years ago. By building on Noble's work and creatingeven more elaborate computer models, Winslow believes the team isbreaking important new ground. "Before our project," he says, "noone had ever simulated electrical arrhythmias in athree-dimensional model of the heart and then used it as avehicle for testing drug actions." In recent months, Winslow has discussed this research before TheInternational Union of The Physiological Society in St.Petersburg, Russia, and at a conference on Computational Biologyof the Heart in San Diego. His current model replicates a dogheart, which functions much like a human one. But Winslow says,"The methodology will also work with other organ systems andtissues." This technique -- using numerical models to study biologicalfunctions -- dates back to the early 1950s, when two Britishscientists used crude hand-cranking calculators to come up withmathematical equations representing the electrical activity of asquid's nerve. Today, advances on two scientific fronts have madethis area of research even more fruitful. First, biologists arecollecting far more detailed information about how cells, andeven genes, interact to determine a person's health. At the sametime, computer technology is much more powerful and accessible,making it easier for researchers to compile and manipulate thesecomplex findings. "There's just an explosion of cellular and molecular data on theproperties of heart tissue," Winslow says. "In a sense, themodels have not kept pace with this explosion of data, andthere's a real need to create ever more biophysically detailedmodels of individual heart cells that incorporate all of thisinformation." By using such computer models of the heart, Winslow says,pharmaceutical companies will be able to dramatically narrowtheir searches for life-saving medicines--and save millions ofdollars now spent on conventional trial-and-error methods. "Ifyou can tell a company to search for a drug that has a specificeffect on a particular ion channel," he says, "that's important,because once these companies know what kind of drug to look for,they have the technology to screen more than 10,000 compounds aday in an effort to find such a drug." This technique could also lead to breakthroughs involving otherorgans. "Models are tools for discovering the functions ofbiological mechanisms," Winslow says. "The approach can be usedbeyond just the heart. It could be applied to other diseases,other biological systems. We're using the heart as a firstexample, sort of a jumping-off point." Some of Winslow's computer simulations of electrical activity inthe heart can be found at the following World Wide Web address: http://www.bme.jhu.edu/~rwinslow   
--------
564-> Contaminants Found In Aleutian Otters, Eagle Eggs
Contact: Robert Irion (408) 459-2495; irion@ua.ucsc.edu RESEARCHERS FIND CONTAMINANTS IN SEA OTTERS ANDBALD EAGLE EGGS IN THE WESTERN ALEUTIAN ISLANDS * This news release is embargoed until Friday, July 25, 1997,when the Marine Pollution Bulletin will publish the research. SANTA CRUZ, CA--Remote islands of surreal beauty, the foggy, windswept Aleutians are thousands of miles from heavily populated areas. Even so, the islands harbor a nasty reminder of human activity: Sea otters and bald eagle eggs from the western Aleutians carry potentially harmful levels of DDT and other contaminants. A team led by scientists from the University of California, Santa Cruz, found that sea otters from the western Aleutians contained almost twice as much of the industrial compound PCB as otters from the central California coast, an area known to have agricultural and industrial contamination. The otters also carried almost 40 times more PCBs than otters from a relatively uncontaminated site in southeast Alaska. Such high PCB levels may have an insidious effect on the otters' health. Similarly high levels can cause reproductive failure in mink, a closely related species. Bald eagle eggs contained elevated levels of both DDT and PCB. DDT, known to thin the eggshells of birds of prey elsewhere, may harm these raptors as well: Eagles on the island with the highest levels of DDT are reproducing at half the rate of those on other islands. Although the researchers can't pinpoint the sources of the pollutants, their distribution patterns yield some clues. The PCBs may come from former military activity on some of the islands; the DDT could be windborne or waterborne contamination from agricultural use in Asia. "We expected the Aleutians would be very clean because it's a remote oceanic environment--that's why we picked it," said James Estes, a wildlife biologist with the U.S. Geological Survey and UC Santa Cruz. "We found these high levels in the Aleutian Islands, higher even than in California, so that was a big surprise. The levels of compounds in these animals are alarmingly high." Estes and several colleagues published their work in the current issue of Marine Pollution Bulletin. Coauthors are researchers Corinne Bacon and Walter Jarman of UCSC's Institute of Marine Sciences; Ross Norstrom of the Canadian Wildlife Service; and Robert Anthony and Keith Miles of the U.S. Geological Survey at Oregon State University and UC Davis, respectively. Sea otter populations are still recovering from intensive hunting in the 1700s and 1800s. Most otter populations in Alaska and the Aleutians are now growing at almost 20 percent per year, a healthy rate. In contrast, the California population is increasing at just 5 percent per year and is still listed under the Endangered Species Act as threatened. To investigate whether contaminants such as DDT and PCB are impeding the recovery of sea otter populations off California's Central Coast, the researchers compared contaminant levels in the livers of California sea otters to otters from sites believed to be clean. To test for pollutants, the team collected carcasses from beaches in central California and on the Aleutian island of Adak in 1991 and 1992. Alaskan Natives provided otter carcasses from southeast Alaska. Surprisingly, California's otters did not carry the highest amount of PCBs. That dubious honor went to the otters from Adak. Their livers harbored 309 parts per billion total PCBs, while California otters had 185 parts per billion, and those from southeast Alaska had only eight. Because they found no dead otters on the other Aleutian Islands, the scientists also collected bald eagle eggs that had failed to hatch. That analysis confirmed the PCB contamination in the western Aleutians, particularly on the islands of Adak, Amchitka, and Kiska. DDT also contaminated the eagle eggs, and it exhibited a striking trend: The further west the island, the more DDT. These patterns provide clues to the pollutants' origins. The PCBs may come from military operations: Eggs from the three islands with former military activity had four times more PCBs than eggs from Tanaga, the only island that has not been a military site. Since eggs from the more westerly islands have higher DDT levels, that subtance may come from Asia via wind and water currents. "Anytime you see DDT, it's a recent application, within the last few months or years," Jarman said. "One theory is that if they use a ton of it in China, we'll see it in the Aleutians." DDT also may come to the Aleutians via migratory animals, especially birds, Estes noted. Other studies also hint at trouble for the region's marine birds and mammals. Said Estes: "That whole North Pacific ecosystem is a worry because lots of things are declining--the Stellar sea lion, for instance. It raised the issue in our minds that maybe contaminants were playing some role." After the team completed its study, Estes discovered that otter populations on Adak are not faring as well as previously. With funding from the Department of the Navy, the team is starting a more detailed investigation of contamination levels in otters from the western Aleutians to southeast Alaska. Jarman said, "I expect there'll be hot spots and clean spots." ##### Editor's notes: You may reach the coauthors as follows:    Estes: (408) 459-2820 or jestes@cats.ucsc.edu (wildlife issues)Jarman: (801) 585-3082 or wjarman@egi.utah.edu (toxicology) Mari N. Jensen, a former intern in the UCSC Public Information Office, wrote this news release.
--------
565-> Known Tumor Suppressor Gene May Play A Role In Breast Cancer
July 22, 1997Contacts:Robert Irion, UC Santa Cruz: (408) 459-2495; irion@ua.ucsc.eduJulianne Remington, OHSU: (503) 494-8231; remingju@ohsu.edu KNOWN TUMOR SUPPRESSOR GENE MAY PLAY A ROLE INBREAST CANCER FOR IMMEDIATE RELEASE SANTA CRUZ, CA--A gene linked to the most common abdominal cancer in children also may contribute to the development of breast cancer, according to a study at the University of California, Santa Cruz, and Oregon Health Sciences University. A team led by UC Santa Cruz biologist Gary Silberstein found evidence that a gene called WT1, which prevents abnormal cell division in the kidney, also is active in healthy breast tissues. However, the gene was silent, or nearly so, in two-thirds of the cancerous breast tissues examined by the team. These tissues included tumors in their earliest stages of growth--just a few cells beginning to run amok. The study is the first to make a connection between breast cancer and WT1, so named because of its role in the childhood kidney cancer called Wilm's tumor. The team published its research today (July 22) in the Proceedings of the National Academy of Sciences. "It is not inconceivable that the loss of WT1 function is an early event in the progression to breast cancer," said Silberstein, an associate research biologist at UCSC. "This really is a brand-new finding, a once-in-a-lifetime connection that should open new avenues of breast-cancer research." Silberstein emphasized that the research will not lead to new medical or preventive treatments in the near future. However, by shedding light on the cellular machinations of diseased breasts, it may give researchers a new strategy as they attempt to devise "gene therapy" approaches to restore the normal functions of genes that stunt the growth of tumors. Silberstein led the study in the laboratory of Charles Daniel, research professor of biology at UCSC. Other coauthors included Charles T. Roberts, Jr., professor of pediatrics at Oregon Health Sciences University and an expert on Wilm's tumor, and UCSC researchers Katharine Van Horn and Phyllis Strickland. The scientists received samples of both healthy and diseased breast tissues via Daniel's ongoing collaboration with physicians at Dominican Santa Cruz Hospital, most notably pathologist Dr. Kelly O'Keefe and surgeon Dr. John Snyder. All tissues were obtained with the informed consent of patients. Other samples came from the University of Michigan's Breast Tissue Bank. WT1, it appears, is among a chain of genes that helps govern the production of important hormones, called growth factors, in both the kidney and the breast. The growth factors are part of a fine-tuned hormonal system of checks and balances that controls the extent to which cells proliferate. WT1's key targets in the cell are hormones known as insulin-like growth factors (IGFs) and transforming growth factor beta (TGF-b). Research in the labs of Daniel and others has shown that both IGFs and TGF-b are crucial to regulating growth in mammary glands. When WT1 does its job, it instructs the cell to churn out proteins that manage the amount of IGFs and TGF-b. "WT1 essentially is a middle-management gene," Silberstein said. "It's expressed in an exceedingly complex way--it's basically four genes in one. But there is a direct connection between WT1 and factors that control the growth of breast tissues." The researchers examined normal tissues from the breasts of six patients who had undergone breast-reduction surgery at Dominican Hospital. The WT1 protein was present in cells from all of these patients, indicating that the gene was active and functioning properly. Then, the team looked at tissues excised from 21 breast-cancer patients, ranging in age from 29 to 88 years. In 40 percent of all the tumors studied, the researchers could not detect the WT1 protein--the gene, for unknown reasons, had malfunctioned or fallen silent. In another 28 percent of the tumors, most of the cells lacked the WT1 protein. "The story is complex, because it has been difficult to find a single molecular or genetic defect that is common to all the various forms of breast tumors," said Roberts, who directs the Doernbecher Pediatric Research Laboratories at OHSU. "Finding abnormal WT1 activity in several types of breast cancer suggests that defects in WT1 action may underlie many forms of breast cancer." Curiously, the WTI gene was active in a highly malignant subset of advanced breast tumors, called estrogen receptor-negative tumors. However, the researchers also detected another well-known tumor suppressor gene, called p53, in these malignant cells. Those two genes can interact, so p53 may interfere with WT1's normal function. There is no evidence of a mutation in the WT1 gene, Silberstein said, so WT1 would not be a factor in hereditary breast cancers. No relationship is yet evident between the WT1 gene and the previously discovered BRCA I and II genes, which play a role in hereditary forms of breast cancer. Those cases comprise 5 to 10 percent of all breast cancers. Silberstein, Daniel, and their UCSC colleagues are completing a study of the developmental regulation of WT1 in the mammary glands of mice. Early results support the findings from human tissues: the gene's products are absent in precancerous tissues but present in more mature tumors. The research was supported by grants from the National Institutes of Health to the laboratories of both Daniel and Roberts. ##### Editor's notes: You may reach the principal researchers as follows:Gary Silberstein: (408) 459-4428 or silberstein@biology.ucsc.eduCharles Roberts: (503) 494-4307 or robertsc@ohsu.eduCharles Daniel: (408) 459-4171 or daniel@darwin.ucsc.edu
--------
566-> Quick Rise In Temperatures Suggests A Blockbuster El Nino For The Late Nineties; NCAR El Nino Colloquium This Month
1997-26FOR IMMEDIATE RELEASE: July 17, 1997 BOULDER--El Nino is a warming of the surface waters of the tropical Pacific Ocean whose far-reaching climatic consequences affect societies and economies around the globe. As the second El Nino of the nineties builds in the Pacific, the National Center for Atmospheric Research is hosting a colloquium of experts July 20-August 1 in Boulder. This Tip Sheet has information about the current El Nino, the upcoming colloquium, the relationship between El Nino episodes and global warming, and a recently published book on El Nino for the lay reader. Also included are a list of experts and helpful World Wide Web sites. The current El Nino A strong El Nino has developed over the past several months. According to the National Oceanic and Atmospheric Administration (NOAA), waters across the eastern tropical Pacific have warmed to levels of 2 to 3 degrees Celsius above normal. Near the South American coast, waters are the warmest observed since the El Nino of 1982-83. That El Nino, the century's strongest, triggered over $10 billion in weather-related damages worldwide. One signal of the current El Nino's strength: for about 10 days last month, the northeasterly trade winds across the entire equatorial Pacific reverted to westerlies. Such a switch has been observed only once in the past 30 years--again, during the 1982-83 El Nino. If this event behaves as most do, the present oceanic signals of El Nino will continue to intensify during the summer and fall. The colloquium A two-week colloquium, "A Systems Approach to El Nino-Southern Oscillation (ENSO): Oceanic, Atmospheric, Societal, Environmental, and Policy Perspectives" will be held in Boulder July 20-August 1. Sponsored by NCAR with additional support from NOAA, the colloquium will update participants on current understanding of the causes, effects, and implications of ENSO and the various roles ENSO plays in the global climate system. By taking a multidisciplinary, systems-based approach, the colloquium seeks to stimulate new insights about climate-society interactions. Prominent ENSO experts will draw from oceanography, atmospheric science, statistics, ecology, and biology, as well as economics and other social sciences, in their presentations. The colloquium is open to the press by prior arrangement with organizer Michael Glantz (303-497-8119; glantz@ucar.edu). A session schedule is available on the colloquium's interactive Web site, http://www.dir.ucar.edu/esig/enso, or by calling 303-497-8117. El Nino and global warming El Nino has been showing up more often since the late 1970s, with a prolonged episode from 1990 to 1995 and another quickly building up now. According to NCAR atmospheric scientist Kevin Trenberth, one possible explanation is that the warm pool in the tropical western Pacific Ocean may be growing larger. Climate models are not yet accurate enough in simulating El Nino to clearly attribute these changes to global warming. However, even without affecting how often El Nino occurs or how long it stays around, global climate warming is likely to intensify the extremes of flooding and drought already experienced in different parts of the world during a normal El Nino and its inverse, La Nina. Trenberth believes that global warming and El Nino reinforce each other in their impact on the environment and society, primarily through their combined effects on the hydrological cycle and the repercussions for water supplies. The book: Currents of Change Published in fall 1996 and now in its second printing, Michael Glantz's book, Currents of Change: El Nino's Impact on Climate and Society (Cambridge University Press) is aimed at a broad audience. Glantz defines El Nino, describes its far-reaching impacts on climate and society, and discusses how those impacts might be forecast. The book considers the state of prediction research and the value of forecasts in preparing for widespread effects, from drought to malaria epidemics. An introductory crossword puzzle tests readers' knowledge of El Nino. ENSO experts Michael (Mickey) Glantz     303-497-8119	    glantz@ucar.eduNCAR/Environmental and Societal Impacts Group (ESIG)Specialty:  Interaction between climate anomalies and human activities. A political scientist, Glantz has studied El Nino's societal impacts for 23 years. Kevin Trenberth	    303-497-1318   	trenbert@ucar.eduNCAR/Climate and Global Dynamics DivisionSpecialty:  Global climate analysis. Trenberth has studied ENSO's interaction with global change and its impact on weather and climate anomalies worldwide, including the Midwest drought of 1988 and floods of 1993. Gerald Meehl	    303-497-1331	    meehl@ucar.eduNCAR/Climate and Global Dynamics DivisionSpecialty:  Tropical climate and climate change. Meehl has studied El Nino phenomena using observations and global climate models and has analyzed links between El Nino and the Asian-Australian monsoons. Nick Graham	    619-534-1858	    ngraham@ucsd.eduScripps Institution of Oceanography/Climate Research DivisionSpecialty:  Role of tropical oceans and climate in global climate variability and climate change; seasonal-to-interannual climate prediction; impacts of climate variability and El Nino; marine meteorology of U.S. West Coast. Ants Leetmaa	    301-763-8396, ext. 7553	    wd01al@sun1.wwb.noaa.govNational Center for Environmental Prediction/Coupled Modeling ProjectSpecialty:  Coupled ocean-atmospheric modeling and seasonal climate prediction, with an emphasis on ENSO. Martin Hoerling	    303-492-1114	    mph@cdc.noaa.govNational Oceanic and Atmospheric Administration (NOAA)/Climate Diagnostics CenterSpecialty:  The global impact of El Nino on weather and climate. Antonio Moura	    914-365-8493	    amoura@iri.ldeo.columbia.eduLamont-Doherty Earth Observatory of Columbia University/International Research Institute for Climate PredictionSpecialty:  Climate impacts over South America; applications of seasonal-to-interannual forecasts to agriculture in northeast Brazil and flooding in southern South America. Moura served as director general of Brazil's weather service. Michael McPhaden	    206-526-6783	    mcphaden@pmel.noaa.govNOAA/Pacific Marine Environment LaboratorySpecialty:  Development of ocean observing systems for climate studies; interpretation of resulting data to understand and predict climate variability. Pertinent sites on the World Wide Web Interactive Web Site for ENSO Colloquiumhttp://www.dir.ucar.edu/esig/enso     The night before each presentation, extended abstracts will be posted on the Web. Visitors to the site may pose a question for the next day's discussions. A session summary, including responses to Web questions, will be posted after the session. Spanish translations of the extended abstracts, funded by the National Science Foundation, will be available on the Web site through the assistance of CATHALAC (Centro del Agua del Tropico Humedo para America Latina y el Caribe/Water Center for the Humid Tropics of Latin America and the Caribbean) and TC3 (Trade Convergence Climatic Complex).Contact: Jan Stewart, 303-497-8117 NOAA/An El Nino Theme Pagehttp://www.pmel.noaa.gov/toga-tao/el-nino/home.html     This award-winning page features a comprehensive set of links to many sou 
--------
567-> Stopping "Cellular Suicide" Could Boost Production In Biotech Labs
THE JOHNS HOPKINS UNIVERSITYOFFICE OF NEWS AND INFORMATION 3400 N. Charles StreetBaltimore, Maryland 21218-2692Phone: (410) 516-7160 / Fax (410) 516-5251 ---------------------------------------------------------------- July 15, 1997FOR IMMEDIATE RELEASECONTACT: Phil Sneidermanprs@jhu.edu STOPPING "CELLULAR SUICIDE" COULD BOOST PRODUCTION IN BIOTECH LABS Every day, for reasons that are not clearly understood, somehuman cells commit suicide. Some cells, such as those that havebeen infected by a virus, kill themselves to preserve the healthof the body as a whole. Other self-destruct simply because theysense that a threat to their survival or merely somethingunfamiliar is lurking nearby. This process, called apoptosis or programmed cell death, is anormal biological occurrence that can promote proper organdevelopment and help to prevent cancer. But it's unwelcome inmodern biotech labs, where scientists turn living cells intominiature pharmaceutical factories that produce proteins,enzymes, antibodies and viruses to help patients with an array ofillnesses. Apoptosis prompts many of these microscopic workers toput physiological "guns to their heads" after just a few days onthe job. Working closely with molecular biologists, Johns HopkinsUniversity engineer Michael J. Betenbaugh is trying to disablethese guns and allow the drug-making cells to lead longer, moreproductive lives. "Ideally, we'd like to extend the lifetime of these cells andincrease their efficiency in making biotech products that savepeople's lives," says Betenbaugh, an associate professor in theDepartment of Chemical Engineering. His research has important implications. If scientists find a wayto stop cellular suicide, they may be able to keep some cardiaccells from killing themselves after a heart attack. They may alsobe able to extend the life of artificial organs made from animaltissue. The key is to halt apoptosis, which is often triggered by changesin a cell's environment. "It may be a viral infection, the lossof a key nutrient, radiation or a chemical toxin, all at sub-lethal levels," Betenbaugh explains. "These would not kill thecell by themselves. Nevertheless, the cell turns on thisphysiological chain of events that causes it to self-destruct." In biotech labs, however, researchers want genetically engineeredcells to thrive and produce medicines for as long as possible, agoal that is thwarted by programmed cell death. To remove thisstumbling block, Betenbaugh installs "stop signals" at specificpoints along a cell's road toward self-destruction. To find thesesignals, he works with researchers led by J. Marie Hardwick, anassociate professor of molecular microbiology and immunology atThe Johns Hopkins School of Public Health. Hardwick's team ismapping out the genetic path that a cell follows toward self-destruction. In his own biotech lab, Betenbaugh uses thesefindings to figure out the best way to block the cell's progressalong this path. "There is a point of no return as the cell goes through theprocess of killing itself," Betenbaugh explains. "But at somepoint you can stop it. I'm collaborating with the biologists whoare figuring out what those stop signals are. Then, as anengineer, my job is to apply those stop signals to the cell linesthat I'm developing." One potential stop signal is membrane protein called bcl-2. Whenthis material is inserted during the genetic engineering of a newcell line, it appears to shut down the suicidal impulses,Betenbaugh says. He is also experimenting with chemicals thatmimic the effects of bcl-2 when added to cells that are alreadygrowing in the lab. "Maybe our cells see the signals that tellthem to commit suicide," Betenbaugh says. "But we can halt thatprocess before it hits the point of no return. Instead of dyingafter two days, our cells might live for six or seven days,making pharmaceuticals for a longer period of time." In his initial experiments, Betenbaugh has more than doubled thelife-span of some biotech lab cells. Thus far, however, each ofthese hardier cells has not produced as much medicine as the onesthat died quickly. By trying new genetic and chemical strategies,the researcher seeks to improve the system signi  
--------
568-> Researchers Probe Mechanism Behind Heartbeat
Houston--(July 18, 1997)--Scientists at The University of Texas-Houston Medical School and the University of Alberta in Canada have determined the three-dimensional structure of cardiac troponin C (cardiac TnC), a protein responsible for regulating muscle contraction in the heart. Described in the July 18 edition of The Journal of Biological Chemistry, the work lays the foundation for the development of new drugs which can modify the properties of this critical molecular 'switch' and aid in the treatment of congestive heart failure. Using nuclear magnetic resonance (NMR) spectroscopy and recombinant DNA techniques to model its three-dimensional solution structure, John Putkey, Ph.D., associate professor in the department of biochemistry & molecular biology at UT-Houston, in collaboration with Brian D. Sykes, Ph.D., professor of biochemistry at the University of Alberta, Edmonton, Canada, revealed elements of cardiac TnC which may help explain functional differences between cardiac and skeletal muscle contraction. Found only in heart muscle, cardiac TnC closely resembles skeletal TnC, one of a family of calcium-binding proteins which change shape as they relay biochemical signals which lead to muscle contraction. Now that the structure of cardiac TnC is known, researchers' ability to design clinically effective drugs will be significantly improved. Dr. Putkey said: "A fundamental feature of the molecular mechanism of muscle regulation is a cyclic change in the three-dimensional conformation of the protein TnC as it binds and releases calcium. Troponin C can be conceptualized as a molecular switch: when calcium is bound, the muscle contracts--when calcium is released, the muscle relaxes. To fix or modify any machine one must know how it works. If that machine is a protein, then you need to know its three-dimensional structure. The structures of the cardiac and skeletal forms of TnC reveal profound and largely unexpected differences. These three-dimensional views provide valuable clues about how cardiac TnC works and how we may selectively modify its function." Numerous studies have been conducted to identify drugs which increase cardiac TnC's affinity for calcium, thereby 'boosting' the action of heart muscle. These were based on the assumption that the drug-binding potential of cardiac TnC was similar to the skeletal form. The work of Putkey and Sykes will aid efforts to produce new therapies for heart attack patients who develop congestive heart failure -- the condition in which insufficient blood is pumped throughout the body. Treatment with appropriate calcium sensitizing drugs may help counter the heart muscle impairment found in these patients. The NMR spectroscopy was conducted in Dr. Sykes' Edmonton laboratory where much of the earlier work on skeletal muscle troponin C took place. Commenting on his association with the UT-Houston team, Dr. Sykes said: "This has been an excellent collaboration bringing together the different expertise of the Houston and Edmonton research teams. The structure of cardiac TnC has revealed some quite unexpected features, and will go a long way towards explaining both the differences between cardiac and skeletal muscle contraction and also, on a very molecular level, how calcium binding to regulatory proteins such as TnC is linked to their triggering function in many biological systems." Note to editors: The authors of 'NMR Structure of Cardiac Troponin C Reveals an Unexpected Closed Regulatory Domain' are Samuel K. Sia, Monica X. Li, Leo Spyracopoulos, Stephanie M. Gagne, Wen Liu, John A. Putkey and Brian D. Sykes*. * Corresponding Author.
--------
569-> NASA Technology May Help Assess Risk Of Bone Problems
July 18, 1997 Michael BraukusHeadquarters, Washington, DC(Phone:  202/358-1979) Ann HutchisonAmes Research Center, Moffett Field, CA(Phone:  415/604-4968) RELEASE:  97-155 NASA TECHNOLOGY MAY HELP ASSESS RISK OF BONE PROBLEMS A portable device developed for the space program to examine how physical activity relates to bone density may someday serve as a way to assess a person's risk of osteoporosis. The device, developed by researchers in the Life Sciences Division at NASA's Ames Research Center, Moffett Field, CA, provides a record of the major forces people apply to their bodies throughout the day.  It does this by measuring and recording the interaction between the foot and the ground during daily activity.  This "loading" of the body plays an important role in maintaining muscle and bone strength in the lower limbs. "This device was designed to quantify daily physical activity and daily musculoskeletal loading by measuring the ground-reaction force," said Dr. Robert Whalen, head of the Musculoskeletal Biomechanics Laboratory in the Gravitational Research Branch at Ames.  The device measures the force that occurs on the foot during each step.  The force can reach one and one-half times a person's body weight during walking and two to three times body weight during running.  "It's very important to monitor this force throughout the day because it also is responsible for high muscle and bone forces in the legs and critical bone regions such as the hip and pelvis," Whalen explained. The force exerted on the body when it meets the ground is what keeps muscles and bones in the lower body strong.  If muscles and bones aren't used, they become significantly weaker, a problem encountered by astronauts during space flight, particularly by astronauts who do not exercise vigorously in space.  "Maintaining muscles and bones during long duration space flight is primarily a biomechanical problem," Whalen said.  "With current in-flight exercise devices, it is difficult to achieve force levels equivalent to levels achieved during normal daily activity on Earth.  We are investigating new ways to counteract these changes with devices capable of imposing Earth-equivalent levels of force on the body in space." Whalen and Dr. Gregory Breit, researchers at Ames, are studying the relationship between the mechanical forces humans put on the skeleton every day and the structure of the skeleton.  "Bone is highly responsive to mechanical forces," Breit said.  "That may be the key to understanding why bone is lost gradually with age and why certain exercise programs can't build bone mass," Whalen added. The key, Whalen explained, is determining how individuals can "load" their bodies to maintain muscle and bone strength.  Since our muscles generate their own forces, we are limited by how strong our muscles are.  "If you don't have the muscle strength, you can't exert high forces on bones to increase bone mass," Whalen said.  "As people age, a gradual decline in activity level and intensity contributes to a decline in muscle strength, and therefore our ability to load our bones also decreases."  The result can be less dense, weaker bones that are more prone to fractures. The device consists of  two elements:  a force sensor resembling an insole that is worn in the shoe, and a small computer carried in a fanny pack.  A cable connects the sensor to the small computer, which samples the applied force 100 times per second.  It stores only the significant maximum and minimum forces occurring during each loading or gait cycle, as well as the peak loading and unloading rate and the time at which each event occurred.  The device is capable of storing approximately two weeks of activity data. Although scientists have used step-meters and activity logs to estimate a person's daily activity level and musculoskeletal loading history, Whalen said these devices don't give a reliable measurement of forces on the skeleton, due to differences among people and differences in the amount and "intensity" of their daily activities.  A person walking quickly will generally experience higher forces than when walking more slowly, for example.  The new device provides a reliable measure of the actual forces exerted on the body. The Ames researchers are collaborating with the Palo Alto Veterans Administration Hospital and with Stanford University, Palo Alto, CA, to study how daily activity level and exercise influence bone density.  "Once we have enough data, we can get an idea of the daily physical activity level of an 'average' person," Breit said.  "Then people can decide if they are above or below average and what they need to do to improve.  In the future, we hope to understand bone adaptation well enough to assess whether an individual's bone density is consistent with his or her daily activity level." Breit said that this device will allow measurement of an individual's activity to assess his or her risk of low bone density from low physical activity level and will allow an individual exercise prescription to improve the health of an older person. For photographs or more information about the Musculoskeletal Biomechanics Laboratory, visit the Web site at URL: http://pioneer.arc.nasa.gov/~rwhalen/ -end-
--------
570-> NASA Statement On The Passing Of Gene Shoemaker
Douglas IsbellHeadquarters, Washington, DC(Phone: 202/358-1753) July 19, 1997 RELEASE:  97-156 NASA STATEMENT ON THE PASSING OF GENE SHOEMAKER Planetary scientist Dr. Eugene ("Gene") Shoemaker, 69, was killed in a two-car accident near Alice Springs, Australia, on the afternoon of July 18.  His wife Carolyn Shoemaker suffered broken bones, and reportedly is hospitalized in stable condition. A geologist by training, Shoemaker is best known for discovering, with his wife Carolyn and colleague David Levy, a comet near Jupiter.  Comet Shoemaker-Levy 9 was broken up by tidal forces from Jupiter, and its fragments collided with the planet in July 1994. Together, the Shoemakers were the leading discoverers of comets this century. "Gene was one of the most renowned planetary scientists in the world, and a valued member of the NASA family since the earliest days of lunar exploration," said NASA Administrator Daniel S. Goldin. "His work on the history of meteor impacts and the role that they play in the evolution of the Solar System is a fundamental milestone in the history of space science. "Gene was an extremely articulate man who could explain the wonders of the planets in simple language that anyone could understand and get excited about," Goldin added.  "Although he never realized his dream of doing field geology on the surface of the Moon, all future exploration of that rocky world owes a debt to his pioneering spirit.  Our warmest thoughts are with his dear wife Carolyn as she recovers from her injuries." Shoemaker's signature work was his research on the nature and origin of the Barringer Meteor Crater near Winslow, AZ, which helped provide a foundation for cratering research on the Moon and planets. This work led to the establishment of a lunar chronology, allowing the dating of geological features of its surface. Shoemaker took part in the Ranger lunar robotic missions, was principal investigator for the television experiment on the Surveyor lunar landers (1963-1968), and led the geology field investigations team for the first Apollo lunar landings (1965-1970). In 1961, he organized the Branch of Astrogeology of the U.S. Geological Survey in Flagstaff, AZ, and acted as its director from 1961 to 1966. On his retirement from the U.S.G.S. in 1993, Shoemaker became a staff member at Lowell Observatory in Flagstaff. An early supporter of the idea that an asteroid or comet impact had doomed much of Earth's life (including the dinosaurs) 65 million years ago, Shoemaker chaired key NASA working groups on how best to survey such near-Earth objects in 1981 and 1994.  Most recently, he was active in the Clementine mission that imaged the Moon, and was science team leader on the planned Clementine 2 mission. Shoemaker won numerous awards during his career, and in 1980 became a member of the National Academy of Sciences. -end-
--------
571-> Hypertension In Blacks: Dietary Salt Plays Key Role
Embargoed for July 20, 1997 Hypertension in BlacksDIETARY SALT PLAYS KEY ROLE A study of first and second-generation African Caribbeans living in the West Midlands of England found many undiagnosed cases of high blood pressure and more whose blood pressure medications were not adequately controlling their hypertension. The study is the first to focus on blood pressure, dietary salt intake and salt sensitivity among both first and second-generation African Caribbeans living in the United Kingdom. It is one of the largest studies ever to examine the effects of dietary salt on blood pressure in a black population. Dr. Elijah Saunders, head of the Division of Hypertension at the University of Maryland School of Medicine, will present his preliminary findings on July 21 to the 12th International Conference on Hypertension in Blacks, in London, England.  A co-founder and current chairman of the board of the society sponsoring the conference, he directed the six-week study of 150 African Caribbeans living in Birmingham and Wolverhampton. Participants had their blood pressure, pulse rate, height and weight measured at a baseline screening prior to the study.  Blood and 24-hour urine examinations were done at baseline.  and then weekly for three weeks while the subjects ate their normal diets, usually high in salt. Blood pressure, pulse, weight and 24-hour urine exams (for salt) were repeated weekly for a total of six weeks. During the last three weeks the subjects ate diets containing 50 percent less salt than at baseline. Preliminary results suggest that on the salt-restricted diets, most subjects lost weight and their blood pressure dropped. "We were not surprised to see high blood-pressure rates nearly twice that of whites, and we were not surprised to find a significant amount of obesity and diets excessively high in salt—we have seen this phenomenon in African Americans," Saunders said. Some surprises did await the researchers, though.  "Not only was a significant amount of hypertension undiagnosed, but many people who were being treated had blood pressures that were not being very well controlled by their medication," Saunders said. Another surprise, he said, was that some doctors and patients did not seem to be aware of just how serious a condition high blood pressure can be in blacks. With complications including diabetes, kidney disease, stroke and heart disease, untreated or inadequately treated hypertension is probably the number one killer in the Western world, Saunders said. In other research reported at the London conference, Saunders and colleague, Dr. Matthew Weir, head of the Division of Nephrology at the University of Maryland School of Medicine, reported that certain kinds of high blood-pressure medications are less effective in black people when used in the usual doses and/or when there is an excessive amount of salt in their diet. "There are ethnic differences in response to some medication, and physicians need to be aware of this," Saunders said. The four-day international conference in London is focusing on new ways to prevent and control high blood pressure and the organ damage it can cause. The scientific meeting is sponsored by the International Society on Hypertension in Blacks, a nonprofit organization dedicated to improving the health and life expectancy of ethnic populations in the United States and around the world. The society was founded in Atlanta, Georgia, in 1986 to respond to the problem of high blood pressure among  people of African descent.  It has since expanded its organizational scope and now implements programs to address other medical conditions which affect black people and other minorities disproportionately, including kidney disease, diabetes, stroke, and some heart disease.  It publishes a medical journal called Ethnicity and Disease. 
--------
572-> Reluctant Research Subjects: Minorities Can Benefit From Medical Research
Embargoed for July 20, 1997 Reluctant research subjectsMINORITIES CAN BENEFIT FROM MEDICAL RESEARCH They said it couldn’t be done.  "You won’t be able to find enough black people willing to participate in your clinical trial," some British researchers warned the American cardiologist from Baltimore.  Like many African Americans, the African Caribbeans of England are somewhat suspicious of medical research involving them. But Dr. Elijah Saunders and his colleagues did it. Head of the Division of Hypertension at the University of Maryland School of Medicine, Saunders not only succeeded in recruiting 150 African Caribbeans in the West Midlands communities of Birmingham and Wolverhampton for a six-week study of blood pressure and salt sensitivity, he had them collecting their urine for 24 hours once a week for six weeks. Also they came to their church hall for weekly examinations.  The program in both communities was conducted at churches, where most of the participants were members. Another 200 black residents of Bristol, Manchester and Wolverhampton were begging him to study their blood pressure as well. An associate professor of medicine, Saunders will present his preliminary findings at the 12th International Conference on Hypertension in Blacks, in London July 20-23. HIS co-investigators were Professor Gareth Beevers, Drs. Ralph Rogers and Gregory Lip, nurse Ronnie Haynes and many volunteers from the two churches. Saunders himself is black and has known many of the church participants for years, and of course that helped.  "It will get you through the door," he says, "but then you have to stand on your own two feet like anyone else." An internationally recognized hypertension clinician, educator and researcher whose work focuses on ethnic factors in high blood pressure rates, treatment and prevention, Saunders credits his success in England to his team’s commitment to giving something of value to the people who participated in the study. "We explained exactly what we were asking them to do and why; we shared the results of all their tests with them and their physicians; and we made a real effort to educate them about positive, preventive lifestyle changes they can make," he said.  Follow-up counseling was an integral part of the study. "They knew we weren’t just coming in, taking what we wanted from them without giving them anything in return, then disappearing." Saunders is deeply concerned about the reluctance of African Americans and other ethnic minorities to participate in medical research that could have crucial implications for their present and future health. He encourages researchers to become more sensitive to ethnic differences in the medical needs of minority groups, to make a special effort to include on their research teams people from the target community, to make results of medical tests available to the people studied and their physicians, and to incorporate an educational/counseling component in research studies. 
--------
573-> MGH Researchers Connect Alzheimer's Mutations To Cell-Death Process
Researchers at the Massachusetts General Hospital (MGH) have discovered that two genes associated with early-onset Alzheimer's disease are involved in programmed cell death, a natural process in which unneeded or worn-out cells commit suicide.  They also showed that an Alzheimer's-causing mutation in one of these genes increases the propensity of nerve cells to undergo the cell-death process, which also is called apoptosis. In the July 18 issue of Science, the scientists describe their studies of the protein products of two genes called presenilins.  Rudolph Tanzi, PhD, director of the MGH Genetics and Aging Unit and leader of the study, explains that this work is the first to directly and clearly connect these Alzheimer's genes with apoptosis, which has long been suspected as a mechanism in several neurodegenerative diseases. "Both presenilins now join a select group of proteins which help bring about cell death," Tanzi says.  "In the brain, this process usually takes place during early growth, when extra neurons [brain cells] die to assure proper development.  We hypothesize that in older individuals the cell-death pathway becomes reactivated in certain neurons, especially in regions affected by Alzheimer's.  While mutations in these genes appear to speed up this process and cause early-onset Alzheimer's, environmental factors could set off the process in sporadic cases of the disease. This discovery creates an excellent target for new drug development." Presenilin (PS)1, located on chromosome 14, and PS2, located on chromosome 1, both were discovered in 1995 by multi-institutional collaborations including members of the MGH research team.  When mutated, PS1 (which also has been called S182 and STM-1) is believed to cause roughly 50 percent of inherited, early-onset Alzheimer's, while PS2 (also called STM-2) is associated with a much smaller proportion.  Defects in both genes are directly causative; anyone who inherits a mutated form of the gene is destined to develop the disease, usually before age 65. When apoptosis takes place, many of the proteins that make up a cell are clipped apart by certain enzymes called caspases.  Although clipping proteins into smaller fragments is a normal part of cellular metabolism, apoptosis-associated clipping takes place at alternative locations along the protein strand, changing the molecular message carried by the protein and eventually leading to the cell's death.  The new findings suggest that presenilin proteins are cell-death substrates -- proteins that are clipped by caspases to carry out the process of cell death. To confirm the presenilin proteins' cell-death role, the MGH researchers analyzed the proteins produced by cultured neurons under normal conditions and after apoptosis was induced by substances that trigger the process.  They identified the sites at which both presenilins were clipped in normal cellular proces sing by isolating the two fragments the original proteins were cut into.  When cells undergo apoptosis, the researchers found, both presenilins are clipped in alternative loca tions, producing different protein fragments that contribute to the cell-death process. The researchers then looked at cells carrying a PS2 mutation found in a number of families with early-onset Alzheimer's.  When both normal cells and mutated cells were induced to make PS2, the mutated PS2 was three times more likely to be clipped in the location associated with the cell-death pathway than was the normal PS2. The only other known effect of presenilin gene mutations is to increase production of amyloid-beta42 (A-beta42), a component of the characteristic plaques found in the brains of people with Alzheimer's, which is toxic to cells on its own.   Tae-Wan Kim, PhD, the paper's first authors explains, "A question we need to answer now is how the participation of presenilin genes in the cell-death pathway, particularly the enhanced paticipation of mutant forms of the genes, relates to previous observations of increased A-beta42.  We can see two possibilities:  alternative clipping of the presenilins could set off several cell-death processes within the neurons, including production of A-beta42; or the alternative clipping could directly increase A-beta42 accumulation, which would be the actual trigger for cell death." No matter which pathway turns out to be involved, Tanzi adds, development of drugs that interfere with the caspase-induced alternative clipping of presenilin proteins might delay or prevent the progression of Alzheimer's. D. Stephen Snyder, PhD, program director for the Etiology of Alzheimer's Disease at the National Institute on Aging, says:  "Alzheimer's research is like putting together a giant jigsaw puzzle.  The results reported here, together with the other partially assembled sections we have before us, provide some very solid clues to help us understand the mechanism by which Alzheimer's develops.  These insights will suggest new and, we hope, more effective means by which to thwart this devastating disease." The National Institute on Aging provided major support for this research. # # 
--------
574-> Carbon Dioxide Helps Some Plants Survive Cold Weather, Cornell Researchers Find
FOR RELEASE:  July 17, 1997 Contact:  Blaine P. Friedlander, Jr.Office:  (607) 255-3290E-mail:  bpf2@cornell.edu ITHACA, N.Y. -- Elevated levels of carbon dioxide in the atmosphere benefitsome plants by making them more tolerant to cold temperatures, CornellUniversity researchers have discovered. "This could mean earlier spring planting dates for some crops in thefuture," said David Wolfe, Cornell associate professor in the Department ofFruit and Vegetable Science.  "It may also affect the mixture of species innatural plant communities, because only certain plants benefit in thisway." The researchers' study, "Elevated carbon dioxide mitigateschilling-induced water stress and photosynthetic reduction duringchilling," was published recently in the journal Plant, Cell andEnvironment (1997 20, 625-632).  Steve Boese, instructor at the College ofCharleston, Charleston, S.C., and Jeff Melkonian, Cornell post-doctoralresearcher, co-authored the paper with Wolfe. Also, Wolfe will present a poster on this topic at the  Plant Biology '97conference cosponsored by the American and Canadian Societies of PlantPhysiology, in Vancouver, Canada, on Aug. 3 and 4. "Our results are another example of how the increase in carbon dioxide andother greenhouse gases will shake up the plant world," Wolfe said.  "Ourmaps of global vegetation zones will inevitably be altered by these sortsof direct effects on plants, whether or not we also have major changes inclimate." The research was supported by the U.S. Department of Agriculture's SpecialGrants Agricultural Ecosystems Program. The researchers have focused much of their attention thus far on two crops,beans and cucumbers, that are among a class of plants that tend to wiltwhen temperatures dip below about 45 degrees Fahrenheit.  They knew fromprior experiments that elevated carbon dioxide levels often reduce the rateof water loss from leaves, and they suspected this effect would reduce theamount of chilling damage in these species. This hypothesis was confirmed by their study.  Plants grown and chilled atelevated carbon dioxide levels showed less severe wilting and suffered lesspermanent leaf damage than plants grown and chilled at current atmosphericcarbon dioxide concentrations. "If carbon dioxide in the atmosphere doubles within the next century as weare expecting," Wolfe explained, "these species may be able to withstandtemperatures a few degrees cooler than they do now." The research is the first to fully document that carbon dioxide can havesuch an easing effect on chilling damage.  Most of the work has beenconducted in controlled-environment chambers.  The researchers plan tofollow up with field experiments and test other plant species. Wolfe points out that the rapid rise in atmospheric carbon dioxide is stilla problem from the standpoint of being an important greenhouse gas that maychange our climate in unpredictable ways. Said Wolfe:  "I still think that fossil fuel emissions, the primary culpritin the carbon dioxide rise, are not good for the planet.  Many of the othergases that are produced, such as sulfur dioxide, ozone and nitrous oxidescan have direct negative effects on plants and humans, for that matter." -30- --------------------------------Cornell University News Service324 Judd Falls RoadIthaca, NY 14853607-255-4206 phone607-255-5373 faxmailto:cunews@cornell.eduhttp://www.news.cornell.edu 
--------
575-> New Studies Of Martian Meteorite Launched
Media contacts:Lynn Simarski                                       National Science Foundation(703) 306-1070/lsimarsk@nsf.gov Don SavageNASA Headquarters(202) 358-1547 Program contact:Scott Borg(703) 306-1033/sborg@nsf.gov NEW STUDIES OF MARTIAN METEORITE LAUNCHED The National Science Foundation has awarded grants for sevennew projects to study Martian meteorite ALH84001 in greaterdepth.  The grants are part of a coordinated program with NASA tofurther investigate possible traces of ancient life in theMartian rock. After the announcement last August that the meteorite mayHarbor fossils of ancient Martian life, NSF and NASA called forfurther research into the evidence.  The agencies set up acoordinated, interdisciplinary program which included jointreview of research proposals.  NASA announced on June 19 that ithad awarded 16 individual grants under the program. NSF's seven new grants, totaling nearly $800,000 forprojects over two or three years, will use advancedinstrumentation to further analyze the provocative rock.  Someprojects will study ALH84001 itself.  Others willinvestigate analogous features in terrestrial rocks fromenvironments that may resemble those of ancient Mars--hot springsand other extreme habitats of earthbound microbes--to provide abetter context for understanding the tiny structures in theMartian rock. Meteorite ALH84001 is one of about 8,000 meteoritescollected in Antarctica by U.S. researchers.  NSF is the leadagency for managing the collection and distribution of Antarcticmeteorites, done in collaboration with NASA and the SmithsonianInstitution.  Samples of ALH84001 are being sent to theresearchers from the Antarctic Meteorite Laboratory at NASA'sJohnson Space Center in Houston.  The samples, typically only afew grams apiece, are handled similarly to the lunar samplescollected during the Apollo program. The new research will include scanning the meteorite forextremely fine-scale alteration of the mineral interface bymicrobes.  Other studies will focus on the meteorite's carbonisotopes to see if they reflect a ratio typical of microbiallife, and develop a chemical method to fingerprint biologicalactivity in meteorites using different isotopes of iron, some ofwhich may be taken up preferentially by living organisms. Still other projects will look at mineral particles--oxidesand sulfides of iron--with potential as "biomarkers" (signs ofpast life) both in the Martian meteorite and in bacteria onEarth.  Some researchers will attempt to: fix the temperature andfluid composition under which the meteorite's minerals formed,presently an area of controversy; develop thermodynamic modelsfor mineral alteration in hydrothermal environments; anddelineate the rock's temperature history and its pastinfiltration by fluids. Institutions receiving the grants are the University ofWisconsin-Madison, the University of Wisconsin-Milwaukee,California Polytechnic State University-San Luis Obispo, IowaState University, Arizona State University, University ofMinnesota, University of California-Santa Cruz, University ofHawaii, Washington University in St. Louis, and the CaliforniaInstitute of Technology. -NSF- Editors: For further details on the new grants, contact ScottBorg, NSF polar earth sciences program manager, at 703-306-1033,or by e-mail at: sborg@nsf.gov. 
--------
576-> UCSD Researchers Use Gene Therapy To Promote Recovery From Spinal Cord Injuries
FOR RELEASE: TUESDAY, JULY 15 (A.M.s) Media Contact: Nancy Stringer,(619) 543-6163 UCSD RESEARCHERS USE GENE THERAPY TO PROMOTE RECOVERY FROM SPINAL CORD INJURIES Researchers from the UCSD School of Medicine report the first successful use of gene therapy to achieve partial recovery from spinal cord injuries. In studies involving laboratory rats, gene therapy was used to stimulate the regrowth of damaged axons by changing the function of an injured animal's cells allowing them to produce a growth factor directly at the site of injury. "This novel use of gene therapy provides the opportunity for injured axons to regenerate through the spinal cord and restore function," said Mark H. Tuszynski, M.D., Ph.D., associate professor of neurosciences at the UCSD School of Medicine and a neurologist at the Veterans Affairs Medical Center in San Diego. The findings appear in the July 15 issue of The Journal of Neuroscience. Axons are the "wires" that cells use to communicate with one another as they relay messages from the brain. Injured adult mammal spinal cords show little spontaneous recovery after injury often leading to paralysis. In previous studies, Tuszynski and his colleagues have shown that injured spinal cord cells can be stimulated to regrow when exposed to certain nerve growth proteins. In the study reported today, rats with spinal cord injuries had a sample of normal skin cells removed that were cultured in the laboratory and genetically modified to produce the growth factor neurotrophin-3 (NT-3). When grafted back into the animal, the modified cells secreted NT-3 at the site of spinal cord injury, which in turn stimulated axon regrowth and resulted in some recovery of walking ability. In addition, the genetically modified cells were also found to deliver NT-3 continuously for several months, further enhancing the regeneration of injured axons and the partial restoration of function. "The goal in spinal injury research is to promote the regrowth of cut or damaged axons," said Tuszynski. "These results indicate that cellular delivery of NT-3 through gene therapy can restore function by promoting the sustained growth of axons after spinal cord injury." Individuals contributing to the study included Ray Grill, Ph.D.; Keith Mural; Fred Gage, Ph.D., and Armin Blesch, Ph.D. This work was supported by the Hollfelder Foundation, International Spinal Research Trust, and Veterans Affairs Research. # # #
--------
577-> Biology Of A Monogamous Bond: Findings Reported In Hormones And Behavior Help Explain Social Attachment, Provide Clues For Autistic Behavior
July 10, 1997 Contact: Kate Egan,404-727-7709, email: kegan @rmy.emory.edu Biology of a Monogamous Bond Findings reported in Hormones and Behavior help explain social attachment, provide clues for autistic behavior As a youngster, he's a tad timid but he gets along well enough with others. He doesn't fight much. Then something happens. He meets an attractive female and mates with her. Within 24 hours, he becomes quite aggressive, actively excluding all others save for her. Why the sudden change? Apparently, says Thomas R. Insel, MD, Director of the Yerkes Regional Primate Research Center of Emory University, this kind of behavior among prairie voles is part of a larger network of social behaviors that preserve the bond between the lovebirds, while excluding all others. The couple is held together like glue by a mutual interest that favors staying together. Dr. Insel, a self-described "psychiatrist turned neuroscientist," has spent years figuring out how this bond is formed and maintained, neurobiologically speaking. His research focuses on the mechanisms underlying affiliative behaviors, which he hopes will help in developing treatments for autism and even schizophrenia, both of which result in social isolation and detachment. There is currently no therapy or cure for these problems. The antipsychotic drugs used currently are useful only for symptoms like hallucinations or self injurious behaviors; they do not help social deficits. Specifically, Dr. Insel and his research team examine the peptide hormones vasopressin (AVP) and oxytocin (OT) and their vital roles in influencing complex social behaviors such as affiliation, parental care, territorial aggression, and several behaviors associated with monogamy (pair bonding, paternal care, mate guarding). To demonstrate how OT and AVP influence these behaviors, Dr. Insel compares neuropeptide pathways in two rodent species: the prairie vole and the montane vole. Although the two species are 99% genetically identical, they exhibit very different social behaviors. The prairie vole is highly social and forms lasting, monogamous pair bonds after mating. A prairie male prefers the company of its mate and shows aggression toward other males once he has bonded with a female. The breeding pair nests together and both parents provide extensive and prolonged parental care, with the offspring remaining in the parental nest for several weeks beyond weaning. Manipulating their exposure to AVP and OT will drastically alter these behaviors. In contrast, the montane vole typically nests in isolation and breeds promiscuously. Montane breeding partners do not form a pair bond after mating, the males are notparental, and females abandon the offspring soon after birth. Why such a difference? It's all in the wiring. The neural wiring, that is, deep inside the brain. It turns out that the receptors for vasopressin (in males) and oxytocin (in females) are distributed in different areas of the brain in the two species. Dr. Insel and his colleagues, Larry Young, Ph.D, and Zuoxin Wang, Ph.D., think they have an idea why: the promoter portion of the AVP receptor gene, which possibly instructs the gene where in the brain it should be expressed, is configured differently in the two species. "This difference in receptor distribution is what we think makes the species respond differently to AVP," says Dr. Insel. "It's not just that prairie voles have more AVP than montane voles. Montanes just act differently, even when we inject AVP directly into the brain." Drs. Insel's lab has carefully mapped out the specific locations of the receptors in the brain. The next step is to determine which aspect of social behavior each area is responsible for ----and if and how behavior is altered when the receptors are blocked or otherwise manipulated. For instance, is one location associated with pair bonding, and another with aggression? Or perhaps paternal care? To study the question further, Drs. Insel and Young are using a mouse that has been genetically altered to contain the prairie vole's AVP and OT receptor genes. Their work is described in the June issue of Hormones and Behavior. "Hopefully, this will result in a mouse with altered receptor distribution," explains Dr. Young. "Then we'll look at behavior." Will the mouse's social behavior mimic that of a vole? Will the mouse become more monogamous? Dr. Young's theory is that every species has different receptor distribution----which leads to different social patterns. "Throughout evolution, AVP and OT receptor distribution has changed. When it changes behavior favorably, it is selected for," explains Dr. Young. "Now we are trying to determine whether we can modify social behavior in the laboratory the same way evolution has over millions of years." Dr. Insel and his team eventually plan to map the receptors for AVP and OT in the rhesus monkey. These studies will reveal much about the evolution of monogamy and the the neuroendocrine basis of affiliation. The obvious question is what impact might this have for humans? How similar is the human biology of attachment? It is hoped that these studies will improve understanding of the determinants of human social bond formations, as well as provide clues to the social deficits characteristic of devastating human diseases such as autism and schizophrenia. # # #
--------
578-> Sandia's 8 "R&D 100" Awards Are Its Best Effort
Media contact: Neal Singer, 505-845-7078, nsinger@sandia.gov Sandia's 8 "R&D 100" Awards are its best effort ALBUQUERQUE, NM -- Researchers at Sandia National Laboratories won eight awards in this year's R&D 100 competition --the largest number Sandia has garnered since it began competing in the late 1970s. Sandia winners proposed devices -- newly or nearly in use -- in fields ranging from medicine to computers, and from manufacturing to resource exploration to the prevention of widespread power failures. The winners: * PQ2000 Power Quality System. One of those awful power surges comes down your power line, heading for your hard drive. If you were clever, you've purchased a surge protector that will open your circuit, thus (hopefully) preventing your computer from frying. But you've lost information you haven't yet saved. Large power users have even worse problems. Tens of billions of dollars in production losses, according to the Electric Power Research Institute in Palo Alto, Calif., occur annually because of power sags and momentary, 100 percent power losses which shut down microprocessor-controlled systems. (We notice these in our homes when the lights flicker and the VCR needs to be reprogrammed.) The PQ 2000 is a battery-based, energy storage and delivery system designed to mitigate the effects of factory-wide power disturbances on sensitive electronic and electrical equipment, says Sandia project leader Garth Corey. It may also mitigate the effects of a power surge, sag or outage on a utility grid. (Late bulletin: the first system will be officially installed July 10, 1997 in a Southern state.) Rather than acting like a circuit breaker and shutting down a utility line, the PQ2000 monitors the line for voltage sags, swells or momentary interruptions. Sensing something amiss, the PQ2000 transfers the line in one four-hundredths of a second to stored battery energy. This acts as a high-power voltage source for up to 10 seconds before returning the equipment to normal power service as the momentary disturbance passes. The system possesses the potential to provide wide area grid voltage support, and to reduce momentary peaks of demand for power that sometimes necessitate building entirely new power plants to accommodate them. The work was done jointly by Sandia, the AC Battery Corporation (East Troy, WI), Electric Power Research Institute (Palo Alto, Calif.), Oglethorpe Power Corporation (Tucker, Ga.) and Pacific Gas and Electric Company (San Ramon, Calif.). DOE was an early sponsor of the project with Sandia. * Biological Microcavity Laser. A handheld device that analyzes blood samples in minutes -- it currently may take laboratories hours to weeks to return an analyzed sample -- has been jointly patented by researchers at Sandia and the National Institutes of Health, says principal researcher and Sandia project leader Paul Gourley. The proof-of-principle device, which uses many tiny fingers of laser light to image cells in a drop of blood placed in a small chamber, can be miniaturized to microchip size and would be field-portable. The apparatus eliminates the need to "stain" blood cells for better visibility, or send them to a distant lab for analysis, thus eliminating transportation costs and delays as well as potential for additional error. Using the device, "It's possible to take a blood sample containing millions of cells and extract information about each cell within a few minutes," said Gourley. "The method determines variations in cell characteristics that might be indicative of disease." The device should prove useful in combat situations or terrorist attacks when shipment of a blood sample to a remote location is impractical, and correct determination of foreign gaseous or biologic components in the blood must be effected quickly to save lives. The nonvolatile field effect transistor device, a new class of memory technology more familiarly known as the protonic chip, saves a computer user's sanity when the power unexpectedly turns off. The chip uses clunky protons that maintain screen memory by staying where they are, rather than skittish electrons that vanish into the night, taking with them your latest entries. The device is inexpensive, low-powered, and simple to fabricate, says Bill Warren, lead Sandia researcher on the project. To create the memory-retentive chip, the key fabrication step is to bathe the hot microchip in hydrogen gas. The gas, permeating the chip, breaks up into single ions -- i.e., protons -- at defects in the silicon dioxide. (The defects were created by the heat of the manufacturing process.) The protons can roam only within the chip's central layer of silicon dioxide, where they are trapped by two layers of silicon that sandwich the silicon dioxide. A positive low-voltage applied to one side of the silicon repels the protons to the far side of the silicon dioxide. A negative low-voltage applied to the silicon attracts the protons to the near side of the silicon dioxide. If the power is turned off, the protons stay where they are, retaining information until the machine is repowered. * Filmetrics F-30 optical probe. Varying a conception in the middle of a task may mean one is the Michael Jordan of one's field, adaptable and high scoring. Until Filmetrics F-30, there was no simple, inexpensive way for growers of thin films of materials (essential components of modern microelectronics) to modify the recipe that deposits film as it was being grown. Instead, a production run would repeat what had just been grown, or be limited to the awkward procedure of modifying a physical or chemical condition before beginning and then judging results after finishing. With the F-30 probe, "Failure within a growth run is detected immediately," writes Sandia researcher and project head Bill Breiland, "and the source of the failure is quickly determined by studying the real-time in situ history of the growth run." The recipe can be modified as the run progresses. The F-30 probe -- approximately 1/5 the cost of comparable probes -- also can be used as a pre-growth calibration tool: procedures at Sandia that used to take weeks can now be accomplished within a single one-hour growth run, Breiland says. The device works by reflecting visible or near-infrared light from films to measure their growth rates. The technique is based on the principle that different film thicknesses and materials cause different patterns of reflected light. The sensitive probe can evaluate almost 10 times the number of wavelengths as its closest competitor. The sensitivity is important in distinguishing between materials that refract at different wavelengths. * Hierarchical High-Performance Storage System (HPSS). Everyone knows -- well, many people know -- that the amount of data storable in a modern desktop computer exceeds that of the entire North American Strategic Air Command in the early 1960s. Now, in the Internet age, the rent's come due -- how, online, can we continue to store and make use of government, corporate, foundation, university, commercial and private data, when at least one study suggests the amount of such data is increasing about 100 percent annually? The HPSS project at Sandia National Labs is part of a research collaboration between industry, university research centers, and national laboratories to develop mass storage system software. The system improves performance and increases storage merely by adding more units. The primary purpose of the HPSS is to store large amounts of data and move them rapidly between high-performance computers, clusters of work-stations, and storage libraries. "Rapidly," in this case, means at speeds 100 times or more faster than today's storage software systems. "We have 13 sites already running our software at national labs, universities, and industry, on IBM-type platforms across the country," said Sandia project leader Rena Haynes. The storage system transfers files at rates of billions of bytes per second and can contain millions of gigabytes of data. As one of five principle development sites, researchers at Sandia -- both in Albuquerque and in Livermore, Calif. -- helped develop the algorithms to make high-capacity storage systems both secure and high-performing in a massive computational environment. (The other principal sites are at Lawrence Livermore, Oak Ridge and Los Alamos national laboratories, and at IBM.) * Aztec. Those who remember their desperate attempts in high school to solve groups of equations with two, three or even four "unknowns" may be impressed that scientists today sometimes solve problems featuring several hundred million unknowns. But not easily. The frustrations of a physicist or engineer who must slog through a mire of equations to solve an otherwise interesting problem can be lessened by Aztec. Aztec is a library of equation solvers developed at Sandia for very fast supercomputers. The group of solvers mean that scientists are relieved of a major computational burden and can focus more fully on the fundamental issues of their problems. "Aztec has allowed Sandia to solve scientific computing problems previously unsolvable by any other means -- problems of importance to the Department of Energy and to U.S. industry," says Ray Tuminaro, Sandia project leader. Aztec's approach is iterative, which means that it approximates a solution by repeatedly correcting an initial 'guess.' The method is faster than reducing large systems equation by equation, which can be laborious. Aztec has helped make massively parallel computing a practical platform for large-scale simulations and design codes. * GEOSEIS mini-hole seismic surface initiation system. The earth doesn't come with signs on it pointing downward, saying, "This Way To The Oil," or to any other natural resource. So, once companies target a general area, how do they know precisely where to drill? "One way is to put an array of little detonators and explosives in the ground, fire them, and when the echoes come back, you can map where the oil is," says Sandia researcher Bob Bickes, coinventor of the semiconductor bridge (SCB). The SCB is far more precise than previous methods in setting off explosions that aid seismic explorations: The more accurate the timing on the explosions, the sharper and more powerful the seismic wave, and the better the data collected from return echoes. The SCB detonator ignites the energetic material pressed against the bridge in a few microseconds -- a formerly unattainable precision for low-energy initiators. The SCB detonator used in GEOSEIS (trademarked) system is designed, manufactured and marketed by the Ensign Bickford Company in Simsbury, Conn. The SCB chip is designed and manufactured by SCB Technologies Inc., in Albuquerque, the exclusive licensee for commercialization of the SCB technology. The semiconductor bridge patent was the first wholly owned patent (1987) granted to Sandia. * CLIP-C, or Closed Loop Induction Process Controller. The horror of "morphing" in movies -- when the bad guy turns from a human into a vampire, or from a pool of mercury into a bad cop from the future -- is that no control is possible as the process is occurring. The good people have to wait until the process is finished, and the bad person appears intact at full strength. The same waiting period could be said to happen in engineering, when a part being hardened begins to change its physical characteristics -- sometimes for the worst -- as it's being heated-treated. During this period, there's nothing to be done; the heating process goes dumbly on as the part takes shape. The result may be a bad part. Using signals from the heat-treated part to control the induction process has been an unattainable goal for five decades. But under a partnership between Sandia and Delphi Saginaw Steering Systems (a subsidiary of General Motors), a system was developed and brought to the factory floor in less than three years, says Sandia principal investigator Phil Kahle. The new technique, CLIP-C, monitors material as its physical characteristics change. It has five times less tolerance for error than previous methods. A feedback loop orders changes in operating conditions to take into account changes in materials. Prior to introduction of the patented technique -- currently used to harden half-shafts for Saturn automobiles, and now being installed in Ford and Chrysler plants -- the only feedback in most systems was after the process was over. Inspectors would test a completed part and then keep it or toss it on the scrap pile. With CLIP-C, corrections to the process can be made in real time, so scrap losses are all but eliminated, and good parts are made more accurately. Award info Winners will receive plaques at a black-tie dinner at the Chicago Museum of Science and Industry on September 25. All winning projects will remain on display at the museum for a month after the awards, said Vic Camello, a senior editor at R&D Magazine, a technical trade magazine in Des Plaines, Ill. that sponsors the annual event The magazine will announce its "Researcher of the Year" at that time. The awards honor inventors of the 100 most significant technological innovations of 1996, as judged by a panel of experts selected by the magazine. The inventions must already be applied, or close to it, rather than 'breadboard' -- good ideas with much still to be worked out. Sandia was second in the total number of awards won only to Oak Ridge National Laboratories, which won nine. Los Alamos, a national laboratory also located in New Mexico, won six. The bulk of the applications, which "number in the hundreds," come from industry, which won the lion's share in total number, said Camello. Each entry is judged by "a minimum of six judges out of a volunteer pool of 51 from national labs and industry," said Camello. If judges reach a consensus on a product, the editors of R &D Magazine "generally do not presume to overrule them." But, when there are split decisions, "the editors take into account comments that are made by the judges, particularly if one has a particularly insightful view into the product." Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national security, energy, and environmental technologies and economic competitiveness. # visuals: photos of winners available.
--------
579-> Contaminants From Coal-Burning Byproduct Affecting Aquatic Wildlife
UNIVERSITY OF GEORGIASavannah River Ecology LaboratoryNEWS RELEASE Contacts: Jane M. Sanders, (706) 869-9703, Beeper: (706) 785-8289, Email: sanders@srel.edu Marie Fulmer, (803) 725-9724, Beeper: (803) 867-0284, Email: fulmer@srel.edu FOR RELEASE JULY 11, 1997 Contaminants from coal-burning byproduct affecting aquatic wildlife AIKEN, S.C. -- Ecologists at the Savannah River Site are finding high levels of heavy metals in animals exposed to coal fly ash left over from burning coal at the federal reservation, and they suspect that the same problems are widespread because gigatons of coal are burned around the world every year. Drs. Justin Congdon and Chris Rowe, both of the Savannah River Ecology Laboratory, have found elevated levels of arsenic, cadmium, selenium, strontium and mercury in bullfrog tadpoles and the freshwater softshell turtles that feed on them. The animals live in coal fly ash basins, in areas surrounding the basins and in Beaver Dam Creek that flows for a quarter mile and enters the Savannah River, south of Augusta, Ga. "We have observed effects on many biological systems of tadpoles exposed to the heavy metals," Dr. Rowe said. "That means the animal is suffering system-wide failure. The contaminants alter tadpole mouth morphology and reduce the tadpole's ability to take in food compared to normal tadpoles. At the same time, tadpole metabolic rates are higher, so they need more energy to maintain themselves. In addition, their ability to escape predators is reduced probably because some of the contaminants are found in the muscles." Dr. Congdon added: "We think the cadmium is causing the tadpoles to have central nervous system problems. In our experiments, tadpoles taken from clean water quickly flee when they are put in a maze with a snapping turtle, but the turtles are able to capture most of the tadpoles taken from the fly ash area." Some findings from the researchers' four-year study will be published later this year in the journals Copeia and Journal of Herpetology. The researchers reported the oral deformities of tadpoles from the coal fly ash basins last year in the journal Freshwater Biology. The researchers are continuing to collect data on bullfrog reproduction, and they suspect that it will also be affected, they said. Less than lethal effects to organisms are often difficult to document, Dr. Congdon said, but it is further complicated when contaminants are transported from the aquatic to the terrestrial environments. "When some animals feed on contaminated prey, heavy metals can be transferred into the terrestrial environment and into the Savannah River," Dr. Congdon said. "For example, a snake eats a tadpole, and it in turn, is eaten by a hawk, and so on. 'How much is being transferred out into the environment and how?' are the questions we're trying to answer." Turtles and fish from the Savannah River can enter the areas contaminated by coal fly ash and then return to the river with elevated levels of trace elements, the researchers said. For example, softshell turtles, which are consumed by humans, eat contaminated prey such as fish, crayfish and clams found in and near the ash basins, the researchers said. Then they may return to the Savannah River. Once in the river, soft-shelled turtles can transport the trace elements long distances from the source of contamination, Dr. Congdon said. Fish from the river can swim up the creek and feed on plants and animals that may have been exposed to the same heavy metals from runoff and other pathways, Dr. Congdon said. He and Dr. Rowe have begun sampling for fish from the ash basin to the river, but have not yet analyzed them for contaminants. Researchers at the Savannah River Ecology Laboratory are also looking at possible contamination to plant seeds to see if any of the pollution is leaving the Savannah River Site boundaries through seed-eating birds and animals. That work, to be done by fellow Ecology Laboratory researcher Dr. Ken McLeod, has not yet begun. Continued reliance on coal as a major energy source worldwide may pose greater problems than scientists previously believed, Drs. Congdon and Rowe said. Because coal ash pollution is causing substantial problems in aquatic organisms on the Savannah River Site, researchers believe that aquatic organisms are being affected worldwide. Drs. Congdon and Rowe said they believe the environmental effects of coal ash pollution on aquatic organisms represent "a staggering problem and one that people are not going to want to address." Research into the problems related to coal fly ash storage and disposal should become a priority because about 100 million metric tons of fly ash are produced each year in the United States alone, they said. To reduce the adverse environmental effects of using coal as an energy source, the Department of Energy is pursuing a "clean coal" facility to generate power for the Savannah River Site, DOE officials said. This new facility will eliminate essentially all of the harmful coal fly ash that is normally released into the environment by a conventional coal burning facility. The coal fly ash is instead converted into a useful byproduct called slag, which can be sold. In addition, this "clean coal" facility will dramatically reduce that amount of sulfur dioxide and nitrogen oxide compounds, which are gases that contribute to acid rain and global warming. # 268 FOR MORE INFORMATION: To conduct interviews, you may contact the researchers directly, or seek assistance from one of the public information officers listed above. 1. Dr. Justin Congdon, Phone: (803) 725-5341 or Email: congdon@srel.edu 2. Dr. Chris Rowe, Phone: (803) 952-9041 or Email: rowe@srel.edu (After Aug. 1, 1997, you may reach Dr. Rowe at the University of Puerto Rico at (787) 764-0000, ext. 3551.) DOE CONTACT: 1. Rick Ford, U.S. Department of Energy, Savannah River Site. Phone: (803) 725-8449. ###
--------
580-> Radio Telescopes In The New Movie "Contact" Dish Up Real Science
July 10, 1997 NSF PR 97-49 Media contact: Lynn Simarski, (703) 306-1070/lsimarsk@nsf.gov Dave Finley National Radio Astronomy Observatory, (505)835-7302/dfinley@aoc.nrao.edu RADIO TELESCOPES IN THE NEW MOVIE "CONTACT" DISH UP REAL SCIENCE In the new movie "Contact," astronomer Ellie Arroway, played by actress Jodie Foster, searches for signs of extraterrestrial life using massive, Earth-bound radio telescopes. Much of Contact's scientific intrigue, based on Carl Sagan's 1985 bestseller, unfolds at two National Science Foundation-supported radio astronomy facilities where real-life astronomical mysteries continue to be probed. Scientists use the government-supported telescopes to detect radio waves not from distant civilizations but from planets, stars, galaxies and other objects in space. Radio observations extend astronomers' reach into space and time, letting them "see" through gas and dust in space to detect celestial objects whose visible light cannot be seen from Earth. In "Contact," Foster hears the first guttural, throbbing message transmitted by other-worldly life using the world's most powerful radio telescope, the Very Large Array in Socorro, New Mexico, a collection of 27 antennas spread in a three-armed configuration across the desert. The huge dishes which Foster manipulates in the film from her lap-top computer like a high-tech, movable Stonehenge are run in reality by NSF's National Radio Astronomy Observatory. Electronically linked to simulate a single radio telescope up to 20 miles in diameter, the antennas can be bunched together or moved apart along railroad tracks into different configurations. About 700 astronomers use the VLA each year to observe the universe. Earlier this year the VLA was used to detect the first radio emission from a gamma-ray burster shedding light on the cause and locations of these explosions, one of the great mysteries of astrophysics. In a 1994 discovery, the VLA revealed an object within the Milky Way Galaxy--a double-star system with a black hole or neutron star as one partner--ejecting jets of particles at nearly the speed of light, a process thought to mirror the dynamics at work in the centers of galaxies. In "Contact," Foster gets her scientific start at another NSF-supported facility, the Arecibo Observatory, a huge, stationary radio dish operated by Cornell University in the lush mountain setting of Puerto Rico. The 1000-foot reflector dish, also featured in the James Bond film, "Goldeneye," is the largest stationary radio telescope and most powerful radar in the world. Russell Hulse and Joseph Taylor of Princeton University earned a Nobel Prize by using the dish in the 1970s to discover the first pulsar in a binary system, confirming a prediction of Einstein's theory of general relativity. In the early 1990s, Arecibo was used to detect the first planets outside the solar system. The dish recently received a facelift in a $27-million upgrade which makes it four times more sensitive to radio emissions from distant galaxies. The dish was used in the 1960s to chart accurately for the first time the rate at which the planet Mercury rotates. More recently it studied ice in Mercury's polar craters, the chemistry of Earth's upper atmosphere and rotating pulsars. The new upgrade will let astronomers "hear" signals from much greater distances, and further back in time, than before. -NSF- NSF is an independent federal agency responsible for fundamental research in all fields of science and engineering, with an annual budget of about $3.3 billion. NSF funds reach all 50 states, through grants to more than 2,000 universities and institutions nationwide. NSF receives more than 50,000 requests for funding annually, including at least 30,000 new proposals.
--------
581-> University Of Michigan Laser Performs High-Precision Corneal Surgery Not Possible With Current Technology
University of Michigan July 9, 1997 Contact: Sally Pobojewski Phone: (313) 647-1844 E-mail: pobo@umich.edu University of Michigan laser performs high-precision corneal surgery not possible with current technology. EDITORS: Black-and-white slide of the scanning electron microscope image shown on this release is available at http://www.umich.edu/~newsinfo/Photos/eyeball.gif ANN ARBOR---University of Michigan researchers have developed and demonstrated a new, high-precision laser for eye surgery which can be used to perform surgical procedures within the transparent cornea of the eye---something not possible with current laser technology. The U-M laser uses powerful light pulses lasting just a few hundred femtoseconds or quadrillionths of a second. According to Ron M. Kurtz, assistant professor of ophthalmology in the U-M Medical School, these ultrashort pulses require less energy to cut tissue and do not create large "shock waves" that can damage surrounding structures. Kurtz is currently testing the laser for use in corneal refractive surgery for vision correction and in corneal transplantation. Future research will test the laser's effectiveness in the treatment of glaucoma and cataracts. The new laser system was developed by a team of scientists from the U-M College of Engineering's Center for Ultrafast Optical Science and the U-M Medical School's W.K. Kellogg Eye Center. Tibor Juhasz, an associate research scientist with joint appointments in the College of Engineering and the Medical School, presented the results of recent experiments with the U-M laser at the Advanced Opthalmic Laser Surgery Conference held June 25-28 in Interlaken, Switzerland. These studies compared the precision cuts made in human cadaver corneas with the U-M laser with cuts made by laser and mechanical surgical devices currently used by opthalmic surgeons. "Cuts made by the U-M's femtosecond laser had extremely high surface quality with accuracy better than 10 microns," Juhasz said. "These results were markedly better than similar cuts made with mechanical devices, which are associated with significant risks and complications. Other lasers were unable to perform the procedure." "Although the new laser will not be available for general patient use for at least three to four years, it could represent a major advance in the surgical treatment of several eye diseases and conditions by avoiding the risks and complications associated with less precise mechanical and laser techniques," Kurtz said. An analysis of the optimal laser parameters for corneal surgery based on work by Kurtz and several U-M colleagues is being published in an upcoming issue of the Journal of Refractive Surgery. Animal tests are currently under way with plans for human testing in the near future. A prototype of the new surgical laser system was designed and built by Juhasz and his colleagues in the Femtosecond Medical Research Laboratory at the U-M College of Engineering's Center for Ultrafast Optical Science (CUOS). Since it was established in 1990 with $14.3 million in funding from the National Science Foundation and the state of Michigan, CUOS scientists have developed ultrashort-pulsed laser technology for many applications in high-speed communications, manufacturing and biological imaging. CUOS lasers are based on a technique called chirped pulse amplification---developed by Gerard A. Mourou, U-M professor of electrical engineering and computer science and director of the research center. The U-M has applied for several patents related to ultrafast lasers and is currently assisting in the establishment of a new company to commercialize the technology. A corporate partner will provide the delivery system technology and additional intellectual property for the new company, called InterLase, which will be established in Ann Arbor this summer. Research leading to the development of the new laser was funded by the National Science Foundation, the U-M Office of the Vice President for Research, the U-M College of Engineering, the W.K. Kellogg Eye Center, the Research to Prevent Blindness Foundation and the Midwest Eye Bank and Transplantation Centers. # # # # #
--------
582-> Better Peroxidase Improves Disease Diagnosis
Purdue University News Service 1132 Engineering Administration Building West Lafayette, IN 47907-1132 Voice: 765-494-2096 FAX: 765-494-0401 July 11, 1997 BETTER PEROXIDASE IMPROVES DISEASE DIAGNOSIS WEST LAFAYETTE, Ind. -- When Purdue University geneticist Rick Vierling first looked for ways to add value to soybeans, he didn't expect that he could help doctors diagnose AIDS in China. But that's exactly where his research is leading. In June, the Indiana Crop Improvement Association (ICIA) licensed the use of soybean peroxidase in medical diagnostic test kits to Enzymol International Inc., Columbus, Ohio, and to American Qualex, San Clemente, Calif. In July, American Qualex will announce the use of soybean peroxidase-based compounds in new diagnostic kits at the annual meeting of the American Association of Clinical Chemistry in Atlanta, July 22-23. The company also plans to collaborate with diagnostic, biotechnology, life science and pharmaceutical companies to develop other products that use soybean peroxidase. The soy enzyme replaces horseradish peroxidase, which is an integral part of kits designed to help diagnose a myriad of viral, bacterial and parasitic diseases, including AIDS and malaria. Standard kits lose effectiveness in about four months without refrigeration, according to industry sources. Vierling's preliminary research suggests that kits made with soybean peroxidase should last unrefrigerated for at least a year. Such kits will be very useful in places such as China, Africa and Central America, he says. Vierling, director of the Genetics Laboratory for the ICIA, started experimenting with soybean peroxidase because it is a hot "green" industrial commodity that can be extracted from soybean seed coats. Vierling says researchers have found ways to extract peroxidase from the soybean hulls without reducing the value of the oil or the meal in the beans. "Peroxidase replaces a lot of really harsh chemicals," says Alex Pokora, vice president for technology for Enzymol, a worldwide leader in developing peroxidase technology. "It's a cleaner technology, and it's cost effective." Manufacturers became interested in soybean peroxidase because the supply of horseradish peroxidase was limited and the horseradish enzyme wasn't very stable at high temperatures. Researchers from Enzymol asked Vierling to test soybean peroxidase and to look for soybean varieties with a higher peroxidase content. Vierling immediately confirmed that the soy enzyme worked better. "All plants contain peroxidase, but not all peroxidase is created equal," Vierling says. "Soybean peroxidase is highly reactive and thermally stable. I don't think there's a better peroxidase out there." As Vierling measured enzyme levels in beans, he saw that a quick, chemical test for peroxidase activity would greatly speed his research and plant breeding efforts. He developed one -- and in doing so, he noted that his technique was similar to medical diagnostic test kits that use horseradish peroxidase. He suspected that the medical kits might work better if they were made with the soy peroxidase. Preliminary tests confirmed his suspicions. For further confirmation, Vierling sent samples of soybean peroxidase to John Morrow, a professor at Texas Tech University's Health Science Center in Lubbock, Texas. Morrow and Vierling had worked together when Vierling was a graduate student. Vierling asked Morrow to substitute soybean peroxidase for horseradish peroxidase in clinical diagnostic tests. "I was lukewarm about the idea at first," says Morrow, "but when I tried it, I was converted. I think he's got something that's a nice improvement over current technology." In addition to its superior performance in medical and industrial applications, soybean peroxidase is relatively easy to obtain. The beans are widely grown, and production, transportation and storage facilities already are in place to deliver high-peroxidase beans for enzyme extraction. ACS Code: 9707 Ag Vierling.license/9706a15 Sources: Rick Vierling, (765) 474-3494; e-mail, vierling@mail.dcwi.com Alex Pokora, (614) 856-3050 John Morrow, (806)743-2509 Writer: Rebecca Goetz (765) 494-0461; e-mail, rjg@aes.purdue.edu
--------
583-> Novel Androgen Inhibitors Offer Promise In Treatment Of Prostate Cancer
University of Maryland		Baltimore • NEWS Office for External Affairs -  511 West Lombard Street -  Baltimore, Maryland 21201-1691 For Immediate Release	Contact: Mela Kucera	Phone:	410/706-3803	Pager: 	410/471-0130	Email: melak@oia-2.ab.umd.edu Novel Androgen Inhibitors Offer Promise in Treatment of Prostate Cancer Castration has long been the primary strategy for the treatment of metastatic prostate cancer. Prostatic tumors need androgenic hormones to grow, and until now, efforts to chemically block all of these hormones have proven disappointing. However, researchers at the University of Maryland School of Medicine have identified new androgen inhibitors that they believe could supplant castration as the primary method of treatment for prostate cancer. Dr. Angela Brodie, professor of pharmacology and experimental therapeutics, and research fellow Yang-zhi Ling, believe that several inhibiting compounds discovered in their research show promise as both first-line and complementary treatments of prostate cancer. "It's been known for some time that total androgen inhibition could be more effective than castration, but we hadn't been able to identify and synthesize a compound that would suppress both testicular and adrenal androgens," said Brodie. "Despite removal of the testes, some prostatic tumors can be stimulated even by very low levels of androgens, and some adapt well enough to convert adrenal androgen into a stronger androgen called DHT. These compounds show promise of a more thorough blockade, even against these more difficult tumors, than any we've seen before." The growth of human prostatic tumors is dependent on the presence of androgens, and the testes are the primary synthesis site of the androgen testosterone. Patients who undergo castration frequently relapse because the adrenal gland produces low levels of androgens sufficient to stimulate tumor growth. Tumor cells can also convert these androgens into dihydrotestosterone (DHT), a particularly powerful androgenic hormone. Recent research by the National Cancer Institute suggests that efforts to block the effects of adrenal androgens would result in worthwhile therapeutic gains, but current therapies have shown limited efficacy in clinical trials and can cause undesirable side-effects. Brodie expects to see completion of toxicology tests in six months, commencement of phase one human trials soon after. "I had no doubt of the importance of evaluating these potential new therapies," said Brodie. "We hope these new inhibitors will prove to be more effective than current treatments in limiting the growth of tumors." According to the 1997 American Cancer Society Facts and Figures, prostate cancer will account for approximately 334,500 new cases and 41,800 deaths this year. ###
--------
584-> University Of Florida Researchers Perform The Nation's First Nerve Tissue Transplant On A Paralyzed Man
FOR IMMEDIATE RELEASE GAINESVILLE, Fla.---University of Florida researchers have performed the nation's first nerve tissue transplant on a paralyzed man to slow the progression of spinal cord damage.	The experimental treatment involved injecting small pieces of human embryonic spinal cord cells directly into an expanding cavity that sometimes forms at the site of a specific type of spinal cord injury. Neurosurgeons at the UF Brain Institute performed the procedure Friday (July 11) at Shands at UF to test the safety and feasibility of embryonic spinal cord grafts, which in landmark studies have been shown to help cats regain some use of their paralyzed limbs.	"Our primary goal in this first clinical experience is to test whether these grafts can survive and, if so, to what extent they can fill the cavity in the human spinal cord as they have in our animal studies," said UF neurosurgeon Richard Fessler, who performed the transplant. "We are advising patients that our primary goal in this pilot study is not to restore lost mobility or feeling, but to plug the expanding cavity and prevent further spinal damage."	Researchers say the test is an important first step in developing a future treatment that can restore at least partial use of limbs or organs left paralyzed by a crushing spinal cord injury.	"Our first clinical experience will reveal a lot about cellular transplantation in humans, particularly about the effects of short-term, drug-induced immune suppression (so the body will accept the foreign tissue), how long it takes for the grafted tissue to grow, and how much transplanted tissue is needed to plug the spinal lesion," said UF neuroscientist Douglas Anderson. "You can only answer so many questions in animal studies. If this procedure is successful and causes no adverse consequences to our first patients, it will help us reach our goal faster to aid the recovery of many people disabled by spinal cord injury."	Some 10,000 people become paralyzed each year. Most are men injured in automobile crashes. Actor Christopher Reeve, who became paralyzed from the neck down in 1995 after falling from a horse, has increased public awareness of the problem while crusading for more funding to support research of spinal cord injury.	The Florida man treated Friday is the first of 10 paralyzed volunteers who will undergo the procedure as part of a four-year pilot study at UF. The transplant recipient's identity was not disclosed to protect his privacy.	Only patients who have a chronic disorder called syringomyelia are being considered for the transplant. The condition is characterized by expansion of a fluid-containing cavity within the damaged spinal cord that can cause unbearable pain and progressive loss of sensation and movement. Study participants will be rigorously screened so any existing spinal function or high recovery potential will not be placed at risk.	Patients will receive the tissue grafts while undergoing standard surgery for syringomyelia, which exposes the spinal cord and drains the cavity through a tube. Many patients must undergo the treatment repeatedly.	The embryonic spinal cord graft was obtained from aborted tissue, 6 to 9 weeks old, which otherwise would have been discarded. Researchers said they used such tissue because of its exceptional ability to grow and fill cavities, and because it develops into all of the cell types normally seen in the adult spinal cord.	The tissue was obtained from health-care facilities not affiliated with the university. Researchers at UF and elsewhere report they already are exploring alternatives to embryonic tissue in spinal-cord repair, including laboratory-grown cells and grafts using other nerve tissue cell types.	Friday's milestone has been years in the making, beginning with studies of rat embryos in 1983. In 1992, eminent scholars Paul Reier and Anderson, UF chairman of neuroscience and a research career scientist at the affiliated Gainesville Veterans Affairs Medical Center, conducted studies at the UF Brain Institute involving 15 cats with spine injuries. They showed that transplants of embryonic nerve tissue -- from cat to cat -- helped 40 percent of the animals regain at least partial walking ability. Prompted by that success, a team led by neuroscience Research Assistant Professor Ed Wirth adapted the technology for humans.	Research indicates embryonic tissue transplants also could offer promising advances in the treatment of Parkinson's, Alzheimer's, Huntington's, epilepsy, diabetes, leukemia and other debilitating and deadly conditions.	"Everybody talks about a cure for crippling spinal cord injury," Reier said. "But our philosophy is there's no single 'magic bullet' that will make someone get out of the wheelchair and walk. It will take a combination of approaches. At this point, no other technique has received the degree of scrutiny and work that embryonic tissue transplants have in actually restoring function of a damaged spinal cord."	What may be practical now are what the researchers call "little victories," subtle improvements in function that can make a big difference to paralysis patients. "If you can restore bowel or bladder function, relieve muscle spasticity or restore sexual function," Reier said, "it would yield huge improvements in quality of life and independence for paralysis patients."	For more information, visit the Communications home page at http://www.health.ufl.edu/hscc/
--------
585-> Subtle Biotic Changes Have Big Environmental                          Impact
MADISON - By changing the composition of fish populations in a lake, scientists have found a switch by which the flow of carbon between lakes and the atmosphere can be turned on, off, or reversed. The finding, reported by researchers from the University of Wisconsin-Madison in this week's (July 11) edition of the journal Science, is the first to show that only slight rearrangement of an intact ecosystem's food web can directly influence the atmosphere. The discovery is important because it demonstrates that single, seemingly subtle changes in ecosystems can have far-reaching consequences, and are capable of disrupting the fundamental biogeochemical processes of the Earth. "Linkages in ecosystems are both stronger and stranger than we imagined," said Stephen R. Carpenter, a UW-Madison limnologist who, with fellow limnologists Daniel E. Schindler and James F. Kitchell, authored the report. "Biological processes have powerful feedbacks to processes that are normally thought to be purely physical or chemical in nature." While lakes occupy a very small area of the planet's surface, the discovery that simple biotic change is capable of altering the exchange of carbon between the atmosphere and the Earth's surface raises questions of global significance, said Carpenter. "To what extent could fertilization of the oceans and alteration of oceanic food webs affect global carbon cycles? In fact, runoff from land is now enriching coastal oceans to unprecedented levels, and industrial fishing is causing massive changes in marine food webs. So the global experiment is underway," said Carpenter. Carbon, an essential nutrient in lakes, typically flows from the land in the formof dead leaves and other organic matter that accumulates and decays underwater. Usually, these processes lead to a surplus of carbon dioxide in lakes. Excess carbon in a lake is released as a gas, carbon dioxide, to the atmosphere. When there is a deficit of carbon dioxide, however, lakes draw the gas directly from the atmosphere. Working on an isolated, undeveloped suite of lakes in Michigan's Upper Peninsula, the Wisconsin scientists were able to manipulate the flow of carbon between an entire, intact ecosystem and the atmosphere by placing either minnows or bass at the apex of the lake food web. Bass, by preying on the minnows that consume algae-grazing zooplankton, effectively increased the flow of carbon to the atmosphere by freeing zooplankton from their predators. The booming zooplankton populations grazed the algae to the point where they were no longer a force to use the lake's excess carbon. The lakes, in effect, became pumps, expelling unused carbon to the atmosphere. In lakes dominated by minnows, whose menus include algae-eating zooplankton, burgeoning algae populations and their photosynthetic requirements resulted in a carbon deficit, and the lakes become carbon sinks, drawing carbon directly from the atmosphere. "This effect of fishes on gas exchange results from the changes in aquatic food webs that are regulated by the species of fish present in a particular lake," said Schindler. The changes in lakes, Schindler emphasized, will not have implications for global climate. However, the new understanding of the processes that alter the exchange of carbon dioxide between lakes and the atmosphere can be generalized to other ecosystems such as oceans. "Although the consequences ... are much less known for marine systems than for lakes, we should expect that the ecological responses to exploitation are similar in many ways," Schindler said. The work done by the Wisconsin scientists was funded by the National Science Foundation and conducted under the auspices of the UW-Madison Center for Limnology. ###- Terry Devitt (608) 262-8282, trdevitt@facstaff.wisc.edu (Editor's note: Limnologist Daniel E. Schindler is in transition from the University of Wisconsin-Madison to the University of Washington in Seattle. He can best be reached through the University of Washington's Office of News and Information at(206) 543-2580.)
--------
586-> Study Injects New Interest In How Vaccines Work
WEST LAFAYETTE, Ind. -- A popular theory about how a major component of vaccines works within the body has been shot down by a Purdue University study. Purdue researcher Stanley Hem has found that aluminum hydroxide, a small particle used to carry antigens into the body to boost an immune response, begins to dissolve in the muscle immediately after an injection and is eliminated from the body hundreds of times faster than presumed. "Aluminum hydroxide is used in vaccines to increase the body's production of antibodies, though no one knows how it works," says Hem, professor of industrial and physical pharmacy. "The most popular theory was that it remained in the muscle for months while the body produced antibodies in response to the antigens carried on its surface." The study raises new questions about the mechanism by which aluminum hydroxide works, Hem says. The findings will appear in the September issue of the British scientific journal Vaccine. During the 1930s, researchers discovered that using aluminum hydroxide to carry antigens into the body resulted in a greater production of antibodies than could be produced by the antigen alone. Antibodies are proteins made by the immune system to fight off foreign substances. Antigens -- the proteins or molecules that stimulate the immune system to create antibodies -- are condensed and collected on the surface of aluminum hydroxide particles. Since 1934, aluminum hydroxide has been used as an adjuvant to boost the immune response from vaccines. Currently, it is the only adjuvant approved by the Food and Drug Administration for use in human vaccines. The FDA limits the dosage to 0.85 milligrams per vaccine to minimize exposure to aluminum. "There's been some interest in other materials, but no one has proven them safe enough," Hem says. Though scientists have puzzled over the mechanism by which aluminum hydroxide increases the production of antibodies, the tiny amounts of the substance used in vaccines made it impossible to track or analyze it once it was injected into the body, Hem says. "The most popular theory was that it created a 'depot effect,' where the aluminum hydroxide particles served as a storehouse for the antigen and stayed in the muscle for many months while the body continually produced antibodies," Hem says. Though this explanation was generally accepted, Hem says he questioned how aluminum particles could stay in the muscle for great lengths of time. "The fluid in our muscles, called interstitial fluid, contains citrate, and citrate can dissolve aluminum," he says, "This made me suspect that these aluminum particles didn't stay in muscle for months, because they are continually washed with interstitial fluid." Hem also questioned why the body did not create a wall around the particles, as would be expected when a particle remained in the muscle for a long period of time. "Generally, if you have particles in your muscles for a long time, the body will wall them off and make a nodule or lump," Hem says. "You would expect to see a lot of lumps and nodules in the spot where people get vaccinated, but there are very few reports of such nodules at the site of vaccination." Though these questions nagged him for years, Hem said he didn't have a way of testing the theory until a few years ago, when Purdue established a laboratory for accelerator mass spectrometry. AMS, a technique that uses an atomic accelerator and a mass spectrometer to separate and measure the various components in a sample, is capable of obtaining accurate measurements of molecules that are present in minuscule proportions. "The technique is so sensitive, it can detect the equivalent of a single grain of sand in a football stadium filled with sand," Hem says. Hem and Purdue physicist David Elmore assembled an interdisciplinary team and designed an experiment to see how quickly aluminum hydroxide was eliminated from the body and to track the amounts of the substance that remained in vaccinated tissue over a period of time. They developed a series of rabbit vaccines containing a small amount of aluminum-26, a form of aluminum that is not found in nature. By incorporating aluminum-26 along with aluminum-27 -- the naturally occurring form of aluminum found in small amounts in human and animal tissue -- Hem was able to extrapolate how much of the aluminum in the vaccine the rabbit was eliminating. His study found that aluminum-26 was present in blood samples one hour after the vaccine was injected into the rabbits' muscles, and appeared in urine samples after just four hours. "This means that the particles are dissolving almost immediately because of the citrate in the interstitial fluid," Hem says, "and indicates that the aluminum is not going to stay in muscle for a long period of time. "If the aluminum adjuvant in the body is starting to dissolve within an hour, it's likely that whatever was collected on the surface is being released within a fairly short time." Though he does not have an alternative theory to explain how aluminum hydroxide works to boost antibody production, Hem says that his study may spur new interest into the mechanism behind this reaction. "The study also explains why aluminum hydroxide adjuvants have such a good safety record," Hem says. "The aluminum hydroxide dissolves in the interstitial fluid and is excreted from the body by the kidney." In addition to Hem and Elmore, the interdisciplinary team at Purdue included Richard Flack, graduate student in physics, Joe White, professor emeritus who specializes in mineralogy, Mark Suckow, lab animal veterinarian, Anita Rudy, pharmacokineticist from Indiana University Medical School, and Euphemie Dandashli, a Purdue chemist who worked with Hem to develop the adjuvants. The study was funded by the Purdue University Research Foundation. Source: Stanley Hem, (765) 494-1451; e-mail, jglass@purdue.eduWriter: Susan Gaidos, (765) 494-2081; e-mail, susan_gaidos@uns.purdue.eduPurdue News Service: (765) 494-2096; e-mail, purduenews@uns.purdue.edu
--------
587-> Hopkins Testing New Uses For Improving Sight With Laser
Johns Hopkins researchers are testing a new laser operation that could do for farsighted eyeglass wearers what surgery has long offered the nearsighted: clear vision without glasses or contact lenses. "Excimer laser surgery to gently sculpt the cornea--the clear `front window' of the eye that focuses incoming light, has the potential of opening laser treatment to millions of individuals," says Nada S. Jabbur, M.D., assistant professor of ophthalmology. About 6 percent of Americans are farsighted, and the condition usually affects people in their 40s, she says. The procedure uses the first and only laser system to receive pre-market approval for the treatment of both nearsightedness and farsightedness with astigmatism. A person with astigmatism has wavy, distorted vision. The Hopkins investigators are using the system, called VISX Star Excimer Laser System, to reshape the corneas of volunteers. "Using the laser, we treat the outer edges of the cornea to make the central area steeper," says Jabbur, the lead investigator for Wilmer Eye Institute. "This allows the cornea to focus light properly onto the retina, improving the person's sight without glasses." "We are encouraged by the excellent results at Wilmer of the laser treatment to correct farsightedness, thus far," says Terrence P. O'Brien, M.D., director of refractive eye surgery. "The condition of farsightedness can be a real handicap, and the level of patient satisfaction after treatment has been very high." Earlier studies done with the system showed excellent results for the farsighted, according to Jabbur. In one, in 1996, at the University of Ottawa Eye Institute, 96 percent attained 20/40 vision or better--vision good enough to pass a driver's test in most states without eyeglasses or contact lenses. Candidates for clinical trials must be in good health, wear glasses or contact lenses and must not have had any form of eye surgery. In addition, patients should be willing to follow-up with periodic visits to Wilmer. To find out more about how to participate in these trials, potential volunteers can contact Mary Ann Millar, Wilmer Eye Institute, at (410)-614-2020. The study is being funded by VISX Incorporated. ### --------------------------------------------------------------- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basis on EurekAlert at http://www.eurekalert.org and from the Office of Communications and Public Affairs' direct e-mail news release service. To enroll, call 410-955-4255 or send e-mail to bpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu, http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or on CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".jhm", Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com.
--------
588-> Falling Leaves Much More Crucial To Stream Health Than Previously Thought, According To New Three-Year Study
ATHENS, Ga. -- A new three-year study by ecologists at the University of Georgia and Virginia Polytechnic Institute and State University has discovered that falling leaves are much more crucial to the health of streams than was previously realized. The research, which was funded by the National Science Foundation, was published today in the journal Science. "We believe this is important new information for the overall health of streams," said Dr. Bruce Wallace, a UGA entomologist and ecologist. "Whether the idea is to restore streams or simply to reduce environmental impact, we need to be looking more closely at the streamside vegetation." The three-year study, which was performed at the Coweeta Hydrologic Laboratory near Otto, N.C., is the first to exclude all leaf litter from a 180-meter-long stream flowing from a spring. Using an overhead canopy to exclude leaves from the entire length of the stream, scientists found startling results, with dramatic decreases in numerous species of animals that live in and around the water. Also involved with the project from the University of Georgia were Dr. Judy Meyer, an ecologist, and research coordinator Susan Eggert. From VPI, Dr. Jack Webster was involved in the research. Scientists have known for years that leaf litter is important in the overall scheme of life in free-flowing streams, especially in the southern Appalachians where the Coweeta site is located. But just how crucial falling leaves might be to productivity in the food chain had been unclear. "I first started thinking about this research when I saw an article that said there is no clear relationship between resources and invertebrate abundance in streams," said Wallace. "And I just didn't believe it. I suggested we test the assumption to find out." The mechanical requirements of the study were daunting. A canopy constructed of metal fence posts, a wooden frame and gill netting had to be installed along the 180-meter length of the stream, and workers had to make sure that leaves were kept off the netting when they fell. The project twice survived near-disasters, once during an ice storm and again when a limb fell during Hurricane Opal. The area studied is in a dense oak-hickory forest, with many rhododendrons up to the edge of the stream. This meant that the canopy had to exclude leaf-fall from overhead and a lateral fence was installed to prevent the intrusion of materials from the sides. Susan Eggert and a crew of 12 people spent more than a week just putting the netting on the frame. As a result of litter exclusion during the project, the ecologists "observed major changes in abundance, biomass and production of invertebrate fauna in the treated stream." A nearby stream that had no canopy served as a comparison or reference. Testing at the litter-exclusion site was done at sites determined by random sampling. What Wallace and his colleagues discovered surprised them in its breadth and depth. Seventeen of 29 major taxa showed significant reductions in either abundance or biomass or both. This indicates that the leaves play a crucial role in maintaining the food chain in the rocky stream. "Interestingly, we did find some invertebrates that didn't show decreases as significant as most did," said Wallace. "But these were mostly creatures that feed on woody debris and other organic matter that was present throughout the three-year exclusion period." Invertebrates collected during sampling were classified as scrapers, shredders, gatherers, filterers, primary consumers, invertebrate predators and salamanders. The ecologists also found that the physical nature of the stream bottom dramatically affected the availability of food resources for the different invertebrates. For instance, the moss- covered, steep-gradient bedrock in the stream showed little decrease in the animal populations, suggesting they were less directly dependent on leaf-litter inputs. Litter exclusion shows a strong bottom-up effect of food resources on stream communities, according to Wallace. Studies have been done in the past to determine bottom-up effects by adding nutrients to lakes and streams, but "ecosystem studies examining the effects of resource reduction on communities are rare," the Science paper noted. The study could have important implications for the management of both streams and rivers, said Wallace. "During the history of the country, we have destroyed many miles of the riparian zone [the area next to streams or rivers] and have decoupled the streams from the landscape," he said. "What we show is that leaf litter, among other things, is fuel for these streams. And there are so many threats, from grazing and agriculture to clear-cutting. The problem is the destruction of that linkage." Wallace noted that many large rivers sequester detritus from the flood plain during floods, and yet flood plains were ignored for decades when planners or government agencies studied the health of these waterways. Even the Coweeta Forest was clear cut a century ago and now bears a second-generation regrowth, despite its pristine appearance. The next part of the study is already underway. Last fall, members of the research team removed all the small wood in the litter-exclusion stream. This should give even more precise information about how terrestrial inputs affect stream productivity. Indeed, preliminary data shows that invertebrates populations are continuing to decline. Results of the current study may become a vital part of future conservation efforts for streams and rivers, said Wallace. -30-
--------
589-> New Plant Mutation Produces Tap Root With Large Amounts Of Oil, Proteins, And Starch
Scientists at the Carnegie Institution and the University of California, Berkeley, have discovered a mutation in plants that makes the tap root accumulate large amounts of oils, proteins, and starch. The discovery could lead to genetically engineered plants that store commercially useful substances in an enlarged root. The finding could also make possible the creation of more nutritious root crops with a better balance of oil, protein, and starch. (Most root crops in Third World countries, such as cassava and taro, contain only starch.) The mutation was found in the experimental plant Arabidopsis thaliana. Once the gene containing the mutation has been cloned, it should be possible to track down the analogous gene in other plants, such as turnips, radishes, and sweet potato. The mutation, called "pickle" because of its appearance, was discovered independently by two teams who report their findings in a joint paper in the July 4 issue of Science. The leader of the Carnegie team is Christopher Somerville, director of Carnegie's Department of Plant Biology in Stanford, California. The leader of the Berkeley team is Z. Renee Sung, professor of plant and microbial biology at UC Berkeley. The pickle mutation mimics what happens in seeds, which typically are the major structures accumulating and storing proteins and oils. That's the reason seeds are excellent sources of these substances, and are nutritionally superior to root crops. The scientists found that the mutated plant fails to switch the tap root cells from their seed or embryonic program of storing protein and oil to the adult program. "Normally after germination the plant begins to express a new set of genes that cause the seedling to mature into an adult," says Somervillle. "In this mutation the cells destined to become primary root cells retain the character of embryonic cells. They fail to make the switch from embryonic to adult." The Carnegie team found that gibberellin, a common plant hormone required for seed germination and growth after germination, plays an important part in the switch from embryo to adult. The mutation has its greatest effect when gibberellin is not present during the first 24 hours of growth, thus establishing a hitherto unknown role for this plant hormone. For more information, contact http://www.berkeley.edu/news/index.html The research was supported by an NSF grant to Sung and a US DOE grant to Somerville. Dr. Somerville can be reached at 415-325- 1521, ext. 203 or crs@andrew.stanford.edu; Dr. Sung is at 510-642-6966 or zrsung@nature.berkeley.edu.
--------
590-> Aerospace Research Provides New Understanding Of Atmospheric Turbulence
Cincinnati -- With a sudden and powerful "boom", University of Cincinnati graduate student Donald Freund has found a way to simulate one of the most undesirable conditions a supersonic jet aircraft can face: flying into rapid, severe changes in the atmosphere. His data will help engineers improve the computer codes they use to develop propulsion systems for future high-speed aircraft. Freund will explain his experiments and present his data during the American Institute of Aeronautics and Astronautics (AIAA) Joint Propulsion Conference July 6-9 in Seattle. The "boom" is a large amplitude "acoustic disturbance" in aerospace terms and is used to simulate severe atmospheric turbulence in the laboratory. The difficulty in setting up the experiment was not only generating the boom, but generating it quickly enough to simulate real-world conditions. Freund solved the problem with a novel device nicknamed the "bump." The details are described on Freund's World Wide Web home page at http://www.ase.uc.edu/~dfreund/research.htm. Freund records the "acoustic reflection coefficients," a measure of how much of the boom is reflected back from the engine. Freund is developing a huge database, showing what happens under various engine operating conditions. Current computer codes rely on approximations to simulate the reflection process, but Freund discovered that these approximations are not even close to simulating what really happens. "We found that the reflection comes from a number of stages of the compressor, drastically different from what people were assuming in the past. The amplitude of the reflection is considerably less than what they predict, and it's considerably longer than what they would predict." The information also solves a long-standing problem in high-performance aircraft design. Armed with Freund's data, designers now can modify their codes to predict more accurately how a system will respond to severe atmospheric turbulence. "Once you get the information, it becomes the glue that allows designers to take their inlet code and a compressor code that are normally operated by different people and different companies and make them talk to each other," said Miklos Sajben, Freund's adviser and Ohio Eminent Scholar of Aerospace Engineering. "It's like finding an interpreter for two people who can't speak each other's language." Sajben also believes the findings will have a lasting impact on how such computations are performed in aerospace engineering practice. The work has attracted the attention of aerospace companies and of NASA. Sajben has been awarded a multi-year grant by NASA to use a very similar experimental rig (that uses much of Freund's system) to study another type of atmospheric disturbance involving temperature gradients. "The next project is to see what happens if the engine swallows a big hunk of hot air," said Sajben. "That can create similar problems, and it is a common event." Freund's unique experimental setup and research findings earned him the 1997 Gordon C. Oates Air Breathing Propulsion Graduate Award from the AIAA Foundation. Freund will be presented with his award and a $5,000 check during the AIAA conference. He will present his research results as part of the general meeting and again during a special invited talk as part of the award presentation. Freund is a native of Macon, Georgia and a graduate of Centerville High School near Dayton Ohio. ###
--------
591-> Non-Invasive Method For Diagnosing Cancer Developed At The Weizmann Institute
 Embargoed For Release: July 2, 1997, 5 p.m. ET For press in the U.S., contact: Julie Osler (212) 779-2500Director of Public AffairsAmerican Committee for the Weizmann Institute of Science(212) 779-2500JULIE@ACWIS.ORG CompuServe: 76675.366@CompuServe.COM For foreign press, contact: Luba VikhanskiHead, Foreign Press and PublicationsWeizmann Institute of ScienceRehovot, Israel011 972 8 934 3855RRLUBA@weizmann.weizmann.ac.il Non-Invasive Method For Diagnosing Cancer Developed At The Weizmann Institute REHOVOT, Israel, July 3, 1997...A non-invasive method for distinguishing between different types of tumors, such as malignant and benign, has been developed by Prof. Hadassa Degani of the Weizmann Institute of Science. The approach may also help predict the prognosis of cancer and monitor the effectiveness of therapy. In a study reported in the July issue of Nature Medicine, Prof. Degani and colleagues showed how the method can be successfully employed to diagnose tumors of the breast. The method consists of injecting a contrast-enhancing dye-like material into the patient's bloodstream and using magnetic resonance imaging (MRI) to monitor the way in which this material is taken up and cleared out by the tumor tissue. Because the uptake and clearance differ for malignant and benign tumors, such monitoring makes it possible to make a diagnosis: an image of the tumor shows up on a computer screen in different colors that reflect the distribution of the contrast material, and the color patterns for malignant and benign growths are strikingly different. "Our approach has the potential to reduce the number of biopsies performed to diagnose tumors," says Prof. Degani, a member of the Weizmann Institute's Biological Regulation Department. "Most breast tumors detected by mammography are revealed to be benign on biopsy, so that a noninvasive approach like MRI could help reduce the rate of unnecessary procedures." "We have demonstrated that our approach works, but it now needs to be tested and evaluated in a large-scale trial before it can be widely applied in clinical practice," Prof. Degani says. Apart from diagnosis, Degani's new method of contrast-enhanced MRI could also give a cancer prognosis because it provides information about the tiny blood vessels that feed the tumor. These vessels enable the cancer to grow and spread, and their density and ability to deliver materials to the tumor may make it possible to determine the tumor's potential aggressiveness. Monitoring the blood vessels and the spaces between cells may also help evaluate the effectiveness of therapy: a reduction in the density of the vessels and an increase in the inter-cellular spaces may suggest that therapy is being successful. In addition, if the cost of MRI continues to decline, in the future the new approach may be considered for mass screening as well. Prof. Degani's team was made up of her doctoral students at the Weizmann Institute as well as radiologists from the Hebrew University-Hadassa Medical Center in Jerusalem and the Kaplan Hospital in Rehovot. High resolution reveals tumor properties In magnetic resonance imaging, an image of an organ is obtained by recording signals emanating from the nuclei of atoms, such as hydrogen atoms, that make up the water in the tissues. Adding a contrast material enhances the signals somewhat, but in general the signals are too weak to produce a resolution comparable to that obtained under a microscope. In Degani's method, however, the resolution is very high because the water tissue signals, enhanced by the contrast material, are recorded over an extended period; about 2 to 4 minutes instead of the usual several seconds. The approach is referred to as the Three Time Point method, or 3TP, because imaging of the breast is performed three times: before the contrast material is injected and twice afterwards, at intervals of several minutes. The images reveal how the contrast material enters the tumor, moves inside it and clears out, as well as the pattern in which it is distributed throughout the tumor tissue. These processes are dependent on spaces between cells, on the presence of blood vessels and the extent to which these vessels leak out substances. Benign and cancerous tumors may differ markedly in these properties. Inter-cellular spaces are larger in fibroadenoma, the most common type of benign breast tumor, and the blood vessels that feed these tumors are less leaky and fewer in number. As a result, contrast material tends to accumulate slowly in these benign growths, and washes out slowly. In contrast, in malignant tumors, this material tends to get in and out faster without accumulating. In the 3TP method, these differences show up in color: red for areas of slow wash-out, green for steady levels and blue for fast wash-out. In the study reported in the July Nature Medicine, Prof. Degani's team successfully showed the method's ability to obtain diagnosis of breast tumors in 18 women, eight of whom had fibroadenomas and 10 had cancer. Fibroadenomas looked predominantly red, with patches of green, while cancerous tumors had a great deal of blue. In addition, the colors in benign tumors were uniform and well-defined, while in the cancerous growths the colors were distributed in chaotic, uneven patches. The 3TP method is based on detailed studies of tissue physiology and disease processes, and its effectiveness was previously demonstrated in extensive laboratory and animal studies. Although it has so far been primarily tested in breast tumors, it is applicable to diagnosis of tumors in other parts of the body. Prof. Degani's research on breast cancer using magnetic resonance imaging and spectroscopy has been supported by the National Cancer Institute, the National Institutes of Health, the Israel Academy of Sciences, the German-Israeli Foundation for Scientific Research and Development and the Weizmann Institute's Canadian Women for Science. The Weizmann Institute of Science, in Rehovot, Israel, is one of the world's foremost centers of scientific research and graduate study. Its 2,400 scientists, students, technicians, and engineers pursue basic research in the quest for knowledge and the enhancement of the human condition. New ways of fighting disease and hunger, protecting the environment, and harnessing alternative sources of energy are high priorities. -------------------------------------------------------------- *Photos and graphics of Prof. Degani's research are available. Weizmann Institute news releases are posted on the World Wide Web at:http://www.weizmann.ac.il and also also at http://www.eurekalert.org ### -----------------------------------------------------  Apart from diagnosis, Degani's new method of contrast-enhanced MRI could also give a cancer prognosis because it provides information about the tiny blood vessels that feed the tumor. These vessels enable the cancer to grow and spread, and their density and ability to deliver materials to the tumor may make it possible to determine the tumor's potential aggressiveness. Monitoring the blood vessels and the spaces between cells may also help evaluate the effectiveness of therapy: a reduction in the density of the vessels and an increase in the inter-cellular spaces may suggest that therapy is being successful. In addition, if the cost of MRI continues to decline, in the future the new approach may be considered for mass screening as well. Prof. Degani's team was made up of her doctoral students at the Weizmann Institute as well as radiologists from the Hebrew University-Hadassa Medical Center in Jerusalem and the Kaplan Hospital in Rehovot. High resolution reveals tumor properties In magnetic resonance imaging, an image of an organ is obtained by recording signals emanating from the nuclei of atoms, such as hydrogen atoms, that make up the water in the tissues. Adding a contrast material enhances the signals somewhat, but in general the signals are too weak to produce a resolution comparable to that obtained under a microscope. In Degani's method, however, the resolution is very high because the water tissue signals, enhanced by the contrast material, are recorded over an extended period; about 2 to 4 minutes instead of the usual several seconds. The approach is referred to as the Three Time Point method, or 3TP, because imaging of the breast is performed three times: before the contrast material is injected and twice afterwards, at intervals of several minutes. The images reveal how the contrast material enters the tumor, moves inside it and clears out, as well as the pattern in which it is distributed throughout the tumor tissue. These processes are dependent on spaces between cells, on the presence of blood vessels and the extent to which these vessels leak out substances. Benign and cancerous tumors may differ markedly in these properties. Inter-cellular spaces are larger in fibroadenoma, the most common type of benign breast tumor, and the blood vessels that feed these tumors are less leaky and fewer in number. As a result, contrast material tends to accumulate slowly in these benign growths, and washes out slowly. In contrast, in malignant tumors, this material tends to get in and out faster without accumulating. In the 3TP method, these differences show up in color: red for areas of slow wash-out, green for steady levels and blue for fast wash-out. In the study reported in the July Nature Medicine, Prof. Degani's team successfully showed the method's ability to obtain diagnosis of breast tumors in 18 women, eight of whom had fibroadenomas and 10 had cancer. Fibroadenomas looked predominantly red, with patches of green, while cancerous tumors had a great deal of blue. In addition, the colors in benign tumors were uniform and well-defined, while in the cancerous growths the colors were distributed in chaotic, uneven patches. The 3TP method is based on detailed studies of tissue physiology and disease processes, and its effectiveness was previously demonstrated in extensive laboratory and animal studies. Although it has so far been primarily tested in breast tumors, it is applicable to diagnosis of tumors in other parts of the body. Prof. Degani's research on breast cancer using magnetic resonance imaging and spectroscopy has been supported by the National Cancer Institute, the National Institutes of Health, the Israel Academy of Sciences, the German-Israeli Foundation for Scientific Research and Development and the Weizmann Institute's Canadian Women for Science. The Weizmann Institute of Science, in Rehovot, Israel, is one of the world's foremost centers of scientific research and graduate study. Its 2,400 scientists, students, technicians, and engineers pursue basic research in the quest for knowledge and the enhancement of the human condition. New ways of fighting disease and hunger, protecting the environment, and harnessing alternative sources of energy are high priorities. -------------------------------------------------------------- *Photos and graphics of Prof. Degani's research are available. Weizmann Institute news releases are posted on the World Wide Web at:http://www.weizmann.ac.il and also also at http://www.eurekalert.org ### --------------------------------------------------------
--------
592-> Half Of Ovarian Cancers Linked To More Ovulatory Cycles
DURHAM, N.C. -- A biological link between half of all ovarian cancers and the number of times a woman ovulates over her lifetime has been identified by researchers at Duke University Medical Center, suggesting that ovulation suppression has a protective effect. The scientists believe that constant ovulation, which causes cells in the ovary to divide, is likely to spontaneously damage DNA in those cells over time. That can result in mutations to a critical regulatory gene, known as p53, that normally stops cells from proliferating into cancer. "When a woman ovulates, the egg that is extruded from the ovary blows a hole in the surface of the ovary," said co-author Dr. Andrew Berchuck, professor of gynecologic oncology. "The epithelial cells, where the cancer starts, line the surface of the ovary and they have to proliferate to fill in the hole." The findings indicate that women at risk for this type of cancer can protect themselves by reducing their ovulation cycles through birth control pills, pregnancy and breast-feeding, the Duke researchers said in the study report, published in the July issue of the Journal of the National Cancer Institute. The research was funded by the Centers for Disease Control, the National Cancer Institute, and the American Cancer Society. Ovarian cancer is usually a fatal disease because it is usually found in its late stages, after it has spread beyond the ovaries. In 1996, about 27,000 new cases were diagnosed, and about 14,800 women died of the disease, according to the National Cancer Institute. Mean survival after detection is less than 3 years. Tumors that show evidence of p53 genetic mutation account for half of all ovarian cancer cases, and are considered the most aggressive form of ovarian cancer. The study helps clear up the mystery of why it seems that some women, but not all, can protect themselves against ovarian cancer by suppressing ovulation, the investigators say. "We found that there is a distinct subgroup of ovarian cancer, those associated with p53 mutations, that is linked to ovulation," said lead author, Joellen Schildkraut. "This strongly suggests that women at risk for this type of cancer can protect themselves by suppressing their ovulation." The study also means that the rest of ovarian cancers are likely caused by "different pathways" that aren't linked to ovulation, said Schildkraut, assistant professor in community and family medicine and a researcher at Duke Comprehensive Cancer Center. Some of those pathways are due to different genetic mutations. "This is one of the first studies to show that ovarian cancer is really a collection of a number of different cancers," said Berchuck. "Each subgroup will have its own risk factors, which can help physicians tailor protective strategies and specific treatments." The Duke study is novel because it takes a "molecular epidemiology"approach to the disease, in order to link risk factors seen over a population of patients to alterations in the biology of the cell, Berchuck said. "We are trying to understand on a cellular basis why cancer behaves differently in different patients." For this study, the researchers used one of ovarian cancer's "molecular signatures" -- over-expression of the p53 gene in cell tissue. Such over-expression is characterized by abnormal accumulation of the gene's protein and occurs when that gene is mutated. They then tested for the presence of p53 mutations in samples of ovarian tumors taken from 197 cancer patients. These women had participated in the Cancer and Steroid Hormone (CASH) study, which also included a "control" group of 3,363 cancer-free women. All of the women were interviewed to collect data on their socioeconomic status, age at menarche (beginning of ovulation) and menopause, use of oral contraceptives, and other hormones, infertility, pregnancy, breast-feeding, medical history, family history of cancer, as well as other information. For each woman, the number of lifetime ovulatory cycles (LOC) was computed. The formula derived was based on an average of 13 cycles per year (each 28 days long), minus the months a woman was pregnant, breast-feeding or using birth control pills. Variations in a woman's cycle -- whether she ovulated more or less than the typical 13 times yearly -- was not considered. An average woman starts ovulating at age 12.5 and enters menopause at 50, so her unsuppressed number of lifetime ovulations is about 487. Schildkraut, Berchuck and co-investigator Eugenia Bastos, also from Duke, then compared the LOC of women with cancer that over expressed p53 protein (p53-positive) to women whose cancer did not have a p53 signature (p53-negative). Estimating that 235-375 cycles is a "medium" LOC and 376 to 533 is a "high" LOC, they found: •Women with p53-positive tumors were seven times more likely to have had a moderate number of LOCs and 7.7 times more likely to have had a high number of LOCs than women with p53-negative tumors. •When data were controlled for age, menopausal and child-bearing status, women with p53- positive tumors were 4.3 times more likely to have had a moderate number of LOCs and 9.1 times more likely to have had a high number of LOCs compared with the cancer-free control group. "This supports what other epidemiological studies have postulated -- that suppression of ovulation due to breast-feeding, number of pregnancies, and use of oral contraceptives decreases the risk of this type of cancer," Schildkraut said in an interview. Berchuck added that the results show "a dose response. The more you do of each increases your protection." Additionally, women who have longer cycles than the typical 28 days have less exposure to DNA damage, while women whose cycles are shorter are at a higher risk because they ovulate more over a lifetime, Berchuck said. Berchuck said the study provides the "first real evidence of how birth control pills work at a cellular level to prevent ovarian cancer." The researchers noted that the 197 patients included in the study ranged from 20 to 54 years of age, but that the mean age of onset of ovarian cancer is 60. They said further study of the association between ovulation and p53-associated cancer is needed in a large group of older women. "If our data show this kind of association in younger women who haven't yet completed their ovulatory lives, it makes sense that total LOCs will be even more powerful a risk factor," said Berchuck. The study also suggests that development of a drug that specifically promotes cell death (apoptosis) in ovarian tissue after ovulation might help women reduce their risk of DNA damage, but still allow them to ovulate. "There is some evidence that causing these cells to die protects against ovarian cancer because it eliminates mutated cells," Schildkraut said. Berchuck's presentation of the study's preliminary findings at the Society of Gynecologic Oncologists' annual meeting in March was cited as the best oral presentation and he was given the society's "President's Award."
--------
593-> Gwynn May Top Cobb As Baseball's All-Time Best Hitter
CHAPEL HILL -- Come late July, outfielder Tony Gwynn of the San Diego Padres could best the late, great Ty Cobb as the top hitter in baseball history. So says Dr. Michael Schell of the University of North Carolina at Chapel Hill after investigating a baseball mystery: Why do yesterday's players always look better, statistically, than today's? To Schell, that doesn't make sense. A biostatistician at the UNC Lineberger Comprehensive Cancer Center, Schell attempted to level the playing field, accounting for differences in baseball during Cobb's 1905-1928 career with the Detroit Tigers and Gwynn's career today. Officially, baseball still calculates batting averages the same way, by dividing numbers of hits by numbers of at-bats. Schell says that because the game has changed drastically since Cobb's day, averages must be adjusted statistically to compare players' ability fairly. He modified batting averages with four factors never before combined: the league average, which adjusts for how easy or hard it was to get a hit in a given year; ballpark effects, or how easy or hard it is -- or was -- to get hits in a given stadium; and variability in talent among players of different eras. Finally, he limits comparison to the first 8,000 at-bats to assess hitters only in their prime. The researcher applied the four adjustments to the game's greatest hitters, including Rod Carew, Joe Jackson, Rogers Hornsby, Honus Wagner, Ted Williams, Stan Musial and Wade Boggs. He found that Cobb and Gwynn came out on top and determined that with his 8,000th at-bat, which probably will come late this month, Gwynn could outrank Cobb as the greatest. Baseball figures Cobb's batting average at .366, Gwynn's at .339. But with Schell's four adjustments, Cobb's changes to .342, and Gwynn's became .341 at the beginning of the 1997 season, after 7,595 at-bats. So far this year, Gwynn, who will play in the July 8 All-Star Game, is batting .400 -- better than Schell estimates he must to outrank Cobb by his 8,000th at-bat. "Everyone thinks Cobb is the best ever in baseball, and no player today can touch him," said Schell. "But if Gwynn bats .366 through the end of July, by my estimate he'll be the best." A lifelong Cincinnati Reds fan raised partly in Ohio, Schell developed the data on his own time while researching "The Top 100 Hitters," a book he has proposed to several publishers. He also intends to publish his findings in a statistics journal. In his UNC-CH job, Schell uses statistical analysis to determine which cancer treatments work best with the fewest side effects. Baseball has a lot to do with the line of work he chose: "Statisticians are big fans because baseball has the most detailed numbers of any sport." The first numbers Schell figures into his comparison of Cobb and Gwynn concern league batting averages. Those rise or fall in given years because of such changes as lowering the pitcher's mound or expanding the strike zone. The league average adjustment also accounts for the emergence of night baseball, when hitting is harder, and increased use of relief pitchers, both of which have decreased batting averages. Ballpark effects comprise the second of Schell's adjustments. He estimates Cobb's average was helped 6.4 points by favorable hitting conditions in Tiger Stadium while Gwynn has been hurt 2.3 points by the disadvantages of Jack Murphy Stadium. Though today Tiger Stadium favors pitchers, in Cobb's day it was a hitter's park. Thirdly, Schell adjusts batting averages for differences in overall player talent between the two eras. "Cobb played at a time when his competition was not as strong, and therefore he looked relatively better," Schell said. "Emergence of baseball as a solid career and addition of farm teams and spring training all helped make players more consistently better today than in Cobb's day." This modification is critical, he said. "If one adjusts only for the league batting average and the ballpark effect, the top hitters on average were the early hitters. So were the top double and home run hitters and players leading many other batting and pitching categories. It doesn't make sense that they should be best in all these aspects." A feature associated with the ballpark effect is the size of foul territory. The bigger the territory, the greater the opportunity to catch a batter out. In his final exercise to compare averages fairly, Schell cuts off comparison at 8,000 at-bats -- using 4,000 as a minimum to qualify for comparison -- to assess hitters only in their prime. He aims to avoid favoring players who retired early over those who continued playing after age reduced ability. He maintains that his adjustments are needed to assess true performance: "All those things are going to change how easy or hard it is to get a hit. You have to look at those if you want to compare players of all eras fairly." Schell has seen Gwynn play and soon will again. When the man Schell thinks will be king is scheduled for his 8,000th at-bat, in whatever park, whatever city, "I want to be there." - 30 -
--------
594-> Summer Science: Firefly Babies Advertise Their Bitter Taste
JULY 2, 1997--As children chase twinkling insects and the setting sun throws long shadows across the backyard, consider this: Light cues keep predators from snacking on baby fireflies, according to a UD study published in the Journal of Insect Behavior, released today. "A flashing neon sign may lure hungry humans to an all-night diner," says Douglas W. Tallamy, entomology and applied ecology, "but the bioluminescence of firefly larvae sends a very different message to would-be predators." The UD study is believed to offer the first laboratory-based evidence of an insect using bioluminescence--rather than coloration--as an "aposematic display," which warns predators of an unappetizing or hazardous meal. Bright colors, such as the orange and black patterns on a monarch butterfly or the yellow stripes on a wasp, are far more typical examples of aposematic display. But, Tallamy notes, coloration offers no protection in the dark. Baby fireflies (Coleoptera: Lampyridae) therefore use light signals to ward off predators, Tallamy's research team concludes. This new insight into firefly behavior may serve as an educational tool for both adults and children this summer, Tallamy says. "The more people understand about their natural world, the more they are likely to appreciate why it must be preserved for future generations," he explains. "And, children who understand why fireflies are flashing may get hooked on science." Decoding light signals Since at least 1952, researchers have known that adult fireflies use light patterns as part of a mating ritual, Tallamy says. Because baby fireflies are not mature enough to reproduce, researchers have speculated that younger specimens might use light cues for survival, rather than reproduction. Without laboratory evidence to support the theory, however, the messages sent by firefly larvae have remained a mystery--until now. With John D. Pesek, food and resource economics, and graduate student Todd J. Underwood, Tallamy tested the aposematic display theory on ordinary house mice raised in a laboratory. But first, the UD researchers needed to find out whether mice think firefly larvae taste bad. In previous laboratory studies, vertebrate predators have consistently turned up their noses at lucibufagins, compounds present in adult fireflies. But, Tallamy says, "only anecdotal evidence suggested that larvae are also distasteful." So, mice were offered a choice of either a firefly or a mealworm--a delicacy for rodents. As expected, all mice rejected the bitter fireflies, Tallamy says, even when they were still hungry enough to eat more mealworms. Next, the UD researchers tested the ability of mice to associate light with a bitter taste. At one end of a Y-shaped maze, they placed a single piece of crispy rice cereal. A second piece of cereal was soaked in a stomach-turning concoction of quinine sulphate and mustard powder before being placed on the other side of the maze, which was rigged with a light-emitting diode. Though mice initially entered the maze "with a bias toward the glowing branch," they quickly learned to steer clear of the bitter-tasting tidbit, UD researchers say. Within eight to 47 runs, all mice had selected the darkened side of the maze at least seven times in a row. "Our study answers a fundamental question that entomologists have been pondering for some time," Tallamy says. It also suggests an interesting topic for discussion between parents and children, he adds.
--------
595-> Three Steps Keep Drug Offenders Cleaner And Out Of Prison
JUNE 30, 1997--In a study of 448 drug-involved inmates released from Delaware's Gander Hill prison, a model three-step treatment program helped 77 percent avoid arrest for at least 18 months, while 47 percent remained drug free, University of Delaware researchers report in today's Journal of Drug Issues. By comparison, prison-based drug treatment only--with no follow-up care in a community setting--kept 22 percent of inmates straight, while 43 percent were not arrested for a year and a half, says James A. Inciardi, professor of criminal justice and director of UD's Center for Drug and Alcohol Studies. Among a third group of subjects who received no treatment at all, Inciardi adds, the statistics were predictably dismal. Given no care, only 16 percent of the offenders remained drug free. Forty-six percent stayed out of jail for 18 months, he says. Those who received no treatment were far more likely to drink too much alcohol, he notes. Inciardi's research team conducted lengthy interviews to document each subject's criminal and drug-abuse history, sexual activity, psychosocial and mental health status and sociodemographic background. The researchers also analyzed blood and urine samples to assess drug and alcohol use among the inmates. Drugs and crime often go hand-in-hand, the journal article notes. In fact, the researchers conclude, "street drugs seem to lock users into patterns of criminality that are more acute, dynamic, unremitting, and enduring than those of other offenders." The study compared graduates of KEY, a prison-based treatment program at Gander Hill prison, with those who also participated in the community-based CREST program for work-release candidates. These results were then compared with data collected before the treatment programs were established. Drug-involved offenders seem to stay straight longer when they complete a three-step program--moving from the general prison population to a cloistered treatment group inside the facility and finally into a community-based setting. The UD-managed CREST program, directed by Inciardi, was launched in 1990, thanks to a multimillion-dollar grant from the National Institute on Drug Abuse. To date, more than 550 people have received treatment through the CREST program. ###
--------
596-> Researchers Find Direct Evidence That Humans Cause Global Warming
(Boston, Mass.) -- Scientists have found the strongest evidence to date that human activity--burning fossil fuel and cutting down forests--causes global warming. Robert K. Kaufmann, associate professor of geography at Boston University, and David I. Stern, research fellow at Australian National University, uncovered the evidence using statistical analysis. Their full report, "Evidence for Human Influence on Climate from Hemisphere Temperature Relations," will appear in Nature on July 3. While most climatologists agree that the earth's average surface temperature has increased by about 0.6 degrees Celsius over the past century, they have been uncertain about the cause--natural forces or human activity. Kaufmann and Stern examined the northern and southern hemispheres' historical temperature record from 1865 to 1994. Using a statistical technique known as the Granger causality test, they found that there was a "causal order" from the southern hemisphere to the northern hemisphere. "What causal order means is that past values for temperature in the southern hemisphere help us predict temperature in the northern hemisphere better than just looking at past values for temperature in the northern hemisphere," says Kaufmann. Temperature in the northern hemisphere, he adds, where most human activity takes place, is in a statistical--but not physical--sense, dependent on temperature in the southern hemisphere. The reverse is not true. Kaufmann and Stern then tried to account for the causal order with variables that represent natural forces and variables that represent the effects of human activity. Their results showed that changes in solar and volcanic activity alone could not account for the pattern of temperature change. The best explanation for this causal order pattern, says Kaufmann, was human activity--burning coal, oil and natural gas; cutting down forests; and emitting chloro-flouro carbons (gases used in air conditioners and refrigerators). "The south-north causal order is generated by human activities that increase the warming effect of greenhouse gases globally, but also increase the cooling effects of sulfate aerosols mainly in the northern hemisphere," says Kaufmann. Sulfate aerosols, formed from particles when coal and oil is burned, reflect sunlight and produce a cooling effect on the earth's temperature. "Southern hemisphere temperature, therefore, reflects the increase in greenhouse gases," says Kaufmann. In the northern hemisphere, this "greenhouse signal" is partly obscured by the sulfate aerosols in the lower atmosphere. The differential effect of the greenhouse gases and sulfates on temperature in the northern and southern hemispheres has increased over time. "Eventually, the differential effects became strong enough to generate the causal order," says Kaufmann. "Only since the early 1970s has the greenhouse signal that we uncovered in our study emerged from the background noise of natural climate fluctuations." To further validate their hypothesis, Kaufmann and Stern analyzed temperature data generated by a global climate model run on a supercomputer. They attempted to find the same south-to-north causality in simulations carried out by researchers at Britain's Hadley Centre, a UK Meteorological Office division. "These researchers could not have foreseen our approach and could not have built into their model the kind of relationship we looked for," says Kaufmann. "And yet, the same results showed up in the simulation data." The same south-to-north order appears when the model is run with an atmosphere that replicates the pattern of greenhouse gases and sulfates generated by human activity, says Kaufmann. When they ran the model excluding gases emitted by human activity--or with atmospheres that simulate future rates of human activity--the order was absent or ran in the opposite direction. "The fact that the pattern of causal order changes with the concentration of greenhouse gases and sulfates in the atmosphere implies that the order of temperature change in the northern and southern hemisphere can be used as a fingerprint to identify the effects of human activity on global temperature." For more information on Kaufmann and Stern's report, call Boston University's Office of Public Relations at (617) 353-3666. - 30 -
--------
597-> Lyme Disease Still A Concern In Texas
June 27, 1997 LYME DISEASE STILL A CONCERN IN TEXAS Writer: Edith A. Chenault, (409) 845-2886, e-chenault1@tamu.edu Contact: Dr. Pete Teel, (409) 845-2516 COLLEGE STATION -- As summer heats up and more people head outdoors, precautions need to be taken to avoid two tick-borne illnesses -- Lyme disease and Rocky Mountain Spotted Fever. Both diseases are still carried by ticks in Texas, according to an entomologist with Texas A&M University. "Lyme (disease) is resident here in Texas," said Dr. Pete Teel of College Station. According to the Texas Department of Health, there were 77 cases reported by physicians in 1995 and 97 in 1996. Records to date this year suggest that the number of cases are down but the disease is still a threat to human health, he said. Tick populations are cyclical, Teel said. The Lone Star tick and the black-legged tick, both of which carry Lyme disease, produce a generation about every year to year and a half. That could explain the high number of cases even in a drought year like 1996, he said. Cases may be down this year, he explained, because tick populations are trying to rebound from the drought and because abundant rains this year have kept people from going outdoors as much. As for Rocky Mountain Spotted Fever, which can be transmitted through the American dog tick, there were six cases reported in 1995 and five in 1996. "That doesn't sound like much, but we think a lot of these cases are not reported," Teel said. "I strongly believe that what's reported to Public Health in terms of the spotted fever group activity with ticks is really the tip of the iceberg." The American dog tick is widely scattered throughout the United States, but especially in the southeastern and the central areas. "Rocky Mountain Spotted Fever can get out of hand. It's really easily treatable, it's diagnosable. However, it's often misdiagnosed because people don't think about the disease being in that area," Teel said. The classical sign for Rocky Mountain Spotted Fever is a small, spotted rash that occurs first on the palms of the hands or the soles of the feet and then spreads to other parts of the body, he said. The rash associated with Lyme disease is large and circular. Often it migrates outward from where it begins, taking on rings or redness and looking somewhat like a bull's-eye. "When physicians take biopsies of these rings, they actually find the corkscrew-shaped bacterium that is the causal agent of Lyme disease," Teel explained. The rash does not necessarily occur at the site of the tick bite, he added. Other symptoms may include swelling of the large joints, such as the knees or elbows, something resembling Bell's palsy or other neurological problems where one side of the face will droop, or a severe frontal headache. One of the difficulties in determining whether someone has Lyme disease is that it takes several weeks for the body's immune system to develop detectable antibodies. Even though the person may show symptoms, a blood test may not show the disease. Prevention includes avoiding known tick-infested areas. But if that is impossible, Teel said to wear protective, light-colored clothing. Boots should be worn if possible, with the bottom of pant legs taped around the outside of the boots with 2-inch masking tape. The last wrap of the tape may be turned over. "The ticks will crawl up the outside of your pants, not the inside. If you war light-colored clothing, it gives you a chance to see them and remove them. The tape gives you a physical barrier," he explained. There are several good repellents on the market, too, he said. Inspect children thoroughly after they may have been exposed. "Pay particular attention to the hair around the base of the scalp. That's a notorious place people tend to overlook," he said. There have been cases of paralysis where a child had a tick feed at the base of the hair line, close to the spinal cord. "All you have to do is remove the tick and it stops the tick from injecting more toxins into the bloodstream. Usually within 24 hours that person is back up and walking around," he said. Pets and working dogs that may go along should be inspected, as well. Ticks may be removed by grasping it as close to the head as possible to the head region with a tissue or pair of tweezers, pulling it steadily until it releases itself from the body. Try to avoid direct contact with the tick. Forceps should not be used since they may crush the tick, pinch the body from the head, or crush the salivary glands. Additionally, no one should use alcohol or a hot head of a match or pin. Any of these methods may cause them to salivate more and release more toxins into the body. Teel recommended that anyone who is bitten to save the tick if possible in a container with a moistened paper towel in the refrigerator. If symptoms appear in 10 days to two weeks, the tick can be tested. "Not all ticks are infected with either one of these agents, but if it happens to be infected, that is a tremendous aid in knowing how to diagnose and treat the illness," he said. Once the tick is removed, rubbing alcohol may be used on the bitten area to minimize infection. -30-
--------
598-> Lab Finds "Mad Cow" Signs Completely Absent In Texas
COLLEGE STATION -- No signs of "mad cow disease" have been found in Texas by the state's only laboratory which handles bovine autopsies, the laboratory's director said. "All the work we have done indicates there have been no cases of bovine spongiform encephalopathy, or 'mad cow disease,' in Texas," said Dr. Konrad Eugster, executive director of the Texas Veterinary Medical Diagnostic Laboratory. As part of its work and at the request of ranchers and veterinarians, the laboratory handles autopsies on any Texas cattle whose cause of death is uncertain. Brain lesions characteristic of BSE would be readily noted and the brains sent on to the National Veterinary Services Laboratory, a unit of the U.S. Department of Agriculture, for tests that confirm the presence of BSE. "The lesions are characteristic enough that any pathologist would at least suspect BSE, and we have not seen these lesions," Eugster said. "We look at every bovine brain, an average of 450 to 500 a year, even if we are already certain of others causes of death." The laboratory has tracked information for the USDA on bovine brain specimens both examined and sent on for further analysis. Between the 1990-91 and 1994-95 fiscal years, the lab examined 2,354 brains, an average of 471 per year, and none had to be sent on to the USDA. Those figures are consistent with both previous years and current figures, Eugster said. "That would be some 5,000 brains in the last 10 years, and I am certain that we have not found any lesions during that time," said Eugster, who has directed the laboratory since 1980 and has been employed there since 1970. "That should be a statistically significant sample." BSE is one of a category of diseases called transmissible spongiform encephalophathies, of which Creutzfeldt-Jakob disease is the human form. Researchers suspect cases of BSE in England may be related to a new variant of Creutzfeldt-Jakob disease identified in England, although the links have not been confirmed. Recent news articles have reported incidences of Creuzfeldt-Jakob disease in East Texas. In response, the Texas Department of Health last week issued a statement saying no evidence of BSE in cattle or the new variant of Creuzfeldt-Jakob disease in humans has been found in the United States. Creutzfeldt-Jakob disease is usually found in levels of approximately one case per million people in the United States, but the new variant has been found only in England and France. -30-
--------
599-> Cornell Researcher Helps Interpret Images Taken By Mars Pathfinder Camera
FOR RELEASE:  July 3, 1997 Contact:  Larry BernardOffice:  (607) 255-3651E-mail:  lb12@cornell.edu ITHACA, N.Y. -- When Pathfinder lands on Mars on Independence Day, the images it sends back to Earth will be interpreted with the help of a Cornell University scientist. "We're looking for anything out of the ordinary, in addition to basic geological information," said James Bell, research associate in the Cornell astronomy department's Center for Radiophysics and Space Research. Bell, chosen for the lander imaging team  just a few months ago, will help determine what types of minerals and rocks are present on the Martian surface.  The camera, a CCD video camera similar to that used by consumers for home use, is outfitted with about a dozen color filters to discriminate individual minerals.  Iron oxide, for example, should be abundant because oxidation of rock is what gives Mars its red color. "This is really a geology mission," said Bell, who will help with mineralogy and image interpretation.   "We'll look at the shape, size and color of the rocks, as well as at geologic  formations and surface-atmosphere interactions.  We'll be looking for whether the climate was different in the past, too, and anything else that looks interesting." If successful, images will be stored by the lander camera system and then will be transmitted to Earth two or three times per day, about every eight hours or so. At night, scientists will use the camera as a telescope, training it on stars and the Martian moons as they pass overhead.  "It will be like we're astronomers on the surface of Mars," Bell said. The camera, called the Imager for Mars Pathfinder (IMP), will make observations at various times during the day to detect any changes over the lifetime of the mission that might be attributed to the actions of frost, dust or sand deposition, erosion or other surface-atmosphere interactions. Observations of the general landscape, surface slopes and the distribution of rocks will be obtained by panoramic stereo images. Cornell also has a high-capacity mirror site on the Internet for information and to follow the Pathfinder mission.  The site, , can accommodate 4 million hits, or accesses, per day.  The site is maintained at the Cornell Theory Center, which houses nationally used supercomputers. -30- --------------------------------Cornell University News Service840 Hanshaw RoadIthaca, NY 14850607-255-4206 phone607-257-6397 faxAfter June 30:324 Judd Falls RoadIthaca, NY 14853607-255-4206 phone607-255-6343 faxcunews@cornell.eduhttp://www.news.cornell.edu 
--------
600-> New "Child Indicators" Report Offers Data To Track Children's Well-Being
Media contact:                                 July 2, 1997George Chartier                                NSF PR 97-48(703) 306-1070/gchartie@nsf.gov Program contact:Jeanne Griffith(703) 306-1780/jgriffit@nsf.gov NEW "CHILD INDICATORS" REPORT OFFERS DATA TO TRACK CHILDREN'SWELL-BEING The Federal Agency Forum on Child and Family Statisticsreleased today, in Washington, D.C., a new report that offers acomposite picture of the well-being of the nation's children. "America's Children:  Key National Indicators of Well-Being," presents 25 key indicators on critical aspects ofchildren's lives, including their behavior and socialenvironment, economic security, education, and health. The National Science Foundation (NSF) is one of eightagencies contributing to the new report. "This highly informative report on our nation's childrenrepresents an important new use of statistical informationavailable from many sources in the federal government," saysBennett Bertenthal, a cognitive development psychologist and headof NSF's Directorate for Social, Behavioral and EconomicSciences. "As researchers, we know that data measuring our children'slives are like individual stars; only by studying the stars, orstatistics, in relation to each other, do we begin to seeimportant patterns - a constellation that is far greater than thesum of its parts," says Bertenthal.  "By combining information onnumerous topics, this report enables us to gain a betterperspective on the whole of our children's lives, and tounderstand how each facet is related to the others. "The value of the report will be realized infuture years, as we monitor these and other indicators to learnhow children's lives are changing with changes in theirenvironments," Bertenthal says. The Federal Interagency Forum on Child and Family Statisticswas founded in 1994 and formally established by Executive Order13045 to foster coordination and collaboration in the collectionand reporting of Federal data on children and families.Statistical agencies within the departments of Agriculture,Commerce, Education, Health and Human Services, Housing and UrbanDevelopment, Justice, Labor, the National Science Foundation andthe Office of Management and Budget. For copies of the full report, contact theNational Maternal and Child Health Bureau Clearinghouse, (703)356-1964, or see the National Center for Health Statistics homepage: http://www.cdc.gov/nchswww/nchshome.htm -NSF-                                Attachment: America's Children: Data Resources NSF is making a transition to new forms of electronicdistribution of news materials.  We will eventually replace thecurrent "listserve" with a new Custom News Service.  From the NSFhome page, (URL: http://www.nsf.gov), you are now able toautomatically sign up for and receive electronic transmissions ofall materials (or those of your own choosing).  NSF is anindependent federal agency responsible for fundamental researchin all fields of science and engineering, with an annual budgetof about $3.3 billion.  NSF funds reach all 50 states, throughgrants to more than 2,000 universities and institutionsnationwide.  NSF  receives more than 50,000 requests for fundingannually, including at least 30,000 new proposals.  Also see NSFnews products at: http://www.nsf.gov:80/od/lpa/start.htm,http://www.eurekalert.org/, and http://www.ari.net/newswise FACT SHEET AMERICA'S CHILDREN: DATA RESOURCES Media Contact: George Chartier (703)306-1070, gchartie@nsf.gov The National Science Foundation (NSF) funds a number of studieson the well-being of children and periodically issues severalrelated statistical reports.  An entire directorate of NSF isdevoted to Education and Human Resources, and many researchprograms within the Directorate for Social, Behavioral andEconomic Sciences pertain to child development. Statistical Reports Reports may be accessed via the World Wide Web. For printedcopies, send e-mail request to pubs@nsf.gov, a fax to (703)6444278, or written request to: NSF Forms and Publications Unit,4201 Wilson Blvd., Room P-15, Arlington VA 22230, specifying theNSF publication number and your mailing address. * NSF 96-52  Indicators of Science & Mathematics Education 1995Parent and student profiles (education, languages, race/ethnicorigin), student proficiency in science and mathematics, andtheir learning environment (high school graduating credits,teacher profiles).                  http://www.ehr.nsf.gov/EHR/RED/redpubs.htm * NSB 96-21 Science & Engineering Indicators 1996National assessment of educational progress, changes inproficiencies by sex and race/ethnicity, state comparisons,impact of high school science and engineering course work ontransitions to college and employment, science literacy, computeraccess for the next generation.                 http://www.nsf.gov/sbe/srs/pubdata.htm * NSF 96-311  Women, Minorities and Persons with Disabilities inScience and Engineering 1996Comparative data on representation and achievement in education,factors influencing achievement, family background,characteristics of schools, students with disabilities,transition to higher education.                 http://www.nsf.gov/sbe/srs/pubdata.htm * Third International Mathematics and Science Study (TIMSS)International comparative results, produced by the InternationalAssociation for the Evaluation of Educational Achievement, andfunded in part by NSF.                 http://wwwcsteep.bc.edu/timss                                                  Research Centers and Programs * NSF National Consortium on Violence ResearchBased at Carnegie Mellon University, directed by AlfredBlumstein, this is a cross-disciplinary effort aimed atunderstanding the causes of violence.                   (412) 268-8269, ab0q@andrew.cmu.edu * The Panel Study of Income DynamicsBased at the University of Michigan, directed by Sandra Hofferthand Frank Stafford, this study tracks individual and familyincome sources and amounts, employment, family compositionchanges (economic effects of divorce on children), andresidential data. NSF is the study's major funding source.                    (313) 763-5166, http://www.umich.edu/~psid * National Bureau of Economic ResearchBased at Harvard University, directed by Martin Feldstein, thisis a network of researchers studying the economics of family.Visitors to its Web site can access NBER discussion papers on thefamily. Many of the articles that appear in the NBER Digest onresearch results are from NSF supported projects.                      (617) 868-3900, http://nber.harvard.edu * NSF Directorate for Social, Behavioral and Economic SciencesSocial Psychology research program, Human Cognition andPerception research program, Division for Science ResourcesStudies.                      http://www.nsf.gov/sbe * NSF Directorate for Education and Human ResourcesEducation systemic reform initiative, elementary and secondaryeducation research, International Mathematics and Science Study,and links to initiatives such as the Urban School SuperintendentsCoalition.                      http://www.ehr.nsf.gov                                                              -NSF- 
--------
601-> Asteroid Mathilde Reveals Her Dark Past
Don SavageHeadquarters, Washington, DC               June 30, 1997 (Phone:  202/358-1547) Helen WorthThe Johns Hopkins University Applied Physics Laboratory, Laurel, MD(Phone:  301/953-5113) RELEASE:  97-147 ASTEROID MATHILDE REVEALS HER DARK PAST More than 100 years after her discovery, asteroid 253 Mathilde has been sharing her secrets with scientists in the Science Data Center at the Johns Hopkins University Applied Physics Laboratory in Laurel, MD.  A 25-minute flyby of the asteroid by NASA's Near Earth Asteroid Rendezvous (NEAR) spacecraft on June 27 has resulted in spectacular images of a dark, crater-battered little world assumed to date from the beginning of the solar system. The Mathilde flyby is the closest encounter with an asteroid to date and the first with a C-type asteroid.  The asteroid's mean diameter was found to be 33 miles (52 kilometers), which is somewhat smaller than researchers originally estimated.  A study of the asteroid's albedo (brightness or reflective power) shows that it reflects three percent of the Sun's light, making it twice as dark as a chunk of charcoal.  Such a dark surface is believed to consist of carbon-rich material that has not been altered by planet-building processes, which melt and mix up the solar system's original building block materials. The Mathilde flyby met all its initial goals: getting a clear image of the sunlit side of the asteroid, getting color images that will give clues to the types of rock that make up the asteroid, and getting images that will help researchers determine if Mathilde has any moons.  In the next month, scientists expect to complete initial analysis of their data and have improved measurements of Mathilde's volume, mass, and density. "The Mathilde encounter was one of the most successful flybys ofall time," said Dr. Robert W. Farquhar, of the Applied Physics Laboratory,NEAR Mission Director.  "We got images that were far better than we thought possible, especially since the spacecraft was not designed for a fast flyby." Only the multispectral imager, one of six instruments on the spacecraft, was used during the flyby in order to conserve power provided by solar-powered panels.  The spacecraft was approximately 186 million miles from the Sun, too far to provide power for NEAR's other instruments. "Even though this was a very difficult undertaking," said Dr. Stamatios M. Krimigis, head of the APL Space Department that managed the program for NASA, "the NEAR Operations Team was so well prepared there was little doubt that it would succeed; not only that, but this was the smallest operations team of any planetary encounter, proving that the Discovery Program paradigm of 'smaller, faster, cheaper' is alive and well." Although Mathilde proved to be rounder than asteroids such as Gaspraand Ida, Dr. Joseph Veverka of Cornell University, Ithaca, NY, who leads the mission's imaging science team, said, "Mathilde turned out to be more irregularly shaped than most of us expected.  The degree to which the asteroid has been battered by collisions is astounding.  At first glance there are more huge craters than there is asteroid." The imager found at least five craters larger than 12 miles (20 kilometers) in diameter just on the lighted side of the asteroid.  Scientists wonder how the asteroid can remain intact after having been hit by this many projectiles, each probably at least a mile wide. The craters reveal evidence of the asteroid's makeup.  "We knew that C-asteroids are black, but we did not expect their surfaces to be as uniformly black and colorless as Mathilde's surface turned out to be," Veverka said.  "This global blandness is an important clue telling us that asteroids such as Mathilde are made of the same dark, black rock throughout because none of the craters, which are punched deep into the asteroid, show evidence of any other kind of rock."  Such uniformity seems to confirm that C-type asteroids are in fact pristine samples of the primitive building blocks of the larger planets. Dr. Donald K. Yeomans of the Jet Propulsion Laboratory, Pasadena, CA, who heads the radio science team formed to determine Mathilde's mass said, "Mathilde is an asteroid with a very tortured past."  By determining the bulk density of the asteroid, researchers will have a clue to how it was formed.  A composite of objects would have a lower density than a solid chunk from a larger asteroid.  Data analysis to determine density will not be complete until later this year, but Dr. Yeomans said, "Preliminary results suggest that Mathilde is much less dense than we had thought." One mystery that remains is Mathilde's extraordinarily slow (17.4 days) rotation rate.  Its collision history could be a factor, but more research needs to be done to determine what role such collisions have played.  The search for Mathilde moons continues; none has yet been discovered. The next major event of the NEAR mission will occur on July 3, when the spacecraft's bi-propellant engine is fired to head NEAR back toward Earth.  This deep-space maneuver will be the first time the engine has been fired and will keep both engineers and scientists in suspense for 11 minutes before they know if the maneuver was successful.  An Earth gravity-assist maneuver on Jan. 23, 1998, will send the spacecraft toward its primary target, asteroid 433 Eros.  NEAR will reach Eros nearly a year later and will remain locked in orbit around the asteroid until Feb. 6, 2000, when the mission ends. Commenting on the success of the Mathilde flyby soon after the first images were received, Dr. Wesley T. Huntress Jr., NASA Associate Administrator, Office of Space Science, said,  "It's today that the Discovery Program really begins. NEAR was the first of our Discovery missions to be launched and it's the first to return scientific results."  He said the APL-led team that managed the NEAR program proved the concept behind the Discovery Program:  that exciting planetary missions can be done at low cost, in a short time. The NEAR spacecraft was launched Feb. 17, 1996, from Cape Canaveral Air Station in Florida.  NEAR Science Team Group Leaders are: Joseph Veverka, Cornell University; Jacob I. Trombka, NASA/Goddard Space Flight Center, Greenbelt, MD; Mario H. Acuna, NASA/Goddard; Maria T. Zuber, MIT and NASA/Goddard; and Donald K. Yeomans, NASA/Jet Propulsion Laboratory, Pasadena, CA.  Andrew Cheng, JHU/APL, is the Project Scientist.  The Johns Hopkins University Applied Physics Laboratory operates the mission for NASAÕs Office of Space Science, Headquarters, Washington, DC. -end- EDITOR'S NOTE:   Images of Mathilde and the NEAR spacecraft are available for media representatives by calling the Headquarters Imaging Branch on 202/358-1900, or the JHUAPL Public Affairs Office at 301/953-5113. NASA Photo numbers (black and white only) are:97-H-446; 97-H-447; 97-H-448; 97-H-449; and 97-H-450 Mathilde flyby images and updates can be obtained on the Mathilde homepage at: http://sd-www.jhuapl.edu/NEAR/Mathilde
--------
602-> Hubble's Look At Mars Shows Canyon Dust Storm, Cloudy Conditions For Pathfinder Landing
Don SavageHeadquarters, Washington, DC                 July 1, 1997(Phone:  202/358-1547) Tammy JonesGoddard Space Flight Center, Greenbelt, MD (Phone:  301/286-5566) Ray VillardSpace Telescope Science Institute, Baltimore, MD (Phone:  410/338-4514) RELEASE:  97-148 HUBBLE'S LOOK AT MARS SHOWS CANYON DUST STORM,CLOUDY CONDITIONS FOR PATHFINDER LANDING Hubble Space Telescope pictures of Mars, taken on June 27 in preparation for the July 4 landing of the Pathfinder spacecraft, show a dust storm churning through the deep canyons of Valles Marineris, just 600 miles (1000 km) south of the Pathfinder spacecraft landing site. "Unless the dust storm were to evolve into a massive, global event, its effects on the Pathfinder mission should be minimal," says Steve Lee of the University of Colorado in Boulder.  "This is something we did not expect to see." The Hubble astronomers also report the presence of patchy cirrus clouds over the landing site and very thick clouds to the north.  Since there are so many clouds (related to low temperatures in the atmosphere causing water vapor to freeze), the dust will probably stay confined to the canyons, they conclude. If dust rises to the elevations where the water-ice clouds form, ice condenses on dust grains and the heavier ice/dust particles quickly fall back out of the atmosphere. Though the dust could extend at low altitudes over the landing site, researchers say current prevailing winds should not take the dust northward. "If dust diffuses to the landing site, the sky could turn out to be pink like that seen by Viking," says Philip James of the University of Toledo.  "Otherwise, Pathfinder will likely show blue sky with bright clouds." The imaging team includes Steve Lee of the University of Colorado at Boulder's Laboratory for Atmospheric and Space Physics; Todd Clancy of Boulder's Space Science Institute; Phillip James of the University of Toledo; Mike Wolff of the Space Science Institute; and Jim Bell of Cornell University. -end- EDITOR'S NOTE:  The image is available via the Internet at URL: http://oposite.stsci.edu/pubinfo/PR/97/23.html
--------
603-> NASA's Earth Science Program Adjusts To Loss Of Data From Japanese ADEOS Satellite
Don SavageHeadquarters, Washington DC                    July 2, 1997(Phone:  202/358-1547) Allen KenitzerGoddard Space Flight Center, Greenbelt, MD(Phone:  301/286-2806) Mary HardinJet Propulsion Laboratory, Pasadena, CA(Phone:  818/354-0344) RELEASE:  97-149 NASA'S EARTH SCIENCE PROGRAM ADJUSTS TO LOSSOF DATA FROM JAPANESE ADEOS SATELLITE "The failure of Japan's Advanced Earth Observing Satellite (ADEOS or Midori) spacecraft with the two NASA instruments aboard it is a real blow to NASA's science program," said Mike Mann, Deputy Associate Administrator, NASA's Mission to Planet Earth Strategic Enterprise, Washington, DC. "Fortunately, much of the ozone data provided by the Total Ozone Mapping Spectrometer (TOMS) science instruments aboard ADEOS can be provided by instruments on another spacecraft.  However, the sea-surface winds data provided by the NASA Scatterometer (NSCAT) will be harder to replace and were opening essentially new opportunities for research and operational users worldwide," Mann said. The two NASA instruments were aboard the ADEOS spacecraft, which on June 30 was declared lost by the National Space Development Agency of Japan (NASDA). "The collaboration between NASDA and NASA on this mission has been outstanding and is reflective of the great partnership that exists between Japan and the U.S in the area of global change research," Mann said. "NASDA has performed in an exemplary and open manner in the development of the spacecraft and in dealing with us.  However, space operations is a risky business; those of us involved in the business strive to limit the risk but sometimes mishaps do occur," Mann said. "The data we have obtained to date are extremely valuable," said Jim Graf, NSCAT project manager at NASA's Jet Propulsion Laboratory, Pasadena, CA.  "If we knew we were limited to just nine months of data, we would have chosen the period we actually got.  We obtained coverage over the summer and winter monsoon seasons and what may be the onset of an El Nino.  Perhaps the largest loss is the discontinuity of the long-term data set, which is being used to understand interannual and decadal variations in our climate." The scatterometer measured wind speed and direction over the world's oceans.  The data set is extremely valuable and versatile and is being used by climate change researchers, operational weather forecasters, and commercial ship routing firms.  During its flight, the instrument gathered 42 weeks' worth of data. Within a very few short months after launch, the value of ADEOS data was seen in U.S. weather forecasting.  "NOAA had begun using ocean surface wind products, derived from NSCAT, in weather forecasting," said Helen Wood, Director, Office of Satellite Data Processing and Distribution, National Oceanic and Atmospheric Administration.  "Ocean surface wind measurements are used in numerical weather prediction models and help forecasters more accurately determine the path and intensity of tropical storms and hurricanes." Because this instrument provided measurements that will be needed over the long term, NASA was already developing a second scatterometer instrument to continue this vital data set.  That instrument, called "SeaWinds," will be delivered to NASDA for integration on the spacecraft next April and is scheduled for launch in 1999 on ADEOS II. The launch of a Total Ozone Mapping Spectrometer sensor aboard ADEOS was helping to extend the unique data set of global total column ozone measurements begun by a similar instrument carried aboard NASA's Nimbus-7 satellite in 1978 and extended until December 1994 with the Meteor-3 TOMS. "The ADEOS spectrometer, along with the TOMS Earth Probe (EP) instruments also observed the unusual loss of Arctic polar ozone reported earlier this year," said Dr. Arlin J. Krueger, PrincipalInvestigator and Instrument Scientist for TOMS/ADEOS at NASA'sGoddard Space Flight Center, Greenbelt, MD. Although it also provided ozone coverage, NASA's Total Ozone Mapping Spectrometer/Earth Probe instrument had also been providing high ground resolution research data to complement the global data of the spectrometer on ADEOS.  As a result, its orbit is different than TOMS/ADEOS.  The EP satellite has adequate fuel to raise its present 500 km orbit to an orbit near the 800 km ADEOS orbit, where contiguous Earth coverage is possible for monitoring of ozone and volcanic eruption clouds.  NASA is considering raising TOMS/EP to a higher orbit. With this adjustment, much more complete global coverage of total ozone measurements previously provided by TOMS/ADEOS could be received.  However, some of the unique smaller-scale aerosols and ozone research being done by TOMS/EP would be lost.  The next Total Ozone Mapping Spectrometer mission is planned for launch on a Russian Meteor-3M spacecraft in 2000. The loss of the ADEOS platform has a particularly serious impact on oceanographic research since two instruments, the Ocean Color and Temperature Sensor and the Polarization and Directionality of the Earth's Reflectance, both capable of providing routine global estimates of phytoplankton pigment concentrations, were lost.  These instruments were providing the first routine global observations of ocean color and were initiating the much-needed, long-term time series of such measurements for global change studies. Future routine global ocean-color information will be provided by SeaWIFS, a commercial mission from which NASA will purchase data, currently scheduled for launch July 18. The NASA Scatterometer and Total Ozone Mapping Spectrometer/ADEOS were developed under NASA's strategic enterprise called Mission to Planet Earth, a comprehensive research effort to study Earth's land, oceans, atmosphere, ice and life as an interrelated system. NASA is cooperating with NASDA to identify the cause of the ADEOS failure and recommend a solution for future missions. -end-
--------
604-> Inhibiting Cell-Death Gene May Slow ALS Progression
A team of researchers from the Massachusetts General Hospital (MGH) has found evidence that a key programmed cell death gene may play a role in amyotrophic lateral sclerosis (ALS or Lou Gehrig's disease).  In the July 3 issue of Nature, the team reports that inhibiting the activity of the gene coding for a protein called ICE -- the first identified mammalian cell-death gene -- slowed the progression of symptoms in mice with a gene mutation causing an ALS-like illness. ALS  is a degenerative disorder of the brain and spinal cord, which causes weakness and wasting of muscles.  Patients eventually become paralyzed and die, usually within five years.  The gene that causes ALS when mutated was discovered in 1993 by researchers in MGH laboratory of Robert H. Brown Jr., MD, PhD, who is a coauthor of the current Nature paper.  That gene codes for production of an enzyme called superoxide dismutase (SOD1), known to neutralize dangerous chemicals called free radicals in the body. In the current study, the MGH researchers used two strains of transgenic mice with mutations in key genes.  One strain with mutations in SOD1 develops an ALS-like muscle disease.  The other strain has a specific mutation called M17Z in the gene coding for the ICE protein. Discovered in 1993 by a team of researchers from the MGH and the Massachusetts Institute of Technology, the ICE gene controls some instances of programmed cell death, a natural process in which cells not necessary for normal development essentially commit suicide.  The leader of the group identifying the ICE gene was Junying Yuan, PhD, also a coauthor of the Nature paper. The researchers crossed a group of SOD1 mutant mice with a group of M17Z/ICE mutant mice and determined which of their offspring carried mutations in both genes.  While mice with both mutations developed ALS-like symptoms at about the same age as those mice with the SOD1 mutation only -- about 240 days old -- the mice with both mutations lived significantly longer after disease onset than those with the single mutation -- 27 days versus almost 12 days. The results suggest that inhibiting activity of the ICE gene could slow the progression of ALS in human patients. "This result is the first indication of the genetic pathway which mediates cell death in ALS," says Robert M. Friedlander, MD, a resident in the MGH Neurosurgical Service, who is first author of the report.  "This novel insight into cell death in ALS opens a new avenue of possible therapy using drugs that inhibit the ICE cell death gene family." Yuan, who was a member of the MGH Cardiovascular Research Center (CVRC) when this research was began, now is in the Cell Biology Department at Harvard Medical School.
--------
605-> Optical Technique Allows Non-Surgical Biopsies
MGH contact: Susan McGreevey (617) 724-2764e-mail:  mcgreeveys@A1.mgh.harvard.edu June 27, 1997 Optical technique allows non-surgical biopsies A team of researchers from the Massachusetts Institute of Technology and Massachusetts General Hospital have developed a non-invasive method of detecting early signs of cancer and heart attacks, Science magazine reported today.  The new method, known as optical coherence tomography (OCT), produces a clear picture of a cross-section of bodily tissue without requiring surgical biopsy.  Using laser light, OCT can magnify tissue to allow visualization of individual cells without damaging the tissue. OCT is based on optical fiber technology, the same technology now used in telecommunications.  An optical fiber is a string-like component that guides light waves, allowing a light beam to be controlled over long distances and around bends. OCT can be compared to ultrasound, except that infrared light waves are used rather than acoustic waves.  Ultrasound sends out waves of sound and interprets the echoes reflected back by structures to create a visual image.  A ship's sonar, for example, reveals the ragged terrain of the ocean far below it.  Similarly, OCT shines a beam of infrared light into tissue structure, and its backreflections, measured from different positions, form an image of the terrain within.  Thanks to OCT's high resolution — ten times higher than either clinical MRI or high-frequency ultrasound — microscopic early signs of disruption in tissue terrain can be detected and possibly treated.  The infrared light used in OCT is introduced to tissue by means of a small catheter or endoscope, which can be used practically anywhere in the body. Seven authors are credited for the article in Science, titled "In Vivo Endoscopic Optical Biopsy with Optical Coherence Tomography."  They are senior author James G. Fujimoto, PhD, Professor in the Research Laboratory of Electronics and in the Department of Electrical Engineering and Computer Science at MIT; Guillermo J. Tearney (first author), Brett E. Bouma, Stephen A. Boppart, and Costas Pitris, all graduate student in the MIT Department of Electrical Engineering and Computer Science; and Mark E. Brezinski, MD, an MGH cardiologist. The program for developing OCT had two stages, the first of which involved imaging of transparent tissue.  This began in 1991 in Professor Fujimoto's laboratory at MIT, in collaboration with Carmen A. Puliafito, MD, director of the New England Eye Center and chairman of Ophthalmology at Tufts University School of Medicine.  OCT imaging of the retina provides a "very powerful tool for ophthalmic diagnostics, especially for conditions such as glaucoma and macular edema," says Professor Fujimoto.  To date, several thousand patients have been examined using OCT.  The results suggest OCT may be a promising way to diagnose early-stage glaucoma. In 1994, in a collaboration led by Professor Fujimoto and Dr. Brezinski, OCT imaging was developed for optical biopsy in nontransparent tissue, which represents most of the tissue of the body.  In the Science article, the researchers discuss using OCT to image the esophagus of a living rabbit.  "The key advance described in this article is the demonstration of OCT for imaging nontransparent tissue in vivo [in a living organism]," says Professor Fujimoto.  "This advance opens up the possibility of an incredibly broad range of clinical applications." Developing OCT to its current status required persistence and an effective collaboration among researchers.  "Three and a half years ago, I was told by many people that this project wouldn't work, that light wouldn't penetrate deeply enough.  Now we are just about ready to test OCT in patients through a high-speed, high-resolution catheter/endoscope-based system," says Dr. Brezinski, who also is an assistant professor of Medicine at Harvard Medical School and a research affiliate in the MIT Research Laboratory of Electronics and the Department of Electrical Engineering and Computer Science. "This could not have been accomplished by one or two individuals but represented the vertical integration of students, postdocs and investigators, a fact of which we are all very proud.  If you compare this to other technologies like ultrasound and MRI, we have come a tremendous way in three and a half years. The researchers suggest that OCT may replace conventional biopsy for many applications in the future.  First, OCT can be used where conventional biopsy would be hazardous, with the brain and coronary arteries being the most prominent examples.  Second, OCT could serve well where surgical biopsy can miss the diagnosis, such as in early cancer detection in the colon, esophagus and cervix.  Third, they suggest, OCT can be used to guide surgical and microsurgical procedures, such a nerve repair or prostate surgery. Further research with OCT includes working directly with patients; increasing the resolution to allow OCT to be applied to early diagnosis of such disorders as cervical cancer; and exploring technologies to use with OCT — such as spectroscopy, which may allow biochemical as well as structural information to be gained from the tissue. The National Institutes of Health, the Office for Naval Research and the Whittaker Foundation provided funding for the research described in Science. # # # contact for MIT researchers: Sarah Wright617 258-5400e-mail:  shwright@mit.edu
--------
606-> World Wide Web Worries: New Survey Shows Privacy And E-Mail Concerns -- And Trend Toward False Information
Users of the World Wide Web support government efforts aimed at protecting the privacy of confidential information, but believe the problem of unsolicited electronic mail -- known as "spam" -- can be solved by voluntary efforts similar to those used by traditional marketers. These conclusions result from the analysis of comments made by more than 19,970 Web users responding to an on-line survey conducted in April and May 1997 by researchers in the Graphics, Visualization and Usability (GVU) Center at the Georgia Institute of Technology. Respondents Support Voluntary "Opt-Out" List While few respondents said they liked to receive unsolicited e-mail, the survey found little support for laws against it. The solution favored by 38 percent of respondents was creation of an "opt-out" list of persons who do not want to receive the mailings. This would be similar to the process now used by telephone and direct mail marketers to avoid contacting persons who have indicated they do not wish to receive solicitations. "People don't like it and they see junk e-mail as a problem, but they are not willing to deal with legislative solutions," noted Colleen Kehoe, one of the researchers conducting the 7th GVU World Wide Web Survey. "The vast majority of people just delete it and don't have any filters or other sophisticated means of dealing with it." Just eight percent of the respondents supported legislation to ban the unsolicited e-mail, while 14 percent suggested some type of "impact fee" be levied on those sending the spam. Controlling "Spam" Will be Difficult Legislation now prohibits junk faxes in many states, but Kehoe believes e-mail may be more complicated to regulate because it is difficult to show a real cost to the user. While downloading unsolicited e-mail may take longer and require time to delete, it does not consume paper and toner or prevent incoming calls like unsolicited faxes, she noted. Dealing with the issue of spamming may also be difficult because there are few barriers to entry. Companies or individuals wishing to get into that business can purchase lists of e-mail addresses inexpensively and use a low-cost Internet service provider. While mass mailings violate agreements with most service providers, spammers often simply switch providers when caught. "It's very easy for people who aren't willing to play by the rules to do this," Kehoe added. Web users tend to be more protective of their e-mail accounts than their telephones or postal mailboxes. Kehoe believes that is because unsolicited paper mail and telephone solicitations have become accepted over time, while e-mail remains relatively new. Junk E-mail Less Worrisome Than "Privacy" Invasion While the respondents looked to non-government remedies for junk e-mail, they agreed that government legislation should protect the privacy of information on the Internet. Kehoe suggests the vague threat of privacy invasion is more bothersome than the known problem of e-mail. "When you give people a general concern about protecting their confidential information, which is an unknown risk that people can't assess, they choose government protection," she said. "When you talk about the specific issue of unsolicited e-mail, people know what that is and they can assess how much of a problem it is." Web Users Admit Supplying False Information Results from the latest in a long series of on-line user surveys conducted by GVU researchers may be bad news for companies hoping to charge for access to the information provided on the Web -- and for organizations that rely on information furnished by Web users. The survey found a growing number of users who admitted to falsifying information provided at Web sites. "People say they falsify information because they don't trust the entity collecting it and they are not provided with a statement explaining how the information is going to be used," Kehoe explained. Among the survey respondents, only 60 percent said they had never provided false information while registering at a Web site -- meaning 40 percent had given false information on at least one occasion. Nearly 15 percent of the users admitted to providing false information at least a quarter of the time while registering. Females were less likely than males to say they had falsified information, and older people tended to be more honest. The GVU numbers are higher than those reported in a recent Louis Harris & Associates telephone survey, but Kehoe believes those respondents may have been less willing to admit their "bad" behavior to a survey caller. Paying for Information Unpopular Web users responding to earlier editions of the GVU World Wide Web User Survey have objected to paying fees for information made available on the Web. The new survey attempted to clarify the reasons why two-thirds of respondents said they would not be willing to pay for information. Nearly half the respondents (44%) said they wouldn't pay because the information was readily available elsewhere. Another 29 percent said they did not want to pay for access to specific sites because they were already paying an Internet service provider to access the Web. Other reasons cited included cost of the information and poor quality. "People seem to be seeing the Web as a convenience, and they were not willing to pay for that," said Kehoe. "This says that sites wanting to charge for access will need to have some unique content. People will only pay to get something they couldn't get elsewhere." The results of this and earlier Web surveys may be purchased from the Georgia Tech Office of Technology Licensing (404-894- 6900) and are available on the Web at http://www.gvu.gatech.edu/user_surveys/survey-1997-04/. The next survey begins Oct. 10. Though lacking the validity of a true scientifically-selected random survey, the GVU survey of Web users has provided an interesting and widely-respected "snapshot" of who's using the giant computer network. Data was first taken on-line in January 1994 when the project was begun by researcher Jim Pitkow. Other Survey Information Includes: •Executive Summary •Proportion of Female Users •Main Problems with the Web •Web Surfing Versus Television •Providing Credit Card Info on the Web •Who'll Win The Browser Wars? •Most Important Issues Facing the Internet RESEARCH COMMUNICATIONS OFFICE 223 Centennial Research Building Georgia Institute of Technology Atlanta, Georgia 30332-0828 MEDIA RELATIONS CONTACTS:John Toon (404-894-6986) or Amanda Crowell (404-894-6980);Internet: john.toon@gtri.gatech.edu; FAX: (404-894-6983) WRITER: John Toon
--------
607-> Why Do Americans Want Children?
Do Americans see children from an economic perspective, like consumer durables, or are they perceived as invaluable social assets, like "threads from which the tapestry of life is woven?" An article in the June issue of the Population Council's Population and Development Review explores the reasons why people in low-fertility societies such as the United States continue to have children despite the high economic costs of raising them. According to Robert Schoen and his colleagues, childbearing is purposive behavior that creates and reinforces the most important and most enduring social bonds. The authors used data from the 1987-88 National Survey of Families and Households (NSFH) to examine childbearing intentions and assess the value placed on children in low fertility societies. They analyzed feedback from roughly 13,000 respondents, aged 16-39, who were asked to rank the importance of social and economic priorities, such as "giving my parents grandchildren," "having someone to care for me when I am old," "having someone to love," "being able to make major purchases," and "being able to buy a home." Respondents were also asked whether they agreed with statements such as "It?s better for someone to have a child than to go through life childless," or if they felt "uncertainty about my ability to support a child." The authors concluded that children bring a host of benefits beyond economic advantage. "While the economic value of children to their families has disappeared, their value as a social resource has persisted," the authors say. "Having children is an important way in which people create social capital for themselves." Children create social capital by establishing new relations among persons (parents, grandparents, aunts, uncles, siblings, friends) that are then available to parents as resources that they can use to achieve their interests. Schoen and colleagues add a new perspective to classic demographic theories of fertility that emphasize the economic costs and benefits of childbearing. The classic "wealth flows" theory maintains that high fertility has been economically advantageous to most families over most of human history because children created "wealth" that flowed up from the younger to the older generation. Children were seen as resources who contribute to the family economy and support their aging parents. With the shift from an agricultural to an industrial economy, the economic benefits of children virtually disappear, while their costs--in terms of education and other expenditures--increase dramatically. According to the wealth flows theory, fertility decline in the US is the result of those decreasing benefits and increasing costs. But the theory fails to provide a rationale for why fertility does not continue to fall. "In short, there is no explanation for why Americans still want children," the authors say. The social resource value of children emerges as a powerful predictor of fertility intentions. Attitudes toward childlessness significantly influence fertility intentions among respondents who had no children. For white childless men and women, married and unmarried, there is a direct relationship between the intention to have a child and the statement that "It's better for a person to have a child then to go through life childless." Intended childlessness is still uncommon, the researchers found. "Among unmarried white women, both a low value on the social resource factor and a high value on career concerns are needed before our model predicts an intention to remain childless," they say. "Stopping at one child is also relatively infrequent and is almost always associated with a low value on the social resource variable. In contrast, most persons with two or more children do not intend to have any more." Robert Schoen, Young J. Kim, and Constance A. Nathanson are Professors, Department of Population Dynamics, Johns Hopkins University. Nan Marie Astone is an Associate Professor and Jason Fields is a doctoral candidate. For a copy of this article or subscription information on Population and Development Review, call 212/339-0514 or fax 212/755-6052. For further information, contact Christina Horzepa, 212/339-0520, or Sandra Waldman, 212/339-0525. The Population Council, an international, nonprofit organization established in 1952, seeks to improve the reproductive health and wellbeing of current and future generations around the world and to help achieve a humane, equitable, and sustainable balance between people and resources. The Council analyzes population issues and trends; conducts biomedical research to develop new contraceptives; works with public and private agencies to improve the quality and outreach of family planning and reproductive health services; helps governments to influence demographic behavior; communicates the results of research in the population field to appropriate audiences; and helps build research capacities in developing countries. ###
--------
608-> Internet Moves Toward Privatization -- IP Numbers Handled By Non-Profit
The National Science Foundation (NSF) announced today an action that moves the Internet toward privatization. Internet Protocol number assignments will soon be handled by a non-profit organization. The NSF has approved a plan from Network Solutions, Inc. (NSI) which establishes the American Registry for Internet Numbers (ARIN). Under the plan, ARIN would assume full responsibility for Internet Protocol (IP) number assignments and related administrative tasks previously handled by NSI. The shift, expected to be fully implemented before March 1998, separates the assignment of Internet numbers (addresses) used for Internet routing from domain name registration activities (which will continue to be handled by Network Solutions). The move will affect only a relatively small number of Internet service providers and very large institutional users -- around 300 last year -- who obtain their IP assignments directly from NSI. Most Internet users will be unaffected by the change and most Internet service providers will continue to obtain their IP assignments from their providers. The creation of ARIN is consistent with the recommendations received from the Internet community at workshops over the past eighteen months, and with concurrence from a federal interagency working group. "This move is another step by the federal government in the continuing privatization and commercialization of the Internet," said George Strawn, director of the Networking and Communications Research and Infrastructure division at NSF. "The Internet is no longer in its infancy. It is growing up into a commercially based, self-regulating entity. NSI should be lauded for aiding this transition." The establishment of ARIN is important for the continued growth and the global stability of the Internet, Strawn said. ARIN is patterned after the successful RIPENIC and APNIC registration activities in Europe and Asia. Regional registries are also being created by providers in Latin America and Africa to assume responsibility for IP number assignment in those areas. It is anticipated that before long, a global council of the regional registries may work together to determine consistent and equitable global policies for IP allocation and management. The creation of ARIN will not change any current policies or procedures for obtaining Internet numbers. Creation of ARIN will give the users of IP numbers (mostly Internet service providers, corporations and other large institutions) a voice in the policies by which they are managed and allocated within the North American region. ARIN is intended to provide Internet service providers in North America an opportunity to help develop Internet management policies within the region and, through ARIN's collaboration with other regional registries, globally. -NSF- Editors: More information about ARIN, see: http://www.arin.net NSF is making a transition to new forms of electronic distribution of news materials. We will eventually replace the current "listserve" with a new Custom News Service. From the NSF home page, (URL: http://www.nsf.gov), you will be able to automatically sign up for and receive electronic transmissions of all materials (or those of your own choosing). NSF is an independent federal agency responsible for fundamental research in all fields of science and engineering, with an annual budget of about $3.3 billion. NSF funds reach all 50 states, through grants to more than 2,000 universities and institutions nationwide. NSF receives more than 50,000 requests for funding annually, including at least 30,000 new proposals. Also see NSF news products at: http://www.nsf.gov:80/od/lpa/start.htm, http://www.eurekalert.org, and http://www.ari.net/newswise.
--------
609-> NIH Researchers Find First Parkinson's Disease Gene
Bethesda, MD -- Scientists at the National Human Genome Research Institute (NHGRI) at the National Institutes of Health (NIH) have for the first time precisely identified a gene abnormality that causes some cases of Parkinson's disease. The gene spells out instructions for a protein called alpha synuclein. In the abnormal version of the gene, the researchers found a mutation in a single base pair-one incorrect letter in the string of more than 400 that compose the instructions for making the protein. Because the normal gene plays a role in the function of nerve cells, the finding gives researchers a powerful new tool for understanding cellular abnormalities in Parkinson's disease and demonstrates a connection between Parkinson's disease research and research into other neurological disorders, such as Alzheimer's disease. The research report appears in the June 27 issue of the journal Science. According to NHGRI's Dr. Mihael Polymeropoulos, the paper's lead author, "the finding opens completely new horizons in understanding the disease and interpreting the biology of the illness. Moreover, the finding will have an application in the not too distant future as a clinical research tool within families especially prone to Parkinson's disease and may permit us to design clinical studies for investigating drugs or other ways of postponing or offering protection from the illness." The paper confirms last fall's report-co-authored by the same NHGRI team-that a predisposition to at least one form of Parkinson's disease is inherited and that the gene responsible was situated somewhere in a large region on the long arm of chromosome 4. Until that report, most experts believed that Parkinson's disease was probably due to unknown factors present in the environment. Parkinson's disease afflicts about a 500,000 people in the United States alone, with about 50,000 new cases reported every year. Its hallmark is shaking or trembling of a limb and, in the later stages, a slow, shuffling walk and stooped posture. Parkinson's disease is a common progressive neurological disorder that results from loss of nerve cells in a region of the brain that controls movement. This degeneration creates a shortage of the brain signaling chemical-dopamine-causing impaired movement. When symptoms grow severe, doctors usually prescribe levodopa (L-dopa), which helps replace the brain's dopamine. "This finding could prove to be the most significant advance in our understanding of Parkinson's disease since the dopamine hypothesis was put forward in the mid 1960s. It is a good example of how we make progress towards the conquest of particular diseases by supporting a diversity of fundamental and clinical research. This discovery about Parkinson's disease also deepens our study of Alzheimer's disease, basic neuroscience, cell biology, and genome research and gene mapping," says NIH director, Dr. Harold Varmus. To find the gene, the scientists first studied members of a large family that came originally from Italy. Some had emigrated to the US early in this century, and more than 60 family members on both sides of the Atlantic have been diagnosed with Parkinson's disease. Efforts to locate the gene intensified after a workshop on Parkinson's disease sponsored by the National Institute of Neurological Disorders and Stroke (NINDS). At that meeting, which identified genetic research as an important area of opportunity, scientists from NIH met researchers at the Robert Wood Johnson Medical School in Piscataway, New Jersey, who had been investigating Parkinson's prone families for some time. Soon after, the NIH scientists, led by Dr. Polymeropoulos, began to carry out a genetic analysis of Parkinson's disease using DNA from patients identified and followed by an international team of researchers, including the Robert Wood Johnson team and physicans at the University of Naples, Italy. With the help of collaborators at the University of Patras Medical School in Greece, the NHGRI researchers also studied five additional unrelated families of Greek origin with a hereditary form of the disease. Using information provided by the Human Genome Project, NHGRI researchers rapidly located the mutation to a region of the genome containing approximately 100 genes. One of the genes already placed in this interval was alpha synuclein. The alpha synuclein gene was an excellent candidate for being a Parkinson's disease gene because previous research had already shown that the amyloid plaques of Alzheimer's disease patients contained fragments of the alpha synuclein protein. Considering its potential role in neurodegenerative disease, the researchers began looking at the precise sequence of alpha synuclein in normal and affected individuals. In the Italian family and three of the Greek families, the Parkinson's patients were found to possess an identical mutation in a single base pair of the alpha synuclein gene. Parkinson's disease is characterized by deposits in the brain called Lewy bodies. The researchers hypothesize the mutation in the synuclein protein causes it to aggregate, thus attracting other proteins to form a deposit that damages the cell. A similar mechanism has been proposed for the production of amyloid plaques in Alzheimer's disease. The finding that Alzheimer's disease plaques contain a fragment of alpha synuclein further strengthens the idea that a common mechanism may be operating in both of these neurodegenerative diseases. The NHGRI researchers suspect that the abnormal gene is responsible for a significant portion of familial Parkinson's disease with onset generally before the age of 60. It is not known how frequent alterations in this gene will be in later onset cases with less striking family history, though the same pathway which has been identified to be involved in these four families may turn out to be abnormal in other patients as well. Alpha synuclein is actually a member of a group of similar synuclein genes in the human genome. The NHGRI scientists are now actively searching among patients with familial Parkinson's disease who do not possess this alpha synuclein mutation for mutations in those other synuclein genes. The alpha synuclein gene, and other similar genes known to exist in the human genome, are expected to help scientists decipher additional causes of Parkinson's and perhaps shed light on other devastating and common brain disorders. "For people with Parkinson's disease, this is a small but important step in a very long journey-hopefully leading to an understanding of the basic underlying defect in Parkinson's disease which causes in the death or loss of function of the cells in the brain. If it results in a deeper understanding of how Parkinson's disease comes about, it may make us much smarter in developing therapies. But it is important to stress that at this point there is no direct therapeutic result from this finding," says the paper's senior author, NHGRI's Dr. Robert Nussbaum. Although the researchers caution that a test will provide limited information for most people, one near-term application for such a test in high-risk families will be in research aimed at developing ways of slowing or stabilizing the illness. Investigators are hoping that such preventive measures will eventually be useful in treating Parkinson's disease. The discovery of the mutant alpha synuclein gene raises issues of genetic testing that have become increasingly familiar as the list of gene discoveries lengthens. The issues are especially similar to those that have arisen in connection with genetic testing for predisposition to other diseases that appear late in life, notably Alzheimer's disease and Huntington's disease. "Discoveries like this reflect how rapid disease gene identification can be as the Human Genome Project has continued to mine the genome for its treasures," says NHGRI director Dr. Francis Collins. "As more gene sites are identified, it will become almost routine for disease gene hunters to find an already characterized gene waiting for them when they arrive at the neighborhood they know is involved in a disease. But this discovery, which raises the possibility of identifying healthy individuals at future risk for illness, also underlines again how crucial it is the provide legislative protections against misuse of the information, especially in health insurance and employment." "The results announced today highlight the importance-and benefit-of bringing new ideas into the field of Parkinson's disease research," says Dr. Zach W. Hall, Director of the NINDS. "The identity of this gene suggests an important new link between Parkinson's and Alzheimer's diseases, and may ultimately help us prevent or delay the cell death that is responsible for degenerative brain disease." NHGRI oversees the NIH's role in the Human Genome Project, an international research effort to develop tools for gene discovery. Press contact information: For interviews with Drs. Mihael Polymeropoulos or Robert Nussbaum of the National Human Genome Research Institute, contact Jeff Witherly or Galen Perry at (301) 402-8564 or -3035. For interviews with Dr. Francis Collins, Director of the National Human Genome Research Institute, contact Sharon Durham or Leslie Fink at (301) 402-0911. For interviews with Dr. Zach Hall, Director of the National Institute of Neurological Disorders and Stroke; Parkinson's patients or Parkinson's support group, contact Marian Emr at (301) 496-5924. The NHGRI website is located at: http://www.nhgri.nih.gov/ The NHGRI website will carry the press conference in audio form at 4 pm June 26th. The website will also have additional information on the research, research teams, prior Parkinson's disease research announcements, related links and public and media information on genetic research, genetic testing and the Human Genome Project. For broadcast media, downloadable broadcast quality AIFF. Electronic media will receive laboratory B-roll at the press conference which includes explanatory statements on the finding by Drs. Polymeropoulos and Nussbaum. NHGRI will also uplink B-roll by satellite starting at 1:00 p.m.--under embargo restrictions--for electronic teams unable to make the trek to Washington. --30--
--------
610-> Earthquake Could Cause Flooding Of Yucca Mountain Repository, Study Says
For Immediate Release June 24, 1997 Contact:John B. Davies or Peter Caughey303-492-6522 or 303-492-4007jdavies@colorado.eduUniversity of Colorado at Boulder Earthquake Could Cause Flooding Of Yucca Mountain Repository, Study Says An earthquake in the vicinity of the proposed high-level nuclear waste repository at Yucca Mountain could cause groundwater to surge up into the storage area, according to a new study by two University of Colorado at Boulder geophysicists. The safety of the proposed Nevada site has been debated for more than 10 years, primarily due to concerns about earthquakes and groundwater. Now it appears that one of those concerns could lead to a problem with the other. In a study to be published next month in Environmental Geology, physics research associates John B. Davies and Charles Archambeau present their conclusions on what might happen if a significant earthquake struck the Yucca Mountain area. It is the first study to assess the impact of an earthquake on the area's groundwater levels. Using computer modeling based on geological data, historical quakes and results from about 20 test wells, they showed that a magnitude 5 or 6 earthquake could raise the water table between 450-750 feet at the storage site. Because the repository would be only 600 to 800 feet above the present water table, "flooding could be expected to occur," they write. The water table below the Yucca Mountain site is unusually deep, about 1,500 feet below the surface, Davies said. But within a 6-mile area north of the proposed storage facility the groundwater level rapidly rises to a more normal depth of about 600 feet. The reason for this abrupt change in the water table is a cause for concern, Davies said. Davies and Archambeau believe that the presence of open fractures underneath Yucca Mountain has allowed the water table to descend to unusually low depths, and that closed fractures to the north have resulted in a more normal water table level. The danger is that an earthquake of sufficient magnitude could cause the open fractures underneath the Yucca Mountain site to squeeze shut, forcing the water upward into the storage facility. "If water hits the storage area it could cause a rapid corrosive breakdown of the containers and allow the plutonium to leak into the water table and the atmosphere," Davies said. Historical evidence exists for earthquakes causing groundwater to squeeze upward and even erupt from the surface, the authors said, citing the magnitude 7 quake at Idaho's Borah Mountain in 1983 and the 7.3 quake at Montana's Hebgen Lake in 1959. Both quakes occurred in areas subject to similar geological forces as Yucca Mountain. The inference also is supported by the relatively large water table changes resulting from a 5.6 magnitude earthquake at Little Skull Mountain near the proposed repository in 1992, they said. And the recent discovery by federal researchers that rainwater falling on top of Yucca Mountain has rapidly seeped 800 feet into its interior, presumably through cracks, also supports this hypothesis, Davies said. "The low water table beneath Yucca Mountain . . . implies an open fracture system to large depths producing the low water-table levels and an environment which is particularly likely to produce fracture closing and major seismic pumping following an earthquake," they write. The study of Davies and Archambeau was funded by the state of Nevada, which is opposed to the federal repository at Yucca Mountain. A study by the U.S. Geological Survey provided an alternative explanation for the steep difference in water table levels north of the site. The USGS has hypothesized that a deep underground fault stretches for 60 miles between the two different water table levels and acts as a barrier. Davies and Archambeau doubted that explanation. If an earthquake of magnitude 6 or greater were to strike, the authors' model predicts that the "wall" of water associated with the unusually steep gradient in the water table to the north of Yucca Mountain could shift southward and cause groundwater to rise 750 feet above present levels at the repository site. The containment is being designed for a minimum of 10,000 years and one or more earthquakes of that magnitude are a reasonable possibility during that time frame, the authors said. The region near Yucca Mountain is tectonically active, as witnessed by several recently active volcanic cones within a few miles of the site, the authors said. There also is strong geologic evidence that large volume spring flows have occurred at or near the surface of Yucca Mountain as recently as a few thousand years ago. "These historical geologic observations strongly imply that seismic pumping and major changes in the water table have occurred frequently in the past," Archambeau said. "Our work demonstrates what can be expected in the future and how dangerous that could be." ###
--------
611-> Homing In On Migrating Salmon
Dartmouth researchers have found a novel means of determining the tributary where an adult salmon spent its early years before moving to the sea -- vital information for salmon conservation efforts worldwide. The study, which focused on Atlantic salmon in the Connecticut River, is reported in the current issue of the journal Nature. Using a high precision isotope ratio measurement first developed by lunar scientists to analyze the geology of the moon, Dartmouth biologists Brian Kennedy and Carol Folt and geochemists Joel Blum and Page Chamberlain have shown that a unique isotope signature present in the water of a stream is incorporated into the bony structures of young salmon, or fry, soon after they begin to feed. This natural signal, derived from the geologic formations that underlie the rearing stream, can allow an adult salmon's origins to be traced with unprecedented accuracy. Under natural conditions, anadromous or "sea-going" salmon are born in freshwater streams. One to five years later, as adolescents called smolts, they swim downstream from their freshwater habitats to the ocean where they spend up to three years growing and maturing. Then they return to their home stream to breed. Extraordinary navigators, salmon sometimes cross thousands of miles to return to the site where they were born. Over the past century, dams on many rivers have stopped these natural migrations and have eliminated salmon from much of their historic range. Loss or degradation of habitat and changes in ocean climate also appear to be causing a reduction in salmon populations worldwide, and efforts to restore salmon to their native ranges are under way in many places. As part of the restoration efforts along the Connecticut River, returning adult salmon are captured at the Holyoke dam and taken away to be bred in hatcheries. Millions of young are produced this way annually, hand-stocked into fresh water when they are fingerlings - about the size of a adult's thumb. "Even though it would be useful to know the home streams of migrating fish" and to know which streams produce the most successful fish "there is no practical method of marking and tracking fish on this large a scale," says Kennedy. To address this problem, Dartmouth investigators set out to find a signal that could identify a fish with a particular stream. They chose the trace element strontium, which is dissolved in stream water in several different forms, or atomic weights, called isotopes. The proportion of different strontium isotopes in a stream is related to the composition of rocks and minerals found in the stream's watershed, giving the water in any stream a distinctive isotopic signature. The researchers proposed that this signature would be detected in the bones of salmon reared in that stream. Applying a technique that measures the relative proportions of strontium isotopes (86Sr and 87Sr) the Dartmouth group discovered that within three months of being put into a tributary, salmon incorporated the isotopic signal of that tributary into their backbones and ear-stones (called otoliths). All but two of the 20 fish measured could be precisely matched to a home stream; both of the non-matching fish are believed to have traveled from a distant waterway and retained the isotopic signature of their home stream. Of the 10 sites that were studied, the scientists could distinguish eight unique isotope signatures, suggesting that this technique may be one solution to determining the stream origins of adult salmon. "Our initial results are very promising," says Carol Folt, associate professor of biological sciences. "We are now looking at the use of additional isotopes, like nitrogen, to pinpoint salmon rearing origins with greater accuracy." ###
--------
612-> New Biodiversity Theory Suggests Rain Forest Conservation May Fall Short: Saving 'Edge' Habitats May Be Key To Saving Rain Forest Biodiversity
A team of scientists led by SFSU researcher Thomas B. Smith reports in the journal Science that ecotones, the transition areas between rain forests and savannas, may be integral to generating biodiversity in tropical rain forests. Conserving these ecotones may be critical to preserving the processes that maintain diversity in rain forests, says Smith and his colleagues, Robert K. Wayne, UCLA; Derek Girman, SFSU Romberg Tiburon Center; and Michael Bruford, the Institute of Zoology, London. "Ecotones are dynamic environments that have typically been overlooked," says Smith, an evolutionary biologist who specializes in the tropics. "The general belief is that if we preserve rain forests we're also preserving the processes that create biodiversity. But our findings suggest that the engines generating new species and increased biodiversity may lie in the unprotected ecotones at the forest periphery. " Funded by the National Geographic Society, the National Environment Research Council of the UK, the World Wildlife Fund and the Royal Society, the 6-year-long study of West African rain forests and ecotones suggests a new paradigm for how biodiversity is generated. Using molecular genetic techniques to examine the DNA of 12 populations of the little greenbul (Andropadus virens), a common West African bird species that inhabits both rain forests and adjacent ecotones, and by measuring their distinct physical characteristics, the team uncovered evidence linking ecotones with speciation. "The findings are significant because they contrast with past theories of rain forest speciation which attribute the evolution to new species to geographic isolation, to the dynamics within the forest during glacial periods," says 41-year-old Smith. "Although much more work is needed, our results suggest that, instead, ecotones may be vital to the production and maintenance of biodiversity in tropical rain forests by creating new species through the process of natural selection." In an accompanying Science news article, evolutionary biologist John Endler, who in 1977 was the first to suggest that natural selection may overcome gene flow, says Smith's work is "a major first step" in supporting the long-held hypothesis that natural selection not only shapes the physical appearance of all living organisms, but also may be important to the formation of new species. From 1990 to 1996, the team compared birds from the forest and ecotone sites. Using mist nets to trap them, they drew blood for genetic analysis and measured five physical characteristics--weight, bill depth, and wing, tarsus and upper mandible length. Smith found that although the ecotone populations were significantly different physically from their rain forest counterparts, there was considerable gene flow between them. Smith says this means that differences in natural selection may drive populations apart, despite gene flow. "If new species are formed this way," reports Smith in Science, "they may move from their ecotone cradle to the forest and contribute to the biodiversity. If the work is confirmed by other studies, it may reinforce an idea that many biologists have suggested in the past, that rain forests are sinks for new species, rather than areas where new species are generated." Rain forests contain 50 percent of the world's species, yet constitute only 7 percent of the earth's land mass. As forests shrink, says Smith, ecotones are some of the first habitats to disappear as a result of burning, wood gathering and grazing. "If further research supports the role of ecotones as centers for speciation, they will need to be preserved," he says. "If we lose these habitats, we may be losing the processes that generate biodiversity." Smith's team is continuing their work at 22 sites in West Africa. They plan to expand the study to include plants and mammals. SFSU is a highly diverse community of 27,000 students and 3,500 faculty and staff members. It is the second largest of the nationally recognized 23-campus California State University System. Founded in 1899, the university is approaching its 100th year of service to San Francisco, the Bay Area, California and beyond.
--------
613-> USGS Asks For Public's Help With Deformed Frog Research
For release: June 20, 1997 U.S. Department of the InteriorUSGS Biological Resources Division300 National CenterReston, VA 20192 Technical Contact: Dave Fellows (701) 252-5363, x5514Public Affairs Contact: Casey Stemler (703) 648-4059Casey_Stemler@nbs.gov USGS Asks For Public's Help With Deformed Frog Research U.S. and Canadian residents are being asked to help in the scientific investigation of deformed frogs, toads, and salamanders. Citizens are encouraged to report sightings of both normal and malformed amphibians that are encountered during hiking, fishing, or other outdoor related activities. "We need rigorous scientific investigations as well as observations from the general public to understand the observed decline in North American amphibian populations and the increase in reports of deformed amphibians," said Denny Fenn, Chief, Biological Resources Division of the U.S. Geological Survey. "Many amphibian species, including northern leopard frogs, Pacific treefrogs, and several species of salamanders, have been found with deformities. Although it has not been unusual to occasionally find a deformity, such reports were infrequent until recently," Fenn said. "Only since 1995 have these reports become more common." The North American Reporting Center for Amphibian Malformations (NARCAM) is an Internet Website maintained by the USGS Northern Prairie Science Center in Jamestown, N.D. NARCAM provides information on the geographic distribution of amphibians and makes that information readily available to scientists who are investigating the problem. Scientific concern began in 1995 when middle school students on a field trip reported a high incidence of leopard frogs with misshapen, extra, or malformed limbs in a farm pond in southern Minnesota. Since then, these and other malformations, including missing and misplaced eyes, have been reported among many amphibian species in several states and provinces across the continent. Efforts to determine the cause or causes of the problem are driven by concern both for amphibian populations and for human health. Like the canaries that miners once carried to detect poison gases, amphibians may deserve attention because they are especially sensitive to chemical contaminants and other stressors in aquatic environments. Until the causes of these malformations are understood, scientists do not know whether the amphibians are being affected by something that may also pose a risk to human health. The Website (http://www.npsc.nbs.gov/narcam), which is jointly funded by the USGS and the U.S. Environmental Protection Agency, provides background information on the problem in common-language terms, maps of known incidences, photographs of malformed frogs, and sources of additional information. The site also has an easy to use data-entry form through which anyone can report an observed malformation. The report form can also be used to record the absence of malformations in a location if the observer has examined several animals. Members of the public who do not have access to a computer will soon be able to phone in reports toll-free at 1-800-238-9801. The toll-free number is scheduled to be in operation after July 1, 1997. The public is urged to use the Website or the phone number to report sightings of normal or malformed amphibians. If appropriate, NARCAM will contact a local herpetologist to visit the site to confirm species identity and record additional information. As part of the Nation's largest natural resources science agency, the Biological Resources Division of the USGS works to provide the scientific understanding and technologies needed to support the sound management and conservation of the Nation's living resources. Working in cooperation with more than 1,200 local, state and federal organizations in all 50 states and a dozen foreign countries, the USGS has a deep commitment to make data and information on the Nation's biological resources more accessible to more people. * * * USGS * * * Note to Editors and Outdoor Writers Association of America Meeting attendees: Members of the news media are invited to attend a press availability and interview with Dr. Fenn in which he will discuss the deformed amphibians research as well as the many other biological research projects in the USGS that support the work of the U.S. Fish and Wildlife Service, state natural resources agencies, and others. The availability will be held in Dover Rooms I and II at the Grenelefe Resort and Conference Center, Haines City, Fla., from 6 to 8 p.m. Local inquiries may be directed by fax to USGS at the OWAA Press Room on-site at 941-421-5063.
--------
614-> Deforestation Of Amazon Threatens More Than Just Plants And Animals
WASHINGTON, DC-- June 26, 1997--The Amazon Basin, home to largest rainforest in the world, is known for its astounding variety of plants and animals. But the rainforest may be also be home to an even more overwhelming variety of previously unknown bacteria and this diversity, just as with plants and animals, may be jeopardized by deforestation, says a report in the July issue of the journal Applied and Environmental Microbiology. The report, by James Borneman and Eric Triplett at the Agronomy Department of the University of Wisconsin, Madison, describes a study in which soil samples were taken from a mature rainforest as well as an adjacent pastureland that was the result of deforestation. The soils were sampled, using polymerase chain reaction (PCR), to isolate bacterial DNA. The researchers identified 100 different DNA sequences, 98 from bacteria and two from another domain of microorganisms known as archea. They found no duplicate sequences and none of the sequences they did find had ever been previously reported. Eighteen percent could not be classified in any known bacterial kingdom. "The microbial diversity found in the mature forest and pasture soils from eastern Amazonia is immense," says Dr. Triplett. "Even with all the work that has been done on biodiversity in the Amazon to date, clearly much more work is needed to understand the enormous genetic complexity of this region. This is even more true of microbial life." The Amazon region contains the largest body of fresh water and the largest rain forest in the world. It is home to at least 15,000 documented animal species, 8,000 of which were new to biology when they were discovered. At least 40% of the world's freshwater fish and 25% of the world's bird species reside there. Over 5,000 tree species have been described there, 235 of which were found in a single hectare in central Amazonia. Very few studies, however, have been done to examine soil microbial populations in the Amazon region, say the researchers. "It's such a rich biological reource that we decided to go and study it," says Triplett. "In the discovery of new organisms we can find previously unknown enzymes that can help further the progress of biotechnology. In addition, there are bacteria out there producing antiobiotics that we have yet to discover." In addition to just examining and identifying microbial populations, the researchers also compared the populations of the two soil samples in order to illustrate the potential impact of deforestation on microbial diversity of the soil in the region. "Comparison of the DNA clones obtained from the mature forest soils and pasture soils suggests differences between the two sites," says Dr. Triplett. "A tremendous difference was found between the forest and the pasture soils." Deforestation of tropical forests alters many soil properties, say the researchers. Analysis of the two soil samples showed distinct differences in pH, levels of certain chemicals, density and porosity. These changes in the soil properties could account for the differences in microbial populations. Dr. Triplett can be reached by phone at: (608) 262-9824 or by email at: ewtriple@facstaff.wisc.edu Applied and Environmental Microbiology is a publication of the American Society for Microbiology (ASM). With over 40,000 members worldwide, the ASM is the oldest and largest single biological membership organization in the world. Press releases and further information on the Society can be accessed through the World Wide Web at http://www.asmusa.org. If you would like to receive future releases from the ASM by electronic mail please send a message with your e-mail address to: jsliwa@asmusa.org. ###
--------
615-> Researchers Date Chinese Ice Core To 500,000 Years
COLUMBUS, Ohio -- A team of scientists has reconstructed a detailed climate record for the last 130,000 years from a thousand-foot-long ice core they drilled into a glacier on the Tibetan Plateau in 1992. Analyses suggest that the record in the core actually may go back more than 500,000 years. The ice core draws a vivid picture of a climate that changed frequently and dramatically in that region throughout the last glacial sequence -- an interval that reached back 110,000 years through the last glacial period and into the warm stage, the Eemian, that preceded it. Their report was carried in this week's issue of the journal Science. Ellen Mosley-Thompson, professor of geography at Ohio State University, said that the extreme age of the ice at the bottom of the core isn't the most important discovery coming from the analysis. "A record of this length from the sub-tropics is truly unprecedented," Mosley-Thompson said. "It's good that we've got very old ice at the bottom but the age of the ice is almost secondary to the amount of detail the core provides." With support from the National Science Foundation, the National Geographic Society, Ohio State and the Chinese National Science Foundation, an international expedition retrieved the core five years ago from the Guliya Ice Cap, a 77-square-mile glacier sitting 22,014 feet high in the Kunlun Shan Mountains of western China. Although Guliya is in the sub-tropics the ice is very cold, making it a valuable reservoir of ancient climate records. The team, headed by Lonnie Thompson, professor of geological sciences at Ohio State, used mechanical and then thermal drills to remove a 1,012-foot (308.6-meters) core from the ice cap. The core, which reached through the ice to bedrock, was split and divided between Chinese and American researchers. Ohio State researchers cut their half of the core into 34,800 individual samples that were then tested for oxygen isotope ratios, dust, pollen, and nitrate, chloride and sulfate ions. Each of these give clues to the climate in the area when the ice was originally formed. After five years of analysis, the researchers discovered the following: -- The detailed record dates back 130,000 years making it the oldest recovered from a tropical or sub-tropical ice cap. Ice at the bottom of the core may be even older. Before now, a core Thompson drilled from the Dunde ice cap in China was the oldest with an age of 40,000 years. -- The record also shows that during the last glacial sequence, there were three or four periods called interstadials when the temperature warmed to more like those today. These warm events occurred when methane, a greenhouse gas, was more abundant in the Earth's atmosphere. These warmer interstadials, along with carbon dioxide and methane increases, were first identified in cores taken from polar ice caps but they appeared as only modest changes. The changes in the Guliya core are quite substantial. -- And within parts of the core representing 15,000 to 33,000 years ago, researchers found evidence of about 100 "abrupt climate changes" as inferred from the oxygen isotope record. During this time, the oscillations occurred about every two centuries. To gauge temperature changes, the researchers measure the ratio of oxygen-18 to oxygen-16 in the ice. A reduction in the proportion of oxygen 18 molecules generally indicates a drop in atmospheric temperature as well. "The isotope ratio changes seemed to indicate a temperature shift of up to 30 degrees C," explained Keith Henderson, a graduate fellow at the Byrd Polar Research Center. "But we know that would be ludicrous. We need to come up with a much better explanation for these data." Thompson and his colleagues have spent 20 years seeking out stable ice sheets from the tropics and subtropics, and retrieving the climate records they hold. Polar ice caps such as those in Greenland and the Antarctic are so large that they can control their own weather. But the much smaller non-polar ice caps respond more directly to changes in their climate, making them excellent research tools for studying past climate variations of shorter duration. "The tropics and subtropics cover half of the Earth's surface and house more than 75 percent of the human population," Thompson said. Changes in this region can have profound impacts. For years, researchers have assumed that the climate in the tropics and sub-tropics has been fairly stable, Mosley-Thompson said. But the new core from Guliya, along with their other low-latitude ice core records, suggests that the tropics and sub-tropics may have experienced considerable climate variability during the last 100,000 years. Along with Thompson, Mosley-Thompson and Henderson, the research team included John Bolzan, senior research associate; M.E. Davis, P.-N. Lin and J. Cole-Dai, all research associates from Ohio State's Byrd Polar Research Center; T. Yao from the Lanzhou Institute of Glaciology and Geocryology, Lanzhou, China; J. Beer, Swiss Federal Institute for Environmental Science and Technology, Dubendorf, Switzerland; and H.-A. Synal, Paul Scherrer Institute, Zurich, Switzerland. # Contact: Ellen Mosley-Thompson (614) 292-6662; Thompson.4@osu.edu Written by Earle Holland (614) 292-8384; Holland.8@osu.edu
--------
616-> Breakthrough Research On Ocean Algae Could Lead To Freeze- And Drought-Resistant Crops
"The missing link" has been found in how tiny ocean algae produce a chemical substance that influences cloud formation in the atmosphere. The breakthrough research by a National Science Foundation (NSF)-funded scientist at the University of Florida at Gainesville could help explain global climate changes and make it possible to develop agricultural crops that resist freeze, drought and salt-water damage. Andrew Hanson, a plant biochemist and molecular biologist, describes his research in the June 26 issue of the journal Nature. There, he identifies the four steps by which marine algae make DMSP. Hanson explains how marine algae produce DMSP (dimethylsulfoniopropionate), which is converted into DMS (dimethylsulfide), a sulfur gas that helps clouds form in the atmosphere. For the first time, scientists now understand the precise mechanism by which algae make DMSP. Researchers have been interested in unraveling the mysteries of DMSP for more than 30 years. "This work furthers our understanding of the biological origin of atmospheric dimethylsulfide, which is a significant factor in the global sulfur cycle and may play an important role in climate regulation," said Porter Ridley, program director in NSF's metabolic biochemistry program. "We have established the biochemistry of how algae convert the common compound methionine -- which is found in all algae -- into DMSP," Hanson explained. Algae produce DMSP to protect themselves from the negative effects of high salinity and freezing. DMSP is also formed in some higher plants that are tolerant to drought, freeze and salt stress, according to Hanson. "If we can use genetic engineering to transfer the capacity to make this compound from these simple marine organisms into commercial agricultural crops, we should be able to confer a useful degree of drought, freeze and salt tolerance to these plants," Hanson said. "Citrus, for example, would be a particularly good target because it is quite sensitive to freezing and has no DMSP or any related compounds itself." "We also now have a clearer picture of how marine algae help control world climate," Hanson said. "Since DMS gas from algae is linked to cloud formation, its role in global heating and cooling could be critical. We don't know how future trends in world climate will affect marine algae, but we do know there is a feedback effect operating." When the DMS sulfur gas in ocean water enters the atmosphere by sea-air exchange, the gas is oxidized into sulfuric acid. Tiny sulfuric acid particles then help promote the formation of clouds which block and reflect heat energy from the sun back into space, resulting in a cooling effect on the earth. Hanson is not, however, able to predict whether or not global warming will have an impact on marine algae's ability to make more or less DMS, which would affect cloud formation. Most of the algae used in Hanson's research were collected along the east coast of Florida in Flagler County. -NSF- Editors: Photos are available by calling Thomas Wright in Gainesville at: (352) 392-1773. NSF is making a transition to new forms of electronic distribution of news materials. We will eventually replace the current "listserve" with a new Custom News Service. From the NSF home page, (URL: http://www.nsf.gov), you are now able to automatically sign up for and receive electronic transmissions of all materials (or those of your own choosing). Also see NSF news products at: http://www.nsf.gov:80/od/lpa/start.htm, http://www.eurekalert.org, and http://www.ari.net/newswise ###
--------
617-> Novel CU-Boulder Plant Chamber Set For July 1 Reflight On Space Shuttle
A University of Colorado at Boulder-built plant-growth chamber that carried pharmaceutical and agricultural experiments aboard an abbreviated NASA space shuttle mission in April will be reflown on a 16-day mission aboard the space shuttle Columbia July 1. The April shuttle flight was cut back to four days because of a faulty fuel cell. "Fortunately, we have had an extra three months to fine-tune our hardware and experiments," said Louis Stodieck, associate director of Bioserve Space Technologies Center, headquartered in CU-Boulder's aerospace engineering sciences department. The payload -- known as the Plant Generic Bioprocessing Apparatus, or PGBA -- and seven experiments were developed by faculty, students and industry affiliates from the center in collaboration with a team at the NASA-Ames Research Center in Moffett Field, Calif. Researchers are using the low-gravity space environment to develop products and technologies in life science, agriculture and medicine. The 125-pound, automated plant-growth facility will be used to grow food and pharmaceutical and forest plants in space, said BioServe's Alex Hoehn, who headed up design and development of the television-sized plant chamber. The plant growth chamber is the largest to be flown on a shuttle that can precisely control specific environmental conditions like temperature, humidity, light and carbon dioxide. It also is the first such device with direct data uplink, downlink and video capabilities, said Stodieck, allowing BioServe faculty and students to control and manipulate experiments from the CU-Boulder campus. Two BioServe experiments sponsored by a large U.S. pharmaceutical company will test the effects of microgravity on plant species known as sweet wormwood and rosy periwinkle. Both plants naturally produce tiny quantities of pharmaceutically important compounds --one plant makes an anti-malarial drug while the other produces precursors to anticancer agents, he said. Previous BioServe experiments indicate that significantly less lignin -- a substance in plants that affects their strength and stiffness -- is produced in microgravity. "We are hypothesizing that a decrease in lignin production in space may lead to an enhancement in other plant metabolic pathways which are of commercial benefit," said Gerard Heyenga, a principal science investigator on the study from NASA-Ames. "Increased production of plant secondary compounds could ultimately lower the costs of certain pharmaceuticals or lead to the development of new drugs." "We are entering a new era in space as plans for the construction of the international space station move ahead," said Stodieck. Because much of the cargo shuttle space will be used to ferry building materials into orbit in the coming years, there will be fewer flight opportunities for scientific experiments like those from BioServe, which has flown experiments on 12 shuttle missions, he said. "But once the space station is assembled, we expect to have near continuous access to space over the long duration needed to complete many of these experiments," he said. While the upcoming Columbia mission will provide nearly 16 days of microgravity, the space station will be able to provide months or even years that may be required for particular commercial investigations, especially those involving plants. The plant chamber will occupy the "Express Rack" aboard Columbia. Designed by Marshall Space Flight Center, the novel rack will eventually permit experiments to be quickly transferred from NASA shuttles to the International Space Station. Three of the seven astronauts on Columbia have been trained to use the BioServe plant chamber and will help manipulate experiments during the mission. In cooperation with Dean Foods Vegetable Co. of Green Bay, Wis., BioServe also will fly spinach plants in the chamber. A better understanding of the effects of low gravity on the structure, tenderness and production of sugars, starch and fatty acids in spinach may help researchers develop more tender varieties for dinner tables and heartier strains of vegetables that can withstand severe weather. BioServe also will fly loblolly pine seedlings for Georgia Pacific of Atlanta to monitor lignin and wood formation. Low-gravity research could benefit the forest products industry by allowing for the eventual development of superior strains of commercial lumber and paper products, said Heyenga. Researchers and students from Kansas State University, a joint partner in BioServe, will fly additional experiments in the PGBA. One will test the effects of microgravity on tomato gene expression, while the second will investigate methods of infecting cereal crops with nitrogen-fixing bacteria known as rhizobia that naturally benefit legumes like peas and beans by snaring nitrogen from the atmosphere. Developing ways of infecting crops like corn and wheat with rhizobium could help reduce the need for fertilizers on Earth, researchers believe. BioServe is a joint center of CU, KSU and industrial affiliates and one of 11 NASA Centers for Space Commercialization with active space flight programs. ###
--------
618-> New Study Proves Treating STDs Reduces Infectiousness Of HIV
CHAPEL HILL -- Men infected with HIV -- the virus that causes AIDS -- shed eight to 10 times as much virus in their semen if they also have other sexually transmitted diseases at the same time, according to a new study conducted in Africa. The study, done by University of North Carolina at Chapel Hill School of Medicine researchers and colleagues, proves that aggressively treating those other illnesses cuts virus levels dramatically, the scientists say. Widespread STD screening and therapy could help curtail the HIV/AIDS epidemic in Africa and other parts of the world, the study suggests. "The more virus in semen, the greater the chance for transmission to someone else," said principal investigator Dr. Myron S. Cohen, professor of medicine and chief of infectious diseases at UNC-CH. "We believe transmission of HIV is more efficient in Africa and some other areas because STDs are more prevalent there, and more HIV is transmitted during sex." A report on the findings appears in the June 28 issue of the Lancet, a British medical journal. Besides Cohen, UNC-CH authors of the report are Irving F. Hoffman, research instructor in infectious diseases, and Drs. Rachel A. Royce, assistant professor of epidemiology at the School of Public Health; Susan A. Fiscus, associate professor of microbiology; and Joseph J. Eron, assistant professor of medicine. The study involved analyzing semen from 135 HIV-infected men living in Malawi, an AIDS-ravaged nation in southern Africa where most HIV transmission is between men and women during sex. Of those patients, 86 were treated for other sexually transmitted diseases such as gonorrhea, chlamydia and trichomonas. Another 49 HIV-positive subjects, who did not have other STDs, were treated for skin problems. "We found that after a week of treatment, the amount of virus in the semen of the men with STDs dropped significantly," Cohen said. "After two weeks treatment, the levels were similar to those in men treated only for skin problems and without other diseases." "These findings are very significant," said Dr. Peter Lamptey, director of the AIDS Control and Prevention (AIDSCAP) Project of the United States Agency for International Development and Family Health International. "This study provides us with biological proof that the traditional STDs play a very important role in the HIV epidemic." "The study also demonstrates that some of the control measures that already are being implemented around the world to contain HIV, especially rapid detection and treatment for STDs, are right on," added Hoffman, who did much of the field work in Malawi. "Treating people with traditional -- and treatable --STDs, especially those individuals also infected with HIV, could have a profound effect on HIV transmission throughout the world." Dr. Paul DeLay, chief of the United States Agency for International Development's HIV-AIDS division, said STD control efforts should be expanded, citing epidemiologic studies showing such efforts could cut HIV transmission by 40 percent. "With the results from this study and others, cost-effective STD prevention and control programs can be proposed which will have a major impact on the spread of HIV," said Dr. Penny J. Hitchcock, chief of the sexually transmitted diseases branch of the National Institute of Allergy and Infectious Diseases. The UNC-CH researchers collaborated with Drs. Peter Kazembe and Martin Maida of the Lilongwe Central Hospital staff in Lilongwe, Malawi in testing and treating the patients. Besides USAID, the World Health Organization, the National Institutes of Health's Office of AIDS Research, the National Institute of Diabetes and Digestive and Kidney Diseases and the National Institute of Allergy and Infectious Diseases supported the study. Researchers were able to identify study subjects in only two months because, unlike in the United States, a high percentage of people in some African nations carry the virus, Hoffman said. As many as 15 percent of sexually active adults in Malawi are thought to be infected with HIV, Cohen said. As many as 30 percent of women living in towns and cities are infected. Africans who contract HIV are almost certain to die of AIDS within a few years because few can afford the most promising treatments being developed and offered in the United States and Europe. Other authors of the Lancet paper include John R. Dyer of UNC-CH, Celine Costello Daly of the Malawi STAFH Project, Dick Zimba of Lilongwe Central Hospital, Pietro L. Vernazza of the Kantonsspital in St. Gallen, Switzerland, and the AIDSCAP Malawi Research Group. ### Note: Cohen and Hoffman can be reached at (919) 966-2536. Contact: David Williamson Family Health International contact: Mary O'Grady, (703) 516-9779, ext. 196
--------
619-> Next Generation Internet Will Rely On Oregon Research
EUGENE—University of Oregon researchers will play a key role in developing technologies to replace today’s Internet—already a tool of unprecedented usefulness—with the Next Generation Internet, a system of vastly increased power and capability. The Defense Advanced Research Projects Agency, developers of the first Internet, have awarded UO computer scientists $1.2 million to conduct basic research. The UO researchers will provide a key element in the $300 million government-sponsored research effort. Negotiations continue around additional funding at a similar level for developing applications of the UO group’s work. “These grants put us at the forefront of developing the Next Generation Internet,” says Zary Segall, head of the UO Department of Computer and Information Science. “The government is putting a significant amount of resources into this effort. Much of the money will be spent on building new hardware. Of the money devoted to basic research, we received a significant proportion.” President Bill Clinton and Vice President Al Gore on Oct. 10, 1996, in Knoxville, Tenn., announced their commitment to improving and expanding the Internet. The Next Generation Internet (NGI) initiative carries out that commitment. The initiative is a five-year collaborative effort of numerous government agencies, universities and the private sector. The Clinton administration has made an initial three-year funding commitment of $100 million per year. Unlike the current Internet, which was created as a loosely connected network of networks, the NGI is being conceived of and designed as one huge, integrated system, explains Segall. “The NGI does not represent an incremental improvement over the current Internet, but a whole new approach,” he says. Such an advanced system will be capable of performing much more complex tasks than today’s Internet. For example, it could facilitate surgery where a surgeon is in one city or country and the patient is in another. Or, similarly, engineering experts at the headquarters of a high-tech company could use real-time audio and video links to monitor and supervise a difficult on-site repair of the company’s product that is installed thousands of miles away.  In these kinds of situations, users depending on the Internet cannot afford to receive the ‘Net equivalent of a busy signal or “out of order” message. The NGI would solve that problem. As society raises its level of trust in and reliance on the Internet to such high levels, Segall notes, corresponding increases in the ‘Net’s level of performance, security and availability will be required. UO scientists will create improvements in these areas, known collectively as Quality of Service (QoS), by developing a whole new kind of “smart” software. Members of the Oregon group—computer science Professors Segall and Steve Fickas, Assistant Professor Amr Sabry and Associate Professor Stuart Faulk and several graduate students—have experience in creating software for important and complex computer systems, such as air traffic control systems, NASA space station programs and AT&T telephone switching systems. But all these systems are, in a sense, static in comparison with NGI, which is envisioned as an evolving system. “In the world of the NGI, software needs to be ‘self adaptive’,” says Steve Fickas. “A software application, such as telesurgery, can encounter a wildly varying runtime environment, changing not only over days, but over seconds. Our task is to make software that can respond to these changes and adapt itself on the fly. Again, after the software controlling a remote scalpel has begun its work, a ‘runtime error 3, aborting’ simply will not do.” Segall points out that practical use of the new NGI-related research will begin in two or three years during the application phase of the initiative. ------------ 
--------
620-> NIAID Funds Scientists To Study Acute Infection And Early HIV Disease
An ambitious new program funded by the National Institute of Allergy and Infectious Diseases (NIAID) focuses on innovative ways to study how HIV-1 causes disease in adults.  Scientists at six research units will use interventions, such as highly active antiretroviral therapy given in the acute and early phases of infection, to increase their understanding of the mechanisms and course of HIV disease.   They will also directly study the outcomes of these interventions. The research units supported by this new effort, called the Acute Infection and Early Disease Research Program, will have both basic  and clinical components, and will receive four-year awards totaling $6.7 million for the first year.  The units are located at the Fred Hutchinson Cancer Center in Seattle, the Aaron Diamond AIDS Research Center in New York, the  University of California at San Francisco, the Johns Hopkins University  School of Medicine in Baltimore, the University of Colorado Health Sciences Center in Denver, and the University of Alabama at Birmingham. This program will build upon recent advances in understanding AIDS pathogenesis, developing potent antiretroviral therapies and creating effective tools for measuring HIV in the blood.  "The important bridge that this program will provide between basic and clinical research may have profound implications for treatment and prevention  of HIV disease," says Anthony S. Fauci,  M.D., director of NIAID. Scientists believe that events occurring during acute and early infection may determine the ultimate course of disease in an individual.  In the first weeks of infection,  individuals develop very high levels of HIV circulating in the blood (viral load) reflecting active viral replication.  Earlier  studies have shown that people with more HIV in their blood during the first six  months of infection are at greater risk of  developing AIDS more rapidly than those with less virus.  This suggests that  the degree of suppression of viral replication by the immune system during acute infection may be a critical factor in  later disease.  It also suggests that intervention with active drugs during this  phase of disease might improve outcome many years later.  There are early changes to the immune system; most people with acute infection have a  persistent decline in immune function. Scientists in the new program plan to study the roles of both host and viral factors in this decline.  Identification of such factors could improve prevention and treatment strategies. Approximately 40,000 people are newly infected with HIV each year in the United States.  Nonetheless, acute HIV infection is under-diagnosed because the symptoms associated with early HIV infection (fever, rash and fatigue) are common to many other conditions.  "Because of the difficulties in identifying individuals during the acute  and early stages of infection, few studies have examined the impact of early antiretroviral therapy on viral and immunologic factors," says Jack Killen, M.D., director of the Division of AIDS at  NIAID.  "The studies proposed by this group of renowned scientists are tremendously exciting." Following are the six Acute Infection and  Early Disease Research Program principal investigators and their proposed research plans. **Lawrence Corey, M.D., of the Fred Hutchinson Cancer Center in Seattle, will define the role of cytotoxic T lymphocytes (CTLs) in controlling early infection and determine whether initial HIV-1 specific CD8+ T cell responses are predictive of subsequent disease progression. **David Ho, M.D., of the Aaron Diamond AIDS Research Center in New  York, will examine the effect of antiretroviral therapy on virus in the blood and lymphoid tissue and on CTL response.  His team also proposes to monitor B and T cell responses. **Jay Levy, M.D., of the University of California at San Francisco, will evaluate  the effect of therapy on viral load, the rate at which the virus is produced, immune activation and CD8+ T cell function. **Joe Margolick, M.D., of the Johns Hopkins University School of Medicine, will explore how the virus adapts to the host during early infection and determine whether treatment during acute infection allows the immune system to recover its function. **Robert Schooley, M.D., of the University of Colorado Health Sciences Center in Denver, proposes to  examine the differences among virus in the lymph tissue and blood, and to determine the types of cells that are involved in active  versus latent infection. **George Shaw, M.D., Ph.D., of the University of Alabama at Birmingham, will  study where HIV is distributed and sequestered in the body and its form in various reservoirs, the dynamics of virus  reproduction and the host immunogenetic profile. NIAID, a component of the National Institutes of Health (NIH), supports research on AIDS, tuberculosis and other infectious diseases, as well as allergies and immunology.  NIH is an agency of the U.S. Department of Health and Human Services. ### NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov 
--------
621-> Two Drugs Better Than One For Treating Children With Symptomatic HIV
Initial therapy using zidovudine (AZT) combined with either lamivudine (3TC) or didanosine (ddI) is far more effective at staving off disease progression or death in children with symptomatic HIV disease than using ddI alone, according to a large multicenter study supported by the National Institutes of Health (NIH). Preliminary results of the study, which was terminated early, indicate that combination antiretroviral therapy should  be the preferred initial treatment for symptomatic HIV-infected children, particularly those under 3 years of age, who have never been treated  with anti-HIV drugs.  In many cities in the northeastern United States,  HIV disease is the leading cause of death among children ages 2 to 5. "These results provide new hope for young children who develop symptomatic HIV disease.  The preliminary results of this study clearly demonstrate that combination therapy can significantly slow disease progression and reduce the risk of death in HIV-infected infants and children, as is the case in adults," says Anthony S. Fauci, M.D., director of the National Institute of Allergy and Infectious Diseases (NIAID), which supported the study along with the National Institute of Child Health and Human Development (NICHD). On June 18, 1997, an independent Data  and Safety Monitoring Board (DSMB) reviewed preliminary results of the study, known as AIDS Clinical Trials Group (ACTG) 300, and recommended that enrollment be stopped early and that the study be closed.  The DSMB based this recommendation on the obvious improvement in clinical benefits conferred by the combination regimens over ddI monotherapy, which had been shown earlier to provide significant clinical benefits in a similar population of children.  For example, the DSMB found  that the AZT/3TC combination treatment decreased the risk of death by  80 percent relative to ddI treatment alone. "The dramatic reduction in disease progression and death noted with the combination regimens was most evident in the group under age 3," says Ross McKinney, M.D., of Duke University Medical Center in Durham, N.C., protocol chair of ACTG 300.  He adds, "The findings increase the urgency to explore the effects in young children of more intensive combinations that include protease inhibitors." Two protease inhibitors, nelfinavir and ritonavir, were recently approved for treating HIV-infected children.  Several studies using protease  inhibitors in combination with other antiretrovirals are being conducted by the Pediatric AIDS Clinical Trials Group  (PACTG).  ACTG 300 was conducted at  87 centers in the United States: 65 sites  and subsites of the PACTG, a clinical network jointly funded by NIAID and the  NICHD, and 22 sites supported by Glaxo Wellcome.  A total of 615 infants and children participated in the study; data from 596 of them were included in the preliminary analysis. These included 236 patients on AZT/3TC, 235 on ddI monotherapy and 125 on AZT/ddI.  Of the 596, 42 percent were male; 63 percent were black; 22 percent were Hispanic; 14 percent were white; and 1 percent were of other ethnic origin. ACTG 300, a randomized, double-blind Phase 2/3 study, opened in July 1995.  It was initially designed to determine the safety and efficacy of the three regimens of treatment in symptomatic HIV-infected infants and children up to 15 years of age who had received little or no prior antiretroviral therapy.  However, in February 1996, another pediatric treatment trial,  ACTG 152, found that AZT/ddI and ddI alone conferred similar  clinical benefit.  Based on these results,  the ACTG 300 protocol team decided about a year ago to stop enrollment into the AZT/ddI treatment arm. Therefore, most of the analyses done on ACTG 300  to date have compared data from the AZT/3TC  and the ddI monotherapy groups only.  For their analyses, the investigators stratified the participants by age at entry (less than 3 years or equal to or greater than 3 years) because younger children are at greater risk for developing a faster  course of HIV disease.  About 20 percent of HIV-infected children develop  serious disease in the first year of life; most of these children die by age 4 years.  Fifty-three percent of the ACTG 300 participants included in the data analyzed were younger than 3 years old. At enrollment, the patients ranged in age  from 42 days and 15 years old.  They had symptomatic HIV disease based on criteria developed by the Centers for Disease Control and Prevention (CDC) and had received less than 56 days of prior antiretroviral therapy.  The overall median CD4+ T cell count was 728 cells  per cubic millimeter (mm3) of blood. The primary clinical outcomes of the study were disease progression and survival.  Disease progression was defined as worsening to CDC Category C classification (clinical AIDS-defining condition or abnormally low CD4+ T cell count), inadequate growth, or deterioration in neurologic and  neuropsychologic function. Initially, children were assigned at random to receive either AZT/3TC, AZT/ddI or ddI alone.  Based  on the results of ACTG 152, the protocol team stopped accruing patients  into the AZT/ddI arm in May 1996, and new enrollees continued to be assigned to either of the other two treatment groups.  However, children in all three arms remained on blinded therapy and  were followed for study outcomes. The analyses of the data from children concurrently randomized to all three treatment groups  indicated that survival and delay in disease progression were significantly improved for the groups receiving either combination when compared with those  in the ddI monotherapy arm.  The  two-arm analyses found that AZT/3TC decreased the chance of disease progression, including death, by 70 percent relative to ddI monotherapy.  Growth failures and  central nervous system deterioration were the most common clinical endpoints reported.  The differences between the two groups were primarily due to outcomes in the group of children  under age 3 years, where most endpoints (83 percent) and all the deaths (three on AZT/3TC and 15 on ddI alone) occurred. Only nine cases of disease progression occurred in the older group of patients, limiting the conclusions that can be drawn from that  study stratum.  The results also revealed differences in changes in CD4+ T cell counts between the AZT/3TC and  ddI study arms from baseline to weeks 36-48.  Children who received AZT/3TC  had a significantly greater increase in absolute CD4+ T cell counts (median 73  cells/mm3) compared with the ddI treatment group (median 4 cells/mm3).  The investigators observed no major differences in the safety or toxicity of the three treatment regimens except for a slight increase in hepatic toxicity in the patients who received ddI.  In general, patients tolerated the medications well. Substudies of ACTG 300, including one evaluating HIV levels in the patients' blood and another monitoring the development of drug resistance, are currently being analyzed.   Preliminary data suggest that all treatments reduced viral load below baseline levels but that the combination regimens did so more effectively. The drugs used in the study were provided by their manufacturers, Glaxo Wellcome (AZT and 3TC) and Bristol-Meyers Squibb (ddI).  Glaxo Wellcome also supported the viral load studies. The findings from both ACTG 300 and ACTG 152 demonstrate that combination antiretroviral therapy significantly slows disease progression and decreases mortality among children with HIV disease.  The studies differ, however, as  to their conclusions regarding the relative clinical efficacy of ddI monotherapy compared with combination therapy.  Reasons for the difference between these two studies are not readily apparent but may be due in part to an increased rate of early central nervous system (CNS) progression endpoints observed in the ddI monotherapy arm of ACTG 300.  This might be related to somewhat more sensitive measures used in ACTG 300 to  assess CNS progression.  In addition, ACTG 300 had a shorter average length  of follow-up compared with ACTG 152 (11 months versus 32 months).  The protocol team has further analyses under  way to better understand the differences between the two studies. NIAID and NICHD are components of NIH.  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as HIV  disease and other sexually transmitted diseases, tuberculosis, asthma and allergies.  NICHD conducts and  supports laboratory, clinical and epidemiological research on the reproductive, neurobiologic, developmental, infectious, social and behavioral processes that determine and  maintain the health of children, adults, families and populations.  NIH is an agency of the U.S. Department of Health and Human Services. ### NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov. 
--------
622-> Clues To Impaired Male Fertility In Knockout Mouse At Jackson Lab
BAR HARBOR -- A unique mouse model developed by Jackson Laboratory and Canadian researchers exhibits significantly reduced male fertility, suggesting a critical role in reproduction and early embryonic development for the knocked-out gene product known as PC4 (proprotein convertase 4). The results are reported in the June 24, 1997, issue of Proceedings of the National Academy of Sciences (PNAS) by Majambu Mbikay of the Clinical Research Institute of Montreal at the University of Montreal, Elizabeth M. Simpson of The Jackson Laboratory, and their colleagues. Title of the report is "Impaired Fertility in Mice Deficient for the Testicular Germ-Cell Protease PC4." PC4 is a member of the proprotein convertase family of serine proteases that function in mammals to mature a variety of precursor proteins -- including prohormones, proneuropeptides, cell surface receptors, and viral surface glycoproteins -- into peptides and bioactive proteins that modulate cell growth and differentiation in development. Although some of the seven known proprotein convertases have been found to be ubiquitously expressed in the tissues of rodents and mice, PC4 has only been detected in testicular germ cells. That limited expression made PC4 a logical candidate for developing the first mouse mutant with a deficiency in a proprotein convertase. The researchers disrupted the PC4 locus (Pcsk4) by homologous recombination in embryonic stem cells to produce mice carrying the mutation. The results reported in PNAS suggest that PC4 in the male may be important for achieving fertilization and for supporting early embryonic development in mice. Several precursor proteins, or glycoproteins, are produced in spermatocytes and spermatids, and one theory is that possible failure by PC4-deficient testicular germ cells to properly process those proteins may render them incompetent for fertilization. Co-authors of the PNAS report include Haidy Tadros, Andrew Chen, Nabil G. Seidah, and Michel Chretien, Clinical Research Institute of Montreal, University of Montreal; Norito Ishida, Eve de Lamirande, and Claude Gagnon, Urology Research Laboratory, McGill University, Montreal; Mohamed El-Alfy and Yves Clermont, Department of Anatomy, McGill University; and Charlie P. Lerner, The Jackson Laboratory. 
--------
623-> When Shocking Things Happen To Otherwise Normal Materials
PULLMAN, Wash.--The world of Yogi Gupta is measured in billionths of a second and hundreds of thousands of atmospheres.  It is understandable that he wears of late a permanent grin, for he has just been given a $10 million charter to explore even more remote regions of this very unusual world over the next several years. Gupta is a shock physicist.  That means he and his colleagues study what happens to things when they are subjected to very high pressures very quickly.  One of their  principal tools is a 40-foot-long gas-fired gun deep in the basement of the Physical Sciences building at Washington State University.  They use it to fire large flat projectiles at objects of interest, which they then examine for physical and chemical changes. Gupta's is actually not as odd an occupation as one first suspects.  Though Gupta is most interested in the pure science of it all, there are practical things to be done with shock waves.  Industrial diamonds are made with shock waves.  The newest method of choice for treating kidney stones is with very small shock waves. The prevailing theory of dinosaur extinction pictures a giant meteor crashing into the earth, creating enormous shock waves.  And the conditions that shock dynamacists examine mirror those in the unimaginably hot heavy interiors of the earth and the other planets. Gupta and his colleagues are currently writing up the results of experiments over the past year using shock waves to examine soil contaminated with several organics. Another phenomenon relevant to shock dynamics is a nuclear explosion. When President George Bush established a moratorium on nuclear testing in 1992, he left the U.S. nuclear stockpile in a curious limbo.  Although the missiles are still armed, without setting one off once in a while, no one can say with absolute certainty how well they'll work if needed. But now, following a somewhat uncertain post-Cold War period, the national weapons labs, Sandia, Los Alamos, and Lawrence Livermore, have a new lease on life.  Under the umbrella of the Department of Energy funded "Science-Based Stockpile Stewardship" program, it is now their job to demonstrate, without actual testing, the safety and reliability of those aging bombs. Sandia has a brand new computer that can do a trillion calculations a second.  Not only does it  hold a speed record, it is part of the effort to simulate atomic blasts.  Livermore and Los Alamos are also acquiring comparable machines.  Officials at Livermore are cleared to build a $1.8 billion laser assemblage, the National Ignition Facility, that will be used to generate miniature explosions for studying the reliability of the aging hydrogen bombs.  And Los Alamos is home to the new Dual-Axis Radiographic Hydrotest Project, whose X-ray machines will examine how warhead parts perform during tests with conventional explosives. But esoteric as all this sounds, it is actually very applied stuff.  The scientists at the national labs need some very basic information to support and feed their models and simulations.  Such as how certain materials behave under certain conditions--such as very high pressure within a very short time frame. Which of course is where WSU and other academic institutions come in. As was announced by the Department of Energy on June 23, Gupta is the director of the newly formed Institute for Shock Physics.  Gupta sees this institute filling three roles in relation to the SBSS: doing fundamental research, training scientists, and working in partnership with the national labs. In light of this relationship, what universities are particularly good at, says Gupta, is taking on hard, long-term, fundamental problems.  Universities provide young, bright minds who bring new ideas to difficult questions.  Universities are also, relatively speaking, cost effective for fundamental research. All of this is important, says Gupta, because the SBSS represents a major shift in perspective (or "paradigm," if you will), from the "make it work" mentality of the Cold War and early nuclear era to developing a predictive capability.  The SBSS must answer questions such as what happens to the materials within the bombs over time and will they work if called upon? As such, the institute will study such things as equations of state of materials under appropriate conditions of interest, material yielding and failure, chemical decomposition of condensed explosives, interface response, and material response at high energy densities.  The institute's role will also be, as Gupta puts it, "to help uncover surprises." One example is the role of aging  on the shock response of materials. But the overarching goal that Gupta holds out for the next several years is what he calls "atoms-to-continuum" understanding and modeling of the phenomena involved.  All this means is striving to achieve a detailed understanding of a given shock phenomenon from the atomic level all the way through to the macroscopic effect. The boom, in other words, at both ends of its short-lived reality. Gupta emphasizes that they will be studying only non-nuclear materials and only be looking at basic phenomena. Shock experiments are tricky things.  As Gupta understates it, "They are very fast."  And that's it.  If you didn't catch the effects very quickly, as in a few billionths of a second, you're out of luck.  And these aren't the kind of experiments you do on a whim. Also, the ideal scientific experiment allows one to isolate conditions to test variables.  That can be hard to do with an experiment that's over in a few billionths of a second.  And how do you measure the effects of a million atmospheres? That's the job of this new institute.  And it has the pedigree.  Washington State University has a lengthy tradition of shock research, reaching back to the late 1950s.  WSU physicist George Duvall, under whom Gupta trained, is a pioneer of the field.  Over the years, approximately 65 graduate students and post docs have trained here. Gupta is very proud of the role the new institute will play in national security.  But what really drives him is the freedom given the several faculty members who will be associated with the institute to explore new ground.  A recurring theme with him is how unwilling contemporary science has become to take risks. "I believe every professor must tackle hard problems," he says.  "I can do research that will let me publish routinely.  So what?  Big deal. "I want to tackle problems that may not be do-able." Do-able or not, the journey should be interesting. (Funding for the WSU Institute for Shock Physics was announced on June 23 by Dr. Victor Reis, Assistant Secretary for Defense Programs, Department of Energy, during a televised news conference that linked Washington, D.C., and the university campus in Pullman.  The Department of Energy will provide $10 million over the next five years to WSU researchers as a part of its strategic investment in selected scientific disciplines important to the Science Based Stockpile Stewardship program.  Reis said the SBSS program is the result of a directive by President Clinton to the DOE laboratories to maintain scientific capabilities to sustain a safe and reliable nuclear stockpile without conducting nuclear tests.) ts111 
--------
624-> National Jewish Receives NIH Grant To Study Fibrotic Lung Disease
June  23, 1997 CONTACT:  Jordan Gruener (303) 398-1002 National Jewish Medical and Research Center Receives $9 Million Grant From NIH to Study Fibrotic Lung Disease The National Heart, Lung and Blood Institute at the National Institutes of Health have awarded National Jewish Medical and Research Center a $9 million Specialized Center of Research grant to study the pathogenesis and treatment of pulmonary fibrosis. The grant is $1.8 million a year for 5 years.  This work will be part of the clinical and research program of the Pulmonary and Critical Care Division of the University of Colorado Health Sciences Center. "We need to learn more about the basic mechanisms of fibrosis," said Robert Mason, M.D., a National Jewish physician and principal investigator of the study.  "We’re focusing on inflammation and growth factors as regulators of the fibrotic response." People with pulmonary fibrosis, also known as interstitial lung disease, generally suffer from cough.  Scarring in the lungs, caused by the disease, makes the lungs stiff and causes shortness of breath. "We’re trying to prevent continued scar formation in the lungs," Dr. Mason said.  "Pulmonary fibrosis is a devastating disease, like cancer, with a high mortality rate." National Jewish will continue its basic studies on the mechanism of pulmonary fibrosis and initiate clinical trials aimed at limiting the fibrotic response.  Kevin Brown, M.D., of National Jewish, will head the clinical patient assessment and be responsible for controlled clinical trials.  This work will be performed in collaboration with physicians and investigators at the University of Colorado. National Jewish researchers are conducting four interstitial lung disease research projects.  The research projects include: •  The role of T cells in inducing pulmonary fibrosis •  Interactions between the epithelium and the mesenchyme—a network of cells—during lung injury and treatment •  Regulation of the paroduction of fibrogenic growth factors by macrophages •  A clinical trial using interferon gamma to control inflammation in the lungs and to control the fibrotic response 
--------
625-> Washington State University Selected To Establish Shock Physics Institute
FOR IMMEDIATE RELEASE June 23, 1997 NEWS MEDIA CONTACTS: DOE: Chris Kielich, 202/586-5806 WSU: Al Ruddy, 509/335-4528 WASHINGTON STATE UNIVERSITY SELECTED TO ESTABLISH SHOCK PHYSICS INSTITUTE • TO UNDERSTAND AGING NUCLEAR STOCKPILE The U.S. Department of Energy plans to provide $10 million over the next five years to Washington State University (WSU) researchers to create an Institute for Shock Physics as part of DOE's strategic investment in selected scientific disciplines important to science based stockpile stewardship.  	President Clinton has directed the DOE laboratories to maintain scientific capabilities to sustain a safe and reliable nuclear weapons stockpile without conducting nuclear tests.  Shock wave research explores very rapid compression of materials, shock-induced chemical changes, detonation science and the dynamic response of materials at large compressions and deformations.   Research in shock physics, nuclear physics and radiation physics furthers understanding of the nation's enduring and aging nuclear weapons. 	"In the absence of testing, it is essential that innovative experiments, novel theoretical approaches, and computational advances be integrated to predict changes in aging nuclear weapons," said Secretary of Energy Federico Peña.  "Washington State University has been the home of some of the nation's leading shock physics research, and we look forward to the important contributions they will make, working with the department's laboratories for the nation's stockpile stewardship program." Funding for the WSU institute was announced today by Dr. Victor Reis, the Energy Department's Assistant Secretary for Defense Programs, who said that the WSU facility will conduct no experiments using nuclear materials and will focus purely on fundamental research. 	DOE selected WSU because of its nearly four decades of scientific leadership in this field, state-of-the-art research undertakings, and the noteworthy achievements by WSU alumni at the DOE laboratories.  The University’s Shock Dynamics Center is directed by physics professor Yogendra Gupta, who came to WSU in 1981 and expanded the shock wave research pioneered by George Duvall and others in the 1960s.  Besides defense-related research, a stronger and more diversified program in shock wave physics has the potential to address several other technical areas important to the Washington State region, such as aircraft safety questions concerning explosion and impact, environmental issues related to soil remediation, and the synthesis and development of novel materials. WSU President Samuel Smith called it "an historic day" for the university.  "Although a few laboratories conduct research on these fundamental questions, WSU is unique and the oldest among these university laboratories, and has been an important source of scientists for the Department of Energy.  Having the WSU Shock Physics Center become an Institute for Shock Physics in support of the Science Based Stockpile Stewardship program builds upon WSU’s continuing partnership with the Hanford National Engineering Laboratory, a partnership that has existed for nearly as long as the splitting of the atom.  The leadership of Dr. Gupta ensures an institute of the highest caliber, advancing science in important ways," Smith said. Gupta directs the research lab’s program, conducted in collaboration with other WSU faculty, visiting scientists, and a cadre of graduate students and postdoctoral research associates. Gupta’s laboratory is filled with computers and sophisticated optical, x-ray and electronic equipment.  Its original "gun," built in 1968, fires 4-inch diameter projectiles down a 40-foot long barrel at speeds in excess of 3,000 miles an hour.  When it collides with the target, various sensors and recording equipment analyze the changes occurring at the molecular and atomic levels.  Two other "guns," one that can accelerate projectiles to speeds in excess of 5,000 miles an hour, are now part of the lab’s impact facilities.  Measurements are made ranging from a millionth of a second to a trillionth of a second. The federal funding will support experimental and theoretical work of WSU faculty, students and research associates in a broad range of areas covering physics, chemistry, and materials science.  Gupta stressed that an important component of this grant will be WSU's ability to attract the brightest undergraduate and graduate students to the program. - Joint Release: DOE/AR179
--------
626-> NCSTC-BNHS Series: First Six Titles Released
Bombay: June 5,1997 - At a function held in the Hornbill House, the home of the Bombay Natural History Society, the first six titles of the NCSTC-BNHS Hornbill series of books on natural history were released. Authored by some of the most well-known and celebrated experts in the field, these titles were: 1.PREDATORS AND PREY: Nature strikes a balance by K. Ullas Karanth 2.DIVERSITY the cornerstone of life by Madhav Gadgil 3.THE INDIAN ELEPHANT: endangered in the land of of lord Ganesha by Ajay Desai 4.EXTINCTION is forever by J.C. Daniel 5.MOTHS OF INDIA: An introduction by Isaac Kehimkar 6.EVOLUTION the story of life by Renee Borges The titles have been prepared by the National Council for Science and Technology Communication and the Bombay Natural History Society, and published jointly by Vigyan Prasar and the Sanctuary Magazine.
--------
627-> University Of Florida Dental Material Helps Dentures Stay Planted
By Connie Daughtry GAINESVILLE, Fla.---Denture wearers who fear their new false teeth will slip and slide may have reason to smile. A five-year study of a dental implant material developed at the University of Florida shows it successfully prevents bone loss after tooth extraction. Jaw bone deterioration can alter facial structure, enabling some denture wearers to touch their nose with their tongue and giving them the appearance of cartoon characters Andy Gump or Popeye. Dentures also can dislodge. The problem forces many to have their dentures repeatedly relined or even replaced. Bone loss is most rapid in the first six to 24 months after tooth extraction. In the first five years, the typical person will lose almost three-eighths of an inch from each jaw. But when a slender, translucent cone-shaped implant made of Bioglass is implanted in the jaw, bone loss is slowed or prevented, said Harold Stanley, professor emeritus of oral and maxillofacial pathology and oncology at UF's College of Dentistry and head of the Bioglass implant study. "Of the more than 20 million people in the United States who wear complete dentures, 70 percent say they are dissatisfied with them, especially the lower denture," Stanley said. "Bioglass could be the substance that could make them happier. It is cheaper than alternative materials, stays in place long-term and contains natural body products." Bioglass was invented 28 years ago by former UF materials engineer Professor Larry Hench. The implants, smaller than a dime, range from 4 to 12 mm in length and are inserted into newly emptied tooth sockets. Bioglass implants bond to living bone through a reaction between a chemical substance on their surface and body fluids. Currently, the material appears to have the capacity for the fastest rate of bone and soft tissue bonding of known bioactive materials. More than 20 years ago, UF researchers first used Bioglass in baboons. Their initial strategy was to replace the whole tooth with Bioglass, but the tooth crowns immediately broke off. The Bioglass implant roots, however, remained in place, and bone began reforming on their surfaces. This discovery led to using Bioglass as root replacements in humans in 1983. Researchers were able to track 20 of 29 original patients for more than five years. The total number of implants: 168. To date, only 14.3 percent of the implants have come out of the socket and 7.7 percent required grinding down of the implant as they rose to the surface of the gum. Only 1 percent requiring grinding down, came out. The Bioglass retention rate is 86 percent after five years. Other implant studies using materials such as acrylic resin and calcium phosphate have not proven as successful. Implant losses have been reported between 8 to 55 percent with only 30 months of follow-up.  	"The overall clinical outcome of UF's Bioglass implant study, with an average of more than 85 percent of the implants being retained long-term, is significantly more favorable than results of previous investigations of other implant materials intended for the same type application," said Jack E. Lemons, director of laboratory surgical research and professor of biomaterials and surgery at the University of Alabama at Birmingham. Bioglass appears to have potential widespread use in dental research. "The bottom line for this research is to improve the quality of life for people who have lost their teeth," said co-researcher A.E. Buddy Clark, professor of prothosdontics and associate dean of the UF dental college. "When using Bioglass, future denture wearers can avoid many dental problems." The UF study can be found in the February issue of International Journal of Oral and Maxillofacial Implants. --------------------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html
--------
628-> Near Fast Approaching Asteroid 253 Mathilde
Johns Hopkins University Applied Physics Laboratory FOR IMMEDIATE RELEASE June 19, 1997 JHU/APL Media Contact: Helen Worth, Office of Public Affairs (301) 953-5113/Helen.Worth@jhuapl.edu; NASA Media Contact: Donald Savage, NASA Headquarters Office of Space Science (202) 358-1547/dsavage@hq.nasa.gov NEAR IS FAST APPROACHING ASTEROID 253 MATHILDE The Near Earth Asteroid Rendezvous (NEAR) spacecraft is closing in fast on the main-belt asteroid 253 Mathilde, as scientists prepare for the closest-ever study of an asteroid. On June 27, starting at about 8:50 a.m. EDT, NEAR will be streaking past Mathilde at 22,000 miles per hour (10 kilometers per second), just 750 miles (1,200 kilometers) from the asteroid. For 25 minutes, NEAR will take a series of 534 images using a multispectral imager. "The flyby is an important opportunity to learn more about asteroids in general and C-type [carbon-rich] asteroids in particular," says Dr. Scott L. Murchie, Instrument Scientist from The Johns Hopkins University Applied Physics Laboratory (APL), Laurel, Md. "With the data we get we will be able to determine Mathilde's size, shape, landforms, brightness, and color properties." Using a combination of spacecraft radio tracking and imaging data as well as Earth-based radar imaging techniques, researchers will be able to determine, for the first time, accurate bulk density for an asteroid. "The bulk density will provide clues as to how the asteroid formed and whether it is a monolithic structure or a collection of smaller fragments," says Dr. Donald K. Yeomans of NASA's Jet Propulsion Laboratory, who heads up the radio science experiment. As NEAR reaches its closest proximity to Mathilde, a planned loss of signal will keep researchers in suspense until the captured data begins to flow into APL's Mission Operations and Science Data centers at about 9:40 a.m.      The first complete image is expected to be available later that afternoon. "This is the first science data return of NASA's Discovery Program," says Dr. Robert W. Farquhar, NEAR Mission Director at the APL, where the spacecraft was designed and built. "What makes it even more special is that it is 'bonus science' because it is an add-on to NEAR's primary mission to study asteroid 433 Eros, at virtually no additional cost." Because the Mathilde flyby was conceived after spacecraft integration had begun, the multispectral imager was not designed for a fast flyby.  Still, researchers expect to get images and take measurements that will provide significant new information about Mathilde, which they can compare with data the Galileo spacecraft obtained during its flybys of Gaspra (1991) and Ida (1993) for a better understanding of asteroids. "Mathilde is a black asteroid made of carbon-rich rock, believed by many to be the most primitive -- least changed in the last 4.5 billion  years -- material left in the asteroid belt," says Dr. Joseph Veverka of Cornell University, who leads the mission's Science Team. "Such material has never been studied up close by a spacecraft." Located in the outer part of the asteroid belt, Mathilde will also be the largest asteroid ever visited by a spacecraft. It was discovered in 1885 and is believed to be named to honor the wife of astronomer Moritz Loewy, then-Vice Director of the Paris Observatory.      Interest in Mathilde was minimal until the NEAR flyby was announced in 1995. Since then ground-based telescopes have been used to determine, among other things, that Mathilde is a C-type asteroid and is one of the darkest objects in the solar system since it reflects only 4 percent of the light falling on it. It has been determined that Mathilde is approximately 38 miles (61 kilometers) across and has an amazingly slow rotation rate (17.4 days), which intrigues scientists since only two asteroids, 288 Glauke and 1220 Clocus, have longer rotation periods. When NEAR encounters Mathilde it will be roughly 2.0 astronomical units from the sun and 2.2 AU from the Earth (an AU is the mean distance between the Earth and sun). The spacecraft's great distance from the sun has resulted in the decision to use the limited power supplied by the solar cells frugally by activating only one of NEAR's six instruments, the multispectral imager. The NEAR spacecraft, launched Feb. 17, 1996, from Cape Canaveral Air Station in Florida, is the first spacecraft powered by solar cells to operate beyond the orbit of Mars. Its encounter with Mathilde occurs as the spacecraft heads back toward Earth after a wide swing around the sun for a "slingshot" gravity assist in January 1998.  The maneuver bends the NEAR trajectory nearly 11 degrees out of the ecliptic to put it in an orbit that will match Eros' orbital plane.  The spacecraft will reach Eros Jan. 10, 1999, orbit the asteroid for a year, and end its mission Feb. 6, 2000, with a controlled landing onto its surface. NEAR Science Team Group Leaders are: Joseph Veverka, Cornell University; Jacob I. Trombka, NASA/Goddard Space Flight Center; Mario H. Acuna, NASA/GSFC; Maria T. Zuber, MIT and NASA/GSFC; and Donald K. Yeomans, NASA/Jet Propulsion Laboratory. Andrew Cheng, JHU/APL, is the Project Scientist. Mission Operations have been the responsibility of The Johns Hopkins University Applied Physics Laboratory. ### Mathilde flyby updates can be obtained on the Mathilde homepage.  Photographs of the first Mathilde images will be available sometime during the afternoon of June 27. Also available are photographs of the NEAR spacecraft, launch, and artists' concepts of the rendezvous at Eros, and a video of Mathilde flyby animation with B-roll footage of spacecraft development and testing. Upcoming Media Events: (Please Note Time Changes From Previous Release) June 23 - 1 p.m. - Media Briefing at NASA Headquarters Auditorium, 300 E St. SW, Washington, D.C. To be broadcast live on NASA TV with 1-way audio access by calling (407) 867-1220. June 27 - 2 p.m. - Encounter Day activities at The Johns Hopkins University Applied Physics Laboratory's Kossiakoff Center, Johns Hopkins Road, Laurel, Md. Doors will open at 8 a.m. for those who wish to follow the encounter. June 30 - 1 p.m. - Press Conference at The Johns Hopkins University Applied Physics Laboratory's Kossiakoff Center, Johns Hopkins Road, Laurel, Md. To be broadcast live on NASA TV with 1-way audio access by calling (407) 867-1220. ### 
--------
629-> MACS and ACTG Studies Advance Understanding and Clinical Use of HIV Prognostic Markers
In two of the most definitive studies of prognostic markers for HIV disease published to date, investigators supported by the National Institute of Allergy and Infectious Diseases (NIAID) have found that combining HIV RNA measurements with CD4+ T cell counts provides the most accurate prediction of disease progression in HIV-infected individuals. The studies, one led by John W. Mellors, M.D., of the University of Pittsburgh School of Medicine, and Alvaro Munoz, Ph.D., of the Johns Hopkins School of Public Health, the other by Michael D. Hughes, Ph.D., of the Harvard School of Public Health, and Richard T. D'Aquila, M.D., of Massachusetts General Hospital and Harvard Medical School, appear in the June 15 issue of the Annals of Internal Medicine.  An editorial by NIAID grantee Michael D. Saag, M.D., of the University of Alabama at Birmingham, accompanies these reports. "These studies help refine our understanding of prognostic markers for HIV infection and underscore the value of routinely using both viral load measurements and CD4+ T cell counts in the care and management of individuals with HIV/AIDS," says NIAID Director Anthony S. Fauci, M.D. Last year, Dr. Mellors and his colleagues in NIAID's Multicenter AIDS Cohort Study (MACS) reported that measuring the amount of HIV RNA in the bloodstream, commonly referred to as viral load, is the single best way to predict an HIV-infected person's risk for developing AIDS or dying.  The current MACS study confirms and extends those findings. "Our study showed that, while viral load is the most powerful single predictor of outcome in HIV-infected individuals, combining it with CD4+ T cell counts allows a more precise estimation of prognosis," explains Dr. Mellors. The researchers measured HIV viral load in baseline blood samples obtained from more than 1,600 HIV-infected men who enrolled in the MACS study between March 1984 and April 1985.  Physicians measured the participants' CD4+ T cell counts at study entry and monitored the men for signs of HIV disease progression over a 10-year period.  Nearly 1,000 participants developed AIDS during this period. Using a technique known as regression tree analysis, the researchers divided study participants into 12 categories defined by discrete intervals of viral loads and CD4+ T cell counts and determined how many persons in each category had developed AIDS within three, six and nine years of their entry into the study. The researchers found that CD4+ counts provided important information for discriminating the relative risk for disease progression among individuals with similar viral load levels.  For example, only 3.6 percent of study participants with 500 or fewer copies of HIV RNA per milliliter (ml) of blood and more than 750 CD4+ T cells per cubic millimeter (mm3) of blood progressed to AIDS within nine years.  By comparison, 22.3 percent of persons with the same viral load but 750 or fewer CD4+ cells/mm3 progressed to AIDS within the same period.  At the other end of the risk spectrum, 97.9 percent of persons with baseline viral loads greater than 30,000 copies/ml and less than 200 CD4+T cells/mm3 progressed to AIDS within six years, compared with 66.8 percent who had the same viral load but greater than 500 CD4+ T cells/mm3. The MACS study was initiated prior to the availability of anti-HIV drugs.  Therefore, only 60 percent of the participants were treated with antiretrovirals during the 10-year study period.  Those who were treated received monotherapy with AZT or other nucleoside analogue drugs. "Our results were not confounded by subsequent therapy because there were no baseline differences in the values of the markers between treated and untreated individuals," says Dr. Mellors.  "These markers," he adds, "were highly predictive of outcome independent of subsequent treatment with nucleoside monotherapy.  The value of this study is that it accurately estimates prognosis for the HIV-infected individual considering therapy." In a study of the use of these measures during combination antiretroviral therapy, Drs. Hughes, D'Aquila and colleagues in NIAID's AIDS Clinical Trials Group (ACTG) found that prediction of disease progression can be optimized by measuring viral load and CD4+ T cells before, and viral load shortly after, treatment begins. The researchers measured baseline viral load and CD4+ T cell counts  in 198 HIV-infected individuals participating in ACTG study 241, which compared treatment with AZT and didanosine (ddI) to treatment with AZT, ddI and nevirapine.  These measurements were repeated eight and 48 weeks after treatments started.  Over a one-year  treatment period, the investigators monitored study participants for signs of disease progression. A total of 34 individuals developed opportunistic infections, malignancies or died during the treatment period.  There was no significant difference in the number of these events between the two treatment groups.  The researchers found that low CD4+ T cell counts and high viral loads at baseline independently predicted the risk of disease progression and death.  However, they also found that the combined use of these measures improved their predictive value: individuals with high viral loads and low CD4+ T cell counts were more likely to develop AIDS than were those with high viral loads and relatively higher CD4+ T cell counts. Measuring viral load eight weeks after treatment started provided still more prognostic information -- there was a 52 percent reduction in risk of disease progression for every 10-fold decrease in viral load at this point. "We also found that a 2.5-fold or greater change in viral load probably indicates a true biological change in an individual patient, rather than a random fluctuation," says Dr. D'Aquila.  "Our results, and those of other studies, suggest that clinicians might consider alternate treatments if a patient's viral load is not decreased by at least 2.5-fold within several weeks after a new antiretroviral regimen is initiated." NIAID, a component of the National Institutes of Health (NIH), supports research on AIDS, tuberculosis and other infectious diseases, as well as allergies and immunology.  NIH is an agency of the U.S. Department of Health and Human Services. ### NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov. Note: MACS investigators measured viral load with a branched DNA assay manufactured by Chiron Corporation (Emeryville, Calif.).  In the ACTG study, researchers measured viral load with a quantitative reverse transcription-polymerase chain reaction assay made by Roche Molecular Systems (Alameda, Calif. and Branchburg, N.J.).  Supplemental support for viral load testing in ACTG 241 was provided by Boehringer Ingleheim Pharmaceutical, Inc. (Ridgefield, Conn.).  Boehringer Ingleheim, Bristol-Myers Squibb Co. (Wallingford, Conn.) and Glaxo Wellcome Co. (Research Triangle Park, N.C.) provided study medications for ACTG 241.
--------
630-> Draft HIV/AIDS Treatment Guidelines Available
All people with CDC-defined AIDS should receive combinationantiretroviral therapy, preferably with three drugs including a protease inhibitor, according to comprehensive new Guidelines for the Use of Antiretroviral Agents in HIV-Infected Adults and Adolescents, made available today for public comment.  The Guidelines were developed by the Panel on Clinical Practices for Treatment of HIV Infection, which was convened jointly by the Department of Health and Human Services (DHHS) and the Henry J. Kaiser Family Foundation. "The decisions about treatments for people with HIV/AIDSshould be guided by regular monitoring of the amount of HIV in the patient's blood (viral load) as well as the number  of CD4+ T cells, the immune system cells that fight infection," says Anthony S. Fauci, M.D., director of the National Institute of Allergy and Infectious Diseases, National Institutes of Health. Dr. Fauci and John G. Bartlett, M.D., professor of medicineand chief of infectious diseases, Johns Hopkins University School of Medicine, co-chair the Panel that includes federal, private sector and academic experts in the clinical treatment and care of HIV-infected people, as well as representatives of AIDS interest groups, health policy groups and payer organizations. The Guidelines recommend starting treatment with threedrugs and changing at least two drugs when there are indications that treatment is failing, such as when HIV levels in the blood increase.  Treatment with only two drugs, in general, is considered less than optimal. Treatment with only one drug is not recommended.  However,zidovudine (AZT) as monotherapy is recommended as prophylaxis  to prevent HIV transmission to a baby and should be given to  relatively healthy HIV-infected pregnant women who do not require antiretroviral drugs for their own treatment.  These women and their newborns should receive AZT, according to the regimen recommended by the Public Health Service Task Force, to reduce the risk of HIV transmission to the babies. HHS Secretary Donna E. Shalala praised the Panel for itsefforts.  "Today, we are providing much-needed guidance to patients and medical practitioners," Shalala said.  "We have reason to celebrate that a diagnosis of HIV disease is no longer an automatic death sentence.  At the same time, we recognize that these new medical guidelines raise important public policy issues, and we're working rapidly to address them." DHHS Office of HIV/AIDS Policy and the Kaiser FamilyFoundation convened the three-year panel in December 1996.  "We recognize that treatment decisions have become increasingly complex with the many new drugs available and new ways of monitoring disease progression.  The Guidelines, which will be updated periodically, reflect the current state of knowledge about HIV disease and antiretroviral drugs," says Eric P. Goosby, M.D., director of the DHHS Office of HIV/AIDS Policy. "These Guidelines will help standardize and improve thequality of care for HIV-infected persons in the United States.  The Foundation is pleased to have joined with the Department of Health and Human Services in this unique public-private partnership to bring national attention to the rapid changes in HIV therapies," says Sophia Chang, M.D., director of HIV programs, Kaiser Family Foundation. "The Guidelines relied in part on a companion document, Report of the NIH Panel to Define Principles of Therapy of HIV Infection," explains Dr. Goosby, "and together they provide the scientific rationale for therapeutic strategies as well as practical guidelines for implementing the strategies." The NIH Panel was sponsored by the NIH Office of AIDSResearch and chaired by Charles C. Carpenter, M.D., professor of medicine, Brown University School of Medicine. Panelists included AIDS clinicians and researchers.  The mission of the NIH Panel was to review the current state of knowledge of antiretroviral therapies and prepare a document outlining Principles that would guide therapeutic decisions. Both documents, announced in the Federal Register June 19,1997, are available for a 30-day comment period.  The draftdocuments are available from the National AIDS Clearinghouse (1-800-458-5231) and on their Web site (http://www.cdcnac.org) and from the HIV/AIDS Treatment Information Service (1-800-448-0440) and on their Web site (http://www.hivatis.org). After consideration of comments, both documents will bepublished in the Centers for Disease Control and Prevention (CDC) Morbidity and Mortality Weekly Report.                                                  ###
--------
631-> Reversing Shock -- Gene Protects Against Cell Death
Shock can kill.  A heart attack, stroke, infection or injury can cause the profound disturbance of normal cellular functioning that doctors call shock - a biochemical and metabolic catastrophe that can lead to cell death and even death of the entire organism. University of Maryland School of Medicine researchers have found a potentially powerful new weapon for medicine's war on shock. Ironically, it's an oncogene implicated in a kind of cancer called B-cell lymphoma, from which it gets its name - bcl-2.  The products of the bcl-2 gene help prevent cell death, which is a boon to a cancer cell, although ultimately harmful to its human host. Now bcl-2 may prove helpful in preventing cell death caused by shock. Dr. Benjamin F. Trump, professor and chairman of pathology at the medical school in Baltimore, and colleagues will present results of a study of bcl-2's protective effects, at the 20th Annual Conference on Shock, on June18 in Indian Wells, California. "The precise mechanism by which bcl-2 inhibits cell death remains to be defined," said Trump, "but we believe that its protective action arises from its anti-oxidant properties, its interference with the cellular signaling process, and its modification of calcium ion transport within the cell." Oxidants, which can damage cells, are released in enormous quantities by infection, inflammation and ischemia - a blockage of blood flow - making them a far greater threat than one might think, the pathologist pointed out. For more than a decade, Trump's research has focused on the role played by ionized or electrically charged calcium, which can increase rapidly within cells after they are damaged, activating biochemical and metabolic changes that can lead to cell death. Dr. Masato Ichimiya, a surgeon and research fellow in Trump's lab, and Dr. Paul Amstad, associate professor of pathology at the University of Maryland School of Medicine, engineered normal cells from rats' kidneys to express extra bcl-2.  Those cells proved more resistant than normal controls to death from treatment with hydrogen peroxide. The toxicity of hydrogen peroxide was further reduced by pretreating cells with a chemical that binds calcium ions. After treatment with another chemical that releases calcium ions, the amount of positively charged intracellular calcium increased in both bcl-2 cells and controls, but calcium levels in cells containing bcl-2 dropped again much more rapidly. Trump said his lab's findings suggest that bcl-2 protects against two kinds of cell death, apoptosis and oncosis. In apoptosis, most frequently seen in normal or "programmed" cell death, a cell shrinks, breaks into fragments and is absorbed by other housecleaning cells known as phagocytes.  Oncosis, in which a cell swells and bursts, is more typical of cell death from shock following traumatic injury, infection or ischemia. "Cells overexpressing bcl-2 may prevent oxidant-induced cell death in part by increasing the cells' ability to effectively buffer the effects of increased calcium ions," Trump and Ichimiya concluded. "This could be significant in developing effective methods of preventing and treating shock, which is a major cause of death.
--------
632-> Treat Questionable Water With Filters And Iodine, UA Microbiologist Says
If you want to lie awake and worry before your next vacation, don't fret about bears in your camp or whether your plane will take a bath before reaching Europe. Worry about something that's just as threatening, but much more common -- pathogens in the water supply.  After all, on any given outing you're a lot more likely to run into microbes than bears or wind shear. And these pathogens are something to worry about.  They can be every bit as menacing as a 1,000-pound grizzly and a lot tougher than the wimps that spread common colds.  Some of these bugs don't just ruin your trip.  They can ruin your life. Water-borne pathogens cause everything from severe, month-long bouts of diarrhea to heart disease, ulcers, and hepatitis. Even places that look safe can be risky.  University of Arizona microbiologist Charles P. Gerba and his students have spent a lot of time looking for (and finding) organisms in things like municipal water supplies, restaurant iced tea, non-carbonated bottled water from foreign countries, and the water in airplane rest rooms. Gerba notes that some cities outside the U.S. treat their water but don't filter it, which is just the sort of thing some microbes can live with.  Diarrhea-causing bugs like cryptosporidium and Giardia, for instance, are so resistant to chlorine that they sail right through water treatment plants.  The only way to stop them is to physically filter the water. Which is why backpackers and international travelers are lining up to buy point-of-use water filters.  These hand-held units can be the best defense against questionable municipal water supplies and untreated backcountry streams. But not all filters will do the job.  Anyone can slap together a filter element and a couple of hoses, but that doesn't mean it will stop all the bacteria.  "You need a good engineer to design these," Gerba says.  If the seals don't hold up or water leaks past the filter element when pressure builds up, the microbes get a free ride into your glass. So make sure the filter is registered with the EPA. Gerba's lab does the majority of testing for EPA certification of point-of-use water filters and the procedure is rigorous.  In fact, one technician in Gerba's lab does nothing but test filters. "These are really mini water treatment plants and we have to make sure the units perform throughout their lifetimes," Gerba says.  "The EPA tests give these filters some rough challenges." Gerba recommends both filtering water and treating it with iodine.  While some filters incorporate iodine treatment, most don't. Without iodine, filters stop bacteria that cause diarrhea, but they don't block viruses, which are much smaller. Some backpackers skip the iodine tablets after filtering, figuring that few people in the backcountry means few disease-causing organisms.  Gerba says they're taking a chance.  "You never know what's happening upstream.  People don't have to be using the areas near the water as a toilet, just bathing will do it." Travelers also need to use their filters properly, Gerba says.  The intake should always be isolated from the outlet.  Even a single drop of untreated water can transfer disease organisms.  (A lone virus just 4 millionths of an inch long is all that's needed to cause an infection.) But what do you do when you can't use your filter?  After all, even the most microbe paranoid among us shy away from pumping a water filter in full view of a crowded restaurant. Drink bottled beer or canned soda, Gerba advises.  But don't drink beer drawn from a tap or soda mixed from a machine.  They can be contaminated.  Outside of the U.S. and northern Europe, stay away from non-carbonated bottled water.  Coliform bacteria have been found in bottled water from other countries.  But carbonated bottled water is safe, Gerba adds.  The pH is low enough that microbes can't survive. Don't drink the tap water from airplane bathrooms because the tanks are sometimes refilled in countries where pathogens are common in the water supply.  Travelers might even want to skip the meals loaded on at foreign airports.  At least one planeload of passengers from South America contracted cholera. Also stay away from raw vegetables.  They often are contaminated in handling.  Fruit is okay, if you peel and cut it yourself, Gerba says. In addition, avoid swimming and don't brush your teeth with untreated water. No place is entirely safe.  Anyone can be unlucky enough to run into that microbe with their name on it.  But taking precautions -- especially when traveling outside the U.S. or into the backcountry -- can radically improve your chances of staying healthy. Just pack your water filter and iodine tablets, follow a few simple precautions, and you can figure that you've done about all you can about the microbes. Now it's time to lie awake worrying about lightning strikes on high peaks and the chances of having your passport stolen. ***  
--------
633-> Speedy Land Travelers Or Seagoing Sailors? Temple Archaeologist Investigates Earliest Americans
Were the first Americans coastal sailors or speedy bands of land-bound hunters?  Once, most archaeologists agreed that ancient hunters raced southward over the Bering Land Bridge into Alaska, onto the Southern plains of Texas, and finally to Tierra del Fuego at the southern tip of South America, completing this enormous journey in about 1,300 years. But, in response to recent discoveries of what seem to be older human artifacts in South America, the archaeology profession has prematurely jettisoned this theory for an alternative view based on theoretical sea travel, says Temple University anthropology professor Anthony Ranere. “Mine is a somewhat unpopular position, but I think the bulk of the evidence still supports the late entry, fast movement model,” says Ranere.  “According to the model that I prefer, people first crossed the Bering Strait Land Bridge into North America about 12,000 years ago.” However, older artifacts thought to date to 12,500 years ago have been found in Monte Verde, Chile.  How could archaeologists explain these finds?  By proposing that ancient travelers boated down the North American West Coast 25,000 or more years ago.  “They could hardly have left Alaska any other way during the period from 25,000 to 12,000 years ago since a massive continental ice cap covered the entire upper half of North America, forming a barrier to overland movement,” says Ranere. But Ranere points out that many other sites, once thought to be much older than the 12,000 years before present entry date, have been discredited one by one due to errors in dating.  Only Monte Verde stands unchallenged.  “If some flaw in the dating of Monte Verde is eventually discovered, which leads to a revision of its antiquity to say, 10,500 years before present, then the late entry model again makes sense,” says Ranere. Ranere argues that, given the amount of game available, once on the North American continent, bands of hunters would have been able to move rapidly into new and strange areas without having to wait generations to gain intimate knowledge of the plants in different climates. “Spear points are not root grubbing tools, they’re for killing game, and no specialized plant processing tools have yet to be identified in these early sites,” adds Ranere. Ranere’s own painstaking field work at La Mula-West along the central Pacific coast of Panama backs up his claims.  He has recovered spear points manufactured with the same technology as early spear points from North America. “La Mula-West is essentially a workshop for manufacturing stone tools.  In order to gear up for hunting, ancient people had to stop near sources of jasper, flint, obsidian, or other suitable rock types, and make large numbers of spear points.  Since many points were broken in the manufacturing process, a large amount of workshop debris is left behind for us to analyze.  So, if a lot of time had elapsed between occupation of sites in North America and our site in Panama, you would expect to see an evolution of technology, instead of the identical technology we found,” says Ranere. The spear points could be quite deadly weapons.  “There is some evidence that ancient people used an additional section of wood called a spear thrower to extend the length of their arms, allowing them to really hurl these spears 70 to 80 meters with some accuracy,” notes Ranere. Ranere will take seven students along when he returns to central Panama this summer.  This time, he is looking for remains of early crops that early hunters and gatherers added to their diet between 8,000 and 9,000 years ago. Ranere presented his views in April at the meeting of the Society of American Archaeology in Nashville.
--------
634-> Ozone Gets OK For Food Industry Use
Palo Alto, Calif., -- June 14, 1997 --  A panel of experts from food science,  ozone technology and other related fields has declared Generally Recognized as Safe (GRAS) status for ozone use in food processing. The Food & Drug Administration (FDA) allows independent affirmation of GRAS status of substances by a qualified panel of experts. The Electric Power Research Institute (EPRI) requested R&D Enterprises to review the history and health aspects of ozone for possible use in processing foods for human consumption and for GRAS status. After an initial meeting with the FDA, an expert panel of six scientists met frequently over the course of a year to interpret and evaluate the history of ozone. Some of the panel’s findings include: •Ozone has been shown to be a more powerful disinfectant than chlorine, the 	most commonly used disinfectant •Ozone has been used safely and effectively in water treatment for nine decades and has been approved in the U.S. as GRAS for treatment of bottled water since 1982. •Ozone has been applied in the food industry in Europe for decades and, in some cases, for almost a century. •Ozone doesn’t remain in water so there are no safety concerns about consumption. "Ozone is one of the most powerful disinfectants known. There are no toxic byproducts or potential health hazards when properly used as a microbiocide," said Myron Jones, manager of EPRI’s Food Technology Center. Increasing constraints on the use of toxic gases for sterilants or fumigants also makes ozone use more favorable. Ozone is generated for immediate use.  So, leaks or spills cannot occur with ozone. "An onsite ozone generator produces ozone via an electrical discharge. Ozone gas is then mixed with water for washing the food and process equipment. The wash water, called flume water, can be filtered and recycled for reuse -- a big environmental benefit," said Ammi Amarnath, former manager of EPRI’s Food Technology Center. Jeff Barach,vice president of research and food science policy with the National Food Processors Association commented, "Ozone is very efficient in killing pathogens and spoilage organisms and its use by the food industry will be welcomed as another tool to ensure the production of safe and wholesome foods." Additional potential applications for ozone in the food industry include increasing the yield of certain crops, protection of raw agricultural commodities during storage and transit, and sanitizing packaging materials used for food storage. "While populations increase throughout the world, we are seeing an evolution of new microbiological strains involved in human illnesses. Ozone will help to keep people healthy," said Clark Gellings, EPRI’s Customer Systems Group vice president. EPRI, established in 1973 and headquartered in Palo Alto, Calif., manages science and technology R&D for the electricity industry.  More than 700 utilities are members of the Institute which has an annual budget of some $500 million. ### EPRI. Powering Progress Through Innovative Solutions www.epri.com (For color slides, contact Christine Hopf-Lovette, EPRI at (415) 855-2733 or chopf@epri.com.)  ELECTRIC POWER RESEARCH INSTITUTE’S FOOD TECHNOLOGY CENTER Created by the nation’s electric utilities in 1973, EPRI is one of America’s oldest and largest research consortia, with some 700 members and an annual budget of about $500 million. Linked to a global network of technical specialists, EPRI scientists and engineers develop innovative solutions to the world’s toughest energy problems while expanding opportunities for a dynamic industry. What is EPRI’s interest in the food industry? Food processing is the nation’s largest industrial sector, with industry shipments valued at more than $425 billion annually. Food processing plants employ 6 million workers and consume a significant amount of electricity -- almost 60 billion kilowatt-hours each year. As world population grows, the food processing industry must grow to meet market demand for safe, adequate food sources while complying with stringent environmental and safety regulations. To address these issues and remain competitive, food processors are exploring beneficial electrotechnologies. EPRI’s Food Technology Center helps electric utilities retain and attract food processing customers. In turn, food processors are helped during this time of food industry R&D downsizing. What is EPRI’s Food Technology Center (FTC)? The FTC identifies, develops and deploys electric-based technologies and is a link between the food processing customer and the supporting electric utility. Research and development of new electric-based technologies is directed by Donald Quass, Ph.D., at the University of Minnesota St. Paul campus Outreach and implementation are managed by Barry Homler, Ph.D., at the Edison Industrial Systems Center in Toledo, Ohio. The two offices work together with food processors and utilities to deliver technologies that benefit both. For more information: Myron Jones, Manager, EPRI Food Technology Center, (415) 855-2993 Dr. Barry Homler, EPRI Food Technology Center, (419) 534-3713 Dr. Don Quass, EPRI Food Technology Center, (612) 624-7466 For media inquiries contact: Christine Hopf-Lovette,EPRI, (415) 855-2733 
--------
635-> Disorderly Balls Of Protein May Promote Neurological Disorders
June 9, 1997 Contact: Robert Irion (408) 459-2495; irion@ua.ucsc.edu RESEARCHERS DISCOVER DISORDERLY BALLS OF PROTEIN THAT MAY PROMOTE SCRAPIE, "MAD COW," ALZHEIMER'S, AND RELATED DISEASES FOR IMMEDIATE RELEASE SANTA CRUZ, CA--Writhing balls of snakelike protein fragments may initiate the dysfunctional lesions called plaques that clog the brains of patients with Alzheimer's disease and similar neurological disorders, according to new research at the University of California, Santa Cruz, and UC San Francisco. Unraveling how these disorderly balls of protein promote plaque formation ultimately may help researchers develop drugs to prevent the destructive plaques that impart a Swiss-cheese appearance to the brains of mad cows, scrapie-diseased sheep, and patients with Creutzfeld-Jakob disease (CJD), Alzheimer's disease, and Parkinson's disease. Scrapie, mad cow disease, and CJD are caused by proteins called prions ("PREE-ons") that switch between two shapes, one harmless, one harmful. Once altered, the harmful form seems contagious: It induces others to change into the dangerous version. The harmful forms aggregate together; under some conditions, they may reorder to form long chains, called fibrils, that act like sticky string. In the brain, these chains surround and kill nerve cells. Conglomerations of dead nerve cells and fibrils, similar to the plaques seen in Alzheimer's and Parkinson's patients, often accumulate in the brains of animals and people with prion diseases. In test-tube experiments, the team discovered that a hodgepodge clot of protein fragments called "amorphous aggregate" must exist for pieces of harmless prion protein to transform into the dangerous shape. This research was the first to demonstrate that the presence of amorphous aggregate triggers the shape change. "To understand the disease, you must understand how it forms," said Glenn Millhauser, associate professor of chemistry and biochemistry at UCSC. "If our model is right, it could suggest different strategies for drug development to halt the progress of Alzheimer's--or even prevent it." Former UCSC graduate student Karen Lundberg and several colleagues published their research in the current issue (May 1997) of the scientific journal Chemistry & Biology. Coauthors are Chris Stenland, formerly of UCSC and now at the Bayer Corporation; biochemists Fred Cohen and Stanley Prusiner of UC San Francisco; and Millhauser. Almost 20 years ago, Prusiner proposed the revolutionary idea that certain neurological disorders were caused by infectious proteins, which he dubbed "prions" (proteinaceous infectious particles). Unlike bacteria or viruses, prions contain no genetic material, making it hard to fathom how they could proliferate and spread disease. However, most scientists now accept the idea that prions cause mad cow disease, scrapie, kuru ("laughing cannibal" disease), fatal familial insomnia, and CJD. Some of the diseases occur spontaneously, while others are acquired through infection or inheritance. Prion proteins are a normal but mysterious component of brains. "Your brain is loaded with this protein, and nobody knows what it does," Millhauser said. "So long as they stay in the harmless form and don't convert to the evil twin, you're in good shape." What instigates the shape change from benign to injurious is still unknown, but work in Millhauser's lab suggests a plausible model. For her doctoral thesis, Lundberg studied a short fragment of the benign form of the scrapie-causing prion, suggested by Prusiner. She used a technique called "electron spin resonance" to watch how different solutions of the protein fragment changed over time. The amorphous aggregate developed only when the prion protein was in high concentration. When the aggregate was present, the prion fragments switched to the dangerous shape and linked together into fibrils. Lundberg used electron microscopy to confirm the presence of those chains. However, if the amorphous aggregate was absent, the dangerous fibrils did not develop. "The data suggest that the amorphous aggregate provides a site that induces the formation of fibrils," Millhauser said. "We are proposing a new mechanism. The amorphous aggregate may not only initiate, but also stabilize, the injurious form." This mechanism, should it bear up under further scrutiny, poses an alternate strategy for drug therapy against diseases in which fibrils develop in the brain. Today, many researchers target the fibrils themselves by trying to cap them off and prevent them from elongating into the forms that kill nerve cells. A more fundamental approach, Millhauser hypothesizes, would be to "bust up" the amorphous aggregate in some way. "Then, fibrils would never form. That's a completely different tack, and we'd need to learn what controls the solubility of these proteins." The National Institutes of Health and the National Science Foundation funded the research. ##### Editor's notes: You may reach Millhauser at glennm@chemistry.ucsc.edu or (408) 459-2176. Mari N. Jensen, a former intern in the UCSC Public Information Office, wrote this news release. 
--------
636-> Methacrylic Acid-Containing Nail Products Are Hazardous To Children
BOSTON -- Artificial nails are a growing, $265 million business in the United States.  A study by researchers at Children's Hospital, Boston, and the Massachusetts Poison Control System, has demonstrated that the artificial-nail  primers used to prepare the nail surface prior to application of an artificial nail present a significant hazard to young children and have been associated with severe injuries. These primers are neither contained in child-resistant packaging, nor accompanied by any warning  labels. According to the study by Alan Woolf, M.D., M.P.H., associate in Medicine (General Pediatrics) and clinical director of the Massachusetts Poison Control System at Children's Hospital, Boston, and Judith Shaw,  R.N., M.P.H., health educator at the Massachusetts Poison Control System, methacrylic acid, the active ingredient in the primer, has resulted in toxic exposures, including dermal, oral, and/or eye burns. Over 750 methacrylic acid-containing nail primer exposures were reported to the nation's poison centers over the three years of the study. Using data compiled by the American Association of  Poison Control Centers and the Consumer Product Safety Commission, Shaw and Woolf developed a hazard score calculated on the number of injuries as a fraction of total nail product exposures. Compared to other household products, nail kits containing methacrylic acid are as hazardous to preschoolers as kerosene and ethanol-containing beverages. Shaw and Woolf  recommend the implementation of new product labeling and packaging regulations which recognize this hazard, as well as public education measures alerting consumers to the dangers of these nail primers. Woolf presented the research last month at the annual meeting of the Pediatric Academic Societies in Washington, DC.
--------
637-> Researchers Work Toward Universal Blood Type
Researchers at Albany Medical College have developed a process for camouflaging the surface of red blood cells that, in essence, could create a universal blood type. "It is our belief that this procedure for antigen camouflage may have significant potential in transfusion and transplant medicine, as well as in veterinary medicine," said Mark Scott, Ph.D., associate professor of pathology and laboratory medicine. The work was presented last month at the annual meeting of the Pediatric Academic Societies. Dr. Scott invented the technique with John Eaton, Ph.D., former head of experimental pathology at Albany Medical College, now at Baylor College of Medicine in Houston. Graduate student Kari Murad also contributed significantly to the project. The work has been conducted under a $140,000 grant to Dr. Scott from the National Institutes of Health for the study of the blood disease thalassemia. The process involves coating the cell with a biocompatible polymer called polyethylene glycol (PEG). The PEG molecules form permanent covalent bonds on the cell's surface. This coating effectively hides the antigenic molecules on the surface of the red blood cells such that the foreign cells are not recognized by the blood recipient's antibodies. For example, a person who has type A blood will naturally have antibodies that attach to the antigens on thesurface of type B blood cells and destroy the foreign blood. However, "the attachment of PEG to the surface of type B blood camouflages the surface of the cell so the antigens can no longer be recognized and thus prevents the destruction of the antigenically foreign red blood cells," Dr. Scott said. Furthermore, a number of diseases, including thalassemia, that require repeated blood transfusions are often complicated by the development of antibodies to "minor" red cell antigens. This "allosensitization" can render these patients almost impossible to transfuse. It can be a life-threatening situation. In vitro, the PEG-modified red cells appear not to trigger allosensitization and may also be useful in clinical situations where allosensitization has already occurred. The investigators have tested the process in vitro with human, mouse, rat and sheep red blood cells, and in vivo with mice cells. When they transfused one type of PEG-modified red blood cells into mice that had a different blood type, the treated foreign red cells were not rejected. The modified cells, while antigenically "silent," remained structurally and functionally normal and had normal in vivo survival. Interestingly, the researchers were also able to transfuse sheep blood cells into mice and prolong the survival of these "very foreign" red cells up to 360 times that seen with untreated sheep cells   from five minutes to 30 hours. In addition to allowing blood transfusions between individuals with different blood groups, the techniques may also be useful in tissue and organ transplantation to prevent rejection, Dr. Scott said. Studies with a number of other cell types modified by this technology have shown substantial promise at preventing tissue rejection. The worldwide rights to the technology have been acquired by Biomedical Frontiers, Inc., of Minneapolis. The company is developing techniques to apply this technology in humans, according to Dr. Bo E. Hedlund, president and CEO of Biomedical Frontiers. Human applications are still several years off, however. 
--------
638-> Physicians Over-Estimate Vaccination Coverage, Says CDC
A recent CDC study of private physician's practices related to children's immunization indicated that physicians estimate they are fully vaccinating a higher percentage of children in their practice than may actually occur. The study revealed that estimates of immunization coverage are generally much higher than measured coverage in these practices.   In addition, although physicians administered the recommended vaccinations to preschool children, they frequently did not remind or recall their patients to assure timely vaccination. In the United States, the majority of immunizations are delivered by private practice physicians.  However, the practice patterns of private immunization providers is not well understood, therefore CDC conducted a national survey of pediatricians and family physicians  to assess their immunization practices. The study also revealed that 63 percent of physicians perceived their practices' immunization coverage levels to be greater than 90 percent, and that 75 percent of physicians surveyed lacked a system to identify children who are not up-to-date on immunizations. Results were presented last month at the Pediatric Academic Societies' Annual Meeting in Washington, DC.
--------
639-> New York State Insurance Plan Helps Ensure Childhood Vaccinations
A CDC study indicates that New York state's health insurance plan Child Health Plus, which covered immunization services since 1991, helped ensure children received vaccinations on time and reduced the number of children immunized through public clinics. Private health care providers refer preschool children to public health clinics for immunization most often because the cost of vaccination services would be a burden for the children's parents.  However, when a child's health care is divided between a private practice and a public clinic, the child's vaccination is often delayed. A goal of the national Childhood Immunization Initiative is to reduce vaccine costs for lower-income and uninsured families, especially so that vaccines may be provided in private physican offices.  In 1991, New York State introduced a health insurance plan called Child Health Plus (CHPlus) that provided coverage for ambulatory care, including the full costs of immunization services. Children less than 13 years of age and not on Medicaid were eligible for CHPlus if their family's income was less than 222% of the poverty level.  The study showed that CHPlus insurance coverage caused a large shift of immunization delivery away from public health clinics to private primary care provider offices.  Public clinic use for children's vaccination was decreased by up to two thirds. The decrease in the number of immunizations delivered in the public health clinics was more than compensated for by the increase in immunizations delivered by primary care providers, resulting in improved immunization coverage. Results were presented last month at the Pediatric Academic Societies' Annual Meeting in Washington, DC. Title:		Health Insurance for Low-Income, Working Families: Impact on the Delivery of Immunizations to Preschool ChildrenAuthors:	Lance E. Rodewald, MD; Peter G. Szilagyi, MD, MPH; Jane Holl, MD; Laura R. Shone, MSW; Jack Zwanziger, PhD; Richard F. Raubertas, PhDAffiliations:	National Immunization Program, CDC University of Rochester
--------
640-> Fetal Bone Marrow Best Source Of Stem Cells For Transplantation
WASHINGTON, DC -- Researchers at Georgetown University Medical Center have completed a study comparing the effectiveness of three main sources of stem cells for bone marrow transplantation: fetal bone marrow from spontaneous abortions, umbilical cord blood and adult bone marrow. The study, done by Maria Michejda, Ph.D. and colleagues at Georgetown, shows that fetal bone marrow is eight times more effective than umbilical cord blood, and 23 times more effective than adult bone marrow for bone marrow transplantation Besides the shortage of matching donors, the biggest problem with bone marrow transplantation is graft-versus-host disease (GVHD).  GVHD occurs when the immune system of the donor's marrow identifies the recipient's body as foreign and tries to destroy it. The investigators found that compared to cord blood and adult bone marrow, fetal bone marrow contains the highest concentration of CD34+ cells which are responsible for creating new blood cells, and the lowest concentrations of CD-3 cells, which are responsible for identifying and rejecting foreign tissue.  The lower the level of CD-3 cells, the lower the chances of GVHD. The paper was presented last month at the Pediatric Societies' Annual Meeting in Washington, DC. 
--------
641-> W. Va. Study Says La Crosse Encephalitis Under-Diagnosed
WASHINGTON, DC - La Crosse encephalitis is a dangerous disease that is probably under-recognized in school-age children, according to the authors of a 10-year retrospective study presented to the Pediatric Societies' Annual Meeting last month. La Crosse is a mosquito-borne virus which has been found in most states east of the Mississippi River. It is especially prevalent in the region from Wisconsin to West Virginia and is most often found in hardwood forested areas because the trees support the life cycle of the "treehole mosquito." "We advise physicians to  consider diagnosing La Crosse when a child who is living in or traveled through mid-Atlantic or Midwestern states is diagnosed with meningoencephalitis in the summer or early fall," said Dr. James McJunkin, professor of pediatrics at WVU Charleston Division. Pediatricians and staff at West Virginia University Charleston Division and Charleston Area Medical Center Women and Children's Hospital in Charleston, W. Va. cared for 128 patients- the largest single series of reported cases. This is also the first study which includes experience with intracranial pressure monitoring and specific antiviral therapy. About half the children required treatment for seizures or coma, and more than half of the sample required intensive care. Three patients with severe brain swelling were managed with a pressure monitoring device inside the skull and with intravenous ribavirin, an antiviral drug approved for emergency use by the Food and Drug Administration. Except for the first case in 1987, all patients survived their bouts with La Crosse. Researchers also concluded the virus can be diagnosed early using specific laboratory tests. The WVU Charleston and CAMC team is continuing its study with a randomized clinical trial of intravenous ribavirin for severe cases of La Crosse infection. Dr. McJunkin and his colleagues have also actively worked with West Virginia public health officials and media representatives to alert parents to symptoms of the disease and supply facts about how to interrupt the breeding patterns of the disease-carrying pests. 
--------
642-> Very Low Birthweight Children Have Long-Term Behavioral And Psychiatric Consequences
Children who are born very premature remain at risk of psychological and psychiatric problems into adolescence, despite neonatal intensive care. Neil Marlow, M.D.,  reported the most recent study of this kind last month at the Pediatric Academic Societies' Annual Meeting in Washington, DC.  Marlow and colleagues studied a cohort of 137 children who were placed in neonatal intensive care in Liverpool, UK between 1981-83. Children were free of major disabilities and are considered physically healthy.  All children's birthweights were below 1500 grams (about 3.3 pounds). At ages 11-13 years, these children were almost four times as likely to exhibit behavioural or psychiatric problems, compared to controls.  On a questionnaire, these children were significantly more likely to report themselves feeling depressed, anxious, and less social than peers.  Approximately 10 percent of the very low birthweight children also showed significant learning problems. Attention deficit disorder, with or without hyperactivity -- which has been found in many premature children at younger ages than those of the cohort -- was present in 26 percent of the children, compared to to 6 percent of controls. It was not possible to associate any of these conditions with events that occured in the neonatal period, or with family related factors. "Although much of the detail of intensive care has changed in the intervening 12 years since these children were born, we remain concerned about long term problems in very premature children who survive," said Marlow.  "Studies designed to work out how to reduce these long term effects are urgently needed." The next study from this group of researchers will evaluate how many of the behavioural and psychiatric problems can be ascribed to brain injuries still visible on magnetic resonance images. Other researchers in the study include Richard Cooke, Nicky Botting, and Andrew Powls, of the University of  Liverpool.  The study was funded by the UK Medical Research Council. 
--------
643-> Emergency Department Visits May Signal Depression In New Mothers
BOSTON -- Two percent of all postpartum women are diagnosed with depression,  and 10 to 40 percent exhibit high levels of depressive symptoms.  Maternal depression has substantial adverse impact on infant and child social and emotional development. According to a study of 1,200 women by Kenneth D. Mandl, M.D., M.P.H., assistant in Medicine (Emergency Medicine) at Children's Hospital, Boston, the risk of developing depressive symptoms was elevated three-fold for mothers who brought their infants to a hospital emergency department within the first three weeks of childbirth.  Mothers who brought their infants in for frequent problem-oriented primary care visits showed a two-fold risk of developing depressive symptoms. These health care utilization patterns can help to identify high-risk mothers who need close monitoring. Mandl's study did not discern cause and effect:  A baby's demanding health needs may have an adverse emotional impact on mothers, or mothers may frequently present to the health care system with their babies because of emotional distress. Referral of mothers by pediatric health care providers recognizing these patterns may facilitate early diagnosis and treatment of postpartum depression, improving outcomes for women and their families. The research was presented last month at the Pediatric Academic Societies annual meeting in Washington, DC.
--------
644-> Functional Significance Of Iron Deficiency In Children
WASHINGTON---Children who suffered from severe, chronic iron deficiency as infants are disadvantaged with respect to learning and behavior as they enter adolescence, even though their current iron and growth status is excellent, according to a University of Michigan study.  Roughly 25 percent of all babies in the world have iron deficiency anemia and many more have iron deficiency without anemia. Researchers led by Dr. Betsy Lozoff, director of the U-M Center for Human Growth and Development (CHGD) and professor of pediatrics, have been conducting a longitudinal study of 191 infants born in 1981-83 in a lower-middle class community in Costa Rica.  The infants, who were screened and treated for iron deficiency, had been previously re-evaluated at five years of age. Recently, 167 of them were re-evaluated at ages 10-13.  "Of the 167 children," said Lozoff, "48 had been severely, chronically iron deficient as infants and 119 had been iron sufficient either before or after iron therapy in infancy.  The severe, chronic iron deficient group consisted of children who had had moderate iron-deficiency anemia as infants and those with higher hemoglobin levels with iron deficiency that did not completely correct with iron therapy in infancy." The most recent evaluation included measures of cognitive and motor functions, scholastic achievement, and behavioral problems.  The results were reported last month at the American Pediatric Society Meeting in Washington, D.C. "At the five-year follow-up, we found that children who had had severe, chronic iron deficiency as infants tested lower than the children who had had better iron status on a variety of measures---visual-motor integration, quantitative or numerical concepts, visual matching, and performance IQ. "Unfortunately, the trends continued at ages 10-13 and had a negative effect on their scholastic achievement scores," Lozoff said.  "Although all of them were in the 'normal range,' we found that the children who had severe, chronic iron deficiency now scored lower on standardized achievement tests---about 7 points lower on tests [100 point scales] of reading, writing and arithmetic, with particularly marked differences in written expression.  Sub-tests of IQ measures also determined that they had acquired less general knowledge of the world and were less able to do abstract reasoning.  Their motor scores also continued to be lower," Lozoff said. The children who had severe, chronic iron deficiency also scored higher for behavioral problems, which may have interfered with their learning, Lozoff suggested.  "These children had more internalizing problems---they were reported to be more anxious and socially withdrawn and to have more somatic or physical complaints than the children who had had better iron status in infancy.  In fact, by U.S. standards, their internalization scores were in the clinical range---that is, they would be considered for mental health evaluation and treatment in the United States." The researchers will follow the children over the next five years, examining the impact of severe chronic iron deficiency in infancy on classroom grades, retention, need for special education or tutoring, and school dropout rates. Lozoff's colleagues on the recent follow up study are Eileen Mollen, psychologist and assistant professor, U-M Department of Pediatrics and Communicable Diseases; John Hagen, research scientist at CHGD and U-M professor of psychology; Abraham W. Wolf, assistant professor of psychology, Department of Psychiatry, Case Western Reserve University School of Medicine; and Elias Jimenez, director of research, Hospital Nacional de Ninos, Costa Rica.
--------
645-> Children With AD/HD Have Related Functional Disabilities
WASHINGTON, D.C. -- Pediatric researchers from the University at Buffalo and Children's Hospital of Buffalo have shown that children diagnosed withattention deficit/hyperactivity disorder (AD/HD) have as much functional disability as children with mild mental retardation and are not merely exhibiting "inconvenient" behavior. Results of the study were presented here last month  at the annual meeting of the Society for Pediatric Research. Using a standard developed at UB for use by the developmental and rehabilitation medicine community to assess a patient's needs for rehabilitation services, the researchers determined that most of the 43 children in their preliminary study were significantly less able to care for themselves, recognize appropriate social behavior and communicate than children of similar age who were not diagnosed with the disorder. "When we applied this standard measure of disability to these children, we found that children who get referred for hyperactivity have high levels of documentable needs and require a lot more help than other children their age," said Thomas M. Lock, M.D., who presented the results.  Lock is UB clinical assistant professor of pediatrics and associate medical director of the Robert Warner Rehabilitation Center at Children's Hospital of Buffalo. Lock said the results could have significant impact now because, as of this month, children diagnosed with attention deficit disorder who routinely have been receiving federal Supplementary Security Income funds must demonstrate they are truly disabled. Considerable controversy exists within the medical and education communities about whether AD/HD is a disability or a behavioral problem.  Diagnosis of the disorder occurs most often in school-age children and usually is precipitated by disruptive classroom demeanor. Lock and colleagues felt that if functional deficits of children with AD/HD could be documented outside of school, the results would support the hypothesis that the disorder is, in fact, a disability. To accomplish this, they used an assessment tool called the Wee-FIM. The Functional Independence Measure, or FIM scale, was developed by the UB Department of Rehabilitation Medicine and has been adopted universally as a standard measure to characterize the level of adult disability and to direct treatment.  The Wee-FIM has been standardized for children.  It contains measures for self-care, bowel and bladder control, mobility, communication and social cognition. The 43 children assessed were found to have lower than normal Wee-FIM scores overall, and to show significant deficits in self-care, social cognition and communication.  There also was a correlation between inattention symptoms reported by parents and the self-care and social cognition deficits characterized by the Wee-FIM. "These results confirm that young children with AD/HD have functional deficits in both self-care skills and social skills and that these deficits are related more closely to inattention than disruptive behaviors, age or IQ," Lock said.  "The study should shed light on the public debate about whether these children are disabled or whether their families are playing the system for benefits." If these functional deficits can be confirmed in a broader study, they should be the focus of treatments in children with AD/HD, Lock stated. Other researchers involved in the study were Nadine L. Duchan, Sue E. Olexenko, and Michael E. Msall, of the UB Department of Pediatrics.  The study was sponsored in part by the Children's Guild of Buffalo. 
--------
646-> LIJ Study Compares Virulence Of Penicillin-Resistant Vs. Penicillin-Susceptible Pneumococci
New Hyde Park, NY -- Penicillin-resistant pneumococci (PRSP) may be less virulent than penicillin-susceptible pneumococci (PSSP), according to a study conducted by Itzhak Levy, MD,  and Lorry Rubin, MD, of the Pediatric Infectious Diseases Division of Schneider Children's Hospital of Long Island Jewish Medical Center. The findings, which compare the ability of these two strains of pneumococci to cause disease, were presented by Dr. Levy at the 1997 Pediatric Academic Societies' Annual Meeting last month in Washington, DC. Penicillin-resistant pneumococci exhibit less virulence than penicillin-susceptible pneumococci; animals injected with a resistant strain had more infections and a higher mortality rate. The study found that  animals injected with resistant bacteria did not necessarily develop more serious infection or outcome than animals injected with susceptible organisms. In fact, the latter experienced more serious illness and deaths than the former. According to Drs. Levy and Rubin, pneumococci are the most common bacterial infections in infants and children and the prevalence of resistantpneumococci is increasing. It has been shown that one of the major risk factors for developing resistance is previous and repeated treatment with antibiotics. It has also been shown that resistance to penicillin and related antibiotics is caused by alterations of the proteins that attach to the antibiotic. These proteins, in turn, produce the cell wall that is altered in resistant bacteria. The defective cell wall might explain the lower rate of serious infections seen in the animals. "This theory is supported by a clinical study," said the specialists, "which showed that infections due to resistant pneumococci are not more severe than infections due to susceptible ones." This led the investigators to question whether PRSP are more virulent than PSSP. In order to ensure the integrity and validity of the study, the resistant and susceptible organisms had to be the same for traits other than penicillin-resistance. In order to accomplish this, the resistant organism was derived from a susceptible strain by exposing it to an increasing concentration of antibiotic. According to the investigators, a great deal of time was spent developing the resistant strain from the susceptible in order to keep both strains as closely related as possible. In order to compare the virulence, the animals were divided into two groups, one injected with the resistant strain and one with the susceptible strain. After one or two days, the animals injected with PSSP had more blood stream infections, a higher level of infection, and a higher mortality rate. Several groups of mice were studied over a six month period with similar results. On the impact of the study, Drs. Levy and Rubin stated, "This preliminary data suggests that penicillin-resistant pneumococci may have less of an ability to cause disease than penicillin-susceptible ones." Dr. Rubin is Chief of Pediatric Infectious Diseases and Professor of Pediatrics at the Albert Einstein College of Medicine. Dr. Levy is a Fellow in the same Division of Schneider Children's Hospital of Long Island Jewish Medical Center. The Hospital is well-known for its pediatric research programs. 
--------
647-> Combination Therapy In HIV+ Children
A combination therapy of stavudine (d4T), didanosine (ddI) and indinavir was well-tolerated in a study of HIV-infected children. The study, conducted by Dr. Mark Kline, associate professor of pediatricsat Baylor College of Medicine in Houston, demonstrated that the drug combination was safe in a small group of symptomatic children. "No child required either a dose reduction or interruption of therapy," said Kline. "In addition, there were marked changes in CD4 lymphocyte counts and blood HIV RNA concentrations, which suggests that there is potent antiviral activity." The study evaluated the pharmacokinetics, tolerance, safety, immunologiceffects, and antiviral activity of the combination therapy in 12 children, ages 4 to 13. The children were assessed every four weeks for a period of 24 weeks. All of the children had been treated previously with nucleoside antiretroviral agents including AZT, ddI and/or d4T. "There was no obvious adverse interaction between d4T, ddI and indinavir when given in combination," Kline said.  "Combination therapy produced impressive decreases in virus load in the body, and CD4 lymphocyte counts increased dramatically, suggesting improvement in the health of the patients' immune systems." In addition, Kline found substantial amounts of indinavir in cerebrospinal fluid and an absence of HIV RNA, indicating there were antiviral effects within the central nervous system. Many HIV-infected children experience neurologic and developmental problems as a result of HIV's effects on the central nervous system.The research was presented last month at the the annual meeting of the Pediatric Academic Societies in Washington, DC.
--------
648-> Treatment May Cause Gut And Liver Damage In Cystic Fibrosis Patients
One of the newest and most successful treatments for lung disease in patients with mild to moderate cystic fibrosis may be causing serious intestine and liver damage when taken in combination with pancreatic enzymes, according to researchers at Rush-Presbyterian-St. Luke's Medical Center, Chicago. The research, based on an animal model, was presented by Rush physician Dr. Robert E. Kimura at the 1997 Society for Pediatric Research annual meeting last month in Washington, D.C. Using a chronically catheterized rat model, Kimura and co-investigator Dr. John Lloyd-Still, director of the Cystic Fibrosis Center at Rush Children's Hospital, found that a combined treatment of high doses of pancreatic enzymes and the non-steroidal anti-inflammatory drug (NSAID) indomethacin caused severe intestinal ulcers and liver damage. "The animal findings raise concerns," said Kimura, "because many CF patients are taking a combined therapy of ibuprofen (a NSAID) and pancreatic enzymes to manage the symptoms of their disease.  At this point, we don't know whether these treatments are damaging to people with cystic fibrosis, but we strongly believe this data merit further study." Kimura initially used the rat model to study the cause of a new iatrogenic (physician-induced) disease first described in 1994 in a small proportion of CF patients as fibrosing colonopathy, or fibrosis of the colon.  Those patients had been treated with high doses of pancreatic enzymes, but not NSAIDs. Kimura and Lloyd-Still theorized that the intestines of these patients were morepermeable, or "leaky", a condition in which proteins, bacteria and other potentially harmful substances can leak through the intestinal walls, making them more susceptible to the effects of the enzymes.  To test the theory, the researchers created "leaky" intestines by using NSAIDs, a class of drugs including indomethacin and ibuprofen, which are known to increase intestinal permeability. "What we found in trying to establish the cause for fibrosing colonopathy was that pancreatic enzymes by themselves caused almost no problems, and indomethacin by itself caused only a small problem. But when we put the two together we saw terrible ulcers, and a condition that resembled fibrosing colonopathy.  We also found that the liver was damaged, " said Kimura. Nearly all CF patients take pancreatic enzymes to treat severe digestive problems caused by the disease.  Since the early 1990's, many CF patients also have been taking high doses of the non-steroidal anti-inflammatory drug ibuprofen --  a treatment whichrecently has been shown to slow the progression of lung damage, a major cause of early death in these patients. Kimura advised that the long-term effects of combined treatment with pancreatic enzymes and NSAIDs for cystic fibrosis be studied further.  "We think there is enough evidence to warrant pulling back a little on high-dose ibuprofen therapy," he said. "That may be difficult because ibuprofen is inexpensive, readily available and promises to extend the lives of these patients.  The problem is, we don't want patients to trade lung disease for gut and liver disease." Rush-Presbyterian-St. Luke's Medical Center is the center of a comprehensive, cooperative healthcare system serving some two million people through its 10 member hospitals and a range of outpatient services.  A center for basic and clinical research, as well as a major referral center, Rush includes nearly 10,000 medical and scientific staff, faculty, students and employees, each committed to providing the best care with compassionate attention to the needs of every patient.
--------
649-> Researchers See Positive Results From Behavioral Program For Treating Alcoholism With Marital And Family Therapy
Date:   June 2, 1997 Contact:  Doug Fizel Public Affairs Office                                             (202) 336-5706 public.affairs@apa.org RESEARCHERS SEE POSITIVE RESULTS FROM BEHAVIORAL PROGRAM FOR       TREATING ALCOHOLISM WITH MARITAL AND FAMILY THERAPY Harvard's Project CALM Show Better Sobriety Rates and Fewer       Marital Separations Than Individual Alcohol Counseling Alone WASHINGTON -- The idea of treating alcoholism in the context of marriage and family (as opposed to seeing it solely as a problem of the individual) has gained wider acceptance in the practitioner community in recent years, but according to an article in the June issue of Professional Psychology: Research and Practice, published by the American Psychological Association (APA), "methods that have shown promise in outcome research are not widely used by practitioners who treat alcoholics and their families" and more widely used methods have not been systematically studied. But authors Robert J. Rotunda, Ph.D., and Timothy J. O'Farrell, Ph.D., of the Harvard Medical School also describe a clinical research program that bridges the gap between research and practice. The Harvard Counseling for Alcoholics Marriages (CALM) Project (a.k.a. Project CALM) is a four-phase intensive treatment program for alcoholics and their spouses, the overall purpose of which is to increase relationship stability, which in turn helps clients maintain sobriety.  "We help couples reward abstinence from alcohol and refrain from punishing sobriety [by dredging up past behavior], increase positive feelings and activities and learn better communication skills.  These skills help reduce family stress and the risk of relapse," the authors write. Project CALM's four phases include initial engagement of the identified patient and his or her partner, 10-12 weekly couple sessions, then 10 weekly couples group sessions and quarterly follow-up visits for another 24 months. The couples in the program agree to three commitments:  (1) not to threaten divorce or separation during the course of therapy, even when in a heated argument, (2) to focus on the present and future, not the past drinking or negative events and (3) to dedicate themselves to completing whatever weekly homework assignments they agree to in session. CALM is action-oriented and focused on behavior change, the authors note.  "Emphasis is placed on getting couples to renew their relationship in a more positive way by changing their behavior first and then assessing changes in feelings, rather than waiting to feel more positively toward each other before initiating changes in their own behavior." Outcome studies on Project CALM have shown it produces better sobriety rates and fewer marital separations than does individual alcohol counseling alone.  When a relapse prevention component was added to the program, it had even better results, the authors say, particularly for alcoholics who had more severe alcohol and marital problems. In terms of cost effectiveness, the authors say Project CALM more than pays for itself by decreasing alcohol-related hospital and jail costs markedly.  In fact, they note, "cost savings attributable to reduced hospitalizations after CALM are over five times greater than the cost of delivering CALM."  The incidence of domestic violence after Project CALM also decreases significantly. "For CALM cases whose alcoholism is in remission, violence levels after treatment are similar to nonalcoholic couples," the authors say. Article:  "Marital and Family Therapy of Alcohol Use Disorders:  Bridging the Gap Between Research and Practice" by Robert J. Rotunda, Ph.D., and Timothy J. O'Farrell, Ph.D., Harvard Medical School and Veterans Affairs medical Center, Brockton and West Roxbury, MA, in Professional Psychology: Research and Practice, Vol. 28, No. 3. (Full text available from the APA Public Affairs Office.) Robert J. Rotunda, Ph.D., now with the University of West Florida, can be reached at (904) 474-2294 or rrotunda@uwf.edu.  Timothy J. O'Farrell, Ph.D., who heads the Harvard Families and Addiction Program can be reached at (508) 583-4500 Ext. 3481 or ofarrell@warren.med.harvard.edu. The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists.  APA's membership includes more than 151,000 researchers, educators, clinicians, consultants and students.  Through its divisions in 50 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. #       #       # 
--------
650-> Doula Support Found To Be A Risk-Free Alternative For Pain Relief During Childbirth
For almost 20 years, researchers have been examining a centuries-old phenomenon -- women helping women through childbirth.  Continuous support from an experienced female companion, called a "doula" from the Greek  word for servant, has been demonstrated to have impressive benefits,  including shorter labors, less need for analgesia, and reduced likelihood  of cesarean delivery.  These findings about a time-proven, risk-free method  come at a time when the focus in childbirth is on increased use of technology  and medical intervention. In a recent study, researchers John Kennell, M.D., and Susan K. McGrath, Ph.D., from the Department of Pediatrics at the Case Western Reserve University (CWRU) School of Medicine, looked at the childbirth experience of women at a Houston maternity hospital.  Thirty-nine women were randomly chosen to be supported by a doula.  Another 45 first-time mothers were randomly chosen to receive epidural analgesia to help control the pain of labor and delivery but were not supported by a doula.       The day after delivery, both groups of women were asked to evaluate their pain levels and ability to cope with pain at three different times during childbirth. They rated their pain as ranging from "no pain" to "maximum pain" at the following times:  1) before receiving pain intervention (epidural analgesia or doula support), 2) after pain relief intervention, and 3) 24 hours after delivery.  (Women who delivered by cesarean section were not included in the pain evaluation analysis.) For women in both groups, pain was rated highest before the pain relief intervention, significantly less after the intervention, and much less again 24 hours after delivery.  More importantly, when the pain evaluations from women in the doula group were compared to thosefrom women in the epidural group, the two groups experienced equivalent levels of pain at all three measurement points. Laboring women supported by a doula (with no pain relief medication) experienced the same levels of pain as women who received epidural analgesia, both during and after labor.  Additionally, there were no differences in a laboring woman's ability to cope with pain whether she had an epidural or the continuous emotional support of an experienced doula. According to the researchers, doula support is an effective, risk-free, non-pharmacologic, and inexpensive pain relief method that may be a viable alternative to epidural analgesia for many women in labor.  Without the negative side effects and expense of an epidural, doula support offers the laboring woman a significant reduction in the pain of childbirth while also decreasing the chance for a cesarean delivery.  Physicians, midwives, and consumers should consider these results when choosing obstetric pain relief. The research team also included Vijay S. Varadarajulu, a premedical student at CWRU.
--------
651-> Scientist Uses Cauliflower DNA To Show How Disease Spreads In Child Care Settings
NORFOLK, Va. -- The use of cauliflower DNA as a surrogate marker is a safe and effective way to study the spread of pathogens in a child care setting and to evaluate ways to intervene, according to a scientist at Eastern Virginia Medical School. Xi Jiang, Ph.D., assistant professor of pediatrics in the Center for Pediatric Research, a joint program of EVMS and Children's Hospital of  The King's Daughters, used the harmless cauliflower DNA to mark objects in a child care home and child care center. Jiang found that the DNA markers spread rapidly among the children through touching, toys and other objects.  The markers also spread to car seats, toys, high chairs and cribs in the children's homes.  The study also found that washing hands and wiping "contaminated" surfaces decreased the spread of the DNA. This marker will have broad application in the study of enteric pathogen transmission. Jiang presented the research last month at the Pediatric Academic Societies' Annual Meeting, in Washington, DC. ###
--------
652-> Researchers Identify Cognitive Process That Contributes To Gambling Behavior
Date:   June 2, 1997 Contact:  Doug Fizel Public Affairs Office                                             (202) 336-5706 public.affairs@apa.org (email) RESEARCHERS IDENTIFY COGNITIVE PROCESS THAT CONTRIBUTES TO GAMBLING BEHAVIOR Also Suggest Strategy for Counteracting It That Could Be Useful      For Both Treatment and Prevention of Problem Gambling WASHINGTON -- Gambling has always been a big business and as more states adopt lotteries and permit casino gambling it gets even bigger every year.  From 1993 to 1994, the number of casino visits in the United States rose 35 percent to 125 million and those casino visitors left behind $16.5 billion in losses, more than twice as much as they lost in 1990.  But if gambling is, overall, a losing proposition for the gambler, why do so many people do it? Over the years, psychological researchers have identified several thinking processes that contribute to gambling behavior. These include biased evaluations of past gambling results (explaining away losses and viewing wins as evidence of gambling ability), the illusion of control (overestimating the influence one wields over outcomes and the probability of personal success) and the "gambler's fallacy" (the mistaken belief that over time, chance-determined outcomes will even out). In the June issue of the American Psychological Association's (APA) journal Experimental Psychology: Applied, researchers from Central Michigan University and the University of Utah add another cognitive process to that list:  selective hypothesis testing, that is, considering only one possible outcome when making decisions. The researchers conducted a series of three experiments, in the first of which participants were asked to estimate the probability that a specific National Basketball Association team (one of four) would win the NBA championship and explain how. In the second experiment they were also asked to estimate the probability that a specific NBA team beat the point spread in an earlier game.  In the third they were asked to estimate the probability that an NCAA basketball team (one of four) had won a computer-simulated playoff. In each experiment, participants were invited to place bets on the team they thought would win, had beaten the point spread or had won. In each experiment participants who focused (as instructed) on a single team (as opposed to estimating the probability of winning for all four teams they were considering) consistently overestimated the probability of that team winning.  In addition, study participants who overestimated that probability were more likely to place bets and larger bets than those who were not focused on a single team. This overestimation of probability, the authors say, "could influence gambling decisions in any domain in which the potential gambler may focus on one possible outcome to the exclusion of others.  Thus the blackjack player may be particularly interested in the likelihood of receiving a 10 after her or his first two cards sum to 11, the poker player may be particularly interested in the probability of making a straight on her or his next card, and the sports gambler may be particularly interested in the likelihood that the home team may win the league championship." But, the authors note, selective hypothesis testing is avoidable.  In one of the experiments, some participants (the control group) had to estimate the probability of each of four teams winning a computer-simulated championship.  Under that condition, the participants overestimated the probability of winning for all four teams, indicating that they may have considered each team a viable contender.  But these participants were less likely to gamble than those who had focused on only one team.  "By encouraging potential gamblers to consider a wide number of potential outcomes, the appeal of any specific outcome is lessened and the likelihood that a bet will be placed is reduced," the authors write.  "Thus, this specific cognitive strategy may counteract the influence of the selective hypothesis-testing process." Not only might this strategy be useful in the treatment of problem gamblers, the authors suggest it might be useful in preventing gambling problems from developing.  Training in abstract reasoning skills in secondary schools or college courses "could include a specific component that addresses the necessity of considering numerous potential outcomes when attempting to predict future events.  This research suggests that such training could be relatively general in nature and still be readily applied by students to gambling and other risky choice situations." Article:  "The Effects of Selective Hypothesis Testing on Gambling," by Bryan Gibson, Ph.D., Central Michigan University, and David M. Sanbonmatsu, Ph.D., and Steven S. Posavac, Ph.D., University of Utah, in the Journal of Experimental Psychology: Applied, Vol. 3 No. 2. (Full text available from the APA Public Affairs Office.) Bryan Gibson, Ph.D. can be reached at (517) 774-4404 or at bryan.gibson@cmich.edu The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists.  APA's membership includes more than 151,000 researchers, educators, clinicians, consultants and students.  Through its divisions in 50 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. #       #       # 
--------
653-> Linking Vaccination Status With The WIC Program In Chicago
A recent CDC study shows that a successful strategy to achieve high, sustainable vaccination rates among underserved inner-city children is to link screening for vaccination status with the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC) program.  In Chicago, vaccination coverage rose from 56 to 77 percent for children in sites participating in this program. The Chicago Department of Public Health assessed the vaccination status of WIC-enrolled children under 2 years of age during their WIC certification visit.  Children not up-to-date with their vaccinations were referred to medical providers. CDC measured age-appropriate vaccination rates and monthly WIC enrollment rates during an 8-month intervention period.  They found vaccination rates increased at all sites that used this intervention.  In Chicago, 42,500 of the 65,000 infants were enrolled in WIC. At the WIC sites that screened immunization status, more than 98 percent of the children were African-American or Hispanic and 86 percent of the children were enrolled in Medicaid. At selected sites, of the children not documented to be up-to-date, 91 percent of the parents received a 1-month WIC food voucher during the intervention and asked to return the next month, versus parents of up-to-date children who received 2- or 3-month WIC food vouchers.  Screening children's immunization status through WIC programs and the use of voucher incentives increased vaccination coverage and improved enrollment in WIC.  This strategy has potential applications in other areas with high WIC participation. Results were presented last month at the Pediatric Academic Societies' Annual Meeting in Washington, DC. Title: The Impact of WIC/Immunization Linkage in Chicago. Authors:  Edward Hoekstra, MD; MS, Yannis Megaloeconomou, MBA; Herminia Guerrero, MBA; Thomasine Johnson-Partlow, LD, RD, MS; Jim Mize; Janice R. Devier, MPA.  Affiliation:  Centers for Disease Control and Prevention (CDC), Atlanta, GA; Chicago Department of Public Health, Chicago, IL, Catholic Charities, Chicago, IL.
--------
654-> Children's Mercy Research At Center Of Infant Formula Debate
KANSAS CITY, Mo. — Researchers at Children's Mercy have found no advantage to including long-chain fatty acids in infant formula, despite their being essential components of brain and retinal tissue. The federal Food and Drug Administration takes up the debate this spring. The research, conducted jointly at Children's Mercy in Kansas City, the University of Washington and the Oregon Health Sciences University, was presented last month to the Pediatrics Societies Annual Meeting sponsored by the American Pediatric Society, the Society for Pediatric Research and the Ambulatory Pediatric Association. The research is the first large-scale study to consider cognitive and language assessment of 3-1/4 year-old children fed formula containing long-chain fatty acid during the first year of life. About 300 children were tested. "The bottom line is that we don't think adding long-chain fatty acids to formula is necessary for the development of full-term babies," says Dr. Robert T. Hall, one of the researchers and chief of the division of Human Development at children's Mercy. "The good news is that it shows we are feeding babies formula that produces normal children." One of the reasons the research is controversial — and significant — is that long-chain fatty acids are present in breast milk and are known to be an important constituent of the retina and the brain. If fatty acids in formula could be linked to greater brain development and are allowed by the FDA, formula manufacturers could begin marketing a product closer in composition to breast milk, which is the "gold standard" of infant nutrition. Children's Mercy researchers caution, however, that just duplicating the ingredients of breast milk will not produce a formula as beneficial as breast milk. Furthermore, the exact duplication of the long-chain fatty acids in breast milk is not possible with present technology. Breast milk remains the preferred method of feeding among health professionals. It is known that children who are breast fed have greater mesures of infant intelligence than those who are formula fed. However, it is not certain that it is the breast milk alone which accounts for the higher intelligence. There are other factors involved in the complex intelligence equations, including maternal/infant interaction, maternal educational level and IQ, socioeconomic status and environment. "We did notice that the breast fed babies performed better in some measures of development," Hall says. "And it has long been shown that breast fed babies do better on IQ tests than formula-fed babies. But we believe the reason is not the long-chain fatty acids or other ingredients, but a variety of other influences, such as maternal interaction." Infants who received long-chain fatty acids in formula did not perform better than infants who received regular infant formula. There are a great many differences between breast milk and infant formula beyond fatty acids. Researchers like Dr. Hall are urging caution and more study on the issue. The researchers are already working on a fatty-acid study with pre-term infants. Human infants can make the controversial fatty acids from another essential fatty acid already present in infant formula. But there is a question about the ability of newborns, especially pre-term babies, to make the conversion in sufficient quantity. There is a period of time when these fatty acids are provided to the infants from the mothers through the placenta. If infants are born prematurely, they are presumed more vulnerable to fatty acid deficiency. Hall and his colleagues are urging the FDA and others to proceed cautiously on the issue. After all, current formula seems to be sufficiently meeting the needs of full-term infants. It is known that children who are breast fed have greater mesures of infant intelligence than those who are formula fed. However, it is not certain that it is the breast milk alone which accounts for the higher intelligence. There are other factors involved in the complex intelligence equations, including maternal/infant interaction, maternal educational level and IQ, socioeconomic status and environment. "We did notice that the breast fed babies performed better in some measures of development," Hall says. "And it has long been shown that breast fed babies do better on IQ tests than formula-fed babies. But we believe the reason is not the long-chain fatty acids or other ingredients, but a variety of other influences, such as maternal interaction." Infants who received long-chain fatty acids in formula did not perform better than infants who received regular infant formula. There are a great many differences between breast milk and infant formula beyond fatty acids. Researchers like Dr. Hall are urging caution and more study on the issue. The researchers are already working on a fatty-acid study with pre-term infants. Human infants can make the controversial fatty acids from another essential fatty acid already present in infant formula. But there is a question about the ability of newborns, especially pre-term babies, to make the conversion in sufficient quantity. There is a period of time when these fatty acids are provided to the infants from the mothers through the placenta. If infants are born prematurely, they are presumed more vulnerable to fatty acid deficiency. Hall and his colleagues are urging the FDA and others to proceed cautiously on the issue. After all, current formula seems to be sufficiently meeting the needs of full-term infants.
--------
655-> Impact Of Managed Care On Pediatric Medicaid Patients
COOPERSTOWN, NY ... Bassett researchers have found that the number of hospital admissions and associated costs can be reduced when children are enrolled in and utilize a Medicaid managed care program which provides them with regular primary and preventive care. The study involved analyzing pediatric hospitalization data before and after the implementation of the Maryland Access to Care (MAC) Program, a fee-for-service managed care program which emphasized the establishment of a medical "home base" for Medicaid recipients.  Each recipient chose (or was assigned to) a primary care provider who authorizes emergency, specialty or inpatient care.  The MAC Program began in December 1991 for all adults and children insured by Medicaid in Maryland. The researchers looked at five years of insurance claims (three years pre-MAC and two years post-MAC).  They studied hospital admissions that were likely to have been avoided with improved preventive and primary care.  Examples of these include hospital stays for conditions such as asthma, diabetes, bronchitis or gastroenteritis where the children did not receive sufficient outpatient care prior to the hospitalization. By comparing data prior to and after implementation of the MAC Program, the researchers found that the number of outpatient pediatric visits increased 38 percent.  Visits to the emergency department did not change.   Children who used the MAC Program were less likely to be hospitalized for avoidable conditions than those not enrolled in the MAC Program.  Children who received preventive care were less likely to be admitted for avoidable conditions.  Children using the emergency room frequently were more likely to be hospitalized for avoidable conditions. "These results are encouraging to pediatricians and others who care for children because they suggest that we can prevent certain hospitalizations when children receive regular primary and preventive health care.  When routine health care and preventive measures are more accessible to children, hospital admission and costs are lower," said Anne M. Gadomski, M.D., M.P.H., Bassett Healthcare pediatrician/researcher and principal investigator for the study.  Other Bassett researchers involved in the study were Melissa Nichols, M.S., and  biostatistician Paul Jenkins, Ph.D. The researchers presented the findings at the 1997 annual meeting of the Pediatric Academic Societies held in Washington DC May 2-6, 1997.  The abstract was also published in a special issue of Ambulatory Child Health.
--------
656-> Drop-In Vaccination Clinics Beneficial For High-Risk Children
Pediatricians from Boston Medical Center have shown that urban drop-in vaccination clinics can play a crucial role in providing immunizations for extremely high risk children.  The paper, presented last month at the Ambulatory Pediatric Association annual meeting in Washington DC, found that these drop-in clinics are utilized by the hardest to reach and most vulnerable families. Compared to children who had up-to-date vaccinations and were seen at pediatrics clinics, the researchers found that children seen at drop-in vaccination clinics were more often uninsured, foreign-born, and had missed an average of seven vaccinations. In addition, parents who brought their children to drop-in vaccination clinics were significantly poorer, more often unemployed, less likely to be US citizens, spoke less English and had spent less time in the United States as compared to parents whose children used a pediatrics clinic. According to Glenn Flores, MD, a pediatrician at Boston Medical Center and presenter of the paper, although national immunization rates continue to improve, rates are lowest and risks of vaccine-preventable illness are highest in poor, minority and immigrant children.  "Our data indicate that these clinics are used most often by people who speak little English, are the least knowledgeable about immunizations, lack a primary care provider and are most severely delayed in their vaccinations,"  adds Flores.
--------
657-> Early Marrow Transplant May Cure SIDS
They lived short lives in sterile rooms. Children with a disorder known as "bubble boy" disease were born without an immune system, and they inevitably died from common infections. Their fate was dramatized by a documentary film of a young Texas patient who lived and died in a germ-free plastic sphere. Now, researchers at Duke University Medical Center are reporting that the disease, known as severe combined immune deficiency (SCID), can be cured in many cases if diagnosed and treated early enough. A 15-year study by Duke physicians shows that more than 90 percent of babies born with the disorder can be given a healthy immune system if they receive a bone marrow transplant within three months of birth. They also have learned that these children need not have a perfectly matched donor, but can use a parent's "half-matched" marrow. Furthermore, the babies do not need toxic pre-transplant chemotherapy, as is often thought and currently practiced. The results of the study of 79 children were presented last month at the Pediatric Academic Societies' annual meeting. Duke is one of only a few hospitals in the country that specializes in treating children with SCID. "This once-fatal disease should be now seen as a pediatric emergency, a condition that needs immediate diagnosis and treatment," said Dr. Rebecca Buckley, chief of Duke's division of pediatric allergy and immunology. Buckley said early diagnosis of SCID is rare because doctors do not routinely perform a test in newborns to count white blood cells. Such a blood test could pick up children with SCID as well as those with other serious immune deficiencies that would not be apparent  until the child developed an infection. "A simple blood test could allow us to treat, and most likely cure, SCID in a child for as little as $25,000," Buckley said. "If found later, less effective treatment can run into the millions." Babies born with SCID suffer from a variety of genetic defects, all leading to a lack of T or B immune cell function, which is essential for protection against infection. The defect is said to occur once in every 500,000 to 1 million births, but it could be more common, researchers say, because babies who die of a simple infection often are not given an autopsy. "Without an immune system, a patient is completely vulnerable to infection. A pathogen that would be harmless to a person with normal immunity would destroy a SCID patient. Until 1982, SCID was invariably fatal unless the patient had a brother or sister who was an exact match to donate bone marrow," Buckley explained. "What we see now is that a sibling match isn't necessary; haploidentical parental marrow will work, too." A haploid match is a half match. But the key is timing, according to Buckley. The transplant needs to be done before the onset of opportunistic infection, she explained, and in the first few weeks of the baby's life, when the donor marrow takes hold quickest. Waiting until after the first four weeks of life increases the risk of infection, as well as slowing the development of immunity from the donor transplant. Buckley also found that transplants can be done without exposing the infant to toxic chemotherapy, which can have life-long repercussions. Many doctors give chemotherapy to all bone marrow transplant patients because they are following standard cancer treatment protocol, Buckley said. But chemotherapy is not necessary in children with SCID because they have no T-cells to attack and destroy the foreign donor marrow, as is the case with cancer patients. "Patients with SCID have no immune systems to reject the transplants. Our approach avoids toxic agents and their possible complications," she said. Moreover, Buckley has found a way to reduce a potentially fatal complication of transplants called graft-versus-host disease (GVHD). By removing the donor's T-cells before the transplant, the donor's marrow cannot rise up and attack the patient's vital organs -- a common complication with bone marrow transplants. And, by removing these cells before the transplant, the infant avoids the toxic drugs normally given to suppress the donor's T-cells. Results from the study of 79 SCID patients who received bone marrow transplants at Duke between May 1982 and January 1997 indicate that parents, as well as siblings of SCID-affected babies, can be successful marrow donors. None of the patients received pre-transplant chemotherapy. Overall, 78 percent of the patients have survived -- some are now teenagers --  including all 12 recipients who received identical marrow transplants. Seventy-four percent of the 67 haploidentical (or parent donor) marrow recipients survive. Within the total group of 79 patients receiving marrow transplants, 18 babies were diagnosed with SCID in utero or at birth because of a family history. Thirteen of those early-diagnosed babies received marrow transplants from eight to 24 days after birth. Twelve of 13 -- 92 percent -- survive; one is now 15. The other six received a transplant within three months and all survived. The Duke researchers found no difference in eventual outcome between identical or half-match stem-cell transplants, leading them to support early diagnosis and neonatal transplant as key to curing SCID patients. Newborn screenings can detect the genetic defect in SCID babies. With the mother available as a marrow donor, the life-saving transplant can be done in the first few days of a baby's life. The patient can receive treatment as an outpatient or with "observation admission" (23 hours in the hospital). "This makes the treatment both easier on the mother and baby and cost-effective" said Buckley. "What we're saying is that essentially every baby with SCID could be cured if diagnosed early enough. SCID should be considered a pediatric emergency." Buckley characterized the Duke researchers' approach as conservative when compared with recent attempts to treat SCID in utero. Neonatal treatment bypasses the instrumentation risks associated with pre-term treatment, she said.
--------
658-> Rural Children, Poor Children at Greatest Risk from Deadly Fires
Many people associate deadly fires with poor families and crowed, big-city neighborhoods. Indeed, a new study by researchers at Washington University School of Medicine in St. Louis shows that young children in poor areas are six times more likely than other children to die in a fire. But the same study shows that the deaths are by no means limited to the city. In fact, young children in rural areas are almost three times more likely than young children in cities to die in a fire. The researchers examined the death certificates of all Missouri children who died in household fires between 1990 and 1995. In rural areas, about nine in every 100,000 children under age 5 died in a fire each year, compared with just over three fire-related deaths per 100,000 young children in the cities. The researchers reported the findings last month at the annual Pediatric Academic Societies' meeting in Washington, D.C. "Fire is one of the leading causes of death among children, particularly children less than 5 years old," says Nancy Wick, M.D., a postdoctoral fellow in pediatrics at the School of Medicine and the study's lead researcher. "But a lot of fire-related childhood deaths can be prevented. The point of this research is to find some interventions that work." Wick suspects that unsafe housing is the main cause of the high death rates in both poor and rural areas. She says children in low-income neighborhoods often live in old houses with dangerous heating, such as space heaters and wood stoves. And many children in rural areas live in mobile homes, which can burn quickly and often have only a single exit. Wider use of smoke detectors in all types of housing would probably cut the death rate, Wick says. Other researchers have suggested that fires in rural areas are often fatal because it takes so long to get victims to a hospital, but Wick thinks other factors are more important. "Most children who are killed by fire die at the scene or before they get to the hospital, even in urban areas," she says. In a previous study, Wick and other researchers found that the fire-related death rate for young children in Missouri was twice the national average. Other states in the South and Midwest also have high death rates, including Illinois, Oklahoma, Alabama and Mississippi. Thesestates can probably also trace their death rates to unsafe heaters, mobile homes and old, wooden housing, Wick says. In future studies, Wick plans to compare death rates to the causes of the fires, the type of housing, the amount of adult supervision, and the use of smoke detectors.
--------
659-> New Drug For Deadly Infection Shows Favorable Results In Preliminary Trials
WASHINGTON, DC -- A new drug to prevent a form of pneumonia that kills 4,500 infants a year in the United States shows promise after preliminary clinical testing at Georgetown University Medical Center and nine other centers in the U.S. The new drug, called MEDI-493, has undergone a double-blind, placebo controlled, dose escalation, multi-center, phase I/II trial evaluating important safety and pharmacological properties for treatment of respiratory syncytial virus in infants.  MedImmune Inc. of Gaithersburg, MD, which supported this trial, has the exclusive worldwide marketing and manufacturing rights for MEDI-493. Respiratory syncytial virus (RSV) afflicts the underdeveloped lungs of premature infants, and is responsible for the hospitalization of 90,000 infants each year in the United States alone.  The cost of treating a high-risk infant for RSV can be over $70,000. Currently, a drug called RespiGam™ (Respiratory Syncytial Virus Immune Globulin Intravenous (Human)) is given to high-risk infants to prevent hospitalization due to RSV infection.  At risk infants receive RespiGam™ once a month in a lengthy two to four hour infusion.  RespiGam ™ is marketed in the U.S. by MedImmune in partnership with American Home Products Corporation. MEDI-493 can be given more rapidly by infusion or by intra-muscular injection.  If successful in phase III clinical trials, MEDI-493 has the potential to enhance patient care, reduce costs associated with drug administration and improve convenience for parents, physicians and nurses. Dr. K.N. Siva Subramanian, the principal investigator in this study, presented the findings last month at the Pediatric Societies' Annual Meeting in Washington, DC. # # # Commercialization of MEDI-493 will require prior approval from regulatory authorities, including the Food and Drug Administration in the United States.  There can be no assurances that such approvals will be obtained.
--------
660-> Vaccine For Cytomegalovirus Has Promise
NORFOLK, Va.  --  Researchers at Eastern Virginia Medical School are studying a vaccine that may decrease transmission of cytomegalovirus (CMV) from children to adults. CMV is a virus that may cause mononucleosis-type illness in healthy adults, severe infections in persons whose immune systems are impaired, organ rejection in transplant recipients and birth defects in infants born to mothers infected during pregnancy. Douglas K. Mitchell, M.D., assistant professor of pediatrics at EVMS, led the investigation, which was carried out at the Center for Pediatric Research, a joint program of EVMS and Children's Hospital of The King's Daughters. Mitchell's research, which involved toddlers, used a subunit vaccine combined with a novel adjuvant.  The vaccine was produced by Chiron Vaccines, Emeryville, CA.  The vaccine was well tolerated and highly immunogenic in the toddlers.
--------
661-> Texas Researcher Finds Increased SIDS Risk In Twins
CONTACT:	Robert Lucey, Medical/Health Writer (409) 772-2618 (800) 228-1841 rlucey@mspo1.med.utmb.edu GALVESTON -- Infants from twin births have more than twice the risk of sudden infant death syndrome (SIDS) compared to babies of single pregnancies, a national study examining birth and death records of twins confirmed. Researchers from the University of Texas Medical Branch at Galveston also found an increased risk of a surviving twin dying of SIDS once his twin dies of the syndrome. Michael H. Malloy, M.D., professor in the University of Texas Medical Branch at Galveston's Division of Neonatology conducted the study with co-author Daniel Freeman Jr., Ph.D., director of UTMB's Office of Biostatistics. Malloy presented the data last month at the annual meeting of the Pediatric Academic Societies in Washington, D.C. The study, using national birth and death records from 1987, found 2.76 SIDS deaths per 1,000 live twin births -- more than double the rate of 1.2 SIDS deaths per 1,000 live births of single pregnancies. Of the 66,276 fraternal and identical twins in Malloy's study, 183 were identified as dying of SIDS, including three pairs of twins. Cases of both twins dying were rare. But the risk of a surviving twin dying of SIDS given the death of its co-twin was considerably increased above the risk of either twin dying of the syndrome. "If one twin dies of SIDS, the risk may be from six- to twelvefold greater that the other twin will die," Malloy said. "But the absolute number of such events occurring is still very low." Malloy's study may also dispel a myth that twins die of SIDS on the same day. At least in 1987, none of the three pairs of twins dying of SIDS died on the same day. "There is a lot of mythology out there about twins and SIDS," Malloy said. "This is an area that has not been researched a great deal." SIDS is the leading cause of mortality after infants' first four weeks of life, with 4,073 deaths in the United States attributed to the syndrome in 1994. While the underlying mechanism for SIDS remains unknown, epidemiological studies have linked it with several factors, including the association with twin births. "The increased risk of SIDS among twin births is particularly interesting because it brings forward the issue of trying to understand where environmental contributions causing SIDS may trail off and hereditary contributions to the cause of SIDS may begin," Malloy said. SIDS has been linked to such environmental factors as infants sleeping on their stomachs, soft  bedding, seasonal conditions, low birth weight and exposure to cigarette smoke. Malloy said the increased risk of a second twin dying if its sibling dies of SIDS may simply show that both were exposed to the same environmental factors, or it may show that both were predisposed to the syndrome genetically. "There's more we need to study," he said. "It's likely that a great deal of the risk can be ascribed to the environment, but we don't have enough information to rule out heredity." Previous reports suggesting that twins have a higher incidence of SIDS looked at populations in smaller regions. The UTMB-funded study used a new computer program to identify twins using national vital statistics. Twins -- not identifiable as belonging to the same pair in birth or death records -- were matched using birth dates and locations, as well as demographic information about their parents. "It gives a good look at what's happening across the United States, not just one specific area," Malloy said. Malloy has applied for grants to study more recent years in order to determine if the declining rate of SIDS in the general population is mirrored in the twin population. That decline followed campaigns to inform parents of the importance of laying their children on the backs rather than their stomachs. 
--------
662-> ZBLAN Research Takes Step Forward
Research into a material with the potential to become the optical fiber cable of the 21st century has taken a step forward with the acceptance of space-based research for publication in the peer-reviewed Journal of Materials Research. Dr. Dennis Tucker of NASA/Marshall Space Flight Center, along with co-investigators from the University of Alabama in Huntsville and Boeing have found that ZBLAN manufactured in a nearly gravity-free environment has properties that far exceed current state-of-the-art optical fiber materials or even ZBLAN made on Earth. Discovered by a team of French researchers in 1974, ZBLAN is named after the heavy metals found in the chemical composition of the material: zirconium, barium, lanthanum, aluminum, and sodium (chemical symbol "Na"). ZBLAN is a member of the heavy metal fluoride family of glasses, and has promising applications in fiber optics. It is highly transparent in the infrared region of the electromagnetic spectrum, thus opening an entirely new energy range for optical fiber communications, sensing, and technology development. But to develop this new material fully will require some more hard science be done. In theory, one should be able to make a ZBLAN optical fiber cable that has the capability to carry more than 100 times the amount of data carried by today's traditional silica-based optical fiber cables. In practice, however, the best that has been achieved has only been about 1/5 of current cables.  "This is primarily because of the fact that when you make ZBLAN on the ground, it has this nasty tendency to crystallize - to come out of its glass-like state - which severely degrades its optical properties," commented Tucker. The two pictures accompanying this release demonstrate this. ZBLAN on the left, made on Earth in a one-gravity environment, shows a great deal of non-uniformity and inhomogeneities due to its crystalline state. By contrast, the ZBLAN on the right was made aboard a Conquest-1 suborbital rocket flight. Its glassy nature is readily visible, as are some bubbles that formed when the sample inadvertently came in contact with the container. "It's really fascinating stuff," remarked Tucker. "Most of my colleagues perform experiments in space in order to make very high-quality crystals, but ZBLAN doesn't crystallize." Potential areas of application for this material include medical surgery and cauterization, temperature monitoring, infrared imaging, fiber-optic lasers, optical power transmission, and a host of other areas. A recent marketing survey indicated that the annual impact of ZBLAN on the economy might total as much as nearly $8 billion. "But before we get there, we've got a lot of hard science to do first," said Tucker. "We really have to get to the physical understanding of why ZBLAN behaves the way it does, and what makes it stay in the glass state in microgravity, as opposed to crystallize like it does on the ground." (The images referred to in this text may be found at http://www.ssl.msfc.nasa.gov/newhome/headlines/msad03jun97_1.htm)
--------
663-> Salt Is Not The Only Factor -- Races Respond Differently To High Blood Pressure Treatment
Significant racial differences in response to high blood pressuremedications persist even when the variable of salt sensitivity iscontrolled, says a University of Maryland School of Medicineresearcher.  Up to now, the difference in salt sensitivity among raceswas believed to be the only factor influencing the effectiveness ofdifferent medications in lowering blood pressure in African Americans,Hispanic Americans and Caucasians. At the American Society of Hypertension scientific meeting in SanFrancisco May 27-31, 1997, Dr. Matthew R. Weir presented findingsfrom a clinical trial involving two of the most common kinds of bloodpressure medication.  A professor of medicine and head of the Divisionof Nephrology at the University of Maryland School of Medicine inBaltimore, Weir authored the multi-center study, which compared theblood pressure-lowering effects of enalapril, an angiotensinconverting enzyme (ACE) inhibitor, and the calcium channel antagonistisradipine during high and low salt intake. Nearly 400 African Americans, Hispanic Americans and Caucasians withhigh blood pressure who also were known to be salt-sensitive werestudied.  Weir and colleagues found that isradipine lowered bloodpressure more effectively in African Americans on a high salt diet,while both drugs worked equally well for African Americans on a lowsalt diet.  In Caucasians, both medications produced similar bloodpressure reduction on a high salt diet, but enalapril was moreeffective for Caucasians who restricted their salt intake.  InHispanic-Americans, both drugs lowered blood pressure to similarlevels on both high and low salt diets. "Our results show that there are issues other than salt sensitivity inthe racial differences we see in response to antihypertensivemedications," Weir said.  "We controlled for salt sensitivity, andracial differences - although lessened - persisted.  This reinforcesthe importance of dietary salt restriction for people of all races whohave high blood pressure." In another presentation at the hypertension meeting, Weir discussed the relationship of high blood pressure to kidney disease.  "We arenow observing that more aggressive treatment of hypertension can beboth safe and effective in preventing kidney damage," he said. END
--------
664-> Bell Labs Scientists Demonstrate Record-Setting Ultra-High-Power Single-Mode Fiber Lasers
 Donna Cunningham 802-482-3748 (office) 802-482-2933 (home) donnac@lucent.com Carl Blesch 908-582-7474 (office) 908-306-0784(home) cblesch@lucent.com FOR RELEASE WEDNESDAY,   MAY 28 , 1997 MURRAY HILL, N.J. -- Bell Labs scientists, working with colleagues at Opto Power Corp. in Tucson, Ariz., have demonstrated record-setting output powers from optical-fiber lasers. The fiber lasers, each pumped by a single semiconductor laser and  with the output coupled directly into a single-mode fiber, produced 8 to 21 watts of power. The research team has built a cascaded Raman fiber laser with an output power of 8.5 watts at 1472 nanometers; the laser could be used to boost communications signals in long-haul communications systems. Conventional lasers used for this purpose typically produce only one tenth of a watt. They’ve also built fiber lasers, with ytterbium-doped fiber cavities defined by two fiber Bragg gratings, that yield 16.4 watts of power at 1065 nanometers and 20.4 watts at 1101 nanometers into a single-mode fiber. The lasers’ output power levels are about 80 and 300 percent higher than other single-mode fiber lasers operating at 1065 and 1100 nanometers, respectively. The fiber lasers were pumped by a single high-power laser-diode array with more than 40 watts of optical power at 915 nanometers. In these high-power fiber lasers, light from a semiconductor laser is guided within the outer layer, or cladding, of a specially developed fiber with a single-mode core containing the rare-earth element ytterbium.  The light is absorbed by the ytterbium, which changes its wavelength and makes it possible to “pump” optical amplifiers that boost communications signals.  They make it possible for the signals to travel longer distances and are powerful enough to be used as a single source for distribution of the signals, through a router, to many users. “The ability to have these high output powers coupled into a single-mode fiber is unprecedented in telecommunications technology,” said Kenneth Walker, head of the Bell Labs Optical Fiber Research department.  “Their power levels are so high that they may be more practical as very high-power amplifiers in free-space communications than in traditional terrestrial fiber systems.  It takes a lot of power to transmit signals through fog, snow, and/or rain without degradation or for the distances of greater than 10,000 kilometers that are necessary for satellite-to- satellite communications.” The lasers have potential applications in telecommunications, materials processing, printer and medical fields. “In principal, the ytterbium-doped lasers can operate at any wavelength from 1050 to 1140 nanometers, “ said researcher Daryl Inniss.  “Our results suggest that even higher diffraction-limited continuous-wave output power can be produced in the 1050-to-1700-nanometer wavelength region. Cascaded Raman lasers can be used to efficiently convert these output powers to wavelengths as long as 1.7 micrometers. Inniss presented the research team’s latest experimental results in a talk at the joint Conference on Lasers and Electro-Optics (CLEO '97) and Quantum Electronics and Laser Science Conference (QELS '97) in Baltimore last week. Other members of the research team are D.J. DiGiovanni, T.A. Strasser, A. Hale, C. Headley, A.J. Stentz, R. Pedrazzani, D. Tipton, S.G. Kosinski, D.L. Brownlow, K.W. Quoi, K.S. Kranz, R.G. Huff, R. Espindola, J.D. LeGrange and G. Jacobovitz-Veselka, working with D. Boggavarapu, X. He, D. Caffey, S. Gupta, S. Srinivasan, K. McEuen and R. Patel of Opto Power Corp., Tucson, Ariz. "Breakthroughs in record, reliable, CW high-power laser-diode arrays have unleashed the high-power potential of fiber lasers," said Rushi Patel, vice president, engineering, Opto Power Corp. Lucent Technologies designs, builds and delivers a wide range of public and private networks, communications systems and software, consumer and business telephone systems and microelectronics components.  Bell Labs is the research and development arm for the company. Bell Labs has a long history of laser invention and innovation, beginning in 1958 with publication of the scientific paper describing the concept of the laser by Arthur Schawlow and Charles Townes.  Both worked for Bell Labs at the time, Schawlow as a researcher and Townes as a consultant. Further information about the company is available at http://www.lucent.com. -###- BELL LABS ULTRA-HIGH-POWER SINGLE-MODE FIBER LASERS ADDITIONAL TECHNICAL INFORMATION Bell Labs researchers, working with colleagues at Opto Power Corp., have demonstrated ultra-high-power single-mode fiber lasers from 1.065 to 1.472 micrometers, using ytterbium-doped cladding-pumped and cascaded Raman lasers. They have demonstrated the highest reported output powers at multiple wavelengths with well defined spectral outputs in a conventional single-mode fiber.  They have shown that ytterbium-doped fiber cavities defined by two fiber Bragg gratings are both efficient and versatile when lasing at either 1065 or 1101 nm.  They have built and operated cascaded Raman fiber lasers with an output power of 8.5 watts at 1472 nm, demonstrating that these output powers can be efficiently converted to any desirable wavelength between 1.1 and 1.7 micrometers. The fiber lasers were assembled with Yb-doped cladding pumped fiber having a low index polymer coating.  The high reflector (99.9 percent reflectivity) was UV-induced in D2 sensitized fiber by conventional phase mask exposure at 242 nm.  The output coupler of the cavity was a similar UV-induced grating in a standard high-index coated fiber.  The cavities were assembled by fusion spicing the fiber gratings to the Yb-doped fiber.  The fiber laser was pumped by a single Opto Power 915 nm one-centimeter-wide high-power semiconductor laser bar in a specially designed beam-shaper configuration for optimal fiber coupling.  Power levels of more than 40 watts from a 400-micrometer 0.22 NA fiber were achieved. At 1065 nm, 16.4 W is the highest power reported from any cladding- pumped fiber laser.  The previous highest power reported is 9.2W from a Nd-doped cladding-pumped fiber laser pumped with 40W, with an output bandwidth of 13 nm.  At 1101 nm, the 20.4 W is the highest conventional fiber-coupled single-mode output power from a fiber laser; the 8.5 W output power of the cascaded Raman laser is the highest power available for pumping a conventional Er amplifier. The researchers have demonstrated the great flexibility and excellent performance of Yb-doped cladding-pumped cavities defined by fiber Bragg gratings.  In principal, this laser can operate at any wavelength from 1050 nm to 1140 nm, where Yb is a quasi-four-level system.  Cascaded Raman lasers can be used to efficiently convert these output powers to wavelengths as long as 1.7 microns. -###- 
--------
665-> Bell Labs Scientists Demonstrate New High-Power, Laser-Based Sensor Technology For Gas Detection, Pollution Monitoring
 Donna Cunningham 802-482-3748 (office) 802-482-2933 (home) donnac@lucent.com Carl Blesch 908-582-7474 (office) 908-306-0784(home) cblesch@lucent.com FOR RELEASE TUESDAY, MAY 20, 1997 MURRAY HILL, N.J. -- In a major breakthrough, Bell Labs scientists have demonstrated the world’s first laser-based semiconductor sensor that operates at room temperature and at high power to detect minute amounts – potentially parts per billion -- of trace gases or pollutants by scanning for their optical-absorption "fingerprints." Gases or pollutants are identifiable by their absorption wavelengths, which depend on their chemical nature.  The invisible but telltale fingerprints can be detected by focusing the sensor on an area and precisely tuning the laser’s wavelength until its light is absorbed. "This is a major accomplishment," said Alastair Glass, director of the Bell Labs Photonics Research Laboratory.  "The tuning range and peak power of these prototype laser sensors are unprecedented for mid-infrared semiconductor lasers – about 10 and 100 times better, respectively, than commercial lasers of this type – all of which must be cooled." The experimental sensor is  based on the novel quantum-cascade (QC) laser invented at Bell Labs just three years ago and demonstrated at room temperature operation last year.  The newest versions can be continuously tuned to operate at any of a wide range of single frequencies in the mid-infrared region of the  electromagnetic spectrum, the region in which light is invisible and causes heat. The laser’s wavelength is determined by several factors.  In manufacture, varying the thicknesses of the material layers of the laser sets its wavelength, and adding a grating (etched material) on top of the laser makes the wavelength more precise.  In use, adjusting the temperature or the electrical current applied to the laser changes its wavelength. Using the sensor to detect pollutants involves scanning the area over a smokestack, for example, and shifting the laser’s wavelength until the light crossing the smokestack hits the pollutant’s "fingerprint" and is affected by it. "This work opens up an entire field of uncooled, tunable mid- and far-infrared laser sensors," said L.N. Durvasula, program manager, Defense Sciences Office, U.S. Defense Advanced Research Projects Agency (DARPA), which partly funded the work.  "This is a revolutionary development for sensor applications." The Bell Labs research team includes Jerome Faist, Claire Gmachl, Federico Capasso, Carlo Sirtori, Deborah Sivco, James Baillargeon and Alfred Cho, in collaboration with Professor Edward Whittaker of the Stevens Institute of Technology in  Hoboken, N.J. "We’re happy to have moved very quickly from basic research to practical application," said  Federico Capasso, head of the Quantum Phenomena and Device Research department.  "The enabling technology behind all this is the marriage of optics, quantum physics, and crystal growth, in the QC laser, and we foresee a number of market opportunities for these portable, robust devices." Potential environmental applications include pollution monitoring, automotive emission sensing and combustion diagnostics; law-enforcement possibilities, such as the detection of explosives or of fugitive emissions from illicit drug-manufacturing sites; military applications like portable  battlefield sensing of  toxic gases and biological toxins; as well as industrial process control, collision-avoidance radar and medical applications. Conventional semiconductor lasers, which operate at wavelengths from near-infrared to visible, are widely used in other applications such as lightwave communications and compact-disk players. Detailed information about the distributed-feedback QC laser sensor appears in this week’s issue of the journal Applied Physics Letters.  Gmachl will present the research team’s latest experimental results in a post-deadline talk on Thursday at the joint Conference on Lasers and Electro-Optics (CLEO '97) and Quantum Electronics and Laser Science Conference (QELS '97) in Baltimore. Lucent Technologies designs, builds and delivers a wide range of public and private networks, communications systems and software, consumer and business telephone systems and microelectronics components.  Bell Labs is the research and development arm for the company.  Further information about the company is available at http://www.lucent.com. -###- BELL LABS DISTRIBUTED-FEEDBACK QUANTUM-CASCADE LASERS ADDITIONAL TECHNICAL INFORMATION Bell Labs researchers have demonstrated continuously tunable, single-mode, high-power room-temperature QC distributed-feedback lasers operating at mid-infrared wavelengths (5 and 8.5 micron) in pulsed mode.  The single-mode tuning range is typically 50 nanometers in wavelength, and the peak powers are 60 milliwatts, one and two orders of magnitude better, respectively, than commercially available mid-infrared lead-salt lasers. The lasers’ high peak power, 50 milliwatts at 300 degrees Kelvin, allows the use of uncooled detectors and enables LIDAR (radar using light) applications.  They are particularly well suited for portable, robust sensors in applications such as the point detection of trace gases and remote sensing applications. QC lasers are made using molecular beam epitaxy (MBE), a materials-growth process from Bell Labs that makes it possible to build structures with layers only a few atoms thick.  The QC laser’s emission wavelength is determined initially by quantum-confinement effects: the fact that its layers are so thin – typically a few nanometers, or about 100 billionths of an inch – that electrons are squeezed and change their quantum-mechanical properties, allowing a range of possible wavelengths. The distributed-feedback lasers incorporate a grating that makes it possible to further refine the laser’s wavelength, making them continuously tunable. QC lasers were invented at Bell Labs in 1994.  Their operation is unlike that of all other laser.  They operate like an electronic waterfall: When an electric current flows through a QC laser, electrons cascade down an energy staircase; every time they hit a step, they emit an infrared photon, or light pulse. At each step, the electrons make a quantum jump between well defined energy levels.  The emitted photons are reflected back and forth between built-in mirrors, stimulating other quantum jumps and the emission of other photons.  This amplification process enables high output power. Bell Labs has a long history of laser invention and innovation, beginning in 1958 with publication of the scientific paper describing the concept of the laser by Nobel Laureates Arthur Schawlow and Charles Townes.  Both worked for Bell Labs at the time, Schawlow as a researcher and Townes as a consultant. -###- Applications of Quantum Cascade Lasers Important potential commercial applications of the QC laser -- based on the spectroscopic detection of molecular species – include environmental sensing and monitoring, with particular emphasis on pollution monitoring and measurement of air quality, in particular: ·  remote sensing (over a range from hundreds of meters to a few miles) of chemicals such as toxic gases and vapors emanating from industrial smokestacks, landfills and other  hazardous waste sites. ·  point sensors, based on multipass absorption cells, of the local concentration of hazardous gases and vapors and short-range sensing (a few to tens of meters) for uses such as monitoring of automobile emissions on the entrance and exit ramps of highways, etc., combustion diagnostics via fast on-line monitoring of gases in automobile exhausts, collision avoidance radar, industrial process control, ammonia- and water-vapor sensing in agriculture to monitor dosages of fertilizer. The enactment of the Clean Air Act Amendments (CAAA) of 1990 has resulted in a strong increase in these environmental monitoring needs.  Most of the toxic chemicals (gases and vapors) included in the CAAA have strong absorption features in the 3-to-5-micron and 8-to-13-micron wavelength atmospheric transparency windows. Other applications include medical diagnostics, molecular clocks,  laser radar heterodyne detection. Military applications include sensors for biological toxins and  toxic gases such as nerve and mustard gas, countermeasures and infrared scene projection, treaty verification, etc. In the law enforcement area, the detection of explosives and of illicit drug production sites are among the possible uses. -###- 
--------
666-> New Findings Blame Jump In Hurricane Toll On Coastal Growth, Not Climate Change
BOULDER--In the past eight years, three U.S. hurricanes--Andrew (1992), Hugo (1989), and Opal (1995)--have wreaked a total of over $40 billion in damage.  However, according to a new study, this number does not reflect any unusual increase in hurricane strength or frequency.  Instead, it indicates that more and more Americans have put themselves and their property at risk by flocking to vulnerable coastal locations.  The population shift could spell further trouble if hurricanes again make landfall as often as they did in the 1940s or 1960s. "Normalized Hurricane Damages in the United States: 1925-1995" was presented by Roger Pielke (National Center for Atmospheric Research, or NCAR, Boulder, Colorado) and Christopher Landsea (National Oceanic and Atmospheric Administration/Atlantic Oceanographic and Meteorological Laboratory, Miami, Florida) on May 22 in Fort Collins, Colorado, at the 22nd Conference on Hurricanes and Tropical Meteorology, sponsored by the American Meteorological Society.  NCAR is operated by the University Corporation for Atmospheric Research under sponsorship of the National Science Foundation. Pielke and Landsea note that a variety of sources from the U.S. Senate to Newsweek magazine have linked global warming to the past decade's rise in hurricane damages.  Yet most of the Atlantic hurricane seasons since 1970 have seen tropical cyclones occurring at a less frequent rate than the century-long average.  Only in 1995 and 1996 (the two busiest consecutive seasons on record) did the pace pick up significantly.  Some climatologists now believe that a natural multidecadal cycle will inevitably return to a period of increased Atlantic hurricane activity similar to the 1940s-1960s. How might that affect today's society?  Pielke and Landsea examined landfalling U.S. hurricanes since 1925 and normalized their effects to 1995 values, taking into account three factors: (1) inflation; (2) a disproportionate increase over time in the number of Americans living near the Atlantic and Gulf Coasts; and (3) increase in material wealth held by the average household (families own more possessions than ever before). Through this analysis, Pielke and Landsea estimate that the 1926 Miami hurricane--which passed just north of Andrew's track across south Florida, then struck the Mobile, Alabama/Pensacola, Florida region--would inflict some $72 billion in damages if it struck today.  That storm was a category 4, one notch below the strongest ranking on the Saffir-Simpson scale, the hurricane rating system used by U.S. meteorologists. The analysis also shows that seven hurricane seasons between 1940 and 1969 would have produced damages of more than $10 billion each had they occurred in 1995, while only three seasons since 1970 would have done the same.  (See graphs on back page.) "The normalized data indicate clearly that the United States has been fortunate in recent decades with regard to storm losses.  The data also refute recent claims that the rapid increase in nonnormalized damages is due to climatic changes," says Pielke. According to Landsea, "The normalized damages suggest that the nation should expect about $5 billion in damages per year, and substantially more than that if we are entering a regime of more active hurricane conditions." If the normalization methodology is any indication, Pielke adds, "It is only a matter of time before the nation experiences a $50 billion or greater storm, with multibillion-dollar losses becoming increasingly frequent.  Climate fluctuations which return the Atlantic basin to a period of more frequent storms will enhance the chances that this time occurs sooner, rather than later." Writer:  Bob Henson A draft of the referenced paper will be available on the Web after May 22 at http://www.dir.ucar.edu/esig/hp_roger/hurr_norm.html Reporters are free to quote from this version of the paper. This press release is available on the World Wide Web at http://www.ucar.edu/ucargen/press/hurricane.html CAPTION: Although U.S. hurricane damage tolls have soared in recent years (left), a new study puts these figures in perspective by adjusting them for increases in coastal population and wealth during this century.  The normalized values (right) show that landfalling hurricanes in 1926 would have produced over $74 billion of damage if they struck today.  Several other hurricane seasons in the 1940s, 1950s, and 1960s would have topped $10 billion in damage. (Illustrations courtesy Roger Pielke, Jr., and Christopher Landsea.) 
--------
667-> Limited Course of Thalidomide Effective in Treating AIDS-Related Mouth Ulcers
Thalidomide effectively heals severe mouth and throat ulcersin people with HIV infection, according to a study supported by the National Institute of Allergy and Infectious Diseases (NIAID) and reported in the May 22, 1997, issue of The New England Journal of Medicine. "For the many patients with HIV infection who suffer fromthese ulcers, eating can be excruciatingly painful, which exacerbates wasting and debilitation," says Division of AIDS Director Jack Killen, M.D.  "Thalidomide is the first treatment shown in a scientific study to heal these ulcers, but the course should be carefully monitored and limited in its duration because of the drug's potential toxicity." The ulcers of 55 percent of the patients receiving four weeksof thalidomide healed completely, compared to healing in only 7percent of the patients receiving placebo.  Almost all (90 percent) of those receiving thalidomide had at least partial healing. The AIDS Clinical Trials Group (ACTG), a network of clinicaltrial sites supported by NIAID, conducted this study, called ACTG 251.  Baseline and weekly health evaluations of study volunteers included a quality-of-life questionnaire to assess pain and discomfort during eating.  Results from these questionnaires showed that the thalidomide group improved much more than the placebo group in regaining comfort while eating. "Thalidomide appears to have great potential as a therapy forHIV-infected patients who have severe oral aphthous ulcers," says Lawrence Fox, M.D., Ph.D., one of two NIAID authors, "but only when administered by a physician who is vigilant for the possible serious side effects, including irreversible, painful peripheral nerve damage, rash and birth defects. Patients experienced only minimal adverse effects while theywere taking thalidomide.  Seven patients reported drowsiness and seven had rashes.  The authors caution, however, that those patients who received thalidomide showed a small, but statistically significant increase in HIV ribonucleic acid (RNA) blood levels from the baseline through the fourth week of the study as compared to patients receiving placebo.  "There is not sufficient information, however, to judge whether this increase is of any clinical significance," says study director Jeffrey M. Jacobson, M.D., of the Departments of Medicine atboth Bronx Veterans' Affairs Medical Center and Mount Sinai School of Medicine, New York. A second reason for caution, according to the study results, isthat patients taking thalidomide had elevated plasma levels of tumor necrosis factor (TNF)-alpha, a substance released from phagocytes and from some T cells during the immune response and known to provoke HIV replication and expression from infected cells.  This was unanticipated because earlier studies had reported that thalidomide inhibited production of TNF-alpha . These patients also showed increased soluble TNF-alpha receptor levels, a phenomenon shown to be associatedwith clinical progression of HIV disease. Scientists at 19 sites conducted the double-blind, randomized,placebo-controlled study.  Of 57 volunteers, 29 received thalidomide.  The remaining patients received placebo, but were offered open-label thalidomide at the endpoint of the study.  All patients in the study were HIV-positive and had oral or throat ulcers for at least two weeks before the start of the study. At each of the study sites, physicians evaluated patients ininitial screenings, in baseline physical examinations, and then weekly throughout the study.  Because of thalidomide's well-known ability to cause severe birth defects, every precaution was taken to prevent pregnancy, and pregnancy tests were given weekly to women of childbearing age.  Each baseline and weekly evaluation included an assessment of nerve function, (peripheral sensory nerve disorders are a known complication of longer-term thalidomide treatment), laboratory analyses of blood cells, serum chemistries and serumthalidomide levels, and evaluation of liver and kidney function. The National Center for Research Resources supported thisstudy in part through the General Clinical Research Center Units. Andrulis Pharmaceutical Corporation of Beltsville, Md., providedthalidomide and placebo for the study. In addition to Drs. Jacobson and Fox, authors are John S.Greenspan, B.Sc., B.D.S., Ph.D., and Laurie A. MacPhail, D.M.D., Ph.D., both of the Department of Stomatology, University of California, San Francisco; John Spritzler, Sc.D., and Miriam Chernoff, Ph.D., both from the Statistical and Data Analysis Center, Harvard School of Public Health, Boston, Mass.; Nzeera Ketter, M.D., Division of AIDS, NIAID, Bethesda, Md.; John L. Fahey, M.D., Department of Medicine, University of California, Los Angeles; J. Brooks Jackson, M.D., Department of Pathology, Johns Hopkins University School of Medicine, Baltimore, Md.; Albert W. Wu, M.D., M.P.H., Department ofMedicine, Johns Hopkins University School of Medicine, Baltimore, Md.; Guillermo J. Vasquez, M.D., Department of Medicine, University of Puerto Rico Medical School, San Juan; and David A. Wohl, M.D., Department of Medicine, University of North Carolina, Chapel Hill. Other participating study sites are Mount Sinai MedicalCenter, New York; University of  Hawaii, Manoa; University ofSouthern California, Los Angeles; Northwestern University, Chicago; University of Washington, Seattle; Stanford University, Palo Alto, Calif.; Harvard Medical School, Boston, Mass.; New York University, New York; Indiana University, Indianapolis; Meharry Medical College, Nashville, Tenn.; University of Pennsylvania, Philadelphia; Case Western Reserve University, Cleveland, Ohio; University of Colorado Health Sciences Center, Denver; University of Rochester, New York; and Albert Einstein College of Medicine, New York. NIAID, a component of the National Institutes of Health (NIH),conducts and supports research aimed at preventing, diagnosing and treating illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies. NIH is an agency of the U.S. Department of Health and Human Services.                                              ###                       References:Jacobson JM, Greenspan JS, Spritzler J, Ketter N, Fahey J, Jackson JB, Fox L, Chernoff M, Wu AW, MacPhail LA, Vasquez GJ, Wohl DA. Thalidomide for the treatment of oral aphthous ulcers in patients with human immunodeficiency virus infection. New Engl J Med 1997;336:1487-93. Makonkawkeyoon S, Limson-Pobre RNR, Moreira AL, Schauf V, Kaplan G. Thalidomide inhibits the replication of human immunodeficiency virus type 1. Proc Natl Acad Sci USA 1993;90:5974-8. Peterson PK, Hu S, Sheng WS, et al. Thalidomide inhibits tumor necrosis factor-alpha production by lipopolysaccharide- and lipoarabinomannan-stimulated human microglial cells. J Infect Dis 1995;172:1137-40. Poli G, Kinter A, Justement JS, et al. Tumor necrosis factor alpha functions  in an autocrine manner in the induction of human immunodeficiency virus expression. Proc Natl Acad Sci USA 1990;87:782-5. Sampaio EP, Moreira AL, Sarno EN, Malta AM, Kaplan G. Prolonged treatment with recombinant interferon   induces erythema nodosum leprosum in lepromatous leprosy patients. J Exp Med 1992;175:1729-37. Sampaio EP, Sarno EN, Galilly R, Cohn ZA, kaplan G. Thalidomide selectively inhibits tumor necrosis factor alpha production by stimulated human monocytes. J Exp Med 1991;173:699-703. Tramontana JM, Utaipat U, Molloy A, et al. Thalidomide treatment reduces tumor necrosis factor alpha production and enhances weight gain in patients with pulmonary tuberculosis. Mol Med 1995;1:384-97. Wulff CH, Hover H, Asboe-Hansen G, Brodthagen H. Development of polyneuropathy during thalidomide therapy. Br J Dermatol 1985;112:475-80. NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov.
--------
668-> Vitamin Supplements May Help Asthmatics Cope With Air Pollution
 SAN FRANCISCO -- Simply taking antioxidant vitamins could help asthmatics exposed to polluted air breathe easier. Preliminary results of a double blind study indicate that adults with asthma who took daily supplements of both vitamins E and C showed improved pulmonary function, compared to when they took a placebo, after being exposed to two common air pollutants, ozone and sulfur dioxide. Ozone is formed from precursors in automobile exhaust, while sulfur dioxide is emitted from pulp mills, coal burning and other industrial processes. "Our results show that a combination of antioxidant vitamins can benefit people with asthma who are sensitive to air pollutants," said lead author Dr. Carol Trenga, who conducted the study while completing doctoral research at the University of Washington School of Public Health and Community Medicine.  Co-author of the study is Dr. Jane Koenig, an international expert on the respiratory health effects of air pollution. Trenga presented her preliminary findings on Tuesday, May 20, at the American Lung Association/American Thoracic Society International Conference. The study monitored pulmonary function in 17 asthmatic volunteers, who took a daily course of vitamins E and C (400 I.U. and 500 mg., respectively) and a daily course of placebo for separate five-week periods. Near the end of each course, participants received separate, 45-minute exposures to purified air and ozone at the current National Ambient Air Quality Standard (0.12 p.p. million). To measure effects of ozone exposure, volunteers then were exposed to two 10-minute sulfur dioxide challenges. Test results showed an overall decrease in sensitivity to ozone exposure when volunteers took vitamins as compared to placebo.  Improvements in pulmonary function were especially dramatic in a subset of six volunteers.  While on vitamin supplementation, this group had a 5 percent increase in peak expiratory flow during the sulfur dioxide challenges after ozone exposure compared to a 13 percent decrease in peak expiratory flow for the same period while on placebo.  These volunteers were previously identified as more sensitive to sulfur dioxide. Trenga explains vitamins E, which is fat soluble, and C, which is water soluble, complement one another, helping increase the potential to reduce oxidative damage in the lungs.  When polluted air comes in contact with the lung lining fluid, vitamin C is part of the body's first line of defense,  serving to reduce both ozone and free radicals formed by ozone exposure.  Vitamin E helps reduce lipid radicals and can be regenerated by vitamin C.   	People with asthma may not be the only ones who could benefit from antioxidant vitamin supplements.  Increases in daily vitamin intake may also benefit others exposed to chronic oxidative stress Ð such as smokers or industrial workers, Trenga said. She adds that future research should focus on linkages between nutritional factors and toxicity and disease.  This would include investigating whether regular antioxidant vitamin intake could ultimately reduce the need for medication or frequency of use among people with asthma. ###
--------
669-> In The Air And On The Ground: Scientists Seek Clues To Better Weather Forecasting
BOULDER-From April 22 to May 22, low-flying planes and an array of new surface gauges in the Walnut River watershed east of Wichita, Kansas, are gathering data from the lowest few thousand feet of the atmosphere, called the boundary layer.  Scientists Peggy LeMone of the National Center for Atmospheric Research (NCAR) and Bob Grossman of the University of Colorado are coordinating the experiment to learn more about the interactions between the boundary layer-which strongly influences weather and climate-and the watershed. Scientists understand most of the surface-boundary layer interactions.  "The real challenge," says LeMone, "lies in translating these processes into equations that can aid weather forecasters."  To do that, researchers must measure the rates of heating and evaporation at the surface, as well as how quickly air in the lower part of the boundary layer mixes with air in the upper part.  The Walnut River watershed (see map) was selected for its shape, size, land-use patterns, and hydrological characteristics.  In addition, the existing watershed instrumentation provides a useful historical data base. CASES researchers will share their observations and findings not only with other scientists, but with students as well.  Data collected in this first and future experiments in the multiyear project will be available on the Internet for use by students from middle schools through university graduate departments. The University of Wyoming's King Air and the National Oceanic and Atmospheric Administration's (NOAA) Twin Otter aircraft are gathering data to supplement information from surface weather stations, weather balloons, and radar provided by NCAR and the U.S. Department of Energy's (DOE) Argonne National Laboratory.  Called the Cooperative Atmosphere- Surface Exchange Study (CASES), the experiment is a joint effort by the National Science Foundation (NSF), NOAA, and the DOE. On the ground between Eldorado and Winfield, Kansas, 12 small towers measure evaporation, heating, and friction inside a triangular area marked off by three boundary-layer profilers that measure wind speeds and temperature.  The two low-flying aircraft, equipped with computers and atmospheric sensors, fly in special patterns between 100 and 10,000 feet above the sparsely populated research area.  Researchers are also releasing weather balloons at noon and 3:00 p.m. daily from two of the three profiler locations. The public is invited to view the aircraft at the Ponca City Airport during no-fly periods; contact Dr. Grossman (405-763-5809) to schedule an appointment.  CASES researchers are also available to visit classrooms.  Students and teachers can find more information about the experiment, including daily observations, on the World Wide Web at http://www.mmm.ucar.edu/cases/cases.html. NCAR is managed by the University Corporation for Atmospheric Research under sponsorship by the National Science Foundation. -The End- Writer:  Zhenya Gallon Find more information about the CASES project at http://www.mmm.ucar.edu/cases/cases.html 
--------
670-> Allen Foundation Pledges $3.2 Million For Prostatitis Research At The University Of Washington
The Paul G. Allen Foundation for Medical Research has committed $3.2 million for research at the University of Washington into the causes of and cures for prostatitis, a common but under-studied infection of the prostate gland. The foundation will contribute approximately $552,000 annually for the next five years to underwrite research into prostatitis conducted by the UW School of Medicine's Department of Urology. The research is under the direction of Dr. Richard E. Berger, professor of urology. The balance of the funding will go toward laboratory renovations and equipment costs. The UW has already completed a number of significant research projects on prostatitis, funded by more than $1 million in earlier contributions from the Microsoft co-founder and philanthropist. UW President Richard L. McCormick expressed gratitude for the gift and cited the "remarkable support in many areas" that Paul Allen and the foundations he has created have provided at the University of Washington. "This splendid gift continues and enhances the Allen Foundation's investment in medical research, an area of giving that has been very important to the University but one that many people did not know about," said McCormick. "We are pleased to support the University's groundbreaking research efforts and we hope that in some significant way, our gift will help to conquer this disease," said Jody Allen Patton, executive director of the Allen Foundations. "Past financial support from the Allen Foundation has already made the UW the leader in prostatitis research," said Berger. "We have made many exciting discoveries that will offer benefits for men with chronic prostatitis. This generous new support will enable us to significantly broaden our efforts." Despite the prevalence of prostatitis, there has been limited research into the condition, which may be the most common urologic disease of young and middle-aged men. Research has focused on the other maladies of the prostate: benign prostatic hypertrophy (BPH or enlarged prostate) and prostate cancer. Many men with BPH have symptoms of prostatitis as well. Estimates are that up to 50 percent of men will experience symptoms of prostatitis in their lifetimes. Symptoms can be varied and severe, including genital and bladder pain, inflammation, urinary problems, and perhaps infertility. While it is often dismissed as a minor condition, the decline in quality of life with prostatitis is similar to that experienced with congestive heart failure, according to UW research. Prostatitis is frequently difficult to diagnose, and causes are usually not clear. The various bacteria known to cause it often become resistant to antibiotics. Research directions with the new funding will include studies of the microbiology and molecular biology of prostatic tissue, development of diagnostic tests and treatment protocols, studies of host resistance factors that may cause susceptibility to infection, epidemiologic studies, and studies to determine any relationships to BPH and prostate cancer. The Paul G. Allen Foundation for Medical Research promotes medical research in a variety of disciplines, including biochemistry, biomedical engineering, virology, immunology, cell and molecular biology, pharmacology and genetics.
--------
671-> Testimony Therapy Helps Survivors Of Genocide In Bosnia
Psychiatrists at the University of Illinois at Chicago (UIC) are using a "testimony" method of psychotherapy to help survivors of the "ethnic cleansing" in Bosnia-Herzegovina. These survivors of genocide have suffered extreme psychological traumas that require special attention from mental health professionals. [UIC psychiatrists will present workshops on testimony psychotherapy at the annual meeting of the American Psychiatric Association in San Diego May 19 and 20.] "This method is an innovative way of working with survivors of human rights violations," says Dr. Stevan Weine, assistant professor of psychiatry and co-director of UIC's Project on Genocide, Psychiatry and Witnessing. "The survivor tells the story of what happened when traumas shattered their life, and the psychiatrist is the witness who records it. "Together, they make a document of the survivor's story to integrate the stress of their traumas into the saga of the rest of their lives and look for appropriate ways to make the survivor's story known to others so it is not forgotten." Since the "ethnic cleansing" began in Bosnia in 1992, more than 10,000 refugees have fled to the United States, including more than 2,000 to Chicago. "There are many ways in which the skills of a psychiatrist can be deployed to help survivors, uphold human rights and protect communities and societies in the face of genocide," says Weine. "The clinical benefits of testimony for the survivor are often plain to see," Weine adds. "However, as a narrative means of exploring phenomenon on the boundaries between the self and history, and as a story that is shaped both by the survivor and also the witness, testimony narratives are not at all straightforward. "Testimony and its narrative can be a type of psychotherapy, but it can also be considered autobiography, oral history, or even art." Weine says his interest in helping survivors of genocide grew from his Jewish heritage, in which genocide "has always been a part of my historical memory and cultural experience." "When I saw what was happening in Bosnia, I thought, ‘This is wrong, I want to try to do something about this as a psychiatrist.'" Weine will chair a workshop on testimony psychotherapy at the annual meeting of the American Psychiatric Association in San Diego.  The workshop, "Therapy, Story and History," will be held on Tuesday, May 20 from 11 a.m. to 12:30 p.m. in the Solomon Room on Level One of the San Diego Marriott Suites, 701 A Street.  Workshop speakers will include a Croatian psychiatrist and a Bosnian literary scholar who have extensive experience doing testimony psychotherapy with Bosnians and doing clinical, narrative and historical research and intellectual inquiry on the testimony. Weine will also chair a separate workshop at the APA meeting, "Psychiatrists for Genocide in Bosnia: Evidence and Interpretation," focusing on the issue of psychiatrists' involvement in the ethnic cleansing in Bosnia-Herzegovina. The workshop will be held Monday, May 19 from 11 a.m. to 12:30 p.m. in the San Diego Convention Center, 111 West Harbor Drive. Weine will review his interviews with former psychiatric colleagues of Radovan Kardzic, the former leader of the self-proclaimed Bosnian Serb government, and present an interpretation on these psychiatrists' various public uses of survivors' stories to nurture nationalism, hatreds, violence and denial. The workshop will discuss new forms of psychiatric abuse in the post-communist era and the roles that psychiatrists have fulfilled in relation to the recent genocide in Bosnia and critical issues that arise in evaluating the relationship between psychiatric professionals and state-sponsored violence. 
--------
672-> Hand-Held Computers Speed University Of Florida's Home Nursing Visits
By Christine Martinez de Castro GAINESVILLE, Fla.---The University of Florida is one of five universities selected to test new software that can shorten the time nurses spend documenting patients' health conditions. With the help of a hand-held, touch-screen computer running on software called the Nightingale Tracker -- named for the British nurse Florence Nightingale, hospital reformer and humanitarian -- UF nursing students document and track the condition of patients. The Nightingale Tracker makes home visits quicker and more efficient. Thanks to reduced paperwork, students found an extra 90 minutes or more each week. The new software enables nurses and nursing students in the field to collect patient information and communicate with faculty members and consultants who are back in their offices. The data is sent over standard telephone lines or through cellular phone technology. The Nightingale Tracker will enable real-time voice and data transmission via the Internet, and also can be used to browse the World Wide Web or to fax information. The software runs on a 3-pound, hand-held communication device called a personal digital assistant, comparable in size to a VCR tape. FITNE Inc. (formerly the Fuld Institute of Technology in Nursing Education), an Ohio-based developer of interactive technology for health-care education, chose UF to test its software "because it has a strong commitment to community health nursing and a clear vision for the future of health care," said FITNE project manager Vicky Elfrink. "The common thread among the universities chosen in the testing is their emphasis on providing students with learning opportunities in the community," Elfrink said. "Since a large part of nursing care is moving out of hospitals, we feel this kind of training is an investment in the future." College of Nursing clinical assistant professor Joan Castleman, who heads the UF Nightingale Tracker field test, said it gives the students practical experience with technology they will use once they graduate. Along with real-time communication, the software makes it easy to enter information into a clinical documentation record. It also is time-efficient in that nurses do not have to write long narratives on the patients' conditions. "I have done admissions papers and had to fill out 17 documents," said Kathryn Pearce, a registered nurse pursuing a bachelor1s degree in nursing at UF.  "The Tracker condenses the work so you don't have to handwrite anything." A unique feature of the Nightingale Tracker is its use of the Omaha System, a clinical language developed for health-care providers practicing in community or home health settings. The language provides a framework for encoding and communicating patient data in a manner that helps providers make decisions about a patient's care. UF just completed three months of software testing with 10 nursing students. The students were given questionnaires before, during and after the testing period. Students kept journals describing their experiences.  FITNE's Elfrink met with UF nursing students to get feedback. An upgraded version of the program will incorporate their suggestions. Elfrink found students to be generally positive. The UF students found the prototype saved them time because they were able to e-mail their clinical reports to their instructor. One shortcoming was that the computer1s operating system functioned slowly when large amounts of data were stored on it. In the second version of the software, which is being developed, this problem will be corrected by providing a server to store data, freeing up memory. The new version will enable users to send and receive faxes, e-mail and use Internet technology in a faster and more efficient manner. The hand-held computer also will be lighter, weighing less than 2 pounds, with better speaker phone quality. -------------------------------------------------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html 
--------
673-> Lucent Technologies Announces Industry's First All-Optical Cross Connect
Lucent Technologies announces industry's first All-Optical Cross  Connect FOR RELEASE: TUESDAY, MAY 06, 1997 MURRAY HILL, N.J. -- Lucent Technologies announced today the industry's first All-Optical Cross Connect that  delivers quicker recovery from service interruptions, significant savings in operating costs, higher reliability and greater  administrative flexibility. The Optical Cross Connect allows service providers to efficiently move wavelengths from point to point in their network  without making unnecessary and costly conversions along the way. Managing wavelengths at the optical level is less costly  than dropping down to the electrical level because the cost of the electrical devices is eliminated. In addition reliability is  increased and operations costs are decreased because fewer network elements such as back-to-back terminals are  required. The Optical Cross Connect also provides the important service restoration capabilities found in today's Synchronous  Optical Networking (SONET) layer. In particular, in the event of catastrophic failures, services can be restored at the  wavelength level using an Optical Cross-Connect, potentially delivering much faster restoration than today's electrical  restoration schemes. "The idea of an all-optical network and its promise of cost effective unlimited bandwidth has been a concept found only in  research papers and labs - until now, " said Richard Moscioni, SONET Business Management Vice President. "Deploying  an all-optical network takes more than just technology or more wavelengths. Dense Wavelength Division Multiplexing is  just the ticket to entry for optical networking. Service providers are demanding a level of network expertise in their  vendors that includes total network solutions. Lucent Technologies is uniquely positioned to provide this complete package  to our customers." The Optical Cross Connect continues the migration to an all-optical network that Lucent began in 1995 with the  introduction of its Optical Line System - Lucent's Dense Wavelength Division Multiplexing (DWDM) product. Lucent  Technologies is the worldwide leader in optical networking with thousands of amplifiers and hundreds of systems shipped  to customers worldwide. The Optical Cross Connect will be demonstrated at Lucent Technologies' booth #3549 at SuperComm '97 in New  Orleans from June 3-5. Lucent's SONET Business Group demonstration at SuperComm '97 will focus on three areas:  Bell Lab's Innovations; Optical Networking Solutions (including the Optical Cross Connect); seamlessly integrating  embedded SONET systems to deliver all services (Voice, Data and Video) over one network. The Optical Cross Connect builds upon Lucent's long-standing research efforts on DWDM and optical networking  including Lucent's participation in the Multiwavelength Optical Networking (MONET) Consortium. The Optical Cross Connect will be available in limited production in third quarter '97. Lucent will be working closely with  customers to determine features and functionality for future releases. Lucent Technologies designs, builds, and delivers a wide range of public and private networks, communications systems  and software, consumer and business telephone systems and microelectronics components. Bell Laboratories is the  research and development arm of the company. More information about Lucent Technologies, headquartered at Murray  Hill, N.J., is available at http://www.lucent.com. For more information, reporters may contact: Kabby Hong  303-290-2641 (work)  303-779-0977 (home)  Email:khong@lucent.com Jane Moulton  908-582-7658 (work)  201-763-7017 (home)  Email:jmoulton@lucent.com
--------
674-> New X-Ray Microprobe From Bell Labs
Donna Cunningham 802-482-3748 (office) 802-482-2933 (home) donnac@lucent.com Tom Topalian 908-508-8673 (office) 908-713-6240 (home) ttopalian@lucent.com NEW X-RAY MICROPROBE FROM BELL LABS HELPS LUCENT DESIGN BETTER LASER MODULES FOR RELEASE TUESDAY, MAY 6, 1997 MURRAY HILL, N.J. -- Lucent Technologies is designing better laser modules thanks to a new tool developed by Bell Labs scientists -- an X-ray microprobe (XMP) that  measures strain in smaller volumes of material and detects trace elements better than any other non-destructive deep probe in the world. The instrument produces an X-ray spot only two  microns across -- one two- hundredth the diameter of the period at the end of this sentence.  That’s 1,000 times smaller than spots produced by conventional X-ray probes. The XMP makes it possible for scientists to study micron-size features in a range of structures, from naturally patterned biological systems to lithographically patterned devices such as electronic circuits and solid-state lasers.   They’re interested in strain, the displacement of atoms from their naturally occurring positions, for example, because the right amount of strain is essential to efficient laser operation but too much strain can cause defects that make a laser inoperable. "Bell Labs inventions like this one substantially reduce trial-and-error experimentation, which accelerates the ‘time to market’ for new Lucent products," said John Pilitsis, vice president, Optoelectronics Products, Lucent Technologies Microelectronics Group. The XMP was used to generate a "map" of the micro-structural properties of the 266 EM-ILM (electro-absorptive modulated isolated laser module) made by Lucent’s Microelectronics Group.  The module, used in fiber-optic communications systems, integrates a laser and modulator and can transmit 2.5 billion bits of information per second over 600 kilometers of fiber. Lucent engineers used the map to adjust their device design, varying the chemical composition, thickness, and strain of the atomic layers of the laser to optimize the structure of the laser. Bell Labs researchers developed the scanning X-ray microprobe at the National Synchrotron Light Source at Brookhaven National Laboratories in Upton, N.Y.  Synchrotrons are large machines, some as much as a kilometer in circumference, that accelerate electrons in a circular orbit to emit X-rays and other electromagnetic radiation. An XMP takes these very bright X-rays and sends them  through high-quality X-ray optics, such as mirrors, lenses and pinholes.  It uses X-ray diffraction, a technique in use for more than 80 years to determine the three-dimensional atomic structure of materials.  The wavelength of X-rays is ten thousand times smaller than that of visible light, so X-rays can make measurements of smaller features than can be made with optical probes, which use visible light to discern features as small as one- thousandth the thickness of a human hair. The Bell Labs XMP consists primarily of a pair of X-ray mirrors, one focusing horizontally and the other vertically.  Within its two-micron spot size, the XMP can accurately and non-destructively measure the average distance between atoms in a solid. "The X-ray microprobe will revolutionize characterization of materials in a broad range of disciplines, including device engineering, materials science, chemistry, biology and environmental sciences," said Pierre Wiltzius, head of  the Bell Labs Condensed Matter Physics Research department. "There are many other problems of interest to Lucent Technologies that can take advantage of the X-ray microprobe," added researcher Ken Evans-Lutterodt.  "A key problem for silicon-based microelectronics is long-term device reliability.  Thermal and electromigration stresses result in the development of voids in the aluminum wires that provide electrical interconnection between sub-micron devices on silicon chips.  These voids lead to device failure.  The XMP allows characterization of the stresses and the development of voids." The Bell Labs research team is now refining the XMP to provide spot sizes one-fifth as large as those produced by their current XMP. "An important aspect of this work is that it demonstrates how a long-term research project, like the XMP development, can have a very tangible impact on the short-term needs of a high-tech company like Lucent Technologies," said Eric Isaacs. X-ray microprobes are being developed by teams of scientists at other synchrotron sources, such as the Advanced Photon Source in Argonne, Ill., and the European Synchrotron Radiation Facility in Grenoble, France.  The Bell Labs XMP team includes Evans-Lutterodt, and Isaacs, of the Physical Research Lab, Matthew Marcus and William Lehnert, of the Silicon Electronics Research lab, and former Bell Labs researcher Alastair MacDowell, of the Advanced Light Source in Berkeley, Calif. Isaacs and Phil Platzman, of the Bell Labs Physical Research Lab, presented information on the development and current uses of  the Bell Labs XMP and X-ray synchrotron sources at this year’s American Physical Society annual meeting. Lucent Technologies designs, builds and delivers a wide range of public and private networks, communications systems and software, consumer and business telephone systems and microelectronics components.  Bell Labs is the research and development arm of the company. Lucent’s Microelectronics Group designs and manufactures integrated circuits, optoelectronic components, and power systems for the computer and communications  industries.  Lucent’s Optoelectronics Group is the number-one worldwide supplier of optoelectronic components for telecommunications and cable TV applications. More information about Lucent Technologies, headquartered at Murray Hill, N.J., is available at http://www.lucent.com. -###- 
--------
675-> Study Provides Baseline Measurements of Viral Load in Pediatric AIDS
The amount of HIV in the blood of perinatally infected infantspeaks at 1 to 2 months of age and then declines slowly to level off at 24 months at relatively high concentrations compared to those for an adult, according to a study supported by the  National Institutes of Health (NIH).  The study was reported in the May 8, 1997, issue of The New England Journal of Medicine.  Peak viral loads at 1 month of age suggested that the majority of the infected infants were exposed around the time of delivery.  A small number of infected infants had high blood levels of HIV at birth, indicating that some may have become infected in utero. "The results are the first to provide a baseline on the naturalhistory of HIV blood levels (viral load) in infants and children, and can provide guidance on how to use viral load information to evaluate treatment options for HIV-infected children," says Anthony S. Fauci, M.D., director of the National Institute of Allergy and Infectious Diseases (NIAID), one of the sponsoring institutes at NIH. Scientists measured the amount of HIV in the blood of 106HIV-infected babies from birth up to 5 years of age.  The studydemonstrated that viral load measurements could be used to predict the severity of disease and suggested that babies with higher viral loads might benefit from antiretroviral treatment.  Children with HIV viral loads greater than a 299,000 (median level) virus particles per milliliter (mL) of blood during the first few months of life had a 44 percent probability of progressing to AIDS or death within the first 24 months of life. For those children with viral loads less than 299,000 (medianlevel) particles/mL, the rate of progression to AIDS or death was only 15 percent.  The authors note that although there was no threshold above which all children were rapid progressors, there was a lower threshold below which they saw no progression to overt disease or death.  Those infants in the study with viral loads of less than 70,000 particles/mL within the first few months of life did not progress rapidly to AIDS or death within their first 18 months of life. "The surprise to the investigators," says William T. Shearer,M.D., Ph.D., study chair and professor of pediatrics, microbiology and immunology at Baylor College of Medicine and at Texas Children's Hospital, "was that the very early HIV blood levels may predict the outcome of progression to AIDS in children.  Thus, it may be important to determine HIV RNA levels very  early in life." Patients in the study were participants in the Women andInfants Transmission Study (WITS), a multicenter natural historystudy of HIV-infected pregnant women and their infants.  The infants in this study were born between Jan. 8, 1990, and Dec. 3, 1993.  Of the 619 children born to HIV-infected mothers in the WITS group during this period, 114 were perinatally infected with HIV.  Of these, 106 were available to participate in the study.  To measure fluctuations in viral load, investigators collected plasma at birth and at 1, 2, 4, 6, 12, 15 and 18 months of age, and every six months thereafter.  They determined viral load using reverse transcription polymerase chain reaction methods to measure amounts of HIV ribonucleic acid (RNA) in stored blood specimens. All infants in this study were born prior to the closing of theAIDS Clinical Trials Group 076 study, in which the administration of zidovudine during pregnancy, labor and to the newborn for the first 6 weeks of life was shown to decrease significantly risk of HIV transmission.  Since March 1994, women have been counseled on the benefits of using zidovudine to prevent HIV perinatal transmission to their infants. The median viral load for all of the infants in this study was318,000 particles/mL of blood at 1 month of age and 256,000/mL at 2 months.  Viral load levels then slowly declined to a median of 34,000 particles/mL at 24 months of age.  The researchers found that infants whose first positive HIV culture was at 48 hours of age or younger showed higher HIV RNA blood levels during their first 2 months of life than those infants whose first positive HIV culture was not until 7 days of age or older.  Predictably, infants with rapid disease progressionhad high peak HIV levels (median 724,000 particles/mL) from birth to 2 months.  Infants who did not show rapid progression had lower peak values (219,000 virus particles/mL). "The dynamics of viral replication in these HIV-infected infantsare distinctly different from those observed in infected adults," says Thomas C. Quinn, M.D., senior investigator at NIAID and professor of medicine at Johns Hopkins University.  "Following a dramatic rise in viremia during their first month of life, the viral burden remains very high in infants in contrast to the sharp decline usually seen in adults.  This persistently high viremia may partially explain the more rapid progression to AIDS observed in infants compared to adults, and further underscore the need for early antiretroviral therapy." The prospective observational study was conducted atmultiple sites by scientists at several collaborating institutions.  Inaddition to Drs. Shearer and Quinn, contributing authors on the article are: Philip La Russa, M.D., Columbia Presbyterian Hospital, N.Y.; Judy F. Lew, M.D., NIAID, Bethesda, Md.; Lynne Mofenson, M.D., National Institute of Child Health and Human Development (NICHD), Bethesda, Md.; Susan Almy, M.S., New England Research Institutes, Watertown, Mass.; Kenneth Rich, M.D., University of Illinois at Chicago; Edward Handelsman, M.D., State University of New York Health Science Center at Brooklyn; Clemente Diaz, M.D., University of Puerto Rico, San Juan; Marcello Pagano, Ph.D., Harvard School of Public Health, Boston; Vincent Smeriglio, Ph.D., National Institute on Drug Abuse (NIDA), Rockville, Md.; and Leslie A. Kalish, D.Sc., NewEngland Research Institutes, Watertown, Mass. The WITS study is supported by the NIAID, NICHD and NIDAof the National Institutes of Health, an agency of the U.S. Department of Health and Human Services.  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies.                                         ###NIAID press releases, fact sheets and other materials areavailable on the Internet via the NIAID home page athttp://www.niaid.nih.gov.
--------
676-> NIAID Study: Cockroaches Important Cause of Asthma Morbidity Among Inner-City Children
A large study supported by the National Institute of Allergy andInfectious Diseases (NIAID) has conclusively demonstrated that the combination of cockroach allergy and exposure to the insects is an important cause of asthma-related illness and hospitalizations among children in U.S. inner-city areas. The report from NIAID's National Cooperative Inner-CityAsthma Study (NCICAS), and an accompanying editorial, appear in the May 8, 1997, issue of The New England Journal of Medicine. "Some of the most vulnerable of our citizens, children in thepoorest neighborhoods of our large cities, suffer disproportionately from asthma," says Anthony S. Fauci, M.D., NIAID director.  "Allergy and exposure to cockroach allergen clearly play an important role in the alarming rates of asthma-related sickness among these children." "Reducing exposure to cockroach allergen, as part of a multi-faceted approach to asthma management, may be a cost-effective way of reducing the burden of this serious disease," says Daniel Rotrosen, M.D., acting director of NIAID's Division of Allergy, Immunology and Transplantation.  "Simple and relatively low-cost interventions that have been explored in the NCICAS, such as patient education, roach traps and child-safe insecticides, are potentially important adjuncts to previously established medical therapies that can help asthmatic patients." The first five-year phase of the NCICAS, recently completed,enrolled more than 1,500 children with asthma, ages 4 to 11, living in eight major metropolitan areas: The Bronx, N.Y.; East Harlem, N.Y.; St.Louis, Mo.; Washington, D.C.; Baltimore, Md.; Chicago, Ill.; Cleveland, Ohio; and Detroit, Mich. In the current analysis, David L. Rosenstreich, M.D., of theAlbert Einstein College of Medicine in the Bronx, N.Y., and hisNCICAS colleagues studied 476 of these children.  Most of thechildren were either African-American (78 percent) or Hispanic (16 percent).  The researchers measured levels of cockroach, dust mite and cat allergens in the children's homes, and determined with allergy skin tests that 37 percent of the children were allergic to cockroaches, 35 percent to dust mites, and 23 percent to cats.  The investigators then assessed the severity of the children's asthma over 12 months. They found that children who were both allergic to cockroaches and exposed to high cockroach allergen levels were hospitalized for their asthma 3.3 times more often than children who were allergic but not exposed to high levels of cockroach allergen, orchildren who were exposed to high levels of cockroach allergen but who were not allergic. Children who were both allergic and heavily exposed tocockroach allergen also missed school more often, needed nearly twice as many unscheduled asthma-related medical visits, and suffered through more nights with lost sleep.  In addition, the activities of the adults who cared for these children werefrequently disrupted. In contrast, neither the combination of allergy to dust mitesand high exposure to mites, nor the combination of allergy to cats and high exposure to cats was associated with more severe asthma among the 476 children in the study sample. Despite the availability of effective asthma therapies, asthma-related deaths among individuals younger than 25 in theUnited States increased 118 percent between 1980 and 1993. "These disturbing trends, which are especially pronounced inminority populations, underscore the importance of the Institute'sresearch into understanding, preventing and treating asthma," says Dr. Fauci. NIAID, a component of the National Institutes of Health (NIH),conducts and supports research aimed at preventing, diagnosing and treating illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies.  NIH is an agency of the U.S. Department of Health and Human Services.                                             ###References:Platts-Mills TA and Carter MC.  Asthma and indoor exposure toallergens.  New Engl J Med 1997;336:1382-1384. Rosenstreich DL, et al.  The role of cockroach allergy and exposure to cockroach allergen in causing morbidity among inner-city children with asthma.  New Engl J Med 1997;336;1356-63. NIAID press releases, fact sheets and other materials areavailable on the Internet via the NIAID home page athttp://www.niaid.nih.gov.
--------
677-> "Deep Blue" Inspires Deep Thinking About Artificial Intelligence
May 1, 1997 Contact: Robert Irion (408) 459-2495; irion@ua.ucsc.edu "DEEP BLUE" INSPIRES DEEP THINKING ABOUT ARTIFICIAL INTELLIGENCE BY UC SANTA CRUZ COMPUTER SCIENTIST FOR IMMEDIATE RELEASE SANTA CRUZ, CA--When world chess champ Garry Kasparov and IBM's "Deep Blue" computer program check in for their much-hyped rematch in New York starting on May 3, Robert Levinson of UC Santa Cruz will watch with more than a passing interest. Levinson, an associate professor of computer science, is an expert on artificial intelligence (AI), the effort to imbue machines with human qualities such as autonomy, the ability to learn from experience, and even intuition and creativity. Deep Blue is impressive, Levinson feels, but it's little more than a brutally efficient chess-playing automaton. In the field of AI, it doesn't even rate a pawn. "Deep Blue is a powerful entity, and it represents a wonderful engineering effort," Levinson said this week as he looked forward to following the games live on the Internet. "I do agree that it sits somewhere on the scale of 'intelligence.' But even if it proves the most successful approach toward beating the world champion in chess, it's a long way from artificial intelligence. What it really lacks is autonomy and adaptability." Levinson and UCSC graduate student Jeff Wilkinson outline their views on Deep Blue and AI in a provocatively titled paper, "Deep Blue is still an infant." They will present the paper on July 28 at the 14th national conference of the American Association for Artificial Intelligence in Providence, RI. The authors describe several ideals toward which the creators of software must strive in order to make their programs weightier on the intelligence scale. Most critical is the notion of autonomy: Can the program manage its computational resources, assess its errors, generalize from its past experiences, and communicate about its progress? In short, can it succeed--and improve--apart from its human architects? Deep Blue barely touches these regimes, Levinson and Wilkinson note. Further, it lacks what the authors refer to as "meta-reasoning," the ability to study itself and modify its own decisions as a result. If Deep Blue had these capacities, Levinson believes, it not only could vie with humans at chess but also could excel at many other complex tasks. "IBM has written a terrific program to play chess, that's all," Levinson said. "But it doesn't know that it's playing chess. It doesn't have a model of itself as a program. If it wins, it can't tell you why. We need computers that can understand computer science. That's the real AI." Levinson's own interests in computer chess go beyond monitoring Deep Blue's progress. "When I was 10 years old, someone gave me a book on computer chess, and I've been hooked ever since," he recalled. In recent years, he parlayed that fascination into an ambitious, National Science Foundation-funded project on using computer chess as a means to advance toward certain goals in AI. His group developed a unique chess program, called "Morph," and continues to refine it. Morph relies on a far different strategy than Deep Blue's brute-force calculations: It "learns" chess from the ground up, becoming familiar with the intricate patterns that permeate the intellectual's ultimate board game. Essentially, the system mimics how a child would pick up chess given just two things: lists of legal moves and a playing partner who reveals only whether the child wins or loses. Early versions of Morph could occasionally defeat novice tournament players, but its performance plateaued. The group's newest model relies heavily on information theory to determine which patterns on the chessboard are worth remembering. "I can point to the actual equations and statistics that the program uses to make these decisions for itself," Levinson said. "In the past, much of AI has ignored the importance of such mathematical tools." Instead, it became fashionable for researchers to try to mimic the human brain. According to Levinson, that tactic skirted rigorous scientific method. Levinson feels confident that Kasparov will prevail in his rematch with Deep Blue, but the new and improved machine should present a stiff challenge. It's speedier than its predecessor, which Kasparov vanquished (after losing Game 1) in February 1996. This Deep Blue analyzes 200 million possible moves per second--nearly 40 billion during each three-minute time limit. Chess grandmaster Joel Benjamin joined IBM's team to improve the program's recognition of strong and weak positions. Even so, Levinson said, "Kasparov has never lost a world championship match, so you have the feeling that he will do what it takes to win. But he won't underestimate the machine. He'll have to make sure he doesn't overlook anything and that he doesn't create too many complications that make it very difficult to calculate many moves ahead." What if Deep Blue triumphs? "That would be mind-blowing," Levinson said. "People already have a hard enough time understanding why Kasparov plays chess so much better than anyone else." ##### Editor's notes: Levinson plans to watch all six games of the Kasparov-Deep Blue match live on the Internet from his office at UC Santa Cruz, in room 334 of the Applied Sciences Building. He welcomes reporters who seek comment on the match and on the general issue of artificial intelligence. Games are scheduled to begin at 12 noon on each of the following days: Saturday, May 3; Sunday, May 4; Tuesday, May 6; Wednesday, May 7; Saturday, May 10; and Sunday, May 11. Please contact Levinson in advance to arrange a visit. You may reach him at levinson@cse.ucsc.edu, (408) 459-2087 (office), or (408) 425-0691 (home). For a copy of Levinson's paper on Deep Blue, call Robert Irion at (408) 459-2495 (office) or over the weekend at (408) 335-4185. 
--------
678-> New Study Of The Genetic Causes Of Obesity Defies Traditional Thinking About The Role Of Adrenaline
New study of the genetic causes of obesity defies traditional thinking about the role of adrenaline Scientists have long thought that the sympathetic (or autonomic) nervous system determines how the body uses energy from food, deciding whether calories are burned up to keep the body warm, or stored in the form of fat. However, new studies reported in the May 1 edition of Nature  appear to contradict traditional thinking about the sympathetic nervous system's influence in people who never gain weight no matter how much they eat, versus those who seemingly put on pounds if a piece of cheesecake is merely passed under their nose. To test whether deficiencies in the sympathetic nervous system may be a cause of obesity, University of Washington researchers Dr. Steven A. Thomas and Dr. Richard D. Palmiter produced mice that cannot make adrenaline (the hormone of the adrenal gland) or noradrenaline (the chemical messenger of the sympathetic nervous system). These two compounds are released in response to stress and regulate many body functions, including the ability to keep warm. The mice that cannot make adrenaline and noradrenaline are unable to increase heat production, and they cannot defend themselves against heat loss; consequently, they lose heat rapidly in the cold. "This was expected," said Palmiter, UW professor of biochemistry and an investigator of the Howard Hughes Medical Institute. "However, many scientists believed that under normal temperatures these mice would become obese because they wouldn't burn excess calories but instead would deposit them as fat." "Instead, we found that at normal temperatures these mice do not become obese, despite the fact they eat more than normal," said Thomas, a senior fellow in biochemistry and first author of the UW study. "Our research suggests that obesity is not likely to involve defects in the sympathetic nervous system or in the production of adrenaline." Noradrenaline normally produces heat by stimulating the production of protein called the uncoupling protein (UCP) in special brown fat cells. In the mice that lacked noradrenaline, this production did not take place. A second study in the same issue of Nature corroborates the UW findings. Scientists at the Jackson Laboratory in Bar Harbor, Maine, produced mice that cannot make UCP. Like the UW mice, these mice do not become obese and they, too, are more sensitive to the cold. A previous study by Drs. David E. Cummings and G. Stanley McKnight of the UW School of Medicine's Department of Pharmacology (published in Nature last year) indicated that chronic activation of the pathway leading to UCP production resulted in lean mice. Thus, there was ample reason to think that the opposite might be true if mice could not increase heat production after eating a meal. "Both of the current studies, done independently and without each others' knowledge, produced consistent and unexpected results that are leading us to look in new directions for the genetic causes of obesity in humans," said Thomas. The UW research was funded by grants from the Howard Hughes Medical Institute and the National Institutes of Health. 
--------
679-> Blood Test May Yield Marker For Childhood Behavioral Disorders Say University Of Florida Researchers
By Larry Lansford GAINESVILLE, Fla.---A telltale protein believed to be linked to certain formsof obsessive-compulsive disorder (OCD) and Tourette's syndrome, a mysteriousand humiliating nervous disorder, may be detected through a simple blood test,according to a recent University of Florida study. Researchers at UF's College of Medicine say such a screening test could beused to identify patients who are genetically predisposed to developing thesedisruptive disorders and could lead to improved treatments or even ways toprevent the illnesses. In the UF study, blood analyses revealed that all 31 patients with eitherchildhood-onset OCD or Tourette's syndrome had abnormally high levels of aspecific protein in crucial blood cells of the immune defense system. Among acontrol group of 21 healthy participants, only one displayed evidence of themarker protein, known as antigen D8/17. Antigens are proteins that lock onto the surfaces of invading viruses andmark them for destruction by the immune system. More than 5 million Americans suffer from OCD, which is characterized by apreoccupation with unwanted fears, thoughts and images, such as fear ofcontamination. These obsessions lead to compulsive behaviors--repeatedlywashing hands, wiping off door handles, for example. Tourette's syndrome affects more than 200,000 people nationwide. Onceconsidered an emotional illness, the neurological disease is oftencharacterized by involuntary muscular tics -- such as eye twitching, headjerking and other facial grimaces -- along with socially awkward snorting,throat noises and involuntary outbursts of obscenities. The common biological marker revealed in the UF study, reported in the Marchissue of the American Journal of Psychiatry, strengthens evidence thatTourette's and some forms of OCD are related -- physiologically and possiblygenetically. The same antigen marker, in fact, also is known to be present in excessiveamounts in people with another movement disorder called Sydenham's chorea,which produces symptoms similar to those of OCD or Tourette's syndrome.Sydenham's chorea sometimes accompanies rheumatic fever, a rare complicationof streptococcus infection, or strep throat. "Sydenham's chorea may serve as a medical model for some forms ofobsessive-compulsive disorder and Tourette's syndrome," said UF pediatricpsychiatrist Tanya Murphy, lead author of the recent journal report. "Ourfindings suggest that this antigen may serve as a marker for susceptibility tosome forms of childhood-onset obsessive-compulsive disorder and Tourette'ssyndrome, as well as Sydenham's chorea and rheumatic fever." "It is too early to know whether some cases of childhood-onset OCD andTourette's may be related to strep throat," Murphy added. "It may becoincidental or it may be directly related that these illnesses all share thesame biological marker. These questions give us a direction for futurestudies." Previous research indicates these illnesses may share more than a commonmarker. Evidence also shows Sydenham's chorea and OCD involve chemicaldisruptions in the brain's basal ganglia -- clusters of nerve cells at thebase of the brain that help regulate body movements. The disruptions arethought to occur when antibodies directed against the streptococcus infectionreact with these nerve cells and other brain tissue, causing movementdisorders and behavioral disturbances. While Murphy cautions that more research is required before the D8/17 antigencan be conclusively declared as a marker for children at risk of OCD andTourette's, she does offer some advice to parents of children with strepthroat. "If a child had a strep throat infection and within two or three monthsexhibits significant behavioral changes," Murphy said, "the parents shouldconsider that this may be a complication of strep throat and seek furthermedical evaluation of their child." Murphy's co-researcher Dr. Wayne Goodman, professor and associate chairman ofpsychiatry at the UF Health Science Center's Jacksonville campus, recentlyreceived a three-year federal grant of $887,000 to further study the interplaybetween genetics, infection and autoimmune factors in the biology of childhoodOCD and Tourette's. Their collaborators include Dr. Ralph Williams, an eminent scholar inrheumatoid arthritis research who helped develop the D8/17 screening test, andDr. Elia Ayoub, a distinguished service professor in pediatric infectiousdiseases. --------------------------------------------------------------------------------        Recent UF Health Science Center news releases also are available on the UFHealth Science Center Communications home page.  Point your browser tohttp://www.vpha.health.ufl.edu/hscc/index.html
--------
680-> Why The Heart Stops Pumping: Researchers Identify Cellular-Molecular Defect In Heart Failure
Untreated high blood pressure underlies much cardiovascular disease, including enlargement of the heart, heart failure, arrhythmias and stroke.  It is a leading cause of death in the United States. When high blood pressure persists untreated, it enlarges the cells of the heart and produces a silent defect in the heart's pumping mechanism, according to a team of researchers headed by W. Jonathan Lederer, M.D., Ph.D. at the University of Maryland School of Medicine and Medical Biotechnology Center. They report their findings in the May 2 issue of the journal Science. Although the enlargement of the heart cells may appear as a beneficial adaptation of the heart in its task of pumping blood, the silent defect remains hidden like the enemy army within the Trojan horse.  The Maryland researchers found that the defect within each enlarged heart cell of the animal with high blood pressure - which they traced to the same cellular and molecular changes -  is identical to the defect seen later in heart failure. A professor of physiology at the University of Maryland School of Medicine and senior author of the Science paper, Lederer is head of the Department of Molecular Biology at the University of Maryland Medical Biotechnology Center in Baltimore. He likens the defect to a Trojan horse because it appears to be masked initially by increased activity of the sympathetic nervous system which is able to improve heart function; the defect, therefore, is not readily noticed, Lederer explains.  However as the sensitivity of the heart to continuous activity of the nervous system declines with time, the defect is unmasked and contributes to the developing heart failure. Under normal conditions, the heart beats in response to a complex electrical-chemical process called excitation-contraction (EC) coupling. During EC coupling, an electrical signal sweeps through the heart to trigger the contraction that pumps blood throughout the body. This wave of electrical activation spreads through the heart, permitting a minute amount of calcium to enter each heart cell through some 100,000 calcium channels that cover the surface of the cells. These calcium channels are the targets for widely-used "calcium channel-blocker" medications. Normally, the calcium that enters through each calcium channel is like a muffled starting gun, which must be amplified before it can be heard calling the cell to action. Luckily, there are close to a million amplifier modules throughout the cell, conveniently located close to the calcium channels. They amplify the weak signal from the calcium channels to produce a much larger rise in calcium, which in turn causes the heart cells to contract. Studying the EC coupling of heart cells of rats with high blood pressure displaying either  simple cellular enlargement or contractile failure, Lederer and his research team found a surprising defect.  Although each of the elements in the calcium amplification system worked properly,  the signals produced by the calcium channels were nonetheless inadequately  amplified  and thus remained muffled in both cell types.  This defect reduces the contraction in each heart cell and therefore leads to "cellular" heart failure. They studied the cells' calcium release process using a special confocal microscope to visualize the amplified signal triggered by the calcium channels.  These are  seen as "calcium sparks."   The discovery of "Ca2+ sparks" by Lederer and his co-workers four years ago has revolutionized the investigation of cardiac, skeletal and smooth muscle function and is an essential element in the present work.   All of the other features of heart cell function were measured optically or electrically. "Our data suggest that hypertension-induced cardiac hypertrophy (enlargement of the heart) reduces the ability of calcium channels to activate calcium release from  intracellular stores, even though all elements of the system are normal," said Lederer.  "It appears that defect is one of communication between calcium channels and the intracellular organelles. The activity of the sympathetic nervous system is able to improve the communication without fixing the defect during cardiac hypertrophy before heart failure develops. But in heart failure the defect has its full negative effect because the heart cells respond poorly to activity of the sympathetic nervous system." "Because of our improved understanding of the molecular defects that develop in heart failure, it may be possible to develop novel drugs, molecular therapies or treatment programs to treat this devastating disease.  Furthermore, our findings, which link high blood pressure to the development of the "stealth defect" found within the heart cells before failure develops, provide an additional reason for all hypertensive patients to seek immediate effective treatment.  While late treatment may fix the high blood pressure, it may not be able to reverse this defect and the consequent heart failure." Lederer and colleagues at the University of Maryland School of Medicine and Medical Biotechnology Center collaborated with scientists from the University of Wisconsin Medical Center, the National Institute of Aging, St. George's Hospital Medical School in London, England, and Ohio State University. Their work was supported by the National Institutes of Health,  the Maryland Heart Association, the BHF and Wellcome Trust, the Spanish Ministry of Education and Science, and a Minority Scientist Development Award from the American Heart Association. 
--------
681-> Obesity Research Advance Reported At The Jackson Laboratory
 FOR IMMEDIATE RELEASE APRIL 30, 1997 BAR HARBOR -- Unexpected results from an experiment at The Jackson Laboratory designed to probe the role of a protein implicated in human obesity will help researchers identify the complex thermogenic mechanisms that control regulation of body weight. The results are reported in the May 1 issue of the British journal Nature by Leslie P. Kozak, Senior Staff Scientist at The Jackson Laboratory, and his colleagues. Title of the report is "Mice lacking mitochondrial uncoupling protein are cold-sensitive but not obese." Co-authors include Elizabeth M. Simpson and Carmen Guerra, both of The Jackson Laboratory; Mary-Ellen Harper, University of Ottawa; and former Jackson Lab researchers Sven Enerback (University of Goteborg, Sweden), Anders Jacobsson (Stockholm University, Sweden), and Hitoshi Yamashita (National Defense Medical College, Japan). The scientists built on research conducted at the Laboratory by Dr. Kozak into the mitochondrial uncoupling protein (UCP1). The only known function of UCP1 in mice is the production of heat by "nonshivering" thermogenesis in so-called brown fat. Several species of mammals, including humans, have an abundance of brown fat as newborns to protect them from cold before their body mass and metabolic systems are fully developed. To further investigate the role of UCP1 in energy balance, Dr. Kozak and his colleagues specifically inactivated the UCP1 gene in their transgenic mouse model. A previous experiment in which UCP1 was overexpressed in brown fat had yielded the expected result of reduced obesity. Now, the scientists fully expected to observe in the UCP-deficient mouse an increase in obesity and/or overeating behavior. Instead, the experiment reported in Nature showed a "striking resistance" to obesity and overeating in the UCP-deficient mice. However, the mice were very sensitive to cold, indicating a defect in thermoregulation. "What we've identified is an important pathway for the regulation of body temperature, but surprisingly it's not directly associated with mechanisms controlling body weight," said Dr. Kozak. "It suggests that there must be other mechanisms that are able to compensate for UCP1 loss, and underscores the complexity of body weight regulation." One candidate is UCP2, a recently described homologue of UCP1 that is broadly expressed in different mouse tissues, including brown fat. The discovery of UCP2 has generated enormous interest in the obesity field because it could provide a mechanism for reducing obesity by stimulating thermogenesis in a number of target tissues. Dr. Kozak and his colleagues have initiated experiments to construct mouse models in which the UCP2 gene is overexpressed in brown fat or inactivated in the absence of UCP1 expression, to determine whether UCP2 is indeed a thermogenic protein. These transgenic mice will enable the team to rigorously determine the role of UCP2 in energy expenditure and obesity. 
--------
682-> CD4+ T Cell Diversity, Lost in Late-Stage Disease, Is Not Immediately Restored by Therapy
The immune system's army of CD4+ T cells not only declines in overall size during the course of HIV disease, but also becomes progressively less diverse as specific CD4+ T cells programmed to fight different invaders are lost, according to researchers at the National Institute of Allergy and Infectious Diseases (NIAID). These depleted cell types may not be immediately restored by therapies such as antiretroviral drugs or interleukin-2 (IL-2) that can increase an HIV-infected person's overall CD4+ T cell count.  Rather, such therapy, at least in the short-term, appears to boost only the cells that were present when therapy began.  The findings are reported in the May 1997 issue of Nature Medicine. "Our findings argue for treatment early in disease, before elements of the immune system are significantly depleted," says senior author H. Clifford Lane, M.D., NIAID's clinical director. "Our data also suggest that drugs to prevent opportunistic infections may remain important even for patients with CD4+ T cell counts that are rapidly increasing in response to therapy, because these individuals may be missing part of their CD4+ T cell repertoires." Adds co-lead author Mark Connors, M.D., of the NIAID Laboratory of Immunoregulation, "The loss of CD4+ T cells is a qualitative phenomenon as well as a quantitative one.  In other words, a CD4+ T cell count of 200 per cubic millimeter (mm3) of blood during the natural history of HIV infection may be very different from a CD4+ T cell count of 200/mm3 in the context of therapy. Depletions in the CD4+ T cell repertoires of  HIV-infected people and hence the reduced ability of their immune systems to recognize certain antigens are probably key to the development of immunodeficiency in these people." The current findings shed light on an observation reported by Dr. Lane and his colleagues in the mid-1980s: HIV-infected people often lose their ability to respond to "remote recall antigens": substances to which one was exposed in the past, such as the antigens in a tetanus vaccine.  The new data suggest that this decreased responsiveness is due to a loss of specific CD4+ T cell types, which scientists refer to as "clones." "A loss of CD4+ T cell clones, and the resulting "holes" in a person's CD4+ T cell repertoire, rather than an active immunosuppressive phenomenon, may explain why an HIV-infected person becomes unresponsive to remote recall antigens," says co-lead author Joseph A. Kovacs, M.D. STUDY DETAILS Using molecular techniques, the NIAID researchers have demonstrated that CD4+ T cell diversity begins to decline when an HIV-infected person's CD4+ T cell count falls to approximately 150 to 200 cells/mm3 of blood.  This decline accelerates when a person's count falls to 50 cells/mm3.  A healthy person without HIV infection typically has a CD4+ T cell count in the range of 600 to 1500 cells/mm3. Even when therapies boosted a person's CD4+ T cell counts to 200/mm3 or higher, CD4+ T cell diversity was not restored, the researchers observed. However, Dr. Lane suggests that even patients with advanced disease may be able to mount adequate immune responses if antiretroviral therapy reduces HIV replication to very low levels. With potent suppression of HIV, other clones may be able to proliferate to sufficient levels to perform the job normally done by the missing clones. "Think of a person's CD4+ T cell clones as tiles in a scrabble game," explains Dr. Lane.  "As disease progresses, not only does an HIV-infected person have fewer tiles, but also fewer different tiles.  If a person loses the letter "z," they will be unable to spell out the word "zebra." However, if they have enough other tiles, they still may be able to describe a zebra by spelling a"horse-like animal with black and white stripes." CD4+ T cells have on their surfaces a molecule called a T-cell receptor (TCR) which recognizes and binds to foreign invaders that have been ingested and processed by other specialized immune cells -- antigen-presenting cells (APC) --  and displayed on the surfaces of APCs. Each CD4+ T cell's TCR has an alpha and beta chain.  Each beta chain contains a variable region that is derived from one of at least 22 V-beta subfamilies.  These V-beta subfamilies are often used by immunologists to classify T cells. In their studies, Drs. Lane, Connors, Kovacs and their colleagues used a specialized polymerase chain reaction (PCR) technique to examine differences in size patterns in the V-beta subfamilies of CD4+ T cells taken from both HIV-infected and HIV-uninfected people. Among these subjects were five sets of twins in which one twin was HIV-seropositive, the other HIV-seronegative.  The five healthy, HIV-seronegative twins had TCR V-beta families that were virtually all normal.  Their infected twins had disruptions in as many as 11 different V-beta subfamilies. The researchers applied the same PCR technique to samples taken from HIV-infected people at different stages of HIV infection, and found that disruptions in the CD4+ T cell repertoire became more pronounced as disease progressed.  In a group of eight control patients without HIV infection, fewer than 5 percent of all V-beta families had disruptions.  In a group of five HIV-infected people with CD4+ T cell counts above 200 cells/mm3, approximately 15 percent of all V-beta families had disruptions.  However, among six patients with CD4+ T cell counts lower than 200/mm3, nearly 40 percent of V-beta families had disruptions.  In most cases these were associated with depletions within these V-beta families. Therapy with antiretroviral drugs or interleukin-2 plus antiretroviral therapy led to only minor changes in previously disrupted V-beta repertoires, and in the relative percentages of naive and memory CD4+ T cell subsets, the researchers found. "Most likely, the increase in a patient's CD4+ T cell count after initiating therapy represents expansion of the existing repertoire in a patient's bloodstream and lymph nodes rather than the generation of "new" CD4+ T cells by the thymus," says Dr. Kovacs.  "This view is fortified by our observation that many of the patients in the study had minimal thymic tissue." "In the future, modifications of the techniques used in this study may prove useful clinically for better defining the predictive value of a CD4+ T cell count," he adds.  "Knowing a person's specific T cell repertoire might allow one to better predict the susceptibility of a person to opportunistic infections, and may one day help guide treatment decisions." In addition to Drs. Lane, Connors and Kovacs, co-authors of the paper include Seth Krevat, Juan C. Gea-Banacloche, M.D., Michael C. Sneller, M.D., Mark Flanigan, Julia A. Metcalf, R.N., Robert E. Walker, M.D., Judith Falloon, M.D., Michael Baseler, Ph.D., Randy Stevens, Irwin Feuerstein, M.D., and Henry Masur, M.D.  The techniques used for precisely analyzing CD4+ T cell repertoires were developed at the Pasteur Institute in France by Drs. Christophe Pannetier and Philippe Kourlisky. NIAID, a component of the National Institutes of Health, conducts and supports research aimed at preventing, diagnosing and treating illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies.  NIH is an agency of the U.S. Department of Health and Human Services. ### Reference: Connors M, et al.  HIV infection induces changes in CD4+ T-cell phenotype and depletions within the CD4+ T-cell repertoire that are not immediately restored by antiviral or immune-based therapies.  Nature Medicine 1997;3(5):533-540. NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov.
--------
683-> Eating Disorder Prevention Programs At Universities May Be Doing More Harm Than Good, Study Suggests
Date:   April 30, 1997 Contact:  Doug Fizel Public Affairs Office                                             (202) 336-5700 public.affairs@apa.org (email) First Empirical Evaluation of a College Program Suggests              It Fails By Trying To Do Too Much of a Good Thing WASHINGTON -- Many colleges and universities across the country have set up eating disorder prevention programs to address the well-known fact that female college students are a high-risk group for developing eating disorders.  But as the authors of a study in the May issue of Health Psychology (published by the American Psychological Association APA) point out, "the simple fact that eating disorder prevention programs exist does not mean that the problem is being adequately addressed."  To the contrary, the authors found evidence that the typical college eating disorder prevention program could be making the problem worse. In what is the first empirical evaluation of a college eating disorder prevention program, researchers from Stanford University and the University of Santa Clara examined the effectiveness of the program at Stanford. A total of 788 freshman females participated in a study in which half were invited to participate in a eating disorder prevention program and half were not.  Participants filled out questionnaires three months before the program and four weeks and 12 weeks after the program. The eating disorder prevention program at Stanford (which the researchers found to be fairly typical of college programs) consisted of a 90-minute discussion attended by 10-20 participants at a time.  It was led by pairs of Stanford students with different histories of disordered eating (one was a recovered anorexia patient, the other a bulimia patient who was not fully recovered). In one part of their presentation, the presenters offered information about eating disorders, such as prevalence, symptoms, how they are treated, the better prognosis for treatment if they are detected early and where to get help on campus.  In the second part, the presenters told their personal stories about developing, recognizing and then getting treatment for their eating disorders. The purpose of the program, the researchers note, is to do both primary and secondary prevention.  That is, by giving students this information about eating disorders it is hoped that students who don't have an eating disorder would not develop one (primary prevention) and that students who do have an eating disorder would be motivated to seek help early in the course of the disorder (secondary prevention). In terms of primary prevention, the Stanford program was a failure; it did not prevent eating disordered behavior in students who attended it.  "In fact," the authors note, "exploratory analyses showed that students who attended the program reported slightly more symptoms of eating disorders than did students who did not attend the prevention program." Did it at least motivate those at high risk of eating disorders to seek help?  Only three high-risk participants reported seeking help, which was not enough, the authors say, to make any sort of comparison worthwhile.  "To consider the intervention a success in terms of secondary prevention," the authors say, "we would have to have seen many more high-risk participants seek help." The authors speculate that programs of this type may fail because they are attempting to accomplish both primary and secondary prevention.  The educational messages for primary prevention (emphasizing such things as the health dangers of eating disorders and the difficulty treating them) are very different from the messages that would be used for secondary prevention, such as reducing stigma and emphasizing treatability.   It may have been, the authors say, that the Stanford program overemphasized the secondary prevention component, inadvertently giving some of the students the impression that anorexia and bulimia are fairly common, even normal. While both types of prevention programs are needed for a college population, the authors suggest it might be more effective to offer them separately -- rather than simultaneously -- to appropriately defined student populations.  In the meantime, the authors point out that since this is the only intervention for preventing eating disorders that has been evaluated to date, "as far as we know, effective prevention programs for eating disorders still do not exist." Article:  "Are Two Interventions Worse Than None?  Joint Primary and Secondary Prevention of Eating Disorders in College Females," by Traci Mann, Ph.D., Susan Nolen-Hoeksema, Ph.D., and Karen Huang, Ph.D., Stanford University; Debora Burgard, Ph.D., University of Santa Clara; Alexi Wright, Ph.D., and Kaaren Hanson, Ph.D., Stanford University, in Health Psychology, Vol. 16, No. 3. (Full text available from the APA Public Affairs Office.) (Traci Mann, Ph.D., can be reached at (310) 794-0631 or mann@ucla.edu) The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists.  APA's membership includes more than 151,000 researchers, educators, clinicians, consultants and students.  Through its divisions in 50 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. #       #       # 
--------
684-> Sandia Labs Helps Former Soviet Union Protect Nuclear Material And Facilities
FOR IMMEDIATE RELEASE April 24, 1997 ALBUQUERQUE, N.M. -- In 1994, a band of criminals threatened to blow up a nuclear power plant if their friends weren’t released immediately from a Lithuanian jail. Though the power plant, Ignalina, provided 87 percent of Lithuania’s electricity, the government was forced to shut down the plant’s Chernobyl-style reactors to search for explosives. To forestall future extortion attempts, the government sought international help. For this reason—and the larger concern that nuclear materials could be stolen for use in weapons—engineers and technicians from Sandia National Laboratories are in the former Soviet Union at 44 sites, 30 of them in Russia. The idea is to protect weapons-useable nuclear materials against theft, extortion, or physical takeovers by criminals or terrorists, both at nuclear sites and during transport to other locations. “There’s an element of urgency in protecting this material,” says Rebecca Horton, one of the leaders of the Sandia effort, “given the significant economic and political changes these countries are undergoing. ” The work, performed in conjunction with engineers from other national laboratories, is budgeted for approximately $112 million for fiscal year 1997. Projects are ongoing. The technical assistance program is a priority of the U.S. Department of Energy’s (DOE) Material Protection, Control, and Accounting programs. The name sounds bureaucratic, but the emotions and precautions involved are complex enough to fill the pages of novelists. The programs were developed over the last five years in agreements between governments, agencies or laboratories, under the oversight of the DOE. At the Lithuanian power station, Sandia engineers led construction of an inspection pit area somewhat similar to that of a 10-minute oil change bay. Incoming vehicles must drive through the bay, where they are checked from below for bombs. In addition, sensors detect intruders entering the area on foot. Video monitors, cameras, and an upgraded central alarm warn of intruders in protected areas within the plant. Hand-held radios help the guard force communicate. Aluminum-covered wooden doors are gone, replaced with steel doors. Radiation monitors at exits scan workers for pilfered nuclear materials. Sandia completed the system installation of the project in August 1996. Sandia efforts also have: • completed a “quick fix”-—announced in January 1997 by officials of the republic of Georgia—at a nuclear research reactor to hinder theft of nuclear fuel rods. Each rod is as thick as a pencil, as long as a yardstick, and convertible into weapons-grade fissionable material. The project, begun in January 1996 and completed in two months, included installation of a massive brick obelisk, about three feet on a side and as tall as the door it guards, to prevent the door from being easily opened and fuel rods pilfered. The project is meant to provide temporary security until a more far-reaching agreement is concluded between Russia and Georgia. •worked jointly with an enterprise known as Eleron, in Moscow, to create an automated security system prototype for nuclear materials being transported. In September 1996, 40 high-ranking Russians were given a rail car tour that climaxed with the activation of two advanced mechanisms that would delay any infiltrators attempting to take over the car. •completed the first system for protecting significant quantities of weapons-useable nuclear material at the Kurchatov Institute in Moscow—a preeminent physics institute of Russia—in December 1994. According to Vladimir Sukhoruchkin, head of the division of internal projects for the Institute, “The cooperation and financial support by Sandia National Laboratories... makes our world a little bit safer [by helping] us considerably improve physical security of dangerous nuclear materials at the Kurchatov Institute .” Simple preventive actions include bricking up windows, removing rubble, trees, and other natural and artificial structures within tens of feet of security fences, improving security procedures, and providing training in modern material protection equipment for local security forces. “We realize that some of the improvements we’re making are radically different from the types of security systems with which technicians in the former Soviet Union are familiar, and it may be hard for them to fully understand what we’re doing,” says Sandia’s Mark Soo Hoo, one of the first Americans sent to Eastern Europe three years ago to begin securing the nuclear materials. To make sure the materials will remain secure after American support is reduced, Sandia provides training on operating, testing, and maintaining the systems and also encourages local suppliers to be part of maintenance support. “Early arrangements proved slow-moving. But scientists in the former Soviet Union believe in the need to protect the nuclear materials. When we went to work at a laboratory-to-laboratory level, our mutual efforts at protection started to work,” says Horton. Problems remain. For example, “They can’t understand how we in a free society put up with background checks,” says Mark. “They view background checks as a tool of a repressive society.” Since removal of the continual surveillance conducted by former internal security forces, “now there’s not only no money, police or background checks but there are potential markets for nuclear materials,” he says. While Soviet guards adequately protected facilities in the past, today’s increased labor costs, reduced military support, and growing black market require greater reliance on modern devices to achieve a stricter physical security. The problem now, as Sandia engineers see it, is to help these formerly Soviet countries moving toward a more democratic basis to maintain control of nuclear materials and prevent proliferation to rogue nations. Some Americans wonder if technical help allows Russia to use its freed-up money to pursue other nuclear weapon capabilities, says Horton. In the opinion of Sandia manager J. D. Williams, “I’m sure American citizens wondered at the end of World War II why the US was spending its money to rebuild Germany and Japan. They wondered until they saw what good trading partners the former enemies became. It wasn’t the people we were concerned about, it was their governments. Russia and the Newly Independent States also have the potential of becoming great trading partners.” “It’s a trade-off,” says Horton. “We believe the number one national security problem at the present time is the threat of proliferation of nuclear materials. That threat outweighs by orders of magnitude the threat that freed-up monies will be used for military purposes.” The cooperative program provides safgeguards that technologies are used to secure nuclear materials and not for military purposes. Sandia’s involvement in this area is based on more than 30 years of experience in nuclear material, weapons, and facility security and protection. Sandia engineers have worked at more than 300 facilities in 38 countries. While Sandia takes a lead role in providing physical security at potentially at-risk nuclear sites, other U.S. national laboratories play lead roles in numerically accounting for fissionable material, as well as other important material control measures. Other nations, notably Japan and Sweden, have also provided personnel and material assistance. Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national security, energy, and environmental technologies and economic competitiveness. # Visuals: available. Media contact: Neal Singer, 505-845-7078, nsinger@sandia.gov Sandia National Laboratories' World Wide Web home page is located at http://www.sandia.gov. News releases, fact sheets, and news tips can be found at http://www.sandia.gov/media/whatnew.htm. The Sandia Lab News Online Edition is at http://www.sandia.gov/LabNews/LabNews.html. 
--------
685-> Jackson Lab Scientists Report Advance In Study Of Neuronal Migration In Brain Development
 FOR IMMEDIATE RELEASE APRIL 24, 1997 BAR HARBOR -- Genetic research conducted at The Jackson Laboratory has identified a protein in mice that may play a fundamental role in the critical process of "wiring" the central nervous system during vertebrate embryonic development. The abnormalities observed in mouse models bred at the Laboratory with mutations in the rcm (rostral cerebellar malformation) gene involve significant disruption of neuronal migration during development of the brain. Such genetic mutations in human brain development are known to result in disorders including epilepsy and severe mental retardation. The study -- led by Susan L. Ackerman, Research Scientist at The Jackson Laboratory -- is reported in the April 24 issue of the journal Nature under the title, "The Mouse Rostral Cerebellar Malformation Gene Encodes an UNC-5 like Protein." Co-authors are Leslie P. Kozak, Stefan A. Przyborski, and Barbara B. Knowles, all of The Jackson Laboratory; and Laurie A. Rund, University of Illinois, Urbana, and Bert B. Boyer, University of Alaska, Fairbanks, both formerly of the Laboratory. "This will have an impact on our understanding of how the human brain develops," says Dr. Ackerman. "This mouse mutant is unique in that it has cerebellar neurons in a completely different region of the brain. Our results support a fundamental role for the rcm protein in critical migratory events during cerebellar development." Research in mice and other animals has shed light on the complex process of central nervous system development. Billions of neurons from "nurseries" deep within the brain are born and differentiated at specific times and migrate to precise locations in the central nervous system, where they are wired into the intricate circuit that assures the proper functioning of the brain. But sometimes the migratory process goes astray, with neurons failing to reach the proper destinations and instead forming jumbled-up concentrations in other regions of the brain. In humans, this can result in conditions such as lissencephaly, or "smooth brain," in which the cerebral cortex lacks the normal surface texture. Lissencephalic children seldom survive, suffering severe mental retardation and seizures from birth. The scientists report in Nature that the rcm mouse exhibits a dramatic reduction in cerebellar size and in cerebellar folding; that ectopic cerebellar cells are present in midbrain regions by three days after birth; and that postnatal cerebellar neuronal migration abnormalities are present. The mouse is also ataxic, or stumbling, in its gait. The rcm gene is a member of a newly described family of vertebrate homologues of unc-5 (uncoordinated), a protein that has been found to be essential for normal cell migration during the development of the worm, C. elegans, which suggests an evolutionary conservation of gene function between invertebrates and mammals. 
--------
686-> How Cocaine May Weaken The Immune System
Cocaine may weaken the body's natural defenses by dramatically altering the numbers and genetic machinery of an important type of immune cell from the thymus gland, according to researchers at the University of Illinois at Chicago and at the Veterans Administration West Side Medical Center. Their findings were published in the February 1997 issue of the Proceedings of the Society for Experimental Biology and Medicine. "In mice and cell cultures, we found that cocaine directly affects many aspects of thymocyte functions," says David Ou, clinical associate professor of pathology at UIC and chief of immunology and virology at the VA West Side Medical Center.  "Since the thymus is the essential organ for T-cell maturation and normal immune function, the effects of cocaine may partly explain abnormal immune responses, leading to increased disease or tumor growth." The thymus gland plays a crucial role in the body's defense against viruses and other infections by producing T-lymphocytes that can attack foreign cells or tumors as well as regulate the production of antibodies.  While previous studies have found increased rates of bacterial and viral infections in cocaine abusers, there have been few studies on the effects of cocaine on the thymus. In the study conducted at the VA West Side Medical Center, Ou and his research colleagues injected mice daily for five days with either saline or varied doses of cocaine and analyzed different subpopulations of T-lymphocytes four hours after the last injection.  They found significant decreases in the numbers of one key group of these immune cells.  Their analysis revealed that as the dosage of cocaine increased, so did the rate of these cells undergoing programmed cell death with apoptosis. In addition, the researchers found that the injections of cocaine resulted in much higher DNA material within the surviving thymocytes but without increasing genetic activity. "These results suggest that cocaine may affect the process of T-cell maturation leading to an alteration of the normal immune function," says Ou. "We hypothesize that cocaine harms the immune system by altering the regulatory functions of key immune cells, resulting in increased susceptibility to cancer and infection." "The thymocyte population is normally characterized by a rapid and extensive increase, followed by a tremendous decrease," explains Ou. "This unusual population fluctuation implies a high level of genetic activity that is vulnerable to outside influence." The researchers also found similar results when they cultured normal thymocytes (from mice) with cocaine, with the cell survival rate declining as cocaine concentrations increased.  Ou says the comparable findings suggest that cell-culture studies may be useful in studying cocaine effects on thymocyte biology. "These findings certainly open new avenues for research into the effects of cocaine on the immune system," says Ou. "We now believe that cocaine can reduce thymocytes through direct contact with those cells,  before it is metabolized in the body. Also, our finding that cocaine results in increased DNA content in thymocytes suggests that cocaine may have effects at the genetic level. "Although our research on cocaine was limited to mice, we are concerned that abusers of this drug are making themselves more susceptible to disease and infection," Ou adds. According to the National Institute on Drug Abuse, in 1994, about 22 million Americans age 12 and older had used cocaine at least once in their lifetimes; in 1995, about five percent of 10th-graders and six percent of 12th-graders had tried cocaine at least once. Ou says the implication of these findings for young people is serious because the thymus is more active in the young and is more vulnerable to the effects of cocaine. The other researchers who collaborated in this study were: Yu-Bin Wu of the VA West Side Medical Center, Guo-Gang Gu of UIC's department of pathology, and Ken Anderson of Rush Medical College.  
--------
687-> ‘Mystery Disease’ Sarcoidosis Receives Attention From New England Journal Of Medicine
EMBARGOED UNTIL: 					5 p.m. EDT, April 23, 1997 CONTACT: Jordan Gruener(303) 398-1002 ‘Mystery Disease’ Sarcoidosis Receives Attention from New England Journal of Medicine in Article by National Jewish Physician DENVER-"Sarcoidosis is a result of an unknown environmental agent," says Lee Newman, M.D., a National Jewish Medical and Research Center physician. "Sarcoidosis is a mystery disease. There’s probably more than one cause." Dr. Newman’s "Medical Progress" report  in the April 24 edition of the New England Journal of Medicine outlines what the medical community has learned about the disease during the past 10 years and the best ways to treat it. Sarcoidosis—the most common type of interstitial lung disease—attacks the entire body, focusing on the lungs, eyes, skin and organs.  It is characterized by inflamed, microscopic growths called granulomas, most often found in the lungs.  Sarcoidosis can cause redness in the eyes, shortness of breath, bumps on the skin, fatigue, fever and general pain caused by exposure to light.  Oral corticosteroids are used to treat sarcoidosis.About 3 percent of African-American women risk getting the disease sometime during their adult lives.  It typically affects people between the ages of 20-40.  The disease is slightly less common in African-American men, and Caucasian women and men. In the United States, 30 people in every 100,000, in all ethnic groups, have sarcoidosis.  "Sarcoidosis shows up in every medical practice in the country," says Dr. Newman, director of the National Jewish Division of Environmental and Occupational Health Sciences. Sarcoidosis apparently isn’t contagious, but researchers believe shared environmental exposure, such as living in the same house or town, or working in the same building, may lead to the disease.  For example, sarcoidosis is more common in health care workers, especially nurses, and in rural areas. "It tends to run in families," says Dr. Newman, who has treated people with sarcoidosis for more than 15 years.  "If there’s one person in a family with sarcoidosis, then there is as much as a 16 percent chance another family member will contract the disease." Health care providers have learned:
--------
688-> Heart Drug Steadies Eye Surgeons' Hands
Caffeine, stress, sleep loss, anxiety and physical exertion all can induce unnoticeablehand tremors. Now, experiments with a drug commonly used to treat rapid heart beatsappears to significantly improve hand steadiness of surgeons during simulated eyeoperations. Results of the study with 17 volunteer eye surgeons showed that propranolol, usedto slow the heart rate, decreases tremors, pulse rate and blood pressure without noticeableside effects. The study appeared in the March issue of Archives of Ophthalmology. "Eye surgeons know that the very delicate work we do can be affected by tremors,"says Dante J. Pieramici, M.D., chief resident at Wilmer Eye Institute and a retinal surgeon."While hand steadiness is only one of a number of factors that may influence a surgeon'sperformance, we're obligated to study ways to improve our work. But we are not advocatingin any way drug use by surgeons to reduce tremors." The  researchers measured hand tremor in each subject immediately before and onehour after randomly giving them one of three treatments: a placebo, 10 milligrams ofpropranolol or 200 milligrams of caffeine added to a juice drink--about as much as in twocups of coffee. The tests were repeated on three separate days until each surgeon hadreceived all three treatments. As part of a performance improvement initiative, the Hopkins team measured handtremors using a device they created and named MADSAM--Microsurgery AdvancedDesign Laboratory Stability, Activation, and Maneuverability tester.  MADSAM  tests asubject's ability to hold  hands steady under conditions similar to eye surgery.  MADSAMrecords the position of a small magnet on the end of a microsurgical instrument used toilluminate the inside of the eye during an operation. Sitting on an operating room stool, the surgeons held the illuminator in a model eye containing a sensor that recorded how far themagnet moved in any direction. The sensor and eye were in a life-size mannequin headpositioned beneath an operating room microscope. Before receiving a treatment, the average pretest tremor of surgeons was 3.8microns (1 micron = a millionth of a meter). Following treatment with caffeine, tremorsincreased by an average of 31 percent, compared to a 15 percent  increase followingplacebo. Only propranolol caused a statistically significant decrease in hand tremor--anaverage of  22 percent. When compared to the increase in tremors caused by placebo, propranolol decreasedthe average hand tremor of  the surgeons by 37 percent, while decreasing pulse rate by 11percent and systolic blood pressure by 5 percent. Systolic blood pressure is the pressure inthe blood vessels measured just after the heart contracts and pumps blood into the arteries. Other authors of the study include Michael U. Humayun, R. Scott Rader, Eugene deJuan, Jr., and Carl C. Awh (Retina-Vitreous Associates, Nashville, Tenn.). --JHMI-- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basison EurekAlert at http://www.eurekalert.org and from the Office of Communications and PublicAffairs'direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise oron CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension".JHM",Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com. 
--------
689-> UT-Houston Study Suggests Violence In The Community Impacts Youth Behavior
Houston (April 19, 1997) Adolescents who have been exposed to community violence are more likely to engage in violent behavior themselves, according to the results of a study presented at the Annual Meeting of the Society of Behavioral Medicine in San Francisco, April 19. In her presentation titled "Youth Aggression and Exposure to Community Violence", Jennifer Conroy, M.P.H., UT-Houston School of Public Health, describes how students from a large urban school district who witness incidents involving behaviors such as handgun carrying, fighting and substance abuse, are from two to nine times more likely to engage in such acts. Surprisingly, the source of the exposures was the local neighborhood where, for example, 80 percent of the 12 to 14-year-old study group said they had witnessed a beating, and 50 percent reported seeing drug deals. Conroy explains: "Analysis of data collected a year into the project revealed that the relative risk for violent behaviors increases with exposure.  For example, a youth who had seen people with handguns was seven times more likely to carry one than a youth who had not witnessed this behavior. Overall, there was a strong 'dose-response' association between the extent of the exposure and involvement in aggression and victimization: students who reported seeing more violence also reported being victimized more often, compared to those who had witnessed fewer acts.  While this study does not imply a direct cause and effect between exposure and participation in risky behavior, the two are strongly correlated.  Other studies have suggested a link between violent behavior and exposure to violence on TV or other media; our research describes a phenomenon which is much closer to home in that it deals with real events in adolescents' own community". The results are drawn from analysis of 1995 data from the Students for Peace project which looks at the reported behaviors of inner city school students in Texas over a three year period, beginning in 1994.  The researchers from the Center for Health Promotion Research & Development, UT-Houston School of Public Health, surveyed more than 8,000 ethnically diverse middle school male and female students.  Participants completed a questionnaire which inquired into their experience with and beliefs  about behaviors such as handgun carrying, fighting and gang involvement.  They also answered questions about substance abuse - specifically alcohol consumption, cigarette smoking, marijuana, cocaine and inhalant use.  The study is one of 13 nationwide funded by the Centers for Disease Control (CDC), designed to evaluate the effects of violence prevention initiatives.  Baseline data from all the projects was published by the CDC in October 1996 in the American Journal of Preventive Medicine ; the final results are expected next year. UT-Houston Associate Professor, Steven Kelder, Ph.D., principal investigator on the study, comments on implications for interventionist programs: "Our results, along with others', suggest that in order to reduce youth involvement in violence, appropriate steps should be taken at the community level.  Many questions remain as to where exactly to target remedial efforts, but we now have evidence that young people are strongly influenced by exposure to aggression and violence in their own 'back yard'.  An interdisciplinary approach to violence prevention which encompasses the home, school, neighborhood and other community elements would seem to be called for if we are to introduce measures which prevent the exposure, or help young people develop better ways of responding when they encounter violence and aggression." Note to editors: The 1997 Society of Behavioral  Medicine Annual Meeting is being held April 16-19 at the San Francisco Hyatt Regency Embarcadaro. The authors of Youth Aggression and Exposure to Community Violence are Jennifer L. Conroy*, M.P.H., Steven H. Kelder, Ph.D., M.P.H., Pamela  Orpinas, Ph.D., M.P.H., and Nancy G. Murray, Ph.D., M.A., The University of Texas-Houston, School of Public Health. * Corresponding Author. 
--------
690-> Brain Surgery Boosts Memory For Parkinson's Patients, University of Florida Research Shows
By Victoria White GAINESVILLE, Fla.---An increasingly popular surgical technique to alleviate symptoms of Parkinson's disease also improves memory--a finding that surprised researchers, a new University of Florida study shows.  Pallidotomy surgery, which involves precision burning of a small spot in the brain, provides relief for many patients from some of the tremors and muscle rigidity associated with the central nervous system disorder.  Parkinson's patients also frequently have problems with memory, but researchers did not expect the procedure to help.  "The surgery is done in an area of the brain that is not thought to affect cognition--the process by which we learn about the world around us," said Dawn Bowers, a neuropsychologist at UF's College of Medicine. She presented her findings (4/16/97) at a recent meeting of the American Academy of Neurology in Boston. Parkinson's is an incurable chronic movement disorder affecting 500,000 to 1.5 million Americans. Sufferers produce too little dopamine, a chemical that helps transmit messages between regions in the brain that facilitate muscle movement. This leads to increased activity in an area of the brain known as the globus pallidus and contributes to Parkinson's tremors and rigidity. In pallidotomy, a neurosurgeon probes through a small hole in the skull, guided to the pallidus by the body-scanning technique known as magnetic resonance imaging. The neurosurgeon stimulates the area, testing to see which sites affect disease symptoms. Those spots are then heated to interrupt the overactive brain circuitry. At UF, the surgery is performed by Dr. William Friedman, of UF's Brain Institute and College of Medicine. The procedure is not a cure, and patients continue to need medication. But it does improve the quality of life for many who typically have had trouble with routine tasks because of their tremors, stiffness and difficulties with walking and balance. Pallidotomy generally is considered appropriate only when medication loses effectiveness or its side effects become too disabling. "Often what we see in patients with Parkinson's disease is that they have become much slower at all tasks, including the retrieval of memory. It's not to the same degree as with Alzheimer's disease, but they do show mild to moderate problems with memory and slowness in their thinking," Bowers said. In the research presented in Boston, 21 patients were included in the analysis. The improved-memory trends continued with 25 patients not included in the original group, she said. Three months after undergoing the procedure at Shands Neurological Center at UF, patients generally scored better than before the operation on a word memorization test. Specifically, they improved on a section in which they were given hints. "Their cued recall improved, but their free recall did not," said Bowers, an associate professor of neurology and clinical psychology. Across the board, individuals tended to remember, with assistance, two or three more items out of a list of 16 common words than they had before the surgery. "For example, we would ask, `Which of the words were vegetables?' That sort of clue was more helpful after pallidotomy," Bowers said. Different lists were used before and after surgery. "A final part of the test assessed something called recognition memory. There we would ask a yes -or-no question about individual words. `Was pencil on the list?' They also improved in that area," Bowers said. Many patients had not noticed any improvements in their memory. "For others, it was strong enough that they noted it and were pleased, but usually they're happier about the improvements in their motor symptoms. That is much more important to them," Bowers said. A study published last year in the Annals of Neurology provides one possible explanation for the unexpected improvements, Bowers said. "The study showed increased activity in the front part of the brain after pallidotomy. One area that was more active was the dorsolateral frontal lobe. That may be significant because it plays a role in the retrieval of memory." Bowers plans follow-up assessments of the patients in the coming years to determine if the memory improvements are fleeting or long-lasting. The research is supported in part by grants from the National Parkinson Foundation, which has established a Center of Excellence at UF. ---------------------------------------------- Recent UF Health Science Center news releases also are available on the UF Health Science Center Communications home page.  Point your browser to http://www.vpha.health.ufl.edu/hscc/index.html 
--------
691-> National Jewish Medical And Research Center Shows Rush Immunotherapy  Results In Allergen-Specific Changes In T Cells
April 21, 1997 CONTACT: Jordan Gruener (303) 398-1002 National Jewish Medical and Research Center Shows Rush Immunotherapy Results in Allergen-Specific Changes in T Cells DENVER-Rush immunotherapy targeting a single allergen makes distinct changes in T cells and stops allergic reactions, National Jewish Medical and Research Center physicians found, according to the April issue of the Journal of Allergy and Clinical Immunology. "This study showed for the first time the T cell reaction to immunotherapy is specific," said Erwin Gelfand, M.D., head of the Department of Pediatrics at National Jewish and principal investigator of the study.  "If you give too many antigens in desensitization, the immune system may not be able to distinguish between them.  But attacking one trigger or a few triggers at a time can prevent the allergic reaction." Rush immunotherapy consists of a number of injections given over a short time to desensitize a person to certain allergens, such as dust mites, cat dander or different types of plants. Ten boys and girls, allergic to house dust mites and cat dander, were given rush immunotherapy for house dust mites only.  When treatment ended, the children were desensitized to dust mites but not to cat dander, which showed that T cells can respond selectively to rush immunotherapy.  In rush immunotherapy, T cells produce more interferon gamma, an element that lowers allergic responses, and shut off production of pro-allergic cytokines, which can cause wheezing, runny nose, sneezing and watery eyes. "After rush immunotherapy you are more tolerant to an allergen you would have reacted to without desensitization," Dr. Gelfand said. For more information on allergies, please call LUNG LINEâ, (800) 222-LUNG. 
--------
692-> Women With Low-Risk Pregnancies Receive Fewer Obstetrical Interventions When Cared For By Midwives, Compared To Women Attended By Physicians
Low-risk patients who choose nurse midwives for their obstetrical care have fewer Caesarean sections, receive less anesthesia, have a much lower rate of episiotomy and incur less expense, compared to similar women who choose physicians for their care. At the same time, obstetricians, family physicians and nurse midwives all achieve excellent results. These are the conclusions of a University of Washington study reported in the current issue of the American Journal of Public Health. "Nurse midwives establish a relationship with their patients that leads to excellent outcomes with less use of medical resources," said Dr. Roger A. Rosenblatt, UW professor of family medicine and principal investigator on the study. "Pregnancy is the most common reason that women spend time in hospitals, and there are major differences in the way physicians and nurse midwives approach low-risk patients." The researchers took a random sample of all the urban practitioners in Washington state who deliver babies in hospitals: nurse midwives, family doctors, and obstetricians. They then took a random sample of those practitioners' low-risk patients, eventually analyzing 1,322 medical charts for more than 1,000 variables, covering mothers' and babies' status prenatally and during labor and birth. The study found that the patients of certified nurse-midwives were less likely to receive continuous fetal monitoring or to have their labors induced or augmented. They were also less likely to receive epidural anesthesia.  Overall, patients of midwives used 12 percent fewer resources than patients of physicians. Rosenblatt noted that midwives account for only 4 percent of deliveries in this country; they deliver the majority of babies in many countries, including Britain. The Caesarean-section rate for patients of certified nurse midwives was 8.8 percent, compared to 13.6 percent for obstetricians and 15.1 percent for family physicians. "We used an 'intention-to-treat' protocol," explained Rosenblatt. "For example, if the patient of a midwife ended up needing a C-section, the procedure was attributed to the midwife, not to the obstetrician who performed the surgery." The study found little difference between the practice patterns of the two groups of physicians. Obstetricians and family physicians seem to be very similar in their approaches to low-risk pregnant women. "The major limitation of our study was that women chose their own provider, rather than being randomly allocated to different types of care," Rosenblatt acknowledged. "But in the United States, patient choice is very important. The characteristics of the women as well as the practice style of the provider likely influenced the type of care received. But the study showed that in some patients, it is possible to achieve lower rates of obstetrical intervention by adding midwives to the provider mix. "This was not a study of quality of care, but of cost and outcome," said Rosenblatt. "However, we found that labor and delivery are incredibly safe in the state of Washington. There were no neonatal deaths, and the five-minute Apgar scores (a numerical assessment of newborn status five minutes after birth) were very high. "We hope that this study sparks discussions of less intrusive styles of obstetric care, even among nurse midwives," he said. "Most of them worked in sophisticated urban hospitals, and half of their patients were given continuous fetal monitoring, even though earlier studies have shown that intermittent monitoring is just as effective." The definition of low risk excluded 53 percent of pregnancies. Women were excluded from the study if they had a major medical condition, a previous obstetrical complication, a serious risk factor in the current pregnancy, no obstetrical care in the first trimester, or were under 18 or over 34 years old. The study was funded by the Agency for Health Care Policy and Research. Co-investigators are Drs. Sharon A. Dobie, L. Gary Hart, Ronald Schneeweiss and Michael J. Pirani of the UW Department of Family Medicine; Dr. Thomas J. Benedetti of the UW Department of Obstetrics and Gynecology; Dr. Edward B. Perrin of the UW Department of Health Services; Dr. Debra Gould of the University of Rochester Department of Family Medicine; and Dr. Tina R. Raine of the Georgetown University Department of Obstetrics and Gynecology.
--------
693-> Traditional Bedside Rounds May Improve Patient Satisfaction
Although many U.S. teaching hospitals are bucking tradition by moving morning "rounds" from thebedside to the conference room, patients seem to prefer the bedside discussions by physicians andmedical students, a Johns Hopkins study suggests. "Rather than upsetting patients, bedside rounds, if they're in understandable terms, make them feelmore comfortable and attended to," says lead author Lisa S. Lehmann, M.D., formerly a fellow inmedicine at Hopkins and currently a fellow in medical ethics at Harvard Medical School. Results of the study are published in the April 17 issue of The New England Journal of Medicine. Developed a century ago at Hopkins, rounds bring together young residents and medical studentswith an experienced physician to discuss diagnosis and treatment of each patient. "There should be noteaching without a patient for a  text, and the best teaching is that taught by the patient himself," saidthe late William Osler, M.D., one of Hopkins medicine's founding fathers. But in recent years,concerns about patient discomfort, privacy and sensitivities have led to conference-room roundsinstead. Researchers studied the perceptions of 182 patients during three weeks of rounds: bedsidepresentations were made with 95 patients and conference room presentations with 87 patients. Most patients in both groups said their physicians had introduced themselves properly, explainedtests and medications adequately and treated them respectfully. More than three-quarters of patients inboth groups said rounds did not upset them. In the bedside presentation group, about 87 percent said such presentations should continue and 50 percentsaid the presentations helped them better understand their illness. Results also show that patients in the bedside group thought their doctors spent about twice asmuch time with them during morning rounds (10.5 minutes versus 5.7 minutes) and were slightlymore likely to be satisfied with their care.  "The recent trend in teaching hospitals has been to movecase presentations into the conference room for expediency, and so patients would not be confused orupset," says Lehmann. "But our results suggest that, from the patient's perspective, bedsidepresentations are at least as good and perhaps better." More educated patients were 40 percent less likely to complain about confusing terms and six timesmore likely to say tests and medications were adequately explained than patients who had notcompleted high school, the results show. Patient suggestions for improving bedside presentations included using fewer confusing medicalterms, allowing the patient to say more, reducing the number of physicians in the room, introducing allphysicians in the room, making physicians sit and pay better attention, and respecting patient privacymore. "When presenting at the bedside of less educated patients, physicians should be especially careful toavoid medical jargon and to explain fully their plans for care," Lehmann says. "If interns and residentsare taught to encourage patient participation and avoid confusing terminology, both patients andphysicians in training might benefit from presentations at bedside." Rounds were conducted by teams that each included a chief resident, two senior residents, fourinterns and three medical students. Bedside presentation continues to be the norm at Hopkins. "Bedside presentations encourage physicians to view patients as real people rather than as abstracthosts for disease," Lehmann adds. "They also allow physicians to observe physical findings which mayinfluence their understanding of a patient's illness and  provide an opportunity for students to learn theart and science of clinical medicine from more senior physicians." Other authors were Frederick L. Brancati, M.D., Min-Chi Chen, M.S., Debra Roter, Dr.Ph., andAdrian S. Dobs, M.D. --JHMI--Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basis onEurekAlert at http://www.eurekalert.org and from the Office of Communications and Public Affairs'direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or onCompuServe in the SciNews-MedNews library of the Journalism Forum under file extension 
--------
694-> Listen To Your Mother:  An Apple A Day--Not A Cheeseburger--Keeps The Doctor Away
American mothers' often-ignored advice to eat fruits and vegetables, not cheeseburgers and doughnuts, now appears to substatially and quickly lower blood pressure, according to results of a study performed at Johns Hopkins and several other centers. The findings offer more evidence that healthy diets can reduce the risk of heartdisease and stroke, the nation's first- and third-leading killers, respectively. About 40million Americans have high blood pressure, which is particularly common amongpeople over 50 and a major risk factor for cardiovascular disease and stroke. Results of the study, supported by the National Heart, Lung and Blood Institute,are published in the April 17 issue of The New England Journal of Medicine. "We already know that weight control and reduced salt and alcohol intake areimportant steps to prevent and treat hypertension," says Lawrence Appel, M.D., leadauthor and an associate professor of medicine at Hopkins. "Our findings show that a dietrich in fruits, vegetables and low-fat dairy products and reduced in saturated and total fatoffers an additional nutritional approach." The Dietary Approaches to Stop Hypertension (DASH) study included 459 adultswith high-normal or stage 1-mild hypertension (systolic blood press of less than 160 mmHg and diastolic pressure of 80-95 mm Hg). Researchers examined the impact on bloodpressure of whole dietary patterns rather than individual nutrients or supplements. Participants ate one of three diets for eight weeks: a control diet low in fruits,vegetables and dairy products and with a fat content typical of the American diet; a diet high in fruits and vegetables; or a "combination" diet low in saturated and total fat andhigh in fruits, vegetables and low-fat dairy products. Among the 133 participants with high blood pressure, the combination dietreduced systolic and diastolic blood pressure by an average of 11.4 mm Hg and 5.5 mmHg, respectively. Systolic blood pressure, the higher of the two numbers, occurs when theheart is contracting; diastolic blood pressure occurs when the heart relaxes betweencontractions. "These blood-pressure reductions are clinically important because they are similarto those reductions commonly achieved through use of one anti-hypertensivemedication," Appel says. Among the 326 participants with high-normal blood pressure, the combinationdiet reduced systolic and diastolic blood pressure by an average of 3.5 mm Hg and 2.1mm Hg, respectively. "These reductions are important from a public health perspective because theymay prevent hypertension from occurring," says Appel. Among all participants, the diet high in fruits and vegetables reduced bloodpressure, but to a lesser extent than the combination diet. The reductions occurred withintwo weeks of the start of the study. The blood pressure reductions were independent ofbody weight, salt intake and alcohol consumption, which were held constant. The DASH combination diet provided nine to 10 daily servings of fruits andvegetables (about twice the usual amount in Americans' diets) and three daily servings oflow-fat dairy products (about double the usual amount in Americans' diets). Moreinformation about the DASH diet is available on the World Wide Web athttp://dash.bwh.harvard.edu Other investigators and institutions in the study were Thomas J. Moore, M.D., atBrigham and Women's Hospital, Thomas M. Vogt, M.D., at Kaiser Permanente Centerfor Health Research, Laura P. Svetkey, M.D., at Duke University Medical Center, GeorgeA. Bray, M.D., at the Pennington Biomedical Research Center, and Eva Obarzanek at theNational Heart, Lung and Blood Institute. --JHMI-- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basis onEurekAlert at http://www.eurekalert.org and from the Office of Communications and Public Affairs' directe-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or onCompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM",Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com. 
--------
695-> Neuroscience Teaching Using Multi-Media
WILLIAMS COLLEGE WILLIAMSTOWN, MASS. 01267 (413) 597-4179 IMMEDIATE RELEASE April 17, 1997 For more information Jo Procter, News Director NSF AWARD TO ADVANCE NEUROSCIENCE TEACHING USING MULTI-MEDIA WILLIAMSTOWN, Mass.--The National Science Foundation (NSF) has awarded Williams College $228,987 to redesign the way introductory science of the brain is taught. The project is coordinated by Betty Zimmerberg, associate professor of psychology and chair of the college's neuroscience program.  The effort will involve the work of media producer Lance Wisniewski, president of Innervision Media of Salisbury, Mass. A national advisory committee, formed by Zimmerberg and the NSF will help disseminate project results to the academic community and advise on future directions for the project. The goal is to use the latest digital multi-media technology to teach concepts in neuroscience that are difficult to portray in two dimensions. "Textbook illustrations are generally inadequate," Zimmerberg said, "because they can never convey in two dimensions brain structures and processes that exist in three dimensions and change over time." She and Wisniewski will develop a collection of three-dimensional animated and interactive multi-media resources to support introductory neuroscience courses and related fields in biology and psychology.  These resources will include videos and CD-ROMs for laboratory simulations and process animation. "We plan to take advantage of several new advances in computer technology," Zimmerberg said. One of these is moderately priced but extremely powerful 3-D animation software for use on desktop computers.  These same computers can run powerful new multi-media authoring software. "All the control of the videos plus the related text, graphics and 3-D models will be kept on neuroscience pages on the World Wide Web," Wisniewski said.  "This means we can update the programming of these materials without ever making the video on the CD-ROM obsolete. " The pilot unit on "Synaptic Transmission and Chemical Messengers" will include a real-time interactive simulated laboratory experiment. The ultimate goal of the project is to make the materials available globally for a variety of educational levels and settings. Before joining the Williams faculty in 1989, Zimmerberg taught at Rensselaer Polytechnic Institute and SUNY-Albany.  At Williams, her courses include Introduction to Neuroscience; Drugs and Behavior; and Left Brain, Right Brain-The Great Divide.  Her research has focused on brain development and how it is affected by experiences such as prenatal alcohol exposure or postnatal stress. She is the recipient of numerous grants and fellowships, including 11 years of continuous funding from the National Institute of Alcohol Abuse and Alcoholism of the National Institute of Health. After receiving her B.A. from Harvard University in 1971 and her Ph.D. from City University of New York in 1976, Zimmerberg did postdoctoral work in psychopharmacology at the Mount Sinai School of Medicine in New York City. Wisniewski has produced educational television programs for 20 years, with a specialty in computer animation and science instruction.  His programs have appeared on PBS, CBS, and The Learning Channel, among others.  His most recent project was a program on "Bones" for the Discover Magazine series on the Discovery Channel.  For PBS he produced, directed, and wrote "The Power of Place: World Regional Geography," a series of 26 half-hour programs, shot in 35 countries, about people whose lives are shaped by geographical forces.  He also produced and directed "The Nobel Legacy," and designed the computer animation system for the extensive 3-D motion graphics to illustrate principles of chemistry, medicine, and physics. END ___ 
--------
696-> Pregnancy, Oral Contraceptives, Hormone Replacement Therapy As Risk Factors For Stroke
During the weeks immediately following delivery of a baby, new mothersare at increased risk of strokes, a University of Maryland School ofMedicine neurology professor told the American Academy of Neurologymeeting in Boston this week. Speaking on stroke prevention in the `90s, Dr. Steven Kittner,associate professor of neurology at the medical school in Baltimore,presented data from observational studies indicating a 28-foldincreased risk of intracerebral hemorrhage and a nine-fold increase inrisk of cerebral infarction in women during the six weeks afterdelivery. Pregnancy itself is associated with no increased risk of cerebralinfarction and only a modestly increased risk of intracerebralhemorrhage, Kittner said. Oral contraceptives seem to cause a dose-associated increased risk ofstroke, said Kittner. "Current research supports the accepted practiceof restricting the use of oral contraceptives in women who smokecigarettes, have a history of hypertension or other risk factors forvascular disease," he said. The relationship between postmenopausal estrogen replacement therapyand stroke remains less clear, the neurologist said. One large studyshowed a significantly increased risk of stroke both among womentaking estrogen alone and those taking combination hormone replacementtherapy of estrogen and progestin. But another study showed asignificantly reduced risk of stroke in women taking  combinationhormone replacement therapy. Several large clinical trials now under way should provide moredefinitive data, but for now, "there still are only two wellestablished indications for hormone replacement therapy, relief ofmenopausal symptoms and prevention of osteoporosis," Kittner said. "Many uncertainties persist regarding the risk of combinedestrogen-progestin therapy, and the risks/benefits need to be weighedin each individual case.
--------
697-> University Of Washington Discovery May Point The Way To New Treatment For Hepatitis C Cases That Do Not Respond To Interferon Therapy
Researchers at the University of Washington report in the April 14, 1997 issue of Virology that they may have an explanation for why the currently approved drug treatment for hepatitis C is ineffective much of the time. The drug, recombinant alpha interferon, is ineffective in 60 to 80 percent of cases. "This discovery explains the molecular mechanisms for interferon resistance, and points the way to a potential new target for therapeutic drugs to treat hepatitis C," said the principal investigator, Dr. Michael G. Katze (kates), UW professor of microbiology and associate director of the UW's Regional Primate Research Center. The UW's Office of Technology Transfer has negotiated a patent-based licensing agreement with RiboGene, Inc., a privately-held biotechnology company in Hayward, Calif., which will begin investigating drug therapies based on the UW discovery. Katze is a member of the company's scientific advisory board. Hepatitis C (formerly called non-A, non-B hepatitis), caused by the virus, affects more than 3.5 million Americans. It is the major reason for liver failure necessitating liver transplants. "Many viruses that affect humans -- hepatitis, influenza, herpes, HIV, polio and a host of others -- have evolved mechanisms to resist the effects of interferon, one of the body's first lines of defense against viruses," said Dr. Michael Gale, Jr., UW microbiology fellow who is lead scientist and first author of the study. The drug interferon is an artificial version of naturally-occurring interferon, a protein secreted by cells that "interferes with" viral infection and other challenges. Earlier studies in Japan showed that interferon-resistant HCV strains have a specific RNA sequence within a region of the virus called NS5A. The UW researchers followed up on this research, and tested the ability of NS5A to interact with a key component of interferon response called PKR, a member of an important family of enzymes called protein kinases. Katze and his team found that the NS5A protein in two strains of HCV -- one found mainly in the United States, the other in Asia -- had the ability to bind to and inactivate PKR. "This has strong implications," said Gale. "We have shown that PKR is important in the interferon response." "We believe we've identified a potential target for therapeutics," said Katze. "If a compound can be identified that inhibits or prevents the association of NS5A with PKR without affecting PKR's ability to function, interferon response could be restored. If the compound were administered in combination with interferon, it could potentially bring the virus under control and allow the body's immune system to knock it out." Katze cautions that while his team's research is an important first step, a therapy for HCV is not around the corner. The study is published in the April 14 edition of Virology (vol. 230, no. 2, pp. 217-227, Academic Press) and funded by the National Institutes of Health. Co-authors are Drs. Marcus J. Korth, Norina M. Tang, Seng-Lai Tan, Deborah A. Hopkins, Stephen J. Polyak and David R. Gretch, all of the University of Washington; and Thomas E. Dever of the National Institute of Child Health and Human Development. Facts about Hepatitis C Up to 3.5 million Americans are believed chronically infected with the hepatitis C virus, formerly called non-A, non-B hepatitis. Some 20 to 40 percent of people coming to inner-city hospitals have the virus, as do about 80 percent of intravenous drug users. While hepatitis C is transmitted through blood and shared needles, studies have shown that about 40 percent of carriers do not report such risk factors. The nation's blood supply has been tested for hepatitis C since 1990.The disease causes symptoms such as fatigue, nausea, loss of appetite, dark urine and jaundice, but up to 70 percent of patients lack symptoms in the early stages. Infected individuals usually are unaware of their disease until they develop serious complications. The disease may occur in the acute form and be followed by recovery, or it may become chronic and cause symptoms for years.The federal Centers for Disease Control and Prevention (CDC) estimates that 20 to 50 percent of chronically infected hepatitis C patients will develop cirrhosis of the liver, and 20 to 30 percent of those will develop liver cancer or liver failure requiring transplant.There are an estimated 150,000 to 250,000 new cases of hepatitis C infection each year in the U.S., and the disease contributes to the death of more than 12,000 American annually; this toll is expected to triple by the year 2010, according to the CDC. ###
--------
698-> Getting A Computer To Remember What Was On The Screen When The Power Went Off
 FOR IMMEDIATE RELEASE April 10, 1997 ALBUQUERQUE, N.M. -- One of the minor horrors of the computer age is to be working on a document not yet saved to the hard drive “memory” and lose everything because of a power outage or a screen freeze-up that forces the operator to shut down the computer. Attempts to create circuits that save what’s “up” on a screen have used high voltages, which quickly wears down computer electronic components, and have been expensive. Now scientists at Sandia National Laboratories and France Telecom have applied for a patent on a prototype memory-retention device that is inexpensive, low-powered, and simple to fabricate. The device, referred to as “protonic,” is reported in today’s issue of the journal Nature. To transmit data, the device uses embedded protons, which remain where they are when the power turns off, thus preserving the information. In devices such as D-RAMs (dynamic random access memory), typically based on electron flow, the information is lost when the power is turned off. To create the memory-retentive chip, only a few steps must be added to the hundreds currently used to fabricate microchips. The key additional step is to bathe the hot microchip in hydrogen gas. The gas, permeating the chip, breaks up into single ions -- i.e., protons -- at defects in the silicon dioxide. (The defects were created by the heat of the manufacturing process.) The protons can roam only within the chip’s central layer of silicon dioxide, where they are trapped by two layers of silicon that sandwich the silicon dioxide. The Sandia researchers found that: •A positive low-voltage applied to one side of the silicon repels the protons to the far side of the silicon dioxide. •A negative low-voltage applied to the silicon attracts the protons to the near side of the silicon dioxide. If the power is turned off, the protons stay where they are, retaining information in the chip circuit. Development of the process had its origin on the back of a napkin at an IEEE conference in December 1995 in Charleston, S.C. The discussion, subsequent work, and patent involved Sandians Bill Warren (principal investigator), Karel Vanheusden, Dan Fleetwood, and, at France Telecom, Roderick Devine. First observation of the effect that protons remain in silicon when it is baked at high temperatures in hydrogen gas came as part of a systematic study at Sandia and France Telecom of the effects of hydrogen on silicon. “For defense reasons, we’re always interested in radiation-hardened, low-voltage chips,” said Fleetwood. The work is funded by Sandia’s Laboratory Directed Research and Development Program, which funds which finances speculative defense-related research, and the Defense Advance Research Projects Agency. Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities in national security, energy, and environmental technologies and economic competitiveness. # Technical Visuals: available. Media contact: Neal Singer, 505-845-7078, nsinger@sandia.gov Technical contact: Bill Warren, 505--272-7628;  wwarren@sandia.gov Sandia National Laboratories' World Wide Web home page is located at http://www.sandia.gov. News releases, fact sheets, and news tips can be found at http://www.sandia.gov/media/whatnew.htm. The Sandia Lab News Online Edition is at http://www.sandia.gov/LabNews/LabNews.html. 
--------
699-> UCAR Buys HP Exemplar System For Weather And Climate Prediction
1997-12		 FOR IMMEDIATE RELEASE:   April 8, 1997 Contact also: Kathy Sowards Hewlett-Packard Richardson, TX  75080 Telephone: 972-497-3061 E-mail:  kathys@convex.com BOULDER--The University Corporation for Atmospheric Research (UCAR) has signed a contract with the Hewlett-Packard (HP) Company to purchase an HP Exemplar X- Class system.  The purchase is part of a joint research and development project between the National Center for Atmospheric Research (NCAR) and HP's Convex Division, located in Richardson, Texas. During the project, NCAR and HP expect to develop the expertise and tools needed to utilize distributed shared-memory systems, such as the Exemplar, for numerical computer models employed in climate and weather prediction.  The X-Class is HP's fourth-generation system based on the shared-memory architecture, called CC-NUMA (cache-coherent, non-uniform memory access). The Exemplar X-Class system to be installed at NCAR will have 64 processors and a peak speed of 46 gigaflops, or 46 billion floating point operations per second. "The Exemplar is an intriguing next step in our effort to stay abreast of new architectures and new techniques," says Bill Buzbee, head of NCAR's Scientific Computing Division.  Toward this end NCAR has worked closely over the past eight years with a variety of vendors, including Thinking Machines, IBM, Cray Research, and Cray Computer. NCAR is procuring the HP Exemplar system under the National Aeronautics and Space Administration's Scientific and Engineering Workstation Procurement (SEWP) program, which is open to NASA, NASA contractors, federal agencies, and federal agency contractors. According to Buzbee, there is no relation between this research project and NCAR's procurement of a high-performance supercomputer dedicated to large, long-running climate models. Hewlett Packard is a leading global manufacturer of computing, communications, and measurement products and services.  NCAR is managed by UCAR under sponsorship by the National Science Foundation.  UCAR is a consortium of 62 North American universities offering the Ph.D. in atmospheric or related sciences. -The End- Find this press release on the World Wide Web at http://www.ucar.edu/ucargen/press/exemplar.html Additional information about the Exemplar system is available at http://www.hp.com/go/techservers 
--------
700-> Warming Surgery Patients Reduces Fatal Heart Risks
April 8, 1997 Keeping surgery patients warm is a simple and inexpensive way to significantlyreduce the risk of heart complications, the leading cause of post-operative death, a JohnsHopkins study suggests. Maintaining a surgical patient's normal body temperature has been shown to reduceinfections, speed healing and shorten hospital stays, but this is the first prospective clinicaltrial to show it also reduces the chance of serious heart injury, says Steven M. Frank, M.D.,lead author and an associate professor of anesthesiology and critical care medicine. Results are published in the April 9 issue of the Journal of the American MedicalAssociation and discussed in an accompanying editorial. Most patients experience hypothermia, or lowered body temperature, during majorsurgery because of  anesthesia, chilly operating rooms, open body cavities, intravenousfluids and blood infusions. While cool operating rooms keep surgeons comfortable andprovide patients with some benefits such as slowing metabolism, hypothermia also boostspatients' stress hormones, constricts blood vessels and raises blood pressure. Thiscardiovascular stress may trigger serious heart problems. Researchers studied 300 non-cardiac surgery patients who underwent abdominal,chest or vascular surgery. All patients were above age 60 with coronary artery disease orother risk factors for coronary disease. Body temperature was kept near normal withwarming methods in 142 patients, while 158 patients received routine care which resulted inmild hypothermia. Results suggest a 55 percent risk reduction in cardiac complications when nearnormal body temperature is maintained, particularly immediately after surgery. Heart attack, cardiac arrest or unstable angina occurred in 1.4 percent of the warmer groupcompared to 6.3 percent in the group whose body temperatures were kept at traditionallevels. Also, ventricular tachycardia, or an abnormally fast heart beat, occurred in 2 percentof the warmer group versus 8 percent in the cooler group. A similar number of patients inboth groups had a rapid heart beat during surgery, but heart beat irregularities after surgerywere more common in the lower body-temperature group. "An estimated 25 million Americans have risk factors for heart disease, and ourfindings show they will benefit from active warming during surgery," says Frank. Body temperature was kept near normal by warming intravenous fluids andsurrounding patients with a blanket that fills with warm air during and after surgery.Routine body-temperature care also included warming intravenous fluids, but patients werecovered only with paper drapes during surgery and cotton blankets after surgery. Other Hopkins authors of the study, supported by the National Institutes of Healthand Mallinckrodt Medical, Inc., were Lee A. Fleisher, M.D.,Michael J. Breslow, M.D.,Krista F. Olson, B.S.E., and Susan Kelly, B.S.N. Vanderbilt University Medical Centerparticipated in the study. --JHMI-- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basison EurekAlert at http://www.eurekalert.org and from the Office of Communications and PublicAffairs' direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise oron CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension".JHM", Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com.
--------
701-> Virus May Be Linked To Obesity
 A virus that can cause obesity in animals may be linked to some cases of obesity in humans, researchers at the University of Wisconsin Medical School have found. A preliminary study of 199 people has shown that as many as 15 percent of obese people may carry antibodies to the virus, indirect evidence that they once were exposed to the virus itself. None of the lean volunteers tested had the antibodies. Dr. Nikhil Dhurandhar described the findings Mon., April 7, at the Experimental Biology annual meeting in New Orleans. An assistant research scientist in the UW Medical School department of medicine, Dhurandhar conducted the research with UW Medical School Professor of Medicine and Nutritional Sciences Dr. Richard Atkinson. Between 80 and 90 million Americans are obese, defined as having a body-mass index of 27 or above. Body mass index is calculated by dividing a person's weight in kilograms by the square of height in meters. A viral connection to obesity in humans has never been seriously considered before, the researchers noted. Dhurandhar first found that one type of adenovirus that infects birds and is found only in his native India could induce obesity when it was injected into chickens. Human adenoviruses form a large family of some 50 viruses. Transmitted through the air, they can cause upper respiratory infections, cold symptoms, gastrointestinal problems and eye inflammation in humans. Dhurandhar and Atkinson next injected laboratory animals with a form of adenovirus known to affect humans, Ad-36, which resulted in obesity. "A paradoxical characteristic of the virus is that in animals it appears to produce low levels of cholesterol and triglycerides along with the obesity," said Dhurandhar, noting that obesity is usually accompanied by elevated levels of these substances. In the current study, Dhurandhar tested 154 obese and 45 lean human volunteers for the presence of antibodies to Ad-36.  He found about 15 percent of the obese volunteers had antibodies to Ad-36 while the lean volunteers showed none. The antibody-positive obese people had significantly lower cholesterol and triglycerides levels than the antibody-negative obese people, a pattern similar to that seen in animals infected with Ad-36. But the two groups did not differ on any of 29 other measures the researchers compared, including age or family history of obesity. In males the presence of antibodies was associated with a significantly better response to treatment with obesity drugs, said Dhurandhar. "There has been an alarming worldwide increase in the prevalence of obesity in the past 30 years," said Atkinson, noting that its prevalence in the United States rose 30 percent between 1980 and 1990, affecting more than 33 percent of the population. "This increase is the type of pattern that might occur with a new infectious disease, as has been seen with the AIDS virus. A great deal of further research is necessary to determine if the global epidemic of obesity may be due in part to infection with Ad-36." The research was funded in part by the UW Beers-Murphy Clinical Nutrition Center. CONTACT: Dian Land, 608-263-9893 
--------
702-> NIAID Evaluates N-9 Film as Microbicide
A large two-year study supported by the National Institute of Allergy and Infectious Diseases (NIAID) showed that vaginal contraceptive film containing a commonly used spermicide had no effect on transmission of HIV/AIDS, gonorrhea or chlamydia infections when provided as part of an overall HIV/STD prevention program. Investigators at Family Health International (FHI), a nonprofit health research organization based in the United States, collaborated with those at the Cameroon Ministry of Public Health to conduct this study with female sex workers in two cities in Cameroon.  Of the 1,292 women who enrolled, 941 completed 12 months of follow-up.  Volunteers were given contraceptive films to be used before sexual intercourse.  The films contained either the spermicide nonoxynol-9 (N-9) or a placebo.  The women were supplied with male latex condoms and counseled monthly about reducing their number of partners and other safe sex practices.  They also were examined and treated monthly for any STDs. Preliminary analysis of the results from this recently completed study showed the overall rate of HIV transmission to be 6.7 percent, half the transmission rate that was previously estimated in this population.  This rate reduction was the same in both the N-9 film users and the placebo group. "We are encouraged by the apparent effectiveness of the overall intervention program that included counseling, STD treatment and encouragement of condom use," says Rodney Hoff, Ph.D., chief of the Efficacy Trials Branch in the AIDS Vaccine Research and Prevention Program.  "Correct and consistent condom use is highly effective, but women must depend on the willingness of their partners to use male condoms.  We and other public health officials are committed to developing an STD/HIV prevention method that can be controlled by a woman.  This study is one part of that ongoing effort." The search for woman-controlled methods has focused on the development of virus- and bacteria-killing products that women can apply intravaginally before having sex.  Known collectively as topical microbicides, these products could give women the means to protect themselves from STDs. "We had hoped that the N-9 film might increase a woman's available options for HIV and STD protection," says Willard Cates, Jr., M.D., M.P.H., FHI's senior vice president for biomedical affairs.  "These results show that we must accelerate our research programs dedicated to finding new products and techniques for women to use." Until safe and effective vaginal microbicides are developed, the Centers for Disease Control and Prevention (CDC) recommends consistent and correct use of male latex condoms, with or without the use of a spermicide, to prevent sexual transmission of HIV and other STDs in high-risk populations.  The CDC does not currently recommend the use of spermicides alone.  The agency will continue to monitor data from this and other studies of vaginal products with N-9 to determine if their use results in prevention benefits or adverse effects. N-9 is a detergent-like chemical that has been widely used for more than 30 years in over-the-counter gels, foams, creams and films designed to kill sperm.  Researchers have shown that N-9 can kill HIV and other STD microbes in laboratory experiments.  Previous studies in small numbers of women suggested that N-9 had some benefit as a topical microbicide, but also prompted some concern that frequent use or use of high doses of N-9 could disrupt the cells that line the genital tract, thereby increasing the chances of HIV infection. The primary investigators for this study were Ronald E. Roddy, M.P.H., of FHI and  Leopold Zekeng, Ph.D., of the Cameroon Ministry of Health.  The sex workers volunteered at clinics in Yaounde and Douala between March 1995 and December 1996.  To be eligible, participants could not be HIV-positive, pregnant, or allergic to latex or to N-9.  Of the eligible volunteers, 941 women were randomized into two groups and completed the study.  One group of 478 women were given condoms and contraceptive film containing 70 mg of N-9, and a second group of 463 women were given condoms and film containing  placebo (an inert substance).  Neither the women nor the study investigators knew which product a woman received. The rates of HIV and other STD transmission were essentially the same for both groups and were measured in woman-years.  For every 100 women using N-9 film and condoms for one year, 6.7 became infected with HIV, 33.3 became infected with gonorrhea and 20.6 with chlamydia.  Infection rates for those provided placebo film and condoms were 6.6 for HIV, 31.1 for gonorrhea and 22.2 for chlamydia per 100 woman-years.  Women using N-9 film and condoms had 42.2 genital sores per 100 woman-years compared with 33.5 sores in the placebo group.  Women in the N-9 film group reported 147,996 acts of sexual intercourse, and those in the placebo film reported 146,942 acts. Additional funding for this study was provided by the U.S. Agency for International Development and the Mellon Foundation.  The N-9 film was provided by Apothecus Pharmaceutical Corp. of Oyster Bay, N.Y. NIAID is part of the National Institutes of Health, an agency of the U.S. Department of Health and Human Services.  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies. ### NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov. 
--------
703-> New Variations On Old Drugs Promote Nerve Regeneration
April 2, 1997 Researchers at Johns Hopkins and Guilford Pharmaceuticals Inc., have successfullymodified a group of established drugs to stimulate nerve growth without suppressing theimmune system. The researchers say the development is a critical step toward using the newcompounds as treatments for a wide range of neurodegenerative diseases like Parkinson'sdisease or multiple sclerosis, or brain injuries from stroke or head trauma. "We showed that these compounds can cause recovery of functions and behaviorspreviously lost to nerve damage in lab animals," says Solomon Snyder, M.D., Hopkinsdirector of neuroscience and principal author on the paper, which appears in this month'sNature Medicine. "We believe this is the first demonstration through an orally administered treatment ofa significant regenerative effect on nerve cells without suppression of the immune system." Immunosuppressive drugs like cyclosporin A and rapamycin were originallydeveloped to prevent a patient's immune system from rejecting an organ transplant.  Whenresearchers looked for the compounds immunosuppressive drugs bind to in the body, theyfound a group of proteins called immunophilins. "These are proteins frequently used by the cell for what we call signal transduction,"explains Snyder.  "They bind to something outside the cell, and as a result of that bindingcause changes inside the cell--make it less likely that an immune cell will proliferate, forexample." Hopkins scientists discovered that brain cells have 10 to 50 times more immunophilinsthan immune cells and that immunophilins in the brain are linked to a variety of importantnerve cell functions, including the ability to regenerate lost branches of the cell and generatenew branches. Immunosuppressive drugs bind to immunophilins; together, the two interact with aprotein called calcineurin to suppress the immune system.  Researchers at Hopkins andGuilford, using new techniques from molecular biology and a field called combinatorialchemistry, attached chemical structures to the drugs that prevented them from binding tocalcineurin but did not affect their ability to attach to immunophilins. Scientists at Hopkins and Guilford put the new drugs to the test alongside the originalimmunosuppressive drugs, first in studies of chicken nerve cells in the lab, and later in ratswhose sciatic nerve had been crushed. There was no significant difference in the new drugs'ability to stimulate growth of new nerve cell branches and cause regeneration of lost branches. "The new drugs were even able to regenerate the protective myelin sheath surroundingthe branch, which is critical to recovery of function," says Snyder. Representatives from Guilford hope to begin clinical trials of some of the new drugs ina year or more.  Guilford is a private biopharmaceutical company based in Baltimore. Under an agreement between Johns Hopkins University and Guilford, Snyder and TedDawson, M.D., Ph.D., another Hopkins author on the Nature Medicine paper, are entitled to ashare of royalties received by the University from Guilford.  The University owns stock inGuilford, with Snyder and Dawson having an interest in the University share under Universitypolicy.  Snyder serves on the Board of Directors and the Scientific Advisory Board ofGuilford, is a consultant to the company, and owns additional equity in Guilford.  Thisarrangement is being managed by the Johns Hopkins University in accordance with its conflictof interest policies. Other authors on the Nature Medicine paper were Joseph Steiner, Maureen Connolly,Greg Hamilton and Heather Valentine, of Guilford; and, Ted Dawson, and Lynda Hester ofHopkins. The studies were funded by Guilford and the National Institutes of Health. --JHMI-- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basis onEurekAlert at http://www.eurekalert.org and from the Office of Communications and Public Affairs'direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or onCompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM",Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com.
--------
704-> Huntington's Disease Mouse Model To Be Distributed By Jackson Laboratory
 For Immediate Release April 2, 1997 BAR HARBOR -- The first strain of mouse genetically engineered to model major symptoms of Huntington's disease -- an inherited, degenerative brain disorder that affects an estimated 30,000 Americans -- is now undergoing processing at The Jackson Laboratory for distribution to researchers worldwide. The transgenic Huntington's Disease mouse was developed by Gillian Bates, Ph.D., of Guy's Hospital in London, England, and her colleagues by introducing into the mouse's DNA the human Huntington's disease mutation, which was identified in a breakthrough discovery in 1993 after a decade-long research effort. Called the R-6 strain, it is the first mouse model known to exhibit symptoms resembling chorea, the jerky, random muscular movements characteristic of Huntington's disease. The mice also experience epileptic seizures typical of juvenile onset of the disease, have decreased brain size, and suffer from a progressive loss in weight and muscle bulk. The mouse syndrome clearly results from introduction of the human mutation, although how closely the syndrome corresponds to human Huntington's disease is not yet established, "This mouse represents the beginning of a revolution in the study of Huntington's disease," said Nancy Wexler, Ph.D., President of the Hereditary Disease Foundation and Higgins Professor of Neuropsychology at the Columbia University College of Physicians and Surgeons. "First we found the gene, then the protein, and now we have the mouse. Researchers can now ask how the expansion of an otherwise innocent bit of DNA (and of the protein that it specifies) leads to alteration and degeneration within the brain." The strain has been received into The Jackson Laboratory's Genetic Resources facility, the national center for mice that serve as models for  human disease. Since 1993, at the request of the international research community, the facility has accepted more than 300 medically important new mouse models. To insure their health and genetic integrity before widespread release for biomedical research, the mice are bred in a strictly controlled, disease-free environment at The Jackson Laboratory. Distribution begins when breeding colonies are sufficient in size. "This very important model is just one example of the power of mouse genetics to provide new ways to approach treatment and ultimately to prevent human disease," said Kenneth Paigen, Ph.D., Director of The Jackson Laboratory. Among the hundreds of strains distributed by the Genetic Resources facility -- many of them developed through the Laboratory's own research -- are models for studying Down Syndrome, diabetes, obesity, leukemia, cystic fibrosis, hypertension, epilepsy, and glaucoma. Huntington's disease is named for Dr. George Huntington, a physician who described "hereditary chorea" in 1872. Formerly known as Huntington's Chorea, the disease typically begins in mid-life, between the ages of 30 and 45, although onset may occur at any age. Males and females are affected equally, and it crosses all racial and ethnic boundaries. In addition to the estimated 30,000 Americans with the disease, another 150,000 are "at risk," with a 50-50 chance they inherited Huntington's from an affected parent. Upon isolation of the gene in 1993, a predictive test was developed by which many people at risk can learn with a high degree of certainty whether they will develop the disease. Those who do not inherit Huntington's disease cannot pass it on to their children, and the chain of inheritance is broken. The genetic cause of Huntington's disease has been found to be an abnormal expansion of a CAG (cytosine, adenine, guanine) nucleotide sequence in the coding region for the "huntingtin" gene on chromosome 4. This excess of trinucleotide repeats is characteristic of a number of other diseases, including Fragile X (the most common form of mental retardation), myotonic dystrophy, Haw River Syndrome, three types of hereditary ataxia, Machado Joseph disease, and Kennedy's disease (spinobulbar muscular dystrophy). The Huntington's model was reported in Cell, Vol. 87, November 1, 1996. Co-authors with Dr. Bates were Laura Mangiarini, Kirupa Sathasivam, Mary Seller, and Martin Lawton, all of Guy's Hospital; Barbara Cozens and Stephen Davies of University College; Alex Harper, The Rayne Institute; Colin Hetherington, John Radcliffe Hospital; Yvon Trottier, Institut de Genetique et Biologie Moleculaire et Cellulaire; and Hans Lehrach, Max Planck Institut fur Molekulare Genetik. Dr. Bates is Senior Lecturer in the Division of Medical and Molecular Genetics, United Medical and Dental Schools, Guy's Hospital. She has twice received the Lieberman Award of the Hereditary Disease Foundation in recognition of her research into Huntington's disease. The Hereditary Disease Foundation, located in Santa Monica, Calif., is a non-profit organization dedicated to the cure of genetic disease, with a focus on Huntington's disease. --end-- 
--------
705-> "The Internet" Is The Theme For Mathematics Awareness Week
ROUTE TO SCIENCE, TECHNOLOGY, FEATURE EDITORS The following news release was mailed recently.        (newspapers are encouraged to add local MAW events) FOR IMMEDIATE RELEASE  (suggested use April, 1997) CONTACT: Mike Harris, 301-942-9595 "THE INTERNET" IS THE THEME FOR MATHEMATICS AWARENESS WEEK April 20 - 26, 1997 (Washington, DC) . . . . . Mathematics and the Internet is the theme for Mathematics Awareness Week 1997 which will be observed nationwide from April 20 - 26.   Developments in mathematical fields like number theory and queuing theory have enabled such key Internet technologies as data encryption for secure financial transactions, data compression for messages with audio and/or video components, and routing and network configuration. Moreover, the Internet has given birth to world-wide collaborations among mathematics teachers and researchers.  These collaborations are advancing both education from kindergarten through university as well as our understanding of some of the most difficult problems in pure and applied mathematics. The Internet has played a major role in significantly increasing the impact and reach of Mathematics Awareness Week in recent years. E-mail, discussion lists, and web sites are now commonly used to gather, exchange, and disseminate ideas and materials. Extensive information about Mathematics Awareness Week - including the theme poster and visuals, an annotated essay with links to many other related sites, and news of MAW celebrations taking place around the country - is on the World Wide Web at URL: http://forum.swarthmore.edu/maw/. The 1997 Mathematics Awareness Week theme poster uses visualizations developed by Bell Laboratories that depict world- wide Internet traffic.  The color and thickness of arcs between countries show inter-country traffic, with higher and redder arcs indicating larger traffic flows. During Mathematics Awareness Week 1997 celebrations take place at colleges, universities, and research laboratories across the country. Mathematics Awareness Week activities include public lectures, mathematical games and competitions, and special days in many states which bring high school students to college campuses where they interact with mathematics faculty. Mathematics Awareness Week is coordinated by the Joint Policy Board for Mathematics on behalf of three national mathematics organizations, the American Mathematical Society, the Mathematical Association of America, and the Society for Industrial and Applied Mathematics. These scientific societies are comprised of some 60,000 members who are educators and researchers in mathematics from academia, industry, and government.  Additional financial support is provided by the Institute for Operations Research and the Management Sciences (INFORMS). ### ================================================== Mike Harris, JPBM Public Information Office | tel: 301-942-9595 JPBM - Joint Policy Board for Mathematics | fax: 301-942-2777 * * *                                   Mathematics Awareness Week - April 20-26, 1997                   Theme:  Mathematics and the Internet           WWW URL-> http://forum.swarthmore.edu/maw/ ==================================================
--------
706-> Involvement in School Gives Even High-Risk Students a Good Chance at Academic Success, Says New Study
Contact:  Pam Willenz Public Affairs Office                  (202) 336-5700 public.affairs@apa.org EMBARGO:  NOT FOR RELEASE UNTIL 6:00 PM (EST), MARCH 31, 1997 Students' Family Background and Self-Esteem Are Less Influential    For Completing High School than Positive School Behaviors WASHINGTON -- Going to school, being on time and doing one's coursework can make academic success more attainable for those students who are considered at risk for not completing high school, say researchers, even if other negative influences exist. This finding is examined in a new study of academic achievement of minority students who are at high risk for dropping out of school which appears in the April issue of the American Psychological Association's (APA) Journal of Applied Psychology. "Successful at-risk students who participated in positive engagement behaviors --for example, coming to class and school on time, being prepared for and participating in class work, expending the effort needed to complete assignments in school and as homework and not being disruptive in class -- counteracted other influences to produce acceptable grades, test scores and on-time graduation," said researcher Jeremy D. Finn, Ph.D., who is the lead author of the study. Both Dr. Finn and psychologist Donald A. Rock, Ph.D., of the Educational Testing Service arrived at this conclusion by first classifying 1,803 African American and Hispanic students (from Grade 8 through Grade 12) from low-income homes into those who had good academic performance and completed high school (resilient students), those who had poor academic performance but completed high school and those who dropped out of high school. Their grades, test scores and persistence determined which group they were placed in.  The authors then compared each group on their levels of self- esteem, their beliefs on whether they had control over events or events happened because of external reasons and their engagement behaviors. "We found that not all minority students who were at risk for school problems because of being from a low income home or living with one parent drop out of school or even suffer poor performance in school," said Dr. Finn. "It seems that being involved in school outweighs other factors that might impede an at-risk student.  The resilient students got good grades throughout high school, scored reasonably well on achievement tests and graduated on time with their classmates independent of their family background and their own levels of esteem or beliefs about who is responsible for their success or failures." Article:  "Academic Success Among Students at Risk for Dropout," by Jeremy D. Finn, Ph.D., and Donald A. Rock, Ph.D., Educational Testing Service, in Journal of Applied Psychology, Vol. 82, No. 2. (Full text available from the APA Public Affairs Office.) The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists.  APA's membership includes more than 151,000 researchers, educators, clinicians, consultants and students.  Through its divisions in 50 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. #       #       #
--------
707-> Antifungal Drug May Be New Treatment For Chronic Kidney Disease
March 27, 1997 A common antifungal drug may buy precious time for people with three chronickidney diseases, delaying their need for dialysis or transplantation, a Johns Hopkins studyshows. The drug, which may promote healing of kidney damage by reducingoverproduction of the body's main steroid hormone, could substantially reduce the risk,cost and inconvenience associated with dialysis and transplantation, says MackenzieWalser, M.D., lead author and a professor of pharmacology, molecular sciences andmedicine. "Our findings are early but promising, and point to a new, long-term approachthat may be safe and effective for treating these three types of chronic kidney disease,"says Walser, adding that further studies are needed. Results of the study, supported by the National Institutes of Health and JanssenPharmaceutica, are published in the April issue of the American Journal of KidneyDiseases. Researchers studied 20 patients who had one of four types of chronic kidneydiseases: glomerular disease, interstitial nephritis, diabetic nephropathy or polycysticdisease. The patients were treated with a well-known antifungal drug called ketoconazolefor one to four years. The treatment slowed disease progression by 66 percent in patients withglomerular disease, 55 percent in those with interstitial nephritis and 77 percent in those with diabetic nephropathy. However, the disease rate accelerated by 99 percent in patientswith polycystic kidney disease. In two patients, the treatment continued to slow progression of glomerular diseasefor four years. Ketoconazole caused some side effects, primarily liver problems, thatoften  occur when it is used to treat fungus infections. Treatment was stopped in threepatients because of side effects, and the patients recovered quickly. Ten years ago, Walser and his Hopkins colleagues found that chronic kidneydiseases progressed fastest in patients whose adrenal glands produced a large amount ofcortisol, the body's principal steroid hormone, and slowest in patients whose adrenalglands produced little cortisol. They speculated that reducing production of cortisol mightslow the progression of kidney failure by promoting the healing of injury to the kidneys.Researchers selected ketoconazole for the study because it has been shown to partiallysuppress cortisol production. Cortisol belongs to a group of hormones that control thebody's use of nutrients and the excretion of salts and water in the urine. The study's co-author was Sylvia Hill, B.S. --JHMI-- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basison EurekAlert at http://www.eurekalert.org and from the Office of Communications and PublicAffairs' direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or onCompuServe in the SciNews-MedNews library of the Journalism Forum under file extension".JHM", Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com.
--------
708-> Neighborhood Merchants Target Teens For Cigarette Sales
March 27, 1997 Many "mom and pop" merchants continue to advertise and sell cigarettes tominors in low-income city neighborhoods despite laws and public health campaigns tostop teen-age smoking, a Johns Hopkins study suggests. The findings underscore the need to enforce laws barring tobacco sales to minors,to persuade merchants to remove store-window advertisements that target youths and tostrengthen public awareness of tobacco's health hazards, say researchers. The study,which was funded by the National Heart, Lung and Blood Institute, is published in theApril issue of the American Journal of Public Health. "A teen-ager's decision to start smoking involves a complex interplay ofenvironmental, social and personal factors," says Carolyn C. Voorhees, Ph.D., lead authorand an assistant professor of medicine. "One promising way to stop teen-age smoking isto keep them from getting cigarettes in the first place. That is why it is so important toreach the merchants as well as the youths." Previous Hopkins studies have shown that most cigarettes are sold to customersof all ages in small, neighborhood stores. In the new study, "undercover" African-American and white boys and girls, ages 14 to 16, tried to buy cigarettes in 83neighborhood stores in low-income, African-American and white sections of Baltimore. The teens succeeded in 86 percent of the stores, nearly 60 percent of which hadseveral cigarette poster advertisements in their front windows. Most of the sales occurredin stores with at least five window ads. "It's discouraging that so many merchants enhance these sales by aggressivelydisplaying seductive advertising that targets minors," says Voorhees. Furthermore, most of the sales occurred in stores where merchants and teenbuyers were of different races, according to the results. Teens of both races boughtcigarettes with equal ease, but the youths were eight times more likely to make a purchasewhen the merchant was of another race. The racial difference was 89 percent in stores inAfrican-American neighborhoods and 72 percent in stores in white neighborhoods. "We are not certain why racial difference between merchant and customer was asignificant factor, but it may reflect a greater likelihood of some merchants not fullyunderstanding the health concerns of youths in cultures other than their own," saysVoorhees. The study was conducted in 1994, the year before Maryland adopted a lawprohibiting tobacco sales to minors, but years after the start of public health and school-based programs to reduce teen smoking. In a 1995 Hopkins survey involving half of allneighborhood merchants in East Baltimore, minors were still able to buy cigarettes from97 percent of the stores. Undercover operations using minors to test compliance with thelaw are now illegal in Maryland. The Food and Drug Administration's ban on tobaccosales to youngsters under 18 went into effect Feb. 28. "We've seen nothing to suggest that tobacco advertisers and merchants have doneanything of late to stop these dangerous and illegal sales," says Voorhees. Smoking among young adults, who usually begin smoking as teens, declinedsharply in the United States in late 1970s, but has remained constant since the mid-1980s,researchers say. Possible explanations include an increase in cigarette ads targetingyouths, teens having easy access to cigarettes, poor law enforcement and inadequateefforts to educate merchants, according to researchers. The federal Centers for DiseaseControl and Prevention estimates that one million teen-agers take up smoking each yearand that a third of them will die of tobacco-related diseases if they do not quit. Hopkins and several community groups have formed partnerships to improve thehealth of East Baltimore residents, including efforts to fight lung and heart disease byreducing smoking in all age groups. Other authors were Diane M. Becker, Sc.D., Robert T. Swank, M.A., the Rev.Herbert W. Watson, Jr., M.Div., Frances A. Stillman, Ed.D. and Donna X. Harris, B.S. --JHMI-- Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basis onEurekAlert at http://www.eurekalert.org and from the Office of Communications and Public Affairs'direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail tobpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu,http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or onCompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM",Quadnet at http://www.quad-net.com or ScienceDaily at http://www.sciencedaily.com.
--------
709-> University Of Florida Physicians Launch Cyberspace-Aided Study To Examine Safety Of Controversial Heart Drug
By Melanie Fridl Ross GAINESVILLE, Fla.---University of Florida cardiologists are at the forefront of a $30 million study that will use the Internet to determine whether a treatment strategy for high blood pressure and angina increases the risk of heart attack, stroke or death.  Physicians will compare the approach, which involves a widely prescribed class of medications called calcium antagonists, with a plan that omits these medications.  The international study is striking both for its sheer magnitude -- 1,500 physicians will enroll 27,000 patients from nine countries  -- and because all facets of the project will be conducted in cyberspace, using a computer and the Internet to log in data and generate prescriptions. The International Verapamil SR-Trandolapril Study, known as INVEST, seeks to show treatment based on calcium antagonists is at least as effective as standard therapy using beta-blockers and diuretics. Beta-blockers reduce the heart's work load, slowing heart rate and reducing the force of contractions; diuretics help lower blood pressure. Physicians have used calcium antagonists to treat high blood pressure and other heart-related ailments for more than two decades. The drugs decrease the work of the heart's blood pumping, reduce the pressure of blood flow through the body and improve blood circulation through heart muscle. While studies have shown verapamil SR and beta-blockers are of similar benefit for patients with the chest pain known as stable angina pectoris and for those who have suffered a heart attack, to date researchers have not put calcium antagonists to the same rigorous scientific test for patients with high blood pressure. This past year, a Food and Drug Administration panel concluded there was no reason to discourage the use of calcium antagonists in general, despite early studies linking a short-acting form of the drug to an increased risk of heart attack or death in some patients. "This has created tremendous controversy," says Dr. Carl Pepine, co-director of cardiovascular medicine at UF's College of Medicine and the study's originator. "This is the sort of claim that can't be defended either way because we have no direct data. The purpose of this study is to address that." The project is funded by Knoll AG -- the originator of the first calcium antagonist, verapamil -- and will take place in the United States, Canada, Germany, South Africa and several other countries. UF researchers will receive a grant of $16 million to develop and oversee the project. Knoll AG is a subsidiary of the German chemical company BASF AG. More than 62 million Americans have high blood pressure, also known as hypertension, according to the American Heart Association. Up to half of all patients with coronary artery disease also may be hypertensive. The study, slated to begin this summer, involves 15 regional directors selected by Pepine, the study's principal investigator. The regional directors will identify 150 cardiologists who in turn will recommend 1,500 primary-care physicians. And those doctors, the study's physician investigators, each will identify 15 to 20 patients -- anyone 45 or older with documented high blood pressure and coronary artery disease -- to participate. "We have the ability to totally conduct this trial by electronic means, rapidly enrolling thousands of patients in four to six months and monitoring them for two years with immediate tracking of all the data ," Pepine says. "We believe this is the way trials will be done in the future." Each physician participating in the study will be provided a computer configured to communicate directly with UF through the World Wide Web. This approach has the advantage of providing study data more quickly for analysis while also reducing the number of errors typically made in capturing clinical research data. A second major feature: The computer-generated patient report becomes the official patient medical record, increasing efficiency for the physician. All patient information will be encrypted and secured to ensure it is inaccessible to the public. To visit the study Web site, which will feature a public page with links to other related sites, point your browser to http://invest.biostat.ufl.edu 
--------
710-> Dial-An-Expert Tip Sheet: Flooding
Over the past three months, the United States has been inundated by a series of wintertime floods unusual in their scope and severity.  Especially hard hit were California and the Pacific Northwest around the year-end holidays and the Ohio Valley in early March.  Total damage is in the billions, and dozens of people have been killed.  More trouble may be on the way.  With an extremely heavy winter snowpack beginning to melt this spring, the Red River Valley of North Dakota and Minnesota is bracing for what is expected to be its worst flooding on record. What seasonal weather patterns have placed so much of the country at risk for flooding?  How does society exacerbate flooding and its dangers?  What is the difference between a flash flood and a river flood?  To help you answer these and other questions, below is some background information on U.S. flood risk from a newly published report by Roger Pielke, Jr., of the National Center for Atmospheric Research (NCAR) in Boulder, Colorado.  Also below is a list of flood and flash-flood experts and some relevant World Wide Web sites.  NCAR is operated by the University Corporation for Atmospheric Research (UCAR) under sponsorship by the National Science Foundation. ---Experts on flooding Roger Pielke, Jr.	303-497-8111		rogerp@ucar.edu NCAR/Environmental and Societal Impacts Group Specialty:  Societal aspects of extreme weather events, including flooding A political scientist, Pielke has completed "Midwest Flood of 1993:  Weather, Climate, and Societal Impacts," an in-depth study of the U.S. flood hazard that uses the Midwest flood to examine how society deals with its vulnerability to flooding (see p. 3, Background).  The report is one of a series being prepared for the Extreme Mesoscale Events and Impacts project. Matthew Kelsch	303-497-6719		kelsch@fsl.noaa.gov National Oceanic and Atmospheric Administration (NOAA)/Forecast Systems Laboratory, Boulder, Colorado Specialty:  Hydrometeorology Kelsch, a meteorologist, is one of the lead instructors for an April course at UCAR that will train National Weather Service (NWS) personnel in state-of-the-art forecast techniques.  He has tested and evaluated software that uses NWS/WSR-88D radar returns to estimate rainfall accumulations. Bob Davis		412-262-1591, ext. 401	robert.davis@noaa.gov NWS/Pittsburgh, Pennsylvania Specialty:  Software to assess runoff from heavy rain and subsequent flash-flood risk Davis, a meteorologist, has created a program called AMBER (Annual Mean Basin Estimated Rainfall) which combines rainfall data from the NWS/WSR-88D radar network with geographic information system (GIS) data bases.  The program is being developed for nationwide use by NWS offices to estimate flood risk in stream basins as small as five square miles. Eve Gruntfest	719-262-3513		ecg@mail.uccs.edu University of Colorado at Colorado Springs/Department of Geography Specialty:  Flash flood mitigation; disaster mitigation; societal impacts of warnings and responses Gruntfest, a geographer, has participated in on-site surveys of a number of major flood disasters, including Colorado's Big Thompson Canyon flood of 1976 and the Midwest floods of 1993. Mary Fran Myers	303-492-2150		myersmf@colorado.edu University of Colorado/Natural Hazards Research and Applications Information Center Specialty:  Policy responses to floods and other natural hazards Myers, codirector of the Natural Hazards Center, is an expert on the National Flood Insurance Program and other federal policies regarding flood control and management. ---World Wide Web sites for information on flooding Monthly summary of national water conditions U.S. Geological Survey http://www.usgs.gov/themes/flood.html Flood story ideas and relevant links NWS Office of Public Affairs http://www.nws.noaa.gov/pa/seasonal/index.html Bibliography of research on water resources U.S. Geological Survey/Colorado District http://webserver.cr.usgs.gov/public/Bibliography.html Flood plain management U.S. Army Corps of Engineers/Flood Plain Management Services Program http://www.usace.army.mil/inet/functions/cw/cwfpms Background on flood hazards, insurance, and mitigation Federal Emergency Management Agency http://www.fema.gov/fema/finifp.html (home page) http://www.insure.com/home/flood/index.html (National Flood Insurance Program) ---Background information on flooding The Web links above, and much of the information below, come from "Midwest Flood of 1993:  Weather, Climate, and Societal Impacts," by Roger Pielke, Jr.  The 160-page report summarizes the history of U.S. flood policy, vulnerability, and response and examines the 1993 flood in that context.  It is available from NCAR's Environmental and Societal Impacts Group (303-497-8117, jan@ucar.edu). What are the elements of a flash flood and a river flood? Flash floods are short-term inundations of small areas such as a town or parts of a city, usually by tributaries and creeks.  Heavy rain in a few hours can produce flash flooding even in places where little rain has fallen for weeks or months.  If heavy rainfall occurs repeatedly over a wide area, then river or mainstem flooding becomes more likely, in which the main rivers of a region swell and inundate large areas, sometimes well after rainfall has ended.  The 1993 Midwest floods were caused by 77 events over several months where rainfall of greater than one inch occurred over areas 100 to 200 miles wide and 400 to 600 miles long.  Both flash flooding and river flooding threaten life and property, although the former causes more deaths and the latter more property damage. Are the death tolls from U.S. floods increasing? On average, U.S. flooding kills more than 100 people a year-- more than any other single weather hazard, including tornadoes and hurricanes.  The average flooding toll has increased in recent decades while deaths from tornadoes and hurricanes have dropped.  Almost half of all flash-flood deaths are connected to stream crossings or highway travel.  Victims often underestimate the power of water when driving into flooded areas.  It takes only 18 inches of water to float a typical automobile. How can a 100-year flood occur more than once in a short period? A 100-year flood is one that has a one-percent chance of being exceeded in a given year.  Few locations have rainfall records of more than a century, so 100-year flood values are estimates rather than certainties.  Changes in watershed management, land use, and the like can affect streamflow characteristics and alter the likelihood of a given flood.    Moreover, climatic patterns themselves can change.  There is nothing to prevent more than one "100-year flood" from occurring at a given spot over a century. Is global warming causing more floods? Because flood risk is the result of both environmental and societal factors, it is difficult to single out the impact of climate variations.  According to the United Nations Intergovernmental Panel on Climate Change, the average global temperature at the surface has increase  What seasonal weather patterns have placed so much of the country at risk for flooding?  How does society exacerbate flooding and its dangers?  What is the difference between a flash flood and a river flood?  To help you answer these and other questions, below is some background information on U.S. flood risk from a newly published report by Roger Pielke, Jr., of the National Center for Atmospheric Research (NCAR) in Boulder, Colorado.  Also below is a list of flood and flash-flood experts and some relevant World Wide Web sites.  NCAR is operated by the University Corporation for Atmospheric Research (UCAR) under sponsorship by the National Science Foundation. ---Experts on flooding Roger Pielke, Jr.	303-497-8111		rogerp@ucar.edu NCAR/Environmental and Societal Impacts Group Specialty:  Societal aspects of extreme weather events, including flooding A political scientist, Pielke has completed "Midwest Flood of 1993:  Weather, Climate, and Societal Impacts," an in-depth study of the U.S. flood hazard that uses the Midwest flood to examine how society deals with its vulnerability to flooding (see p. 3, Background).  The report is one of a series being prepared for the Extreme Mesoscale Events and Impacts project. Matthew Kelsch	303-497-6719		kelsch@fsl.noaa.gov National Oceanic and Atmospheric Administration (NOAA)/Forecast Systems Laboratory, Boulder, Colorado Specialty:  Hydrometeorology Kelsch, a meteorologist, is one of the lead instructors for an April course at UCAR that will train National Weather Service (NWS) personnel in state-of-the-art forecast techniques.  He has tested and evaluated software that uses NWS/WSR-88D radar returns to estimate rainfall accumulations. Bob Davis		412-262-1591, ext. 401	robert.davis@noaa.gov NWS/Pittsburgh, Pennsylvania Specialty:  Software to assess runoff from heavy rain and subsequent flash-flood risk Davis, a meteorologist, has created a program called AMBER (Annual Mean Basin Estimated Rainfall) which combines rainfall data from the NWS/WSR-88D radar network with geographic information system (GIS) data bases.  The program is being developed for nationwide use by NWS offices to estimate flood risk in stream basins as small as five square miles. Eve Gruntfest	719-262-3513		ecg@mail.uccs.edu University of Colorado at Colorado Springs/Department of Geography Specialty:  Flash flood mitigation; disaster mitigation; societal impacts of warnings and responses Gruntfest, a geographer, has participated in on-site surveys of a number of major flood disasters, including Colorado's Big Thompson Canyon flood of 1976 and the Midwest floods of 1993. Mary Fran Myers	303-492-2150		myersmf@colorado.edu University of Colorado/Natural Hazards Research and Applications Information Center Specialty:  Policy responses to floods and other natural hazards Myers, codirector of the Natural Hazards Center, is an expert on the National Flood Insurance Program and other federal policies regarding flood control and management. ---World Wide Web sites for information on flooding Monthly summary of national water conditions U.S. Geological Survey http://www.usgs.gov/themes/flood.html Flood story ideas and relevant links NWS Office of Public Affairs http://www.nws.noaa.gov/pa/seasonal/index.html Bibliography of research on water resources U.S. Geological Survey/Colorado District http://webserver.cr.usgs.gov/public/Bibliography.html Flood plain management U.S. Army Corps of Engineers/Flood Plain Management Services Program http://www.usace.army.mil/inet/functions/cw/cwfpms Background on flood hazards, insurance, and mitigation Federal Emergency Management Agency http://www.fema.gov/fema/finifp.html (home page) http://www.insure.com/home/flood/index.html (National Flood Insurance Program) ---Background information on flooding The Web links above, and much of the information below, come from "Midwest Flood of 1993:  Weather, Climate, and Societal Impacts," by Roger Pielke, Jr.  The 160-page report summarizes the history of U.S. flood policy, vulnerability, and response and examines the 1993 flood in that context.  It is available from NCAR's Environmental and Societal Impacts Group (303-497-8117, jan@ucar.edu). What are the elements of a flash flood and a river flood? Flash floods are short-term inundations of small areas such as a town or parts of a city, usually by tributaries and creeks.  Heavy rain in a few hours can produce flash flooding even in places where little rain has fallen for weeks or months.  If heavy rainfall occurs repeatedly over a wide area, then river or mainstem flooding becomes more likely, in which the main rivers of a region swell and inundate large areas, sometimes well after rainfall has ended.  The 1993 Midwest floods were caused by 77 events over several months where rainfall of greater than one inch occurred over areas 100 to 200 miles wide and 400 to 600 miles long.  Both flash flooding and river flooding threaten life and property, although the former causes more deaths and the latter more property damage. Are the death tolls from U.S. floods increasing? On average, U.S. flooding kills more than 100 people a year-- more than any other single weather hazard, including tornadoes and hurricanes.  The average flooding toll has increased in recent decades while deaths from tornadoes and hurricanes have dropped.  Almost half of all flash-flood deaths are connected to stream crossings or highway travel.  Victims often underestimate the power of water when driving into flooded areas.  It takes only 18 inches of water to float a typical automobile. How can a 100-year flood occur more than once in a short period? A 100-year flood is one that has a one-percent chance of being exceeded in a given year.  Few locations have rainfall records of more than a century, so 100-year flood values are estimates rather than certainties.  Changes in watershed management, land use, and the like can affect streamflow characteristics and alter the likelihood of a given flood.    Moreover, climatic patterns themselves can change.  There is nothing to prevent more than one "100-year flood" from occurring at a given spot over a century. Is global warming causing more floods? Because flood risk is the result of both environmental and societal factors, it is difficult to single out the impact of climate variations.  According to the United Nations Intergovernmental Panel on Climate Change, the average global temperature at the surface has increased about 1.0 degree Fahrenheit this century.  At the same time, according to NOAA, there has been a steady increase in the area of the United States affected by extreme precipitation events (more than two inches of rain in one day, or the equivalent in snow).  However, flood reports have not increased uniformly across the country.  For instance, streamflows in the Colorado River basin have decreased over the past 60 years.  Any alteration of global climate can bring either an increase or decrease in precipitation or flood events at a given location.  Current computer models of climate are unable to project local variations with certainty. Are societal choices increasing flood risk? According to a report by the U.S. Congress's Office of Technology Assessment, "despite recent efforts, vulnerability to flood damages is likely to continue to grow."  The factors cited include --growing populations in and near flood-prone regions --the loss of flood-moderating wetlands --increased runoff from paving over soil --new development in areas insufficiently mapped for flood risk --the deterioration of decades-old dams and levees --policies such as subsidies that encourage development in flood plains. Find this press release on the World Wide Web at http://www.ucar.edu/ucargen/press/flooding.html To receive UCAR and NCAR press releases by e-mail, telephone 303-497-8601 or e-mail butterwo@ucar.edu 
--------
711-> Sandia Automotive Research Team Honored By Vice President Gore
FOR IMMEDIATE RELEASE March 31, 1997 ALBUQUERQUE, N.M. --  Four automotive researchers from Sandia National Laboratories have received special recognition from Vice President Al Gore for their work in connection with a multi-player initiative aimed at developing a new generation of fuel-efficient, low-emission vehicles. The four -- Tim Gardner, Steven Lockwood, Linda McLaughlin, and Steve Lott -- are among a group of scientists from four other U.S. Department of Energy labs and Chrysler, Ford, and GM to receive the Partnership for a New Generation of Vehicles (PNGV) medal. The citation, presented during March 31, 1997, ceremonies in Washington, D.C., recognizes significant scientific progress toward development and eventual commercialization of technologies for advanced catalytic converter systems necessary to meet current and near-future standards for motor vehicle emissions set forth by the Clean Air Act. Priority is placed on reducing nitrogen oxide (NOx) emissions in exhaust from lean-burn engines. Lean-burn engines use more air in the combustion cylinder than is chemically required to burn the fuel. “Lean burn” refers to the amount of fuel injected into the cylinder for combustion. The new technology being developed as a result of this work is more energy efficient and aims to reduce smog-producing NOx emissions in automobile exhibit. The government/industry team has been investigating a  number of lean NOx catalyst formulations, including technologies such as aerogels, zeolytes, and hydrous metal oxides (HMOs), which are Sandia’s specialty. Specifically, Sandia researchers used their expertise in HMOs, a family of chemicals that when incorporated with catalytically active metals makes them ideally suited for catalytic converter applications. Those characteristics include a high cation (a positively charged ion) exchange capability, high surface area, and flexible process chemistry -- HMOs can be synthesized as bulk material or as a coating preparation. “The flexibility of the [hydrous metal oxide] chemistry has allowed us to prepare a large number of different oxide support and metal catalyst combinations and screen them for NOx reduction activity in simulated lean-burn automotive exhaust environments,” says Tim Gardner of Sandia’s Catalysts and Chemical Technologies Department. Promising catalyst systems were then fabricated on a small scale using HMO coating and ion exchange techniques, and similarly tested, Gardner explains. The best catalyst systems were then evaluated on a larger scale in both bulk and coated forms, which involved significant process scale-up efforts. “One of the real strengths of our effort,” says Lockwood of Sandia’s Ceramic and Glass Processing Department, “ was our ability to scale-up the HMO coating and ion exchange processes to a full development size (110 cubic inch) catalytic converter. This scale-up, Lockwood, says, is very important to automakers since it demonstrates the manufacturability of Sandia’s HMO-based catalyst processes and allows actual engine testing of these catalyst materials.   “If Detroit doesn’t get this problem solved,” Lockwood says, “automakers can’t sell the lean-burn engine. That means they’ll have to come up with another solution [besides lean-burn] to meet the CAFE [Combined Automobile Fleet Efficiency] standards. Based on the high economic stakes, you can see how important it is to develop this lean-burn-enabling technology.” In announcing the award the Vice President said, “This collaboration is a shining example of the public good that comes from cooperative ventures among industry, government and communities. We are putting the ‘pedal to the metal’ on the creation of technologies for new vehicles that will reduce air pollution, increase fuel efficiency and decrease American reliance on imported oil. The Par  ALBUQUERQUE, N.M. --  Four automotive researchers from Sandia National Laboratories have received special recognition from Vice President Al Gore for their work in connection with a multi-player initiative aimed at developing a new generation of fuel-efficient, low-emission vehicles. The four -- Tim Gardner, Steven Lockwood, Linda McLaughlin, and Steve Lott -- are among a group of scientists from four other U.S. Department of Energy labs and Chrysler, Ford, and GM to receive the Partnership for a New Generation of Vehicles (PNGV) medal. The citation, presented during March 31, 1997, ceremonies in Washington, D.C., recognizes significant scientific progress toward development and eventual commercialization of technologies for advanced catalytic converter systems necessary to meet current and near-future standards for motor vehicle emissions set forth by the Clean Air Act. Priority is placed on reducing nitrogen oxide (NOx) emissions in exhaust from lean-burn engines. Lean-burn engines use more air in the combustion cylinder than is chemically required to burn the fuel. “Lean burn” refers to the amount of fuel injected into the cylinder for combustion. The new technology being developed as a result of this work is more energy efficient and aims to reduce smog-producing NOx emissions in automobile exhibit. The government/industry team has been investigating a  number of lean NOx catalyst formulations, including technologies such as aerogels, zeolytes, and hydrous metal oxides (HMOs), which are Sandia’s specialty. Specifically, Sandia researchers used their expertise in HMOs, a family of chemicals that when incorporated with catalytically active metals makes them ideally suited for catalytic converter applications. Those characteristics include a high cation (a positively charged ion) exchange capability, high surface area, and flexible process chemistry -- HMOs can be synthesized as bulk material or as a coating preparation. “The flexibility of the [hydrous metal oxide] chemistry has allowed us to prepare a large number of different oxide support and metal catalyst combinations and screen them for NOx reduction activity in simulated lean-burn automotive exhaust environments,” says Tim Gardner of Sandia’s Catalysts and Chemical Technologies Department. Promising catalyst systems were then fabricated on a small scale using HMO coating and ion exchange techniques, and similarly tested, Gardner explains. The best catalyst systems were then evaluated on a larger scale in both bulk and coated forms, which involved significant process scale-up efforts. “One of the real strengths of our effort,” says Lockwood of Sandia’s Ceramic and Glass Processing Department, “ was our ability to scale-up the HMO coating and ion exchange processes to a full development size (110 cubic inch) catalytic converter. This scale-up, Lockwood, says, is very important to automakers since it demonstrates the manufacturability of Sandia’s HMO-based catalyst processes and allows actual engine testing of these catalyst materials.   “If Detroit doesn’t get this problem solved,” Lockwood says, “automakers can’t sell the lean-burn engine. That means they’ll have to come up with another solution [besides lean-burn] to meet the CAFE [Combined Automobile Fleet Efficiency] standards. Based on the high economic stakes, you can see how important it is to develop this lean-burn-enabling technology.” In announcing the award the Vice President said, “This collaboration is a shining example of the public good that comes from cooperative ventures among industry, government and communities. We are putting the ‘pedal to the metal’ on the creation of technologies for new vehicles that will reduce air pollution, increase fuel efficiency and decrease American reliance on imported oil. The Partnership for a New Generation of Vehicles will produce new cars for a new century. This provides even more evidence that what is good for the environment is also good for the economy.” The other DOE labs with researchers who were honored as part of the PNGV team: Argonne National Laboratory, Lawrence Livermore National Laboratory, Oak Ridge National Laboratory, and Los Alamos National Laboratory. PNGV was established at a 50/50 cost-shared program, with a federal investment of $300 million being matched by USCAR, the research cooperative between Chrysler, Ford, and GM. It’s vision is to produce a new generation of vehicles that will deliver triple the fuel efficiency of today’s cars and meet Clean Air Act standards without sacrificing affordability, performance or safety. Sandia National Laboratories is a multiprogram national laboratory operated by a subsidiary of Lockheed Martin Corporation for the U.S. DOE. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has broad-based research and development programs contributing to national security, energy and environment technologies, and economic competitiveness. -- 30 -- Media Contact: Rod Geer, wrgeer@sandia.gov, 505-844-6601 Sandia National Laboratories’ World Wide Web home page is located at http://www.sandia.gov. News releases, fact sheets, and new tips can be found at http://www.sandia.gov/media/whatnew.htm. The Sandia Lab News Online edition is at http://www.sandia.gov/LabNews/LabNews.html.  
--------
712-> University Of Florida's Approach To Breast Cancer Boosts Patient Survival Rates
By Victoria White GAINESVILLE, Fla.---For the past decade, University of Florida radiation oncologists have differed with many breast cancer specialists regarding treatment for women who have undergone mastectomies. But recent large-scale studies in Denmark and Canada show UF's approach may be linked to better long-term survival rates. At issue: How extensive should radiation therapy after mastectomy be to prevent cancer from recurring and spreading? The question is critical, since the spread of cancer cells through the body is largely to blame for the more than 40,000 annual breast cancer deaths in the United States. Physicians at the UF Shands Cancer Center have assumed that all sites in the breast and nearby lymph tissue where cancer cells might lurk must be radiated. They reasoned this approach might reduce the risk of cancer cells spreading to distant areas, such as the brain or liver. The risk of death, therefore, also would be lowered. 	 But many other physicians use radiation only in easy-to-target areas and where cancer commonly reappears. "Research done in the 1960s and 1970s seemed to show that cancer cells spread despite local and regional radiation," said Dr. Nancy Mendenhall, professor and chairwoman of the department of radiation oncology at UF's College of Medicine . "Many physicians thought this meant that cancer spread always occurs early and thus cannot be affected by subsequent radiation. Consequently, many radiation oncologists used radiation only for the limited purpose of controlling the cancer right in the breast region," Mendenhall said.  	UF physicians, however, "thought the radiation in those old clinical trials may not have covered all the sites in the breast and lymphatic region where cancer cells might be present," said Mendenhall. "If all the sites at risk were not irradiated, cancer cells could have continued to thrive and spread throughout the body. "Those old trials were done before we had CT scanning available. Such computerized X-ray imaging documents more disease in the breast region than physical examinations and can help us target the radiation better. For these reasons, we have always attempted to treat all areas at risk." The new data reported by the Danish Breast Cancer Cooperative Group and the British Columbia Cancer Agency in Canada strongly back UF's interpretation and treatment philosophy. The studies, which tracked thousands of patients for more than eight years, showed cancer spread sometimes can be curtailed with thorough local and regional  radiation. Such an approach improves the survival rates of breast cancer patients between 7 and 10 percent. "Unquestionably we have been in the minority with our position on radiation treatment," Mendenhall said. "But I think we're going to see a change in attitude among other physicians based on these studies." Mendenhall plans to publish UF's patient survival data this summer in the 2nd edition of the book, The Breast: Comprehensive Management of Benign and Malignant Diseases. The book's editors are Dr. Kirby Bland, former associate chairman of UF's department of surgery, and Dr. Edward M. Copeland III, chairman of surgery and interim dean of the College of Medicine.
--------
713-> Premature Babies Benefit From Inhaling Nitric Oxide At Shands At The University Of Florida
By Melanie Fridl Ross Shands Public Relations GAINESVILLE, Fla.---A gas commonly found in smog and cigarette smoke actually helps premature babies by opening blood vessels in their underdeveloped lungs, causing blood oxygen levels to rise, University of Florida researchers report.        	Though researchers have not yet put nitric oxide to the kind of rigorous scientific scrutiny that would allow them to declare the gas saves lives, early indications point to a significant improvement in the health of the sickest pre-term infants. UF physicians administered the gas through mechanical ventilators to 23 preterm infants diagnosed with respiratory distress syndrome, they reported in the February issue of Journal of Pediatrics. The babies, undergoing treatment in the Neonatal Intensive Care Unit at Shands at UF, were between 27 and 35 weeks' gestation and weighed an average of 2.5 pounds, as light as a dozen boxes of paper clips. The babies were randomly assigned to receive low concentrations of nitric oxide for 15 minutes and were studied one to seven days after delivery.        	Pre-term infants typically have underdeveloped, partially collapsed lungs that cannot absorb oxygen as well as normal ones. Pre-term infants may therefore die or suffer from long-term complications caused by low levels of oxygen in their blood.        	Nitric oxide improves the uptake of oxygen so it can get to the brain and other vital organs, says pediatric cardiologist Dr. Jeffrey W. Skimming, an assistant professor at UF's College of Medicine and the study's principal investigator. "Nitric oxide opens blood vessels. Because this drug is inhaled, it passes into healthy lung regions and bypasses those that have blocked air passages. Blood is thereby re-routed toward the healthy regions," Skimming said. "We believe that this re-routing of blood causes oxygen levels in the blood to rise." The study was not designed to determine the toxic effects of nitric oxide or whether use of the gas improves survival. But because they noted such significant increases in blood oxygen levels, physicians say additional studies should be performed to better evaluate nitric oxide's therapeutic potential.        	Dr. Willa Drummond, a UF neonatologist and the paper's co-author, said nitric oxide is particularly useful for critically ill babies who are too small to be treated with conventional means of raising blood oxygen levels.        	Drummond witnessed the gas' benefits firsthand when she treated a baby girl born 10 weeks early on Jan. 5. On Feb. 21, the baby was discharged from the hospital with no obvious complications. "To be able to let that baby go home without any chronic lung or brain disease in only seven weeks is really a miracle, considering how sick she was," Drummond said. "We all thought she was not going to survive."        	The Food and Drug Administration recently deemed nitric oxide an experimental drug. Since 1993, UF physicians have used it to treat more than 400 patients -- from premature infants to children and adults with various lung diseases. "Unlike antibiotics or other drugs that directly attack specific diseases, nitric oxide treatment may simply help keep the most critically ill patients alive so that both development and healing can occur naturally," Skimming said. The federal Occupational Safety and Health Administration has set limits for safe exposure to nitric oxide in the workplace at about 25 parts per million. The infants in the UF study received either 5 or 20 parts per million. In contrast, a smoker inhales about 1,000 parts per million with each cigarette, while ambient air concentrations of nitric oxide around a city such as Los Angeles register about one-twentieth of a part per million, Skimming estimated. "Many people studied the toxicity of this drug, long before they recognized it had therapeutic value," Skimming said. "Balancing the toxic aspects with the therapeutic aspects of our interventions is a necessary art in medicine."        	Nitric oxide is not the only substance with such paradoxical qualities.        	"Oxygen can be a poison if it is inhaled in its pure form for a prolonged period of time -- it can kill you," she said. "Both nitric oxide and oxygen have similar types of toxicity and biochemical effects." Nevertheless, it's not surprising the journal Science declared nitric oxide the 1992 Molecule of the Year. "These findings could have profound ramifications. What are the biggest killers worldwide? Heart attacks? Stroke? Cancer? It depends on your perception of life," Skimming said. "If you don't think of pre-term infants as being viable people, then you should accept those answers. If you think differently, then you should believe that prematurity is the biggest killer on a worldwide basis -- some studies report that over 30 percent of all births worldwide result in death from prematurity.
--------
714-> Protein Strengthens Link Between Addiction And Long-Term Memory
March 27, 1997 Johns Hopkins Medical Institutions' news releases are available on a PRE-EMBARGOED basis on EurekAlert at http://www.eurekalert.org and from the Office of Communications and Public Affairs' direct e-mail news release service.  To enroll, call 410-955-4288 or send e-mail to bpalevic@welchlink.welch.jhu.edu or 76520.560@compuserve.com. On a POST-EMBARGOED basis find them at http://hopkins.med.jhu.edu, http://infonet.welch.jhu.edu/news/news_releases, Newswise at http://www.ari.net/newswise or on CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM", Quadnet at http://www.quad-net.com  or ScienceDaily at http://www.sciencedaily.com. ************************************************ PROTEIN STRENGTHENS LINK BETWEEN ADDICTION AND LONG-TERM MEMORY Johns Hopkins scientists have discovered a new protein, called Homer, that becomes active in rat brain cells during exposure to cocaine and during a lab model of long-term memory creation. "Homer is one of the first links between drug addiction and long-term memory that directly acts on nerve cells' message-receiving structures," says Paul Worley, M.D., an associate professor of neuroscience and neurology.  "As such, it could be an important step toward understanding the connections between addiction and memory, and toward developing new treatments for addiction." In a study funded by the National Institute on Drug Abuse and published in Nature, he found Homer by exposing rat brain cells to cocaine and to a lab model of memory used by neuroscientists. "We call the protein Homer because it  homes in' on critical areas where messages are being passed between nerve cells," says Worley. In the memory model, researchers stimulate a nerve cell with an electric current and measure the resulting transmission of information between neurons. If the current is given often and rapidly enough over a period of time, the nerve cell activates a number of genes and makes a number of complex changes that allow it to communicate more quickly and more effectively. Neuroscientists think the brain may use this and other similar processes to enhance or weaken connections between nerve cells, and that this may be a key to the creation of memory. Worley's group found that nerve cells increased their Homer production levels nearly  50 times within minutes of their activation, and that Homer binds to a message receptor on the surface of excitatory nerve cells, the metabotropic glutamate receptor. "We think with further research we may find that Homer allows these receptors to stay open longer or to open up more easily," says Worley.  "We believe it does something to enhance message reception, and will provide fundamental insights into how the brain maintains long-term memories or becomes addicted to drugs like cocaine." As scientists learn more about Homer's effects, and its links to other changes in the nerve cell, new targets for drug treatments may become available. Under an agreement between Lynx Therapeutics, a California Company, and the Johns Hopkins University, Lynx has right of first refusal for licensing Homer.  Worley serves as a consultant to Lynx, owns stock in Lynx, and has received Lynx stock options, which are subject to certain restrictions under University policy.  This arrangement is being managed by the University in accordance with its conflict of interest policies. Other authors on the Nature paper were Paul Brakeman, Anthony Lanahan, Richard O'Brien, Katherine Roche, Carol Barnes and Richard Huganir. --JHMI--  Media contact: Michael Purdy, (410) 955-8725 E-mail:  mpurdy@welchlink.welch.jhu.edu 
--------
715-> Hopkins Researchers Study Drugs to Help "Therapeutic Orphans"
The Johns Hopkins Children's Center has been awarded a contract to begin research into medications for children and adolescents with mental disorders.  The three-year, $493,000 contract, awarded to the Division of Child and Adolescent Psychiatry by the National Institute of Mental Health (NIMH), will establish a Research Unit of Pediatric Psychopharmacology (RUPP), one of only two in the country. According to NIMH, some 8 million children deal with behavioral and emotional problems each year.  While medication is often part of treatment, up to 80 percent of the drugs marketed today are not approved for use in children or adolescents. The Food and Drug Administration requires that all new drugs be tested in every population in which they are to be used; however, many obstacles hamper pharmacologic research in children.  Besides overcoming the ethical and methodological challenges, there are few qualified investigators who exhibit the required expertise in pharmacology, child psychiatry and pediatrics. "Children have been therapeutic orphans for many years," says Mark A. Riddle, M.D., director of the Division of Child and Adolescent Psychiatry at Hopkins and principal investigator. "This is especially true in pediatric psychopharmacology; there are sparse data on the safety and efficacy of psychotropic medications in kids.  The RUPPs will make it possible for this to begin to change." Both RUPPs will perform clinical trials and research projects in many areas, including the effects of psychiatric drugs on children's behavior, development, and cognition, the safest dose ranges, and the most effective and safe dose regimens. The RUPP network also is collaborating with the existing network of Pediatric Pharmacology Research Units.  The facilities of the Johns Hopkins RUPP include the NIH-funded Pediatric Clinical Research Center, with fully staffed inpatient and outpatient areas; laboratories and expertise in designing pharmacokinetic studies, provided by the Division of Clinical Pharmacology; and relationships with many pediatric and child psychiatry practices throughout the Baltimore area. Studies planned or in progress at the Children's Center include research on children and adolescents with obsessive compulsive disorder, major depressive disorder, attention deficit hyperactivity disorder, and anxiety disorders, including social phobia and separation anxiety. "My hope is that some day, pediatric psychopharmacology will be as advanced as pediatric cancer chemotherapy," says Riddle.  "There will be multisite studies that compare new agents to standard treatments, making information available to help treatment decisions.  Our patients deserve nothing less than this." In addition to the NIH funds, the division also received a $200,000 supplemental grant from Solvay Pharmaceuticals. The New York State Psychiatric Institute also received a contract. The Johns Hopkins Children's Center is the children's hospital of The Johns Hopkins Medical Institutions.  Maryland's most comprehensive acute-care hospital for children, the center, with its 177-bed hospital and more than 40 divisions and services, treats some 8,000 inpatients annually, with more than 90,000 outpatient visits.
--------
716-> Pediatric Academic Societies' Annual Meeting Comes To DC
Each May, the largest gathering of pediatricians and pediatric researchers meets in the United States.  The conference is sponsored by members of the American Pediatric Society, the Society for Pediatric Research, and the Ambulatory Pediatric Association.  This year's meeting, May 2-6, will be in Washington, D.C. at the Washington Convention Center. FOR MORE INFORMATION:    Contact Nancy Volkers via e-mail or phone. Include mailing address, phone, fax, and e-mail (if applicable).  Those who register by April 10 will receive a packet in the mail on or about April 20, containing press releases and other information about the meeting.  Those registering after April 10 or at the meeting itself can pick up this information in the press room starting May 2.
--------
717-> University Of Florida Researcher Explores Spirituality's Role In Health
By Victoria White GAINESVILLE, Fla.---Can spirituality improve health? A University of Florida researcher is trying to find out, using a new scientific survey to put religion under the microscope. Dr. Robert L. Hatch, an assistant professor of community health and family medicine in UF's College of Medicine, has designed a 26-question survey that attempts to capture attitudes and activities across a wide spectrum of organized religions and personal belief systems. The survey asks respondents if they believe life has a purpose, if they believe in a power greater than themselves and if they believe there is life after death. Regarding actions, they are asked if they apologize when they wrong someone, if they reflect upon their behavior, and how frequently they pray, meditate and participate in spiritual activities with other people. The survey can be used by researchers who want a scientific instrument for determining how spiritual patients are to determine its effect on health. Hatch plans to conduct such studies himself after he further refines the questionnaire in the coming months. "I am convinced from my life and from what I've seen with my patients that the spiritual realm is very important," Hatch said. "I've seen people who had no spiritual connection who have struggled tremendously with things, then seen people who had such a connection not be so tormented. They've handled pain better. From talking to them, I got the sense that their spiritual beliefs and practices helped them." Hatch discussed his efforts to measure spiritual activities and beliefs at the recent Society of Teachers of Family Medicine's national conference in Kiawah, S.C. Scientific studies of religion and health outcomes have had mixed results, with some demonstrating a benefit and others showing no effect. Hatch suspects some study designs have been flawed, leading to contradictory conclusions. "The problem is that in scientific studies you need to quantify suspected causes and effects, but it is very hard to measure the idea of spirituality," Hatch said. "Researchers have been defining it differently. By and large, they have been exploring organized religious activities in the Judeo-Christian tradition. But I think you can be spiritual and never go to church or you can be a regular churchgoer without being that spiritual. So if you just look at formal religious participation, you're missing something." To many physicians, who are trained to seek scientific answers to medical questions, the idea of a spiritual force changing events may seem implausible. Yet in a wide variety of civilizations throughout history, millions have believed in a higher power and turned to religion for aid and comfort. "If for no other reason, spirituality might make a difference because it gives a person a support network. There is very clear data that people who have social support do much better than others," Hatch said. But it may be more than that. Hatch noted one recent experiment showed a group of severely ill people who were prayed for did better than those who were not. "Some of the best evidence spirituality can make a difference is Alcoholics Anonymous," Hatch said. "People have struggled with how to treat alcoholism for thousands of years, with medicine and psychiatry having little success. Then along came AA. With its spiritual approach, it has had by far the best success." Dr. Kathleen Kantwell says religion has helped her through difficult times. Nine years ago, the Gainesville pediatrician was hit by a car while riding a bicycle, leaving her paralyzed. "I find great peace and comfort in knowing that there is a God and there is a life after death," said Kantwell, 47, who retired last year. "It helps me go through the suffering we have to in this life." She thinks her intensive prayers and the prayers of others may have helped her regain some strength in one of her hands. "The doctors had no explanation for it," she said. "It was kind of miraculous." "We're looking for empirical evidence on spirituality because physicians, rightly so, want that to back up the things that we do," Hatch said. "But if spirituality can be helpful, we need to make patients aware of that. At the same time, however, we don't want to alienate patients and we must be respectful of their own individual beliefs.
--------
718-> University of Florida Researcher Explores Protein's Role In Kidney Stones
By Victoria White GAINESVILLE, Fla.---The ultimate therapy for people with kidney stones may lie not only in careful meal planning and drinking plenty of water, but also in changing what the body's cells make, a University of Florida researcher says. "Everyone forms crystals made of calcium phosphate and calcium oxalate," said Saeed R. Khan, a professor and basic scientist in the department of pathology at UF's College of Medicine. "But only some of us develop stones from these crystals. The difference is, some people make proteins that encourage stone development. We need to find a way to force cells to make the right kind of protein to prevent stones from forming." Americans spend $2.4 billion annually on treating kidney stones, which can cause recurring bouts of excruciating pain and kidney damage as they block and/or pass through urinary channels. Some stones must be removed surgically, or broken up through shock wave lithotripsy. An estimated 10 percent of the U.S. population will have the urinary tract disorder sometime in their lives, and the incidence is rising. In the January issue of the Journal of Urology, Khan disputes some long-held assumptions about how kidney stones form. Over time, Khan's work could lead to changes in medical strategies. Most stones are composed of a mass of calcium phosphate and calcium oxalate crystals which build up inside the kidneys. The prevailing theory has been that the calcium phosphate crystals form first; they in turn promote the creation of calcium oxalate crystals surrounding them. Khan developed an alternative view after looking at high-resolution microscopic images of human and rat stones. He noticed that a coating of protein and other organic material lies between the calcium phosphate and calcium oxalate in the stones. "There is so much protein in there--effectively acting as a barrier between the two types of crystals--that there is no possibility of the phosphate having a direct effect on the crystallization of the oxalate," Khan said. In normal human urine, these proteins keep the crystals away from each other. But in stone-formers, the crystals lose the capacity to stay away from each other. The aggregated crystals become the beginning of a kidney stone. People who have one kidney stone run a high risk of forming more. That's why physicians advise them to take preventive measures to avoid kidney damage. They may be asked to cut down on foods containing oxalate, which can be found in spinach, broccoli and asparagus, for example, and reduce calcium intake. They also are told to drink enough water to produce more than 2 liters of urine every day because the greater the volume, the lower the concentration of stone-forming substances. "The idea has been that you should try to stop the formation of calcium phosphate through dietary controls so that the second step, the creation of calcium oxalate, will not happen," Khan said. "But if it is the protein that is important, the approach will be different. You will start trying to find out why those cells make the proteins that they do. If we know there is a molecular deformity, theoretically we can work to change it." "The dietary strategy emphasizes the interaction of inorganic calcium compounds," Khan said. "Research like ours is emphasizing the importance of biological controls of crystallization and stone formation. As we understand more and more, we will be able to develop new protocols to manage stone disease.
--------
719-> Legacy Of The 96 Olympics: Rooftop Photovoltaic System Offers Insights On Solar Electricity Generation
Georgia Institute of Technology  March 24, 1997 The 1996 Summer Olympics ended seven months ago, but one legacy of the Games is giving researchers unique experience and new information that could help make solar energy a more viable source of electrical power. Built to host swimming and diving events, the Georgia Institute of Technology's Aquatic Center features the country's largest rooftop, solar-powered energy system connected to a utility power grid. The 342-kilowatt photovoltaic system converts sunlight into electricity, serving as both a research model and a supplementary power source. It went online in July 1996, and researchers are pleased with its performance and the lessons they're learning about solar power. "The goal is to get a better understanding of how these systems work -- their performance, their reliability and our modeling capability to predict their performance," said Dr. Ajeet Rohatgi, a professor in Georgia Tech's School of Electrical and Computer Engineering. "Even though some of these things are being done elsewhere, very few people have this kind of depth in terms of modeling and experimentation. By combining these two, we think we can provide some new and useful information that is valuable to utility companies." Funding for the $5.2 million photovoltaic system came from Georgia Tech, Georgia Power Co. and the U.S. Department of Energy. The international attention received during the 1996 Summer Olympic and Paralympic Games gave researchers a unique opportunity to showcase this clean and sustainable energy source. So far, the system has operated close to its expected efficiency, although actual energy production has been lower than predicted. "The system has performed very well," said Mike Ropp, a doctoral student in the School of Electrical and Computer Engineering. "We have quantified that by looking at the system's efficiency instead of just the output." For the seven-month period from July 1996 through January 1997, the system produced 162.2 megawatt hours of electricity. For a full year, researchers had predicted 409 megawatt hours, which is enough to power about 35 average Georgia homes. Several factors have affected energy output, including fuses blown when lightning struck the Aquatic Center roof in July and a water main break that flooded the electrical control room and forced a 10-day shutdown in October.  Also, sunlight levels were lower than expected and extremely high temperatures in August decreased the efficiency of the system, which operates better in cooler temperatures. Ongoing experiments to compare performance-model equations to the real operating data brought further shutdowns, but will help take the guesswork out of solar energy production. "If you talk to laymen, the biggest concern they have is that the sunlight changes all the time," Rohatgi said. "You have cloudy days. Somehow they don't realize we can take that into account in our calculations. So it is not a mystery anymore." In the future, Ropp plans to study "islanding," where the main power source shuts down but the photovoltaic system continues to function. This creates a safety hazard for workers doing maintenance or repairs, especially if they're not aware of the secondary power source. The Georgia Tech system includes a solar array that covers about three-quarters of an acre atop the barrel-vaulted roof of the 95-foot-high Aquatic Center.  It's made up of 2,856 photovoltaic modules, each with 72 multicrystalline silicon solar cells connected in series. A power conditioning system, or "inverter," converts the array's direct current (DC) power to utility-compatible alternating current (AC) power, which then feeds into the Aquatic Center's main power system. The inverter also controls and monitors the overall photovoltaic system. A data acquisition system samples all "vital signs" every 10 seconds, then averages and stores them every 10 minutes. Incoming data includes meteorological parameters such as ambient air temperature, wind velocity and array temperature, and performance parameters such as AC power, DC voltage and DC current. The Aquatic Center also features a separate solar thermal system that heats the pool water by circulating it through a different set of rooftop solar panels. It is not part of the research. Although the photovoltaic system is operating as expected, researchers continue to seek ways to improve solar energy production. At 10 percent to 15 percent efficiency, photovoltaic systems are below traditional ones like coal, natural gas or nuclear power, which have efficiency ratings that fall somewhere between 30 and 60 percent. But  their fuel source -- the sun -- is free and unlimited, and its operation is silent and non- polluting. The U.S. Department of Energy (DOE) supports much of Georgia Tech's work in this area through the University Center of Excellence for Photovoltaic Research and Education (UCEP). Established in 1992, it is one of only two such centers in the country; the second is at the University of Delaware in Newark. "There's money to be made in solar technology for those far- sighted enough to make the investment," said Christine Ervin, assistant secretary of the DOE's Office of Energy Efficiency and Renewable Energy. "The work we're supporting at Georgia Tech is at the cutting edge of this technology. What we learn from projects like the Aquatic Center increases the confidence of those potential investors in photovoltaics products and sets the foundation for our industry's growth and profitability." The Aquatic Center's photovoltaic system was designed by Rohatgi and Dr. Miroslav M. Begovic, also a professor in the School of Electrical and Computer Engineering, along with Richard Long, project support manager in Georgia Tech's Office of Facilities. Rohatgi also is director of the UCEP. Although the system was the largest of its kind in the world when it was built, a bigger one has since been constructed in Bonn, Germany. # # # RESEARCH COMMUNICATIONS OFFICE:  223 Centennial Research Building Georgia Institute of Technology  Atlanta, Georgia 30332-0828 MEDIA RELATIONS CONTACTS: Amanda Crowell (404-894-6980) or John Toon (404-894-6986); Internet: amanda.crowell@gtri.gatech.edu
--------
720-> The Rustless Wonder: A Study Of The Iron Pillar In Delhi
New Delhi-January 31, 1997 Dr Karan Singh, Former Union Minister, released the first volume tiltled "The Rustless Wonder: A Study of the Iron Pillar in Delhi" at the India International Centre in New Delhi. The book is authored by Prof. T.R. Anantharaman, the internationally acclaimed and awarded metallurgist who was formerly Head of the Department of Metallurgical Engineering; Director, Institute of Technology, and Rector, Banaras Hindu University, Varanasi, India. This first monograph of the series is on the famous Iron Pillar located at Mehrauli village on the outskirts of Delhi, which has been an object of perennial interest and curiosity for lay persons as well as as well as scientists. It remained an enigma for centuries mainly on two counts. First relates to the technology by which a metallic object of such a large and mass could be fashioned so many centuries ago, and the second had to do with its phenomenal corrosion resistance despite exposure to sun, rain and wind for so long. This study can undoubtedly be termed as th the most comprehensive thus far on the famous pillar.
--------
721-> Il-2 Injections Safely Boost CD4+ T Cell Levels in HIV-Infected Patients
As reported in the April issue of the Journal of Infectious Diseases, investigators at the National Institutes of Health (NIH) have found that self-administered injections of the immune system protein interleukin-2 (IL-2) can produce prolonged, dramatic increases in levels of CD4+ T cells in some people infected with HIV.  Those with higher initial CD4+ T cell counts had the best responses.  Almost half of the 18 persons in the trial sustained CD4+ T cell increases of at least 200 cells per cubic millimeter (mm3) of blood after one year. By testing gradually higher daily dosages of IL-2 in different groups of patients, the investigators also established that intermittent cycles of subcutaneous IL-2 therapy can be self-administered safely at a maximum tolerated dose of 15 million international units (MIU) per day. The latest findings by Richard T. Davey, M.D., senior investigator in the Laboratory of Immunoregulation at the National Institute of Allergy and Infectious Diseases (NIAID), and his colleagues build on earlier reports by this NIH team that infusing IL-2 intravenously can significantly raise levels of CD4+ T cells in certain HIV-infected patients. "This new study demonstrates that subcutaneous IL-2, used in combination with protease inhibitors and other antiretroviral drugs, has the potential to enhance the therapeutic  effects conferred by antiretroviral treatments alone," comments Dr. Davey.  "The CD4+ T cell increases we've seen with injections of IL-2 are similar to those  previously achieved with intravenous IL-2 infusions.  The subcutaneous regimen represents an improvement, however,  because the side effects are less severe and less prolonged, and the treatment can be administered by the patient at home." Phase III studies are needed to determine if these substantial rises in CD4+ T cell counts, a marker of immunologic improvement, translate into clinical benefits, he adds. The trial, which began in 1993, enrolled 18 HIV-infected people with CD4+ T cell counts greater than 200/mm3 of blood (average 350).  None had previously received IL-2.  During the study, the patients continued taking approved antiretrovirals of their choice, including protease inhibitors. The primary objectives of the study were to determine the highest tolerated dose and potential limiting side effects of IL-2 when self-injected daily for five days every two months.  The investigators sought to identify an IL-2 regimen that conferred the same immunologic benefit, as gauged by increased CD4+ T cells, as seen with continuous intravenous IL-2 infusion but that was easier to administer and better tolerated. To determine how much drug patients could tolerate, the investigators started the first group of patients on low-dose (3 MIU) subcutaneous IL-2, and gradually increased the dosage in subsequent groups of patients until serious toxicities arose.  Using predefined guidelines, the investigators determined 15 MIU/day to be the maximum tolerated dose for this IL-2 regimen. At this and lower dosages, the main side effects reported were mild to moderate flu-like symptoms such as fatigue, aches and pains, and headache.  Typically side effects peak around four hours after IL-2 is injected, Dr. Davey explains, at the same time that blood concentrations of IL-2 crest.  Over the next few hours, as drug levels taper off, the side effects diminish. Patients received a minimum of three cycles (six months) of therapy.  One year after the start of therapy, eight patients had sustained a substantial rise (at least 200) in their CD4+ T cell counts, and six others had experienced a change between zero and 200.  CD4+ T cell counts in the remaining four patients had gradually declined from their baseline levels. "Both the likelihood of a positive CD4 cell count change during therapy and the magnitude of the absolute rise from baseline appeared to correlate directly with patients' baseline CD4 cell counts," the authors write. Overall, viral load as measured by the bDNA assay did not increase significantly in any group during the study period. In extended follow-up, eight patients have remained on subcutaneous IL-2 therapy for more than three years.  Five have sustained CD4+ T cell levels of 800 to 2000 cells/mm3 by self-injecting 12 to 15 MIU/day IL-2 (either once daily or a split dose) every two to four months.  The other three have maintained CD4+ T cell counts of 400 to 600 on lower doses of IL-2, with cycles about every two months. In late 1994, the NIH team began an extension of the present study comparing low-dose to high-dose subcutaneous IL-2 in 48 patients with baseline CD4+ T cell counts greater than 500.  The patients, divided into four study groups, self-inject low-dose (1.5 MIU) or high-dose (7.5 MIU) IL-2 twice daily for five days every four or eight weeks. As Dr. Davey reported at the international AIDS conference in Vancouver last summer, a preliminary examination of the data indicates significant increases in CD4+ T cell counts in all groups.  In the two groups of patients taking high-dose treatments, more than half achieved at least a doubling of their baseline CD4+ T cell counts within the first six months of therapy.   Final analysis of this follow-up study should be completed in the next few months. Based on these positive findings, NIAID, in collaboration with its domestic AIDS clinical trials program, the National Centre for HIV Epidemiology and Clinical Research in Sydney, Australia, and other international partners is working on a plan for a Phase III efficacy trial of subcutaneous IL-2 in patients with early HIV disease.  This study will be an international effort designed to determine the clinical efficacy of this novel form of intervention as a complement to standard antiretroviral therapy. IL-2, originally called T-cell growth factor, is produced in the body by T cells and has potent effects on the proliferation and maturation of several types of immune system cells, including T cells, B cells and natural killer cells.  Commercially, IL-2 is produced by recombinant DNA technology and is approved for treating one type of kidney cancer.  The recombinant IL-2 used in the NIAID study was produced by Chiron Corporation of Emeryville, Calif. Dr. Davey's co-authors include Dr. H. Clifford Lane, M.D., Doreen Chaitt, Stephen Piscitelli, Pharm.D., Mary Wells, Joseph A. Kovacs, M.D., Robert E. Walker, M.D., Judith Falloon, M.D., Michael Polis, M.D., M.P.H., Julia A. Metcalf, and Henry Masur, M.D., all of NIH; and Gwendolyn Fyfe, M.D., of Chiron Corporation. NIAID and the Clinical Center are components of the National Institutes of Health.  NIAID conducts and supports research to prevent, diagnose and treat illnesses such as AIDS and other sexually transmitted diseases, tuberculosis, asthma and allergies. NIH is an agency of the U.S. Department of Health and Human Services. ### References: Davey RT, et al.  Subcutaneous administration of interleukin-2 in human immunodeficiency virus type 1-infected persons.  J Infec Dis 1997;175(4):781-89. Kovacs JA, et al.  Sustained increases in CD4 counts in HIV-infected patients treated with interleukin-2 during a randomized, controlled trial.  N Engl J Med 1996;335:1350-56. Davey RT, et al.  Subcutaneous IL-2 therapy is capable of inducing marked, sustained increases in CD4 counts in early HIV-infected patients.  Xith International Conference on AIDS (Abstract #2305), Vancouver,  July 7-12, 1996. Kovacs JA, et al.  Increases in CD4 lymphocytes with intermittent courses  of interleukin-2 in patients with human immunodeficiency virus infection.  N Engl J Med 1995;332(9):567-75. NIAID press releases, fact sheets and other materials are available on the Internet via the NIAID home page at http://www.niaid.nih.gov.
--------
722-> Estrogen Maintains Pregnancy, Triggers Fetal Maturation
For a long time, reproductive endocrinologists have watched estrogen levels climb during pregnancy, but they did not know what all that estrogen did. Now, nearly two decades after publishing their first paper on estrogen’s role in pregnancy, Dr. Eugene D. Albrecht, a University of Maryland School of Medicine professor of obstetrics/gynecology and reproductive sciences, and his colleague, Dr. Gerald J. Pepe, professor of physiology at Eastern Virginia Medical School, have mapped the intricate interactions of estrogen, progesterone and other hormones during fetal development. Their research explains how estrogen helps maintain pregnancy and stimulates the vital process of fetal maturation . With one hormone triggering the production of another, which in turn regulates the development and release of still others, and with cells changing structure and function as they mature, it’s a complicated story.  But the researchers’ conclusions can be summarized simply:  Estrogen regulates progesterone, protecting pregnancy. It also kick-starts one of the major processes of fetal maturation. Without it, a fetus’s lungs, liver and other organs and tissues cannot mature. Speaking at the Society for Gynecologic Investigation’s annual scientific meeting in San Diego on March 22, Albrecht and Pepe outlined their research into what they call the "fetal-placental dialogue" and how it regulates the differentiation of cells that develop into the placenta and fetal adrenal glands, essential elements in the nourishment, maturation and development of a fetus. "Our research has uncovered several roles for estrogen," Albrecht said. "One is to maintain  pregnancy, which it may do by regulating the production of progesterone. Albrecht, a perinatal endocrinologist, told the obstetric and gynecologic researchers that the placenta and fetus communicate extensively with each other with respect to growth and development. And estrogen is in the driver’s seat. Albrecht and Pepe’s estrogen research focuses on the activation of what they call the placental corticosteroid pathway and its impact on the fetal adrenal glands. These glands, located above the kidneys, produce cortisol, a steroid hormone critical for maturation of the lungs, liver and other organs and tissues of the developing fetus. Another hormone known as ACTH (for adrenal corticotropic hormone) produced by the pituitary - a small gland at the base of the brain - stimulates cortisol production. Through much of pregnancy, cortisol passes through the placenta from mother to fetus, suppressing fetal pituitary ACTH, so that the fetus cannot produce its own cortisol, Pepe explained. Studying live, pregnant baboons - primates whose endocrinology during pregnancy is similar to that of humans - the scientists found that fetuses do start producing their own cortisol two-thirds of the way through pregnancy. "What we didn’t know is what triggers this process,"  Albrecht said. Now they do. The trigger is estrogen. Albrecht and colleagues discovered that by doubling their baboons’ estrogen levels halfway through pregnancy, they activated the cortisol production process in the developing fetus. Then they blocked estrogen with an enzyme antagonist that inhibits production of estradiol, the most potent of the estrogens. In the fetuses where estrogen was blocked, the cortisol pathway never developed. Doubling the amount of estrogen also speeded up the transformation of the stem cells of the placenta into mature cells whose structure and function is quite different, Albrecht said. Blocking estrogen resulted in miscarriage. Clinically, Albrecht and Pepe’s findings could lead to a new outlook on the role that estrogen plays in pregnancy, the relationship of estrogen to maturation and development of the fetus and placenta, and the problem of miscarriage. Albrecht and Pepe’s consortium research is funded by the National Institute of Child Health and Human Development, National Institutes of Health. END
--------
723-> Aviation and Turbulence:  FAA and NCAR Continue Investigations
1997-10                            FOR IMMEDIATE RELEASE: March 20, 1997 Contact:  Anatta UCAR Communications Boulder, CO 80307-3000 Telephone: 303-497-8604 E-mail: anatta@ucar.edu Aviation and Turbulence:  FAA and NCAR Continue Investigations The FAA and NCAR explore a new detection and warning system for Juneau, Alaska, and tackle remote sensing and forecasting problems. Meanwhile the U.S. Navy seeks NCAR's help with choppy winds on high-speed vessels. For NCAR news on turbulence studies at Colorado Springs, see NCAR Release 1997-6 (http://www.ucar.edu/ucargen/press/colosprings.html). A State-of-the-Art Warning System for the Juneau Airport BOULDER--Juneau, Alaska, may become the world's first airport to employ a new turbulence detection and warning system developed by scientists at the National Center for Atmospheric Research (NCAR) in Boulder, Colorado. Originally developed for Hong Kong's new Chek Lap Kok Airport, scheduled to open in fall 1998, the system alerts air traffic controllers and pilots to choppy winds at airports located near mountainous terrain. With an eye to assessing the wind-shear problem at such airports, the Aviation Weather Research Program of the Federal Aviation Administration (FAA) is funding data gathering and analysis at Juneau and Colorado Springs, Colorado, this winter. NCAR has deployed an array of sensors for data gathering that could be the basis for a prototype turbulence warning system. NCAR's primary sponsor is the National Science Foundation. "Turbulence alone doesn't bring planes down," says NCAR expert Larry Cornman, "but it may trigger a chain of events that results in a tragedy." In 1991 severe turbulence ripped an engine off a 747 cargo plane departing from the Anchorage airport. With difficulty the pilot managed to return to the airport safely. That same year United Flight 535 crashed on final approach into the Colorado Springs airport in the throes of a powerful windstorm. The National Transportation Safety Board did not find a probable cause for the Colorado Springs accident, but strong turbulent winds and a rudder problem are generally thought to be the most likely explanations. "I call turbulence the silent problem of the aviation industry. People aren't dying from it, but uncomfortable flights and even broken bones are more common than people realize, especially for flight attendants," says Cornman. On average, a significant turbulence incident occurs every other day on a commercial flight somewhere in the United States. Records show planes suddenly dropping 200 to 300 feet vertically, hurling food carts up to the ceiling. NCAR's turbulence programs may signal new awareness of a long-term problem. Last month representatives from the FAA, National Oceanic and Atmospheric Administration, several major airlines, and airline pilots' and flight attendants' associations met at NCAR to discuss the effects of turbulence on commercial aviation. Officials decided to set up a working group to solve the persistent problem of bumpy flights, flight attendants' injuries, and more serious incidents caused by mountain- induced turbulence. Cornman's "silent problem" may have found a voice. The Juneau airport is especially challenging because takeoffs sometimes require a 180-degree turn inside a channel between an island and the mainland, both with steep terrain. Often the plane is being pummeled by high winds. To prevent any possibility of a crash, the FAA temporarily closed the airport's departure routes last fall and later reopened them with restrictions based on wind speeds measured by a network of anemometers in the area. This winter NCAR scientists added two wind profilers, or vertically pointing Doppler radars, to the anemometer network to gather data to develop a real-time turbulence detection and warning system for Juneau. The ground-based profilers measure wind and turbulence at 60-meter height intervals up to 2 kilometers above the ground, updating every 30 seconds. As in Hong Kong, the Juneau system would feature computer monitors in the control tower displaying real-time turbulence information (summarized from the wind profiler and anemometer data), which would then be relayed over radio to pilots landing or taking off. A more involved data collection program is also being planned for Juneau next year, using a research aircraft, three wind profilers, and a Doppler lidar (laser-based detection system). With accurate warnings, pilots will know when it makes sense to avoid a particular turbulence structure, such as a rotor wind--a horizontal, tornado-like vortex that forms on the downwind side of a mountain. Although rotor vortex winds don't reach tornadic speeds, "pilots definitely don't want to find themselves entering a rotor near the ground," says Cornman. NCAR has a long history of helping to develop airport warning systems for the FAA. NCAR, along with other federally funded research centers, participated in a ten-year project to develop the Terminal Doppler Weather Radar, which alerts air traffic controllers to dangerous wind shear and microbursts. Today the TDWR is operating or scheduled for deployment at about 50 airports around the country. Cornman expects the current development of a system for turbulence detection and warning to take only three to five years, if funded. New Work on Forecasting and Detecting Turbulence Developing a real-time warning system is just one part of NCAR's wide- ranging turbulence research program. Cornman and colleagues are also working on improving turbulence forecasting and remote sensing and on gathering turbulence measurements from commercial aircraft, both projects funded by the FAA. The U.S. Navy has hired the team to characterize turbulent winds over helicopter landing pads on fast-moving Navy ships. Numerical computer models are an essential tool for better diagnosis and forecasting of turbulence, and these in turn could lead to more efficient aircraft routing. The Hong Kong system already includes a forecast modeling component, and one may eventually be incorporated into U.S. detection systems as well. To improve remote sensing of turbulence, the NCAR team is working on new algorithms, or mathematical problem-solving procedures, for using data from the National Weather Service's WSR-88D (formerly known as NEXRAD) radar system. Accurate detection of turbulence by the WSR-88D and other instruments would improve real-time warnings for pilots and help scientists verify turbulence forecasts. Cornman is also heading a project to develop software that will turn the aircraft itself into a turbulence-sensing platform. The software uses existing on-board sensors and computers to measure and analyze turbulence as the aircraft flies through it. United Airlines is installing the prototype on about 200 aircraft during 1997, and several other airlines are interested in testing it. Not only airplanes face the problems of chaotic winds. The U.S. and U.K. navies have enlisted NCAR's help in understanding air flow around destroyers and other large ships as they cruise the seas at high speeds. NCAR scientists will help the Navy characterize these flow fields by analyzing data from on-board, state-of-the-art lidars built by Lockheed- Martin. This understanding will then be incorporated into vessel design, especially to aid helicopters landing on windy decks. This research is sponsored by the National Science Foundation through an interagency agreement in response to requirements and funding by the Federal Aviation Administration's Aviation Weather Research Program. NCAR is managed by the University Corporation for Atmospheric Research under sponsorship by the National Science Foundation. --The End-- Find this press release on the World Wide Web at http://www.ucar.edu/ucargen/press/turbulence.html To receive UCAR and NCAR press releases by e-mail, telephone 303-497-8601 or e-mail butterwo@ucar.edu 
--------
724-> USGS Water Resources Applications Software On The Web
United States Department of the Interior U.S. Geological Survey Office of Water Information Reston, Virginia 20192 USGS Technical Announcement Contact: Steve Regan 703-648-5896, h2osoft@usgs.gov For release: UPON RECEIPT      USGS WATER RESOURCES APPLICATIONS SOFTWARE ON THE WEB A suite of 51 software packages and related materials, used by the U.S. Geological Survey for hydrologic analysis and modeling, is now available for electronic retrieval through an on-line repository on the World Wide Web. Access modes -- The repository is accessible via the WWW from the USGS Water Resources Home Page at: http://water.usgs.gov/ Select the announcement for "USGS Water Resources Applications Software" or go directly to: http://water.usgs.gov/software/ In addition, the repository is available via anonymous File Transfer Protocol (FTP) from the USGS Water Resources Information server: water.usgs.gov or 130.11.50.175 (path: pub/software) Note: a mirror site (http://www.geogr.uni-jena.de/software/) is available at Friedrich-Schiller University, Department of Geoinformatics, Jena, Germany that some users may find more convenient.  FTP access is also available at www.geogr.uni-jena.de (path: pub/software). Each software distribution package consists of compiled or source code, test data sets and documentation files.  All of the USGS water resources hydrologic analysis and modeling software applications available publicly on the WWW are documented by published USGS reports. The software distribution packages have been prepared primarily for the Data General AViiON DG/UX platform and for compilation on other UNIX-based computers.  The USGS continues to prepare software packages for its own use on UNIX-based and other computer platforms such as DOS-based personal computers.  As these packages are available, they will be added to the repository. The software available in the repository is grouped into the following categories: geochemical, ground water, surface water, water quality and general.  Examples of the software now available through the on-line repository include: PHREEQC--A program for aqueous geochemical calculations; MOC3D--Three-dimensional method of characteristics ground-water flow and solute-transport model; MODFLOW--A modular three-dimensional finite-difference ground-water flow model; SUTRA--Saturated and/or unsaturated, constant or variable-density fluid flow, and solute or energy transport (two-dimensional finite element code); ANNIE--Interactive hydrologic (time series) data management; BRANCH--Branch-network one-dimensional dynamic flow model; HSPEXP--Expert system for calibration of the Hydrological Simulation Program--Fortran (HSPF). For general information on USGS water resources applications software, please contact:  USGS, Hydrologic Analysis Software Support Team, 437 National Center, Reston, VA 20192 (e-mail: h2osoft@usgs.gov)
--------
725-> Hopkins Scientists Identify Communications "Matchmaker"
Office Of Communications and Public Affairs March 20, 1997 HOPKINS SCIENTISTS IDENTIFY COMMUNICATIONS "MATCHMAKER" Newly identified protein may help organize location of nerve cell message receptors  Johns Hopkins researchers have identified a protein that helps biochemical "ears" on the surface of brain cells line up close to the areas where nearby brain cells "speak." The newly identified molecule, named glutamate receptor interacting protein or GRIP, appears to help structures known as neurotransmitter receptors cluster together on some brain cells directly across from the message-transmitting ends of other nerve cells. "This protein has the potential to affect the ability of nerve cells to communicate and to play a role in learning and memory," says  Richard Huganir, Ph.D., professor of molecular biology and genetics and Howard Hughes Medical Institute Investigator. "This is still speculative, but GRIP might help gather receptors at a frequently used connection between two nerves, ensuring that messages get through more quickly and more strongly at that connection." Huganir and other neuroscientists believe the brain "creates" memories by adjusting the ability of nerve cells to communicate with each other. In a paper in this week's Nature, Huganir's team describes finding GRIP through study of the AMPA receptor, which is involved in the transmission of rapid or "excitatory" signals between brain cells.  AMPA receptors vary in design, but normally one part of the receptor, called GluR2, is consistent.  The lab looked for proteins that bind to the GluR2 c-terminus, a part that sticks down into the nerve cell. "What we pulled out was GRIP, this very large protein with a unit in it that's repeated seven times," says Huganir.  "The repeated unit is a PDZ domain, a new protein structure that's involved in many protein-protein interactions." The fourth and fifth PDZ domains bind to the end of GluR2's c-terminus, so one GRIP protein may anchor two AMPA receptors. To test GRIP's connection to receptor clustering, Huganir made nerve cells in culture dishes produce extra copies of the c-terminus.   With the extra copies blocking GluR2's ability to bind with GRIP, normal clustering of AMPA receptors decreased dramatically. Researchers are currently developing a mouse that lacks the gene for GRIP to further study the protein's role.  Huganir is also eager to learn what proteins plug into GRIP's five remaining PDZ sockets.  "These could be proteins that help message transmission, or they could be structural proteins inside the nerve cell," speculates Huganir. Other authors on the paper were Hualing Dong, a Ph.D. candidate; Richard O'Brien, M.D.; Eric Fung, an M.D./Ph.D. candidate; Anthony Lanahan, Ph.D.; and Paul Worley, M.D.  --JHMI-- Johns Hopkins Medical Institutions news releases can be accessed on-line through the following services: World Wide Web at http://infonet.welch.jhu.edu/news/news_releases CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension        ".JHM". JHMI toll-free Health NewsFeed BBS at 1-800-JHH-0046. Quadnet: send email to: news@quad-net.com.   In the body of the message type "info                   Quadnet.
--------
726-> Hopkins Researchers Report Lack Of Education And Counseling For Patients Undergoing Gene Testing
Media Contact: Karin Twilde Sheifer or Kate Ruddon, (410) 955-1287 March 19, 1997 Hopkins Researchers Report Lack of Education and Counseling For PatientsUndergoing Gene Testing Media Contact: Karin Twilde Sheifer or Kate Ruddon, (410) 955-1287 Hopkins Researchers Report Lack of Education and Counseling For Patients Undergoing Gene Testing Results of a nationwide survey of physicians and genetic counselors conducted by researchers at the Johns Hopkins Medical Institutions show that most patients who underwent genetic testing for a gene linked with colon cancer did not receive adequate genetic counseling or give their written informed consent for the test.  Additionally, the researchers found that nearly one-third of the physicians surveyed did not recognize the test's limitations and without intervention would have incorrectly interpreted the test results for their patients. These findings are reported in the March 20, 1997 issue of the New England Journal of Medicine. "This study is unique because it is one of the first to evaluate the use of a gene test in the commercial setting," says Francis Giardiello, MD, associate professor of medicine and lead author of the study.  "Before genetic testing for cancer susceptibility became available commercially, the tests were offered in a research environment and delivered according to controlled protocols.  Because many patients are now receiving the test from their personal physicians however, we were interested in how well patients not involved in research programs were being informed of the benefits and limitations of the test," says Giardiello.  "The survey confirmed our concerns that there were inadequacies in the genetic testing process." Patients involved in this survey were tested for a mutation of the APC gene, a tumor suppressor gene found to be linked to colon cancer by Hopkins researchers in 1991.  A positive test for an APC gene mutation indicates that the affected individual has an inherited genetic condition called familial adenomatous polyposis (FAP).  This condition is characterized by the formation of hundreds of polyps in the colon. If prophylactic surgery is not performed, nearly all patients with FAP go on to develop colorectal cancer later in life. To assess the test's use, the Hopkins researchers conducted phone interviews with physicians and/or genetic counselors who had ordered the test through LaboratoryCorporation of America (LabCorp).  The Johns Hopkins University has a service contract with LabCorp to provide guidance to physicians concerning test interpretation, patient education and counseling.  Information gathered as a result of these activities allowed the researchers to assess the test in three areas: 1) validity of test indications  2) provision of formal pre-test genetic counseling and written informed consent of the patient, and 3) understanding by providers of the test results. The Hopkins researchers found that of the 177 patients who received testing, 83 percent (147) had valid indications for testing, which included having symptoms of FAP or being a first-degree relative of FAP-affected patients.  Of the patients tested, only 19 percent (33) received genetic counseling prior to testing and 17 percent (28) gave their written informed consent to have the test performed.  Furthermore, in 32 percent of the cases, the physicians did not know how to interpret the test results. Based on these findings, researchers recommended that a comprehensive approach to patient counseling and education be universally implemented.  "Physicians who plan to order this test for their patients must be prepared to offer or arrange for genetic counseling for their patients," says Jill Brensinger, MS, a genetic counselor with the Hereditary Colorectal Cancer Registry at Johns Hopkins and co-investigator of the study.  "Patients need to know that a positive test result indicates the need for routine colon surveillance, eventual prophylactic surgery and possible discussions on family planning.  Additionally, physicians need to be educated that a test reporting that no mutation was found could be a false negative if no mutation was previously detected in another family member," says Brensinger.  "If patients are not informed of this possibility, they may not adopt the appropriate surveillance practices and their disease will not be detected in its earliest stage." Familial adenomatous polyposis affects one of every 8,000 individuals, accounting for about one percent of all colon cancers.  Approximately 131,000 new cases of colon cancer will be diagnosed in the U.S. this year alone.  An additional 37,000 will die from the disease.  It is the third most common cancer diagnosed in both men and women. In addition to Giardiello and Brensinger, other participants in this research study include Gloria M. Petersen, PhD, Michael C. Luce, PhD, Linda M. Hylind, BS, RN, Judith A. Bacon, BS, Susan V. Booker, BA, and Rodger D. Parker, PhD, Stanley R. Hamilton, MD. ### To assess the test's use, the Hopkins researchers conducted phone interviews with physicians and/or genetic counselors who had ordered the test through LaboratoryCorporation of America (LabCorp).  The Johns Hopkins University has a service contract with LabCorp to provide guidance to physicians concerning test interpretation, patient education and counseling.  Information gathered as a result of these activities allowed the researchers to assess the test in three areas: 1) validity of test indications  2) provision of formal pre-test genetic counseling and written informed consent of the patient, and 3) understanding by providers of the test results. The Hopkins researchers found that of the 177 patients who received testing, 83 percent (147) had valid indications for testing, which included having symptoms of FAP or being a first-degree relative of FAP-affected patients.  Of the patients tested, only 19 percent (33) received genetic counseling prior to testing and 17 percent (28) gave their written informed consent to have the test performed.  Furthermore, in 32 percent of the cases, the physicians did not know how to interpret the test results. Based on these findings, researchers recommended that a comprehensive approach to patient counseling and education be universally implemented.  "Physicians who plan to order this test for their patients must be prepared to offer or arrange for genetic counseling for their patients," says Jill Brensinger, MS, a genetic counselor with the Hereditary Colorectal Cancer Registry at Johns Hopkins and co-investigator of the study.  "Patients need to know that a positive test result indicates the need for routine colon surveillance, eventual prophylactic surgery and possible discussions on family planning.  Additionally, physicians need to be educated that a test reporting that no mutation was found could be a false negative if no mutation was previously detected in another family member," says Brensinger.  "If patients are not informed of this possibility, they may not adopt the appropriate surveillance practices and their disease will not be detected in its earliest stage." Familial adenomatous polyposis affects one of every 8,000 individuals, accounting for about one percent of all colon cancers.  Approximately 131,000 new cases of colon cancer will be diagnosed in the U.S. this year alone.  An additional 37,000 will die from the disease.  It is the third most common cancer diagnosed in both men and women. In addition to Giardiello and Brensinger, other participants in this research study include Gloria M. Petersen, PhD, Michael C. Luce, PhD, Linda M. Hylind, BS, RN, Judith A. Bacon, BS, Susan V. Booker, BA, and Rodger D. Parker, PhD, Stanley R. Hamilton, MD. ###
--------
727-> National Jewish Medical And Research Center Promotes Tuberculosis Awareness Through Continued Treatment And Research On World TB Day, March 24
March 19, 1997 Contact: Jordan Gruener						CONTACT: Jordan Gruener (303) 398-1002 National Jewish Medical and Research Center Promotes Tuberculosis Awareness Through Continued Treatment and Research on World TB Day, March 24 This year 3 million people in the world will die of tuberculosis (TB).  Nearly 100 years ago, the deaths caused by TB were a driving force in the creation of National Jewish Medical and Research Center in Denver.  In the late 1800s, TB was the leading cause of death in the United States and the world.  In the following decades, the disease was controlled with new drug therapies. But TB is on the rise again.  In the next 10 years, more than 300 million people will be infected with tuberculosis, according to the World Health Organization (WHO). WHO sponsors World Tuberculosis Day, Monday, March 24. National Jewish continues to lead the TB eradication effort in the United States and worldwide with innovative treatment and research programs.  WHO now recognizes Directly Observed Treatment (DOTS), developed in Denver with the assistance of National Jewish, as the primary way to control TB.  Patients make "contracts" with physicians to take TB medication on certain days of the week at a clinic, home or office under supervision.  Prior to DOTS, people treated for TB were on their own to stay on the medical regimen.  When they stopped following prescription instructions, this led to outbreaks of TB and drug-resistant forms of the disease. "Just like we don’t want people walking around shooting guns, society has said it doesn’t want untreated TB patients in schools and other settings where they can infect innocent people.  We want to make sure the air is safe for people to breathe," explains Michael Iseman, M.D., chief of  the National Jewish Clinical Mycobacteriology Service.  "TB impacts the public in a significant way.  All you have to do is breathe to get TB." National Jewish’s involvement in TB education, treatment and research includes: · The National Institutes of Health awarded National Jewish $2.78 million for the next four years to continue research into new ways to treat tuberculosis.  One goal of the study is justification of an "ultra-short" treatment (3-4 months) with drugs taken twice a week instead of the current daily treatment that lasts 6 months or longer.  The "ultra-short" approach has become feasible by using new "long-lasting" drugs of the rifamycin group.  These drugs accumulate in tissue and are released steadily over time into the blood and other body fluids. · Thousands of TB cases in the United States are diagnosed every year by National Jewish, which is home to one of the largest TB labs in the country. (National Jewish performs tests for more than 1,500 labs in the United States.)  The Mycobacteriology Laboratory has an arsenal of high-tech testing devices to identify TB, from radio-labeling to a sophisticated test that measures the amount of carbon dioxide produced by growing bacteria. When the Centers for Disease Control and Prevention have a particularly difficult case, it invariably is sent to National Jewish.   · The Canadian Department of Citizenship and Immigration has designated National Jewish as one of two centers to diagnose and interpret chest X-rays for people seeking to live in Canada.  Five thoracic radiologists received special credentials to monitor Canadian X-rays for respiratory diseases, including TB.  National Jewish will receive approximately 200 X-rays a week or 10,000 X-rays each year. · National Jewish conducts the leading TB program in clinical education for physicians.  Over the past 25 years, more than 250 clinicians have attended weeklong courses on the control, management and prevention of TB. http://www.njc.org/pa
--------
728-> National Jewish Takes Asthma Expertise To Canyon Ranch In Tucson, Oct. 26-Nov. 2
March 14, 1997		CONTACT:   Jordan GruenerNational Jewish(303) 398-1002Katie PennerCanyon Ranch(520) 749-9655 ext. 287 National Jewish Takes Asthma Expertise To Canyon Ranch in Tucson, Oct. 26-Nov. 2 The world’s leading asthma research and treatment center and an Arizona health resort known as a worldwide leader in healthy living awareness and education are teaming to offer a week-long Adult Asthma Week from Sunday, Oct. 26-Sunday, Nov. 2. Internationally-known asthma experts from National Jewish will meet with participants to discuss the latest treatments and research in asthma.  In addition, National Jewish and Canyon Ranch physicians and health experts will conduct one-on-one consultations, group discussions and workshops to teach more efficient ways to manage the disease. The week-long cooperative program was developed in 1996 by National Jewish physicians and Mel Zuckerman, Canyon Ranch founder, as a forum to educate people with asthma about how to take control of their condition.  Zuckerman, an asthmatic since childhood, had always believed that exercise would cause an asthma attack.  For 40 years, asthma controlled his life and severely restricted his activities until he learned how to manage it.  Now 68, Zuckerman says that for the past 19 years he’s led an active, healthy life by making appropriate lifestyle changes and taking proper medications.	Established in 1899, National Jewish treats the most severe cases of asthma, tuberculosis, emphysema, and other respiratory and immune system diseases.  Approximately 14 million people in the United States have asthma.  Canyon Ranch is known worldwide as a leader in healthy living awareness and education. Canyon Ranch is located at 8600 E. Rockcliff Road, in Tucson, Ariz.Adult Asthma Week rates start at $2,640 per person.  Financial assistance is available for some participants.  For information on how to qualify, call (800) 726-3335.  Adult Asthma Week includes accommodations for seven nights, three nutritionally balanced, gourmet meals each day, full use of spa and resort facilities, a selection of Canyon Ranch services, a physician evaluation, all related Adult Asthma Week lectures and presentations, and more. For reservation information, call Canyon Ranch, (800) 726-9900.
--------
729-> Oral Insulin Possible: Cholera Shares An Ancient Secret
When Vibrio cholerae spoke, Dr. Alessio Fasano listened. The microbe that causes cholera showed the University of Maryland School of Medicine professor the underlying mechanism for a promising new technology for oral delivery of drugs not normally absorbed through the intestine, such as insulin and immunoglobulins, common therapies that now must be administered by injection. Fasano reports on successful initial tests of oral delivery of insulin and immunoglobulins in the March 15, 1997 issue of  The Journal of Clinical Investigation. Insulin, taken daily by millions of diabetics, and immunoglobulins used to treat immune system deficiencies, have to be injected because they are macromolecules, too big to be absorbed through the digestive system. A tangled network of cellular proteins called tight junctions normally prevents all but the tiniest molecules from passing through the cells of the intestinal walls into the blood stream. While studying Vibrio cholerae in hopes of developing a cholera vaccine, Fasano discovered a key that unlocks the tight-junction gate, permitting macromolecules to pass through. That key is a secondary toxin produced by the same micro-organism that causes cholera. Called Zonula occludens toxin (Zot), it is a protein that modulates the tight junctions in the small intestine, making the cells of the intestinal wall more permeable. Zonula occludens is Latin for tight junctions. In studies in rabbits, Zot caused a 10-fold increase in insulin absorption  and a 2 to 6-fold increase in absorption of immunoglobulins in the small intestine. In diabetic rats, Zot administered with oral insulin lowered serum glucose to levels comparable to those obtained with insulin injections. They lived as long on oral insulin as they did when it was injected. "What we have here is a powerful natural system that theoretically can be harnessed to deliver biologically active macromolecules," Fasano said. "Zot seems to be an analog of a normal physiologic process. It’s not a drug; there’s nothing artificial about it." As so often happens in scientific research, Fasano stumbled across Zot while seeking something else entirely. Working to develop a cholera vaccine, researchers at the University of Maryland Center for Vaccine Development -- where Fasano directs the gastrointestinal pathophysiology lab -- genetically engineered a cholera toxin lacking the bioactive subunit responsible for the severe diarrhea that makes cholera such a killer. They administered the Vibrio cholerae vaccine candidate lacking active cholera toxin to volunteer research subjects. They didn’t develop full-blown cholera, but they still had some diarrhea. Something was making the tissues of their intestinal walls more permeable. Something was loosening the tight junctions. Fasano wanted to know what it was. Cholera was never meant to be a human pathogen, the molecular microbiologist explained. It is a swimmer whose ideal environment is a pond. The human intestine is far too warm for Vibrio cholerae; its oxygen-tension level is too low, and its pH (acid/alkali) balance is all wrong. Trapped inside a human body, Vibrio cholerae is doomed. But people sometimes swallow the water in which the cholera bacteria swim. So, to survive, Vibrio cholerae had to find a way to escape its intestinal prison. The cholera toxin it produces dramatically alters the fluid and electrolytes balance of the intestinal lining, allowing much more water than normal to pass through, water to flush Vibrio cholerae back out where it belongs. That’s the underlying mechanism of the unrelenting diarrhea that plagues cholera sufferers. Zot is a second protein produced by Vibrio cholerae to make the cells lining the intestines more permeable if the initial onslaught of cholera toxin fails to free the trapped bacteria. "Through Zot, cholera taught us that the gate from the intestines to the blood stream can be opened and closed," Fasano said. "Zot is a molecule that is able to communicate directly with  the molecules that make up the cell walls, to get them to do things they normally do only under physiological stimuli." The researcher called it "humbling to realize that we must learn from bacteria, but it is experience, not size, that makes the difference. Vibrio cholerae is a smart pathogen," he said. "It has survived at least 3,000 years, and to survive that long, you have to be very smart. You have to learn to interact with your host, to speak the language of its cells. Vibrio cholerae has a lot to teach us." Zot research has progressed rapidly since Fasano discovered the protein in 1991. He spent three years purifying the molecule and the past year and a half testing it in the laboratory and in animals.  He hopes to collaborate with University of  Maryland School of Medicine endocrinologists on Phase I clinical trials in human diabetics soon. 
--------
730-> Antioxidants May Block Molecular Messengers Used By Cancers
Johns Hopkins Medical Institutions Office Of Communications and Public Affairs On Line: 76520.560@compuserve.com. March 10, 1997 ANTIOXIDANTS MAY BLOCK MOLECULAR MESSENGERS USED BY CANCERS Johns Hopkins scientists may have identified how oxidants can worsen cancerous cell growth and how antioxidants can suppress it. Antioxidants have long been thought to fight cancer; the current findings give insight into how the protection may occur and how it may be harnessed for anti-cancer therapies. Previous studies suggest that oxidants, or oxygen-containing molecules called free-radicals, play an important role in causing cancer and that antioxidants, or free-radical scavengers, help suppress cancer. The current study adds a twist: Cancerous cells themselves may be causing an overproduction of free-radicals. Acting as messenger molecules, the free-radicals send signals through protein pathways that promote further uncontrolled cell growth. Results suggest that antioxidants and substances that interfere with the signaling proteins may block this process. Results of the study, supported by the National Institutes of Health, are published in the March 14 issue of Science.          "Control of signaling pathways involving oxidants may explain why some antioxidants appear to prevent development of certain cancers," says Kaikobad Irani, M.D., lead author and a cardiology fellow at Hopkins. The scientists studied connective tissue cells expressing H-RasV12, a cancer-causing gene, and non-cancerous cells. The cancer cells produced large amounts of a superoxide, a key free-radical molecule that is produced from oxygen. The Hopkins team found that the free-radical overproduction was suppressed when the cells carrying genes called Ras or Rac1 produced proteins that blocked the superoxide from signaling the cells to become cancerous. Treatment of the cells with two types of protein inhibitors also blocked the signals. More importantly, runaway cell division also was slowed by treatment of the cancerous cells with an antioxidant, N-acetyl-L-cysteine. Results suggest that in cancerous cells transformed by the Ras gene, the free-radicals are produced by pathways involving proteins called flavoprotein and Rac1 and send signals that promote uncontrolled cell growth even in conditions when non-cancerous cells would not grow. Protein inhibitors and antioxidants may block those signals that increase runaway cell growth, says senior author Pascal J. Goldschmidt-Clermont, M.D., formerly of Hopkins and currently director of the Heart and Lung Institute at Ohio State University. "Our results should help researchers understand important biochemical pathways in cancer and contribute to the future development of treatment strategies," Goldschmidt says. Other Hopkins authors were Yong Xia, M.D., Jay L. Zweier, M.D., and Steven Sollott, M.D.  Investigators at the NIH, University of North Carolina at Chapel Hill and University of Michigan Medical Center also participated in the study.  --JHMI-- Johns Hopkins Medical Institutions news releases can be accessed on-line through the following services: World Wide Web at http://infonet.welch.jhu.edu/news/news_releases CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension  ".JHM". JHMI toll-free Health NewsFeed BBS at 1-800-JHH-0046. Quadnet: send email to: news@quad-net.com.   In the body of the message type "info Quadnet."    To enroll in our direct e-mail news release service, call 410-955-4288. 
--------
731-> 'Whopper' Of A Comet Spurs A Festival Of Science
(Editor's note: We've put together a news media resource page at http://wiscinfo.wisc.edu/news/news_images/comet.html for reporters who are interested in viewing images of the meteorite as they prepare stories or organizations wishing to download for publication.) Comet Hale-Bopp, speeding toward an April 1 rendezvous with the sun, is becoming everything a cautious community of astronomers had hoped: a brilliant object whose brightness and size will enable scientists to dissect a comet like never before. With an arsenal of new observational tools, and enough forewarning to deploy them, astronomers worldwide are engaged in a festival of observations that together promise to reveal new secrets of comets that, like time capsules, harbor clues to the earliest conditions of our solar system. "It's a whopper," said Kenneth H. Nordsieck, a University of Wisconsin-Madison astronomer helping to ready a rocket payload that, in a brief flight to the top of the Earth's atmosphere later this month, will make the world's first ultraviolet polarimetric images of a comet. Nordsieck's pictures, like the observations of four other UW-Madison scientists, will be made with tools rarely, and in some cases never, arrayed for the appearance of a comet.	Likened to dirty snowballs because they are composed mostly of dust-sprinkled ice, comets spend most of their lives beyond the rim of the solar system in elongated orbits that rarely bring them within reach of Earthbound astronomers. "We'll know better how to build a picture of a comet," said Christopher Anderson, a UW-Madison astronomer making an unprecedented set of simultaneous spectral measurements with the state-of-the-art WIYN Telescope atop Kitt Peak, Ariz. "What we're doing has never been done before, and this comet is a beaut. We're having a sinful amount of fun." As comets go, Hale-Bopp is proving to be especially cooperative. By making itself visible more than a year-and-a-half ago, Hale-Bopp gave astronomers ample time to propose and set up programs of observation and experiments that couldn't be done on the short notice that comets typically provide as they race past Earth and the inner solar system. Moreover, Hale-Bopp is big, bright and exhibiting unusual features that may reveal new insights into the composition and behavior of comets. "The comet has been bizarre from the get-go," said UW-Madison astronomer Walter Harris. "We like bizarre. It tells us new things." At the UW-Madison, no fewer than four separate observational programs (see related story) are gathering data from the comet, making the effort here one of the most concentrated and diverse on the planet. In addition to the rocket experiment to be launched March 25 at the White Sands Missile Range in New Mexico, and the novel spectral measurements, Wisconsin scientists are engaged in an ambitious imaging program utilizing the 3.5 meter WIYN Telescope, and a trio of spectrometers designed to sample the faint glow of neutral and ionized gas as it streams off the comet. Combined, all of these new observations will give astronomers the raw material to construct the most intricate portrait of a comet to date. While astronomers already know a great deal about comets, there are many fine points about their composition and behavior that have yet to be resolved. The answers to those questions might yield new insights into the early solar system since comets are believed to be leftovers after Earth, Mars, Venus and the rest of the planets were formed 4.5 billion years ago. And because comets spend most of their time in the distant and frozen reaches of the outer solar system, far from the effects of the sun, they are thought to contain material that may have changed little since the planets were first formed. The chemistry of comets, which are composed mostly of water, is complicated. Sprinkled throughout is a zoo of materials including dust, ammonia ice and carbon compounds like methane, all of which have telltale signatures, and which seem to mutate into different variants as the comet, making its swing through the inner solar system, is subjected to intense radiation from the sun. Materials containing carbon, for instance, are of interest to scientists from a number of viewpoints: "By looking at cometary carbon, we can try to understand how the gas and dust in interstellar space changes when it condenses into cometary material in the far reaches of the solar system," said Nordsieck. "Some things happen to it, even at very cold temperatures." As material boils off the comet, it can undergo violent change. Electrons are stripped off of molecules transmuting them into ionized gas. The change experienced by water molecules as they stream off of a comet, for example, is of fundamental interest to scientists. Using a trio of novel Fabry-Perot spectrometers, two of which are attached to the McMath-Pierce Solar Telescope on Kitt Peak, Ariz., UW-Madison physicists Frederick Roesler and Frank Scherb, can study the faint glow of ionized gas as it streams away from the comet. Using a third Faby-Perot spectrometer known as WHAM for  Wisconsin H-Alpha Mapper, they can study that glow over a very wide field of view which is important, said Scherb, "because comets take up a big piece of the sky." In essence, "what we're studying is one of the most fundamental processes of a comet: how it processes water," said Scherb. One of these processes manifests itself in an "ionized cloud of gas that stretches for millions of miles in the comet's tail." Using instrumentation that is 50 to 100 times more sensitive, and that has a very wide field of view, said Roesler, will help get at fundamental issues such as how many tons of water are blown off the comet every second. "Our gut feeling is that this comet is going to be a bonanza,
--------
732-> New Study Boosts Idea Of Past Life On Mars
(Editor's note: We've put together a news media resource page at http://www.wisc.edu/news/news_images/mars.html for reporters who are interested in viewing images of the meteorite as they prepare stories or organizations wishing to download for publication.) NEW STUDY BOOSTS IDEA OF PAST LIFE ON MARS MADISON - New isotopic analyses of the meteorite that provided hints of past life on Mars reveals a low-temperature origin, boosting the idea that features of the meteorite may have been formed by living organisms. The study, published today (March 14) in the journal Science by a team led by University of Wisconsin-Madison geochemist John W. Valley, lends powerful new support to the notion that the carbonate globules found within the meteorite, dubbed ALH84001, were formed on the Red Planet under conditions consistent with life. The isotopic procedures employed by Valley and his colleagues were developed specifically for the Mars rock. Results contradict claims that the carbonate globules found in the rock were formed at blistering temperatures too hot to support life, or were formed on Earth, two primary arguments advanced against the meteorite as evidence of past life on Mars. "Everything we see is consistent with biological activity, but I still wouldn't rule out low-temperature inorganic processes as an alternative explanation" said Valley. "We have not proven that this represents life on Mars, but we have disproven the high-temperature  hypothesis." Valley said the high-temperature origin hypothesis relies on a set of thermodynamic assumptions that don't measure up on Earth, and therefore don't apply to an ancient Mars that may have had conditions more conducive to life. "If the same assumptions are applied to the carbonates found in the Earth's oceans, one would erroneously conclude that the water temperatures are over 1,000 degrees Fahrenheit and the surface pressures are several thousand atmospheres," Valley said. "These carbonates in the meteorite are easily explained by low-temperature processes similar to those commonly found on Earth," he said. The meteorite at the center of the scientific controversy was blasted off the surface of Mars about 15 million years ago and fell to Earth about 13,000 years ago. There is also widespread agreement that the rock is very old, probably 4.5 billion years, and that it formed in the Martian crust. The age of the rock sparked interest, because it formed at a time when the Red Planet was warmer, wetter and potentially more hospitable to life. The new study was conducted by a team that includes Valley, John M. Eiler and Edward M. Stolper of the California Institute of Technology, Colin M. Graham of the University of Edinburgh, Everett K. Gibson of NASA's Johnson Space Center, and Christopher S. Romanek of the University of Georgia. The analysis was made with a device designed to analyze minute samples of material gleaned from spots less than one-quarter of the diameter of a human hair. Known as an ion microprobe, it uses a beam of high-energy plasma to burn tiny craters on the surface of a sample, in this case a polished sample no bigger than a grain of rice. The vaporized material is held in a vacuum and drawn into a mass spectrometer for isotopic analysis. The advantage of the ion microprobe, said Valley, is that it allows for minuscule amounts of material to be sampled, one million times less than would typically be necessary. Employing the microprobe, Valley and his colleagues were able to look deep within the carbonates themselves and make the first in situ measurements of the controversial globules. "Making these analyses in situ has never been done before," he said. "For the first time, we can actually see what we analyze." He described the carbonates as "pancakes within pancakes" having a distinct chemistry in each. "We can go in and look for differences or similarities within the carbonates themselves." "Without the ion microprobe, one doesn't really know what's being analyzed. We found that the globules are different. There is a very intricate concentric mineral, chemical and isotopic zonation (within the globules)." Valley's team measured the ratios of two different isotopic species of oxygen and two of carbon. They found that the carbon ratios in the meteorite are high, higher than in Earthbound rocks. "This rules out the idea that these features formed while the meteorite was lodged in the Antarctic ice," said Valley. "Such ratios have never been measured in a terrestrial sample." Oxygen isotope ratios are also high, Valley said, but he noted that the significant discovery is that the oxygen isotopes are not evenly distributed within the sample. "The ion microprobe allows us to determine which parts of the meteorite have more of a particular oxygen isotope." The life on Mars hypothesis has been challenged on the grounds that  the carbonates formed in chemical equilibrium above 1200 degrees Fahrenheit. The new data prove that the meteorite is not in isotopic or chemical equilibrium. "There is no self-consistent evidence to suggest such a high-temperature genesis," said Valley. "All of the chemical, mineralogical and isotopic evidence that we present is consistent with a low-temperature origin." The upshot of the analysis is that the carbonates most likely precipitated at temperatures below 200 degrees Fahrenheit, under conditions hospitable to some forms of microscopic life. ### -  Terry Devitt, (608) 262-8282,
--------
733-> Sandia Earns A+ On School Security Program Achievements
FOR IMMEDIATE RELEASE March 14, 1997 ALBUQUERQUE, N.M. -- 	A pilot  school security program between Sandia National Laboratories and Belen High School (N.M.) is being credited for an impressive decline in the number of incidents that typically distress school administrators and students alike -- violence, theft, and drug and alcohol use. In a recent letter sent to President Clinton, Belen High School Principal Ron Marquez attributed the Sandia partnership with reducing vandalism by more than 75 percent, vehicle theft by more than 80 percent and truancy by 30 percent. In addition, fights, previously a weekly occurrence, are down to one per month and what was once a daily false fire alarm is now a monthly incident. Preparation for the exam Mary Green, of Sandia’s Advanced Systems Integration Department and project leader for the Belen pilot program, said the procedures and technologies that were applied to the school were developed after first looking at the whole picture of Belen High through Sandia’s systems engineering glasses. “Our first priority last spring was to identify vulnerabilities, problems and issues the school was facing,” explains Green. “Then, right from the beginning, we involved students, teachers, parents, and the community in the process to find out their concerns and to make them part of the solution. “This was really a ‘right place at the right time’ situation. Belen High was starting to see increases in truancy, theft, vandalism, and drug use and the whole community was eager to put a stop to this misconduct before it got out of hand. Sandia came along with the expertise and interest in applying some of its extensive work in security technologies. The match was perfect.” Other members of the core Sandia team were Tim Malone, Charles Ringler and Paul Brannan. Approximately 150 students helped develop the school security blueprint. Key points: * All students now are required to carry ID cards on campus. This process helps ensure that only authorized people are on school grounds and at school functions. * Tamper-resistant cameras are positioned to monitor areas known for incidents of fights, drug and alcohol use, smoking, and vandalism. * A hand-held metal detector, loaned to the school by Sandia, is used to search for weapons in rare but threatening situations. * Areas prone to graffiti vandalism received coats of anti-graffiti paint, designed so graffiti wipes off easily. * Better lighting is being installed at  strategic outdoor locations thanks to the Public Service Company of New Mexico. * Microdots, air scribes, indelible and invisible paint are used on equipment and other assets to deter theft by providing a unique identification. * Hair-analysis test kits were provided to the school for parents to use in instances of suspected drug use by their children. * A portable breathalyzer unit was supplied to the school and is used in instances of suspected alcohol use by students or employees. Top of the class The result, according to the message relayed to President Clinton, has been a “successful effort to make our high school safer.” The letter said Sandia’s goal was “to make our high school as safe as possible without making it seem like a prison, and doing it in a cost-effective manner that other schools could learn from.” Several Belen community leaders as well as a teacher and student representative also signed the letter. Green is absolutely thrilled by the results of the pilot program and points to the integrated approach as key to the project’s success. “When students returned to school last fall, things had really changed,” says Green. “They were issued ID cards, saw surveillance cameras positioned throughout the school, noticed that school property was tagged to deter thefts, and knew of the capability to detect drug and alcohol use. In addition, the school had instituted a closed campus, which complemented the things introduced as part of the school security program. The success of the program is due to many facets working together.” Green says she would like to do this sort of partnership with a few more schools and eventually gather the data into an “expert system,” perhaps accessible via the Internet. She envisions other schools being able to tap into this electronic resource to address their school security concerns, looking initially at the whole picture to identify unique situations and needs. A detailed program would step educators through the system, leading them to security options relevant to their particular school. Sandia is a multiprogram Department of Energy laboratory, operated by a subsidiary of Lockheed Martin Corporation. With facilities located in Albuquerque, N.M., and Livermore, Calif., Sandia has major R&D responsibilities in national security, energy, environmental technologies, and economic competitiveness. ### Media contact: Kathryn Kuhlmann, 505/844-4207 kkuhlm@sandia.gov Sandia National Laboratories World Wide Web home page is located at http://www.sandia.gov/media/whatnew.htm. The Sandia Lab News Online Edition is at http://www.sandia.gov/LabNews/LabNews.html. 
--------
734-> Hostage Rescues Honed In Virtual Reality Simulation
FOR IMMEDIATE RELEASE March  14, 1997 ALBUQUERQUE, N.M. -- Modern movie superheroes rescue hostages by evading hailstorms of bullets and harming only evil-doers who resist. In the flesh-and-blood world, people who sign on to be cops -- whether city, state or FBI -- need extensive training to make the split-second judgments that would protect themselves, rescue the innocent, and disarm or disable hostage-takers. To widen access to such training, lessen its cost yet broaden its focus, a virtual reality simulation that allows two-person law enforcement teams to grip guns, don virtual reality glasses, and burst into the harsh environment of hostage-takers and their victims has been created in prototype by researchers at Sandia National Laboratories. The simulation, called VRaptor, was demonstrated at the IEEE’s Virtual Reality Annual International Symposium, held in Albuquerque in early March. A participant’s job is to determine who are the hostages and save them, take prisoner those kidnappers who surrender, and shoot those who fire weapons. “It’s less like a video game and more like a flight simulator,” said Sharon Stansfield, who leads the Sandia project.  “It familiarizes law enforcement teams with scenarios.” Four virtual reality characters -- two men, two women -- are sitting, standing or lying in a room when a law enforcement team breaks in through a wall or door, delivering a concussion grenade. The scenario, constructed with input from the FBI, is a sparsely furnished apartment -- kitchen table, chairs, living room couch, and an empty bookcase. Human participants are monitored by sensors placed on their backs and hands. Signals from this electronic equipment determine the perspectives through which each participant sees events. Humans are represented in the scenario by graphical figures. Just as a flight simulator may not distinguish between types of trees lining a runway but clarifies relevant details like the line of the horizon, VRaptor  does not offer detailed images of people or furniture but provides the most important visual clues  -- a falling or rising body, lifted arms, an outthrust weapon. “The advantage is that multiple human  participants can appear in embodied forms within a common, shared virtual environment,” says Sandia researcher Dan Shawver.  “They can experience situations in which they otherwise would have no opportunity to practice effective responses.” Outcomes are unpredictable because the sequences are not preprogrammed. The roles and behaviors of the characters are decided by a human trainer for each session.  The graphics are computed in realtime. Unlike a video game there’s no higher ‘level’ to which to progress, and there’s no way to get familiar with the game enough to memorize its outcomes, says Stansfield. “We feel our model represents an improvement over current law enforcement training methods in ‘shoot houses,’ ” says Stansfield.  “Shoot houses allow agents to use real guns to fire on mannequins, but the mannequins don’t do anything, they’re just there.”  Some cardboard mannequins do pop up, but that’s all they do. VRaptor is an acronym for virtual reality assault planning, training, or rehearsal. The program as it becomes more complicated may eventually be used for evaluating assault plans, training for a variety of rescue circumstances, or rehearsing a particular scenario.  	The work is in its second year of funding by Sandia’s Laboratory-Directed Research and Development program, which finances speculative defense-related research. Sandia is a multiprogram DOE laboratory, operated by a subsidiary of Lockheed Martin Corp. With main facilities in Albuquerque, N.M., and Livermore, Calif., Sandia has major research and development responsibilities  in national security, energy, and environmental technologies and economic competitiveness. # Visuals:  available. Media contact: Neal Singer, 505-845-7078, nsinger@sandia.gov Technical contact: Sharon Stansfield, 505-844-1396, sastans@sandia.gov Sandia National Laboratories' World Wide Web home page is located at http://www.sandia.gov. News releases, fact sheets, and news tips can be found at http://www.sandia.gov/media/whatnew.htm. The Sandia Lab News Online Edition is at http://www.sandia.gov/LabNews/LabNews.html. 
--------
735-> Calcium Storage, Release Mechanism Revealed
Electrically charged calcium ions are key players in the drama of cell life and death. Their movement in and out of cells can determine whether the walls of arteries squeeze shut, restricting blood flow to the brain, whether hearts beat or stop beating. Now, for the first time, physiologists at the University of Maryland School of Medicine have booked a ringside seat at the show. Using a new technology that enabled them to visualize the organization of calcium stored deep within intact muscle and brain cells, researchers in the medical school’s Center for Vascular Biology and Hypertension discovered that calcium is stored in tiny, discrete compartments.  The doors to different compartments can be opened or closed by various drugs or natural chemicals produced by the body, releasing different amounts of calcium to control a broad range of physiological processes. "These findings apply to virtually every cell in the body," said Dr. Mordecai P. Blaustein, professor and chairman of physiology at the University of Maryland School of Medicine.  "This could lead to a better understanding of the physiological mechanisms underlying high blood pressure, heart failure, stroke, even aging." He and Dr. Vera A. Golovina, research associate in physiology, report their findings in the March 14 issue of Science. Most things cells do - contraction, secretion, reproduction, synthesis of proteins - rely on the release of the right amount of calcium at the right time and place. Calcium is stored in cells in a structure called the reticulum, a series of interconnected tubules and tiny sacs distributed throughout the cells. Too much calcium can cause cell injury or even death. The amount of calcium in the reticulum that can get out of storage to do its work depends on the concentration of another potent chemical - sodium - between a cell’s outer membrane and the nearby intracellular calcium stores.  Small changes in sodium concentration can produce large changes in calcium stores.  Increasing sodium increases the amount of calcium that can be released from the stores. In a related paper published in the March 4 issue of Proceedings of the National Academy of Sciences, Blaustein and Dr. Magdalena Juhaszova, research assistant professor in physiology at the University of Maryland School of Medicine, reported finding that although all cells have at least two of three varieties of sodium pump, these varieties are found in different places in the cells. The sodium pump is the body’s natural transport mechanism for moving sodium in or out of cells. One variety of sodium pump is extremely sensitive to endogenous ouabain, a ouabain-like human hormone that impairs a cell’s ability to get rid of excess sodium.  Ouabain is a plant product related to digitalis, long used as a heart medication. Another form of sodium pump doesn’t respond  to the minute amounts of this hormone found normally in the body. Using sophisticated laboratory techniques to study smooth-muscle cells such as those in the walls of arteries, nerve cells and other brain cells known as astrocytes, the researchers pinpointed the locations of these various sodium pumps on each type of cell’s outer or plasma membrane. They found that the pumps that were most sensitive to ouabain are located next to the reticulum, suggesting that these pumps probably play a special  role in regulating calcium levels. "We used to think that all sodium pumps controlled the global sodium concentration in the cell," said Blaustein. "Now we know that some sodium pumps only control the sodium concentration in the space between the plasma membrane and the reticulum, and because of that, actually help to control calcium." In 1991, Blaustein and colleagues reported their discovery that a ouabain-like compound is found naturally in minute concentrations in blood and that it affects a cell’s ability to get rid of excess sodium.  Their discovery was regarded as an important new piece of the high blood-pressure puzzle. "Now we’re starting to understand the crosstalk between the sodium pumps on the plasma membrane and the calcium stores in the reticulum," said Blaustein. "This will give us new insight into the whole story of cell signaling." Blaustein and colleagues’ research is supported by the National Institutes of Health. 
--------
736-> Physicians' Divorce Risk May Be Linked To Specialty Choice
Johns Hopkins Medical Institutions Office Of Communications and Public Affa  March 13, 1997 A Johns Hopkins study finds that physicians in some specialties -- chiefly psychiatry and surgery -- are at higher risk for divorce than their medical brethren in other fields. But the results do not support the common view that job-related anxiety and depression are linked to marital breakup. Alerting medical students to the risks of divorce in some specialties may influence their career choices and strengthen their marriages whatever field they choose, says Michael J. Klag, M.D., senior author and an associate professor of medicine. "Marital counseling during residency training appears to be a good idea for family and career satisfaction in the long term," Klag says. The study, supported by the National Institutes of Health, is published in the March 13 issue of The New England Journal of Medicine. Results also strongly suggest that the high divorce risk in some specialties may result from the inherent demands of the job as well as the emotional experiences of physicians who enter those fields. .	The Hopkins team assessed the specialty choices, marriage histories, psychological characteristics, and other career and personal factors of 1,118 physicians who graduated from The Johns Hopkins University School of Medicine from 1948 through 1964. Over 30 years of follow-up, the divorce rate was 51 percent for psychiatrists, 33 percent for  surgeons, 24 percent for internists, 22 percent for pediatricians and pathologists, and 31 percent for other specialties. The overall divorce rate was 29 percent after three decades of follow-up and 32 percent after nearly four decades of follow-up. Physicians who married before medical school graduation had a higher divorce rate than those who waited until after graduation (33 percent versus 23 percent). The year of first marriage was linked with divorce rates: 11 percent for marriages before 1953, 17 percent for those from 1953 to 1957, 24 percent for those from 1958 to 1962 and 21 percent for those after 1962.  Those who had a parent die before medical school graduation had a lower divorce rate. Female physicians had a higher divorce rate (37 percent) than their male colleagues (28 percent). Physicians who were members of an academic honor society in medical school had a lower divorce rate, although there was no difference in divorce rates according to class rank. Religious affiliation, being an only child, having a parent who was a physician and having a divorced parent were not associated with divorce rates. Physicians who reported themselves to be less emotionally close to their parents and  who expressed more anger under stress also had a significantly higher divorce rate, but anxiety and depression levels were not associated with divorce rate. "Healthy marriages have deep affection, compatibility, expressiveness and conflict resolution, so the higher risk of divorce in those less emotionally close to their parents could be telling," says Klag. "Feeling distant from your parents may indicate a decreased ability to form an intimate relationship with your spouse. Also, marriage after medical school may allow the relationship to develop in a less stressful environment." Researchers cautioned that the study, which looked at marital histories through 1987, did not address quality of marriage and that physicians may be more likely to stay in poor marriages for financial and social reasons. Also, most physicians in the study were white males first married in the 1940s and 1950s when divorce was less socially acceptable, so the risks may vary for contemporary physicians, who include more women and minorities, say researchers. Future studies should examine the quality of marriage, physicians' and spouses' views of their relationship, society's changing expectations of marriage, more women and minority physicians, and the effect of medical school debt and other stresses on divorce risks, the researchers say. Co-authors of the study, which was part of the Johns Hopkins Precursors Study, an ongoing, prospective study of physicians from the Hopkins medical school graduating classes of 1948 through 1964, were lead author Bruce L. Rollman, M.D., Lucy A. Mead, Sc.M., and Nae-Yuh Wang, M.S. --JHMI-- Johns Hopkins Medical Institutions news releases can be accessed on-line through the following services: World Wide Web at http://infonet.welch.jhu.edu/news/news_releases CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM". JHMI toll-free Health NewsFeed BBS at 1-800-JHH-0046. Quadnet: send email to: news@quad-net.com.   In the body of the message type "info Quadnet." To enroll in our direct e-mail news release service, call 410-955-4288.
--------
737-> Drug Slows Blindness In AIDS Patients
Office of Communications and Public Affairs On Line: 76520.560@compuserve.com Media Contact: Marc Kusinitz 410/955-8665 E-Mail: mkusinit@welchlink.welch.jhu.edu March 12, 1997 DRUG SLOWS BLINDNESS IN AIDS PATIENTS AIDS patients facing blindness from a virus infection may respond to the drug cidofovir, according to results of a multicenter study led by a Johns Hopkins researcher. The drug stops progression of cytomegalovirus (CMV) retinitis, an infection of the light sensitive part of the eye and the major cause of vision loss and blindness in AIDS patients.  Unlike traditional treatments that require drug delivery daily through a catheter placed in a central vein, cidofovir is injected into the arm. Central veins are large vessels, for example the jugular vein in the neck, that return blood to the heart.  The researchers found that both a low and a high dose of the drug slowed progression of the disease. "The biggest advantage is that patients receive it only once a week to start and then once every other week," says Douglas Jabs, M.D., professor of ophthalmology and medicine at The Johns Hopkins University School of Medicine. "Other drugs require that a catheter be placed in a vein and left for the duration of treatment." A previous study by other Hopkins researchers has found that CMV retinitis accounts for 75 percent of AIDS-related CMV disease.            The Studies of Ocular Complications of AIDS (SOCA) Research Group, which Jabs chairs, plans to begin another study to compare cidofovir with other drugs now used to treat CMV retinitis. The study was funded by Gilead Sciences, which manufactures the drug.                                                          --JHMI-- Johns Hopkins Medical Institutions news releases can be accessed on-line through the following services: World Wide Web at http://infonet.welch.jhu.edu/news/news_releases CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM". JHMI toll-free Health NewsFeed BBS at 1-800-JHH-0046. Quadnet: send email to: news@quad-net.com.   In the body of the message type "info Quadnet." To enroll in our direct e-mail news release service, call 410-955-4288.
--------
738-> Hyperactivity Linked To Thyroid Hormones
For information, interviews contact: Jennifer Donovanphone:	(410) 706-7946; pager: (410) 407-6873email:   JenniferD@oia-2.ab.umd.edu HYPERACTIVITY LINKED TO THYROID HORMONESThyroid hormone may play a role in the hyperactive and impulsive symptoms of children with attention deficit-hyperactivity disorder (ADHD), University of Maryland School of Medicine researchers say. Dr. Peter Hauser, professor of psychiatry, and Dr. Bruce Weintraub, professor of medicine at the University of Maryland School of Medicine, have found a positive correlation between elevated levels of certain thyroid hormones and hyperactivity/impulsivity in a selected group of patients. They report on their research in the February issue of the international journal Psychoneuroendocrinology. ADHD is one of the most common psychiatric problems of childhood, affecting an estimated three to five out of every 100 children. But up to now, no studies have demonstrated a physiologic basis for the differences between those suffering merely from inattention and those displaying symptoms of hyperactivity and impulsive behavior, a trait psychiatrists call impulsivity. Having previously discovered a strong and specific association between resistance to thyroid hormone and ADHD, Hauser, Weintraub and colleagues studied 75 people diagnosed with resistance to thyroid hormone and 77 of their unaffected family members. They measured levels of three thyroid hormones - TSH, T3 and T4 -  and evaluated symptoms of both inattention and hyperactivity, two constellations of symptoms that together make up ADHD. Resistance to thyroid hormone  is a thyroid disease characterized by elevated levels of serum T3  and T4, as well as inappropriately normal or high concentrations of serum TSH, evidence of a reduced response to the actions of thyroid hormones. ADHD symptoms were identified in interviews by psychologists and psychiatrists who did not know which subjects had resistance to thyroid hormone. TSH concentrations did not correlate significantly with any of the symptoms of ADHD. High concentrations of T3 and T4, while not significant in symptoms of inattention, were significantly and positively correlated with symptoms of hyperactivity/impulsivity in thyroid hormone-resistant subjects, Hauser said. In family members who were not resistant to thyroid hormone, neither TSH nor T4 concentrations were significantly correlated with ADHD. Elevated levels of T3, however, were signicantly correlated with hyperactivity/impulsivity symptoms but not with symptoms of inattention, he reported. "The correlation between thyroid hormone concentrations and symptoms of hyperactivity does not prove causality," warned Hauser, chief of psychiatry at the Baltimore Veterans Affairs Medical Center, a University of Maryland School of Medicine teaching hospital. "What it does show is that thyroid hormones may provide a physiologic basis for the dichotomy between symptoms of inattention and symptoms of hyperactivity." Hauser said the study supports the American Pyschiatric Association’s decision to combine the symptoms of hyperactivity and impulsivity in their 1994 revision of the Diagnostic Manual of Mental Disorders, the bible of psychiatric diagnosis in the United States. "Our findings suggest that further research on the role of thyroid hormone in subjects with ADHD may be of benefit," he said. Research data were collected while Hauser and Weintraub were on the staff of the Molecular and Cellular Endocrinology Branch of the National Institutes of Health National Institute of Diabetes and Digestive and Kidney Diseases, which funded the research.END
--------
739-> New Study Is First To Look Beyond General Attitudes About End-Of-Life Options And Ask Older People What They Would Do
Date:  March 10, 1997                                             Contact:  Catherine A. Bryan                                                Public Affairs Office                                             (202) 336-5700                                                    public.affairs@apa.org (email) NEW STUDY IS FIRST TO LOOK BEYOND GENERAL ATTITUDES ABOUT END-OF-LIFE OPTIONS AND ASK OLDER PEOPLE WHAT THEY WOULD DO Many Want Family Member, Close Friend or Physician to Make the Decision WASHINGTON -- It used to be that when you had a life- threatening illness you waited it out. Nowadays you have options. A new study in the just-released March issue of Psychology and Aging, published by the American Psychological Association (APA), looks at the factors that influence older adults end-of-life decisions. Psychologist Victor Cicirelli, Ph.D., from Purdue University asked 388 older adults (ages 60 to 100) to respond to 17 different situations about end-of-life options. Each scenario depicted either a terminal or nonterminal condition accompanied by a low quality of life. Approximately one-third of the participants wanted someone else -- a family member, close friend or physician -- to make their end-of-life decision. Why? Dr. Cicirelli believes that older adults have been socialized to see physicians as authority figures and may not feel that they can make their own decisions about their end-of-life options. Thus, they defer the decision to their physician. Another explanation is an older person's tendency to think that a family member will make decisions for them if needed. "An additional factor," says Dr. Cicirelli, "is the personality of these older individuals, particularly their belief that powerful others control their destiny." "Earlier studies on end-of-life decisions looked at general attitudes about the options. My study asked older adults what they would do in situations where they had reduced ability to move, were dependent on someone else, were in pain and so forth. The results imply that older adults want the options, but a majority would rather live than end their life," says Dr. Cicirelli. Other results of the study revealed that a minority (approximately one-tenth of the study participants) did want to end their life under low quality conditions, but there was no preference about which method they would use (suicide, assisted suicide or voluntary active euthanasia). Dr. Cicirelli's research also found that the factors that influence older people's views regarding the various decision options at the end-of-life are not the same as those that influence suicide. Well-being, poor health, dependency, stress due to critical life events and lack of social support, all precursors of suicide, were unrelated to decisions to end life in these scenarios. Article:  "Relationship of Psychosocial and Background Variables to Older Adults' End-of-Life Decisions" by Victor G. Cicirelli, Ph.D., Purdue University, in Psychology of Aging, Vol. 12, No. 1, pp. 72-83. (Full text available from the APA Public Affairs Office.) The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists.  APA's membership includes more than 142,000 researchers, educators, clinicians, consultants and students.  Through its divisions in 49 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. #       #       #
--------
740-> Augmented Reality Goggles May Offer Mere Mortals X-Ray Vision
Contact: Steve Bradt, Assistant Science Writer E-mail: sbradt@admin.rochester.edu, Phone: (716) 273-4726 Institution: University of Rochester Augmented Reality Goggles May Offer Mere Mortals "X-Ray Vision" "X-ray vision," once the province of comic book superheroes, is coming to a mere mortal near you: A budding technology called augmented reality uses computers and cameras to mesh views from different perspectives, giving the wearer of augmented reality goggles something like superhuman vision. Now, a group of computer scientists at the University of Rochester -- one of only a handful of groups working on augmented reality -- has proposed a new way for cameras and computers to cooperate to produce an image that very convincingly merges computer-generated images and real-world videos. This ability to seamlessly combine a visible object, like a wall, with a whole database of images you can't see, such as an infrared view or a blueprint of the wall's interior, has many applications in such fields as medicine, entertainment, maintenance, and defense. For example, instead of having to glance back and forth between a patient and an MRI view of his brain tumor, surgeons at Brigham and Women's Hospital in Boston can see on a monitor the MRI view superimposed over a video image of the patient. The next step may be augmented reality goggles -- eyewear that superimposes the MRI view directly over the naked eye's view of the patient so that surgeons can even more precisely eradicate only the tumor. "It sounds futuristic, but this technology's a lot closer than you think," says James Vallino, a Rochester graduate student who has been working on augmented reality with Assistant Professor Kiriakos Kutulakos. "It's been evolving slowly but steadily, led by military, design, and medical projects, some of which already use augmented reality." A version of augmented reality already makes it possible for weather forecasters to appear on the air in front of computerized maps. There are many other high-tech applications being investigated by the Rochester researchers and others at institutions such as MIT, Carnegie Mellon University, and UNC-Chapel Hill: A soldier on the ground looking through augmented reality goggles could see infrared images of the landscape gleaned from a reconnaissance aircraft far above. A group of enemy troops just beyond the top of a ridge can't be seen by the soldier but can be detected by the aircraft -- which can then alert the soldier by superimposing its find onto the soldier's more limited view. Doctors, who must often glance back and forth from patient to medical imaging devices while performing surgery, are benefiting from being able to see everything they need to know at once. For example, augmented reality goggles superimpose an ultrasound image of a developing fetus on an external view of its mother's body, giving doctors an unprecedented view of babies as they develop in the womb. Physicians may even don augmented reality goggles to mix and match medical images from endoscopy, ultrasound, MRI scans, CT scans, and x-rays -- giving them the best views for carrying out treatment. Repairs to buildings or complex machinery can be made much simpler by augmented reality: If a wall's innards are stored as a computerized blueprint, that blueprint can be superimposed on a repairman's view of the wall to pinpoint where hidden ducts, beams, and wiring lie. Augmented reality could help homeowners envision home improvements before they're even started. A remodeling consultant discussing a new deck or addition with a homeowner would aim a video camera at the house and have the augmented reality system show what the home would look like when the work is completed. The biggest problem faced by the few labs now studying augmented reality is how to flawlessly coordinate the video and computer graphic images in an augmented reality sequence. "Most people want to align the video image and the computer-generated image by building a super-accurate computer model of the three- dimensional setting in which augmentation takes place," says Vallino. "If you're working in a small room or an uncomplicated space, this is easy to do. But what if you're designing goggles for a soldier on a battlefield? Things are always changing, and it's impossible to model that setting." "In previous approaches the environment had to be tightly controlled for augmented reality to work," Kutulakos adds. "We're now trying to move outside of the lab into less structured environments." The Rochester group takes a unique approach to this problem of camera-computer coordination. Its approach uses what's called an affine set of axes to place computer graphics into videos using visible natural landmarks as reference points. "You could get the computer to precisely place a three-dimensional computer- generated character on top of a train," Vallino says. "When the train moves, the resulting motion of landmarks around the train is detected to keep the character correctly positioned in the image despite the motion. Augmented reality through such tracking is much easier to manage than the laborious frame-by-frame manipulation now used in Hollywood to make scenes like computerized Martians wandering through the White House." Vallino and Kutulakos are joined in the augmented reality research by Chris Brown, a professor of computer science. The research is funded by the U.S. Department of Defense's Defense Advanced Research Projects Agency (DARPA) and the National Science Foundation.
--------
741-> Formal Training Improves Ultrasound Skills of Obstetricians
Office of Communications and Public Affairs On Line: 76520.560@compuserve.com. Media contact: John Cramer (410) 955-1534 E-mail: jcramer@welchlink.welch.jhu.edu March 5, 1997 FORMAL TRAINING IMPROVES OBSTETRICIANS' ULTRASOUND SKILLS Young physicians who undergo a rigorous formal trainingprogram in ultrasound testing on pregnant women are betterskilled at this procedure than young physicians without suchtraining, a Johns Hopkins study suggests. Results show that Hopkins second- and third-year obstetricsresidents who underwent a formal training program in obstetricalultrasound had a mean score of 67 percent on a practical examcompared with 53 percent by obstetrics residents at a similarinstitution that does not have such a program. Currently, there are no formal guidelines for trainingresidents in obstetrical ultrasound, although 70 percent of womenundergo ultrasound evaluation during pregnancy. Many sonogramsare performed on an informal basis in their obstetrician's officeor by an obstetrician in a labor and delivery unit. "Our findings show that a formal method for assessingresidents' progress and documenting their competence inobstetrical ultrasound is both feasible and effective," saysJessica L. Bienstock, M.D., lead author and an instructor ingynecology/obstetrics. Results will be presented Feb. 28 at the annual meeting of theAssociation of Professors in Obstetrics and Gynecology andCouncil on Resident Education in Obstetrics and Gynecology in NewOrleans. "Our goal was to develop a tool that could be used byresidents to evaluate their progress in ultrasound throughouttheir four years of training and ensure that they acquire theskills required to perform complete obstetricalultrasounds," says Bienstock. The formal program includes a check-list that identifiessonographic skills considered appropriate for each year ofresidency, such as basic concepts, completing screens on theirown, diagnosing problems, reviewing hundreds of cases, andcompleting paperwork. The residents must demonstrate each skillto a senior ultrasound technician or a perinatologist (aphysician specializing in fetal medicine) certified inobstetrical ultrasound. Fetal ultrasound scanning, or sonography, involves passinghigh frequency sound waves into the mother's body; the reflectedechoes are detected and analyzed to build a two-dimensionalpicture of the fetus in the uterus. The study's senior author was Eva K. Pressman, M.D. --JHMI-- Johns Hopkins Medical Institutions news releases can beaccessed on-line through the following services: World Wide Web athttp://infonet.welch.jhu.edu/news/news_releases CompuServe in the SciNews-MedNews library of the JournalismForum under file extension ".JHM". JHMI toll-free Health NewsFeed BBS at 1-800-JHH-0046. Quadnet: send email to: news@quad-net.com. In the body of themessage type "info Quadnet." To enroll in our direct e-mail news release service, call410-955-4288.
--------
742-> Genetic Diversity Study To Begin In Acadia Park
FOR IMMEDIATE RELEASE February 20, 1997 GENETIC DIVERSITY STUDY OF WILDLIFE TO BEGIN IN ACADIA PARK BAR HARBOR -- Acadia National Park has been awarded funding for a pioneering genetic diversity study of resident beaver and spruce grouse populations to be conducted by researchers from The Jackson Laboratory in Bar Harbor and the federal Cooperative Park Studies Unit at the University of Maine in Orono. Utilizing the genetics research expertise of The Jackson Laboratory, the scientists will develop a cost-efficient method for evaluating genetic diversity in the Park's wildlife populations, which are located primarily on Mount Desert Island. Some of the populations, which are restricted to small and isolated patches of suitable habitat, may be more susceptible to loss of genetic diversity through inbreeding and other factors. This can result in lowered fertility, high infant mortality, and less adaptability to environmental change. "Habitat fragmentation is a leading cause of environmental degradation and a threat to biodiversity," said Paul Haertel, Superintendent of Acadia National Park. "This funding will enable us to better understand how habitat fragmentation may be affecting genetic diversity and the long-term viability of these two species. Results of this study will also serve to guide our future conservation strategies." The 16-month, $55,000 Acadia study will be led by Dr. Beverly Paigen -- a Senior Staff Scientist at The Jackson Laboratory who will direct the genetic biodiversity evaluation of the animals -- and by research wildlife biologist Dr. Allan O'Connell, leader of the University of Maine-based Cooperative Park Studies Unit, Biological Resources Division, United States Geological Survey. "Beaver and spruce grouse were chosen for the study because they are not endangered but are declining on Mount Desert Island," said Dr. Paigen. "We need genetic, as well as demographic, information to accurately assess that decline." Recent demographic studies confirm that the resident beaver population has declined by 60 percent in the last 15 years. Anecdotal data suggest the native beaver population was killed off in the 1800s, and the current animals are descended from two or three pairs later introduced from the Mid-Atlantic states. The spruce grouse population comprises less than 100 individuals, and productivity is low, with breeding restricted to 18 discrete patches of black spruce and tamarack (American larch) forest. The project's field phase, expected to begin by April 1, will be directed by Dr. O'Connell. He will be assisted by two science students from Brewer High School in Brewer, Maine, in live trapping the animals and collecting samples for genetic analysis. Forty animals from each species will be studied: 20 from the Park and 20 control animals from the mainland. All animals will be safely released into their native habitats. In Fall 1997, Dr. Paigen -- assisted by researcher Karen Svenson and a science intern from Mount Desert Island High School -- will begin the laboratory phase of the project. Dr. Paigen, a prominent genetics researcher, specializes in using mouse models engineered at The Jackson Laboratory to identify genetic causes of human health concerns such as atherosclerosis, gallstones, and obesity. The cost-saving core of the research plan is to utilize an existing archive of more than 2,000 "genetic markers" in mice that have already been identified as part of the campaign to map the human genome. Each of these marker genes permits quick identification of characteristic DNA sequences known as "simple sequence-length polymorphic repeats" which are present in most mammals. Dr. Paigen has confirmed in ongoing research involving the black rhinoceros that 5 to 10 percent of the mouse markers are valid for assessing genetic diversity in that endangered species. Similar success using existing mouse markers is anticipated in the study of beavers and spruce grouse in Acadia. Once genetic diversity has been calculated in the resident animals and mainland controls, the two sets can be compared to see if inbreeding threatens genetic health among the Island populations. "Our goal is to protect the biodiversity of the Park," said Dr. O'Connell. "With the results of this study, we will be able to develop appropriate conservation strategies if we find that these species are seriously inbred." The Acadia study is one of 13 projects nationwide chosen competitively for the 1997 "Expedition Into The Parks" conservation program, funded by a $1 million contribution from Canon U.S.A., Inc., through the National Park Foundation (NPF). The program -- part of Canon's "Clean Earth Campaign" -- brings National Park Service staff, researchers, and volunteers together to collect data for resource protection through wildlife monitoring, habitat mapping, flora/fauna sampling, photographic surveys, and conservation and restoration work. The $50,000 Canon/NPF grant will be augmented by $5,000 from Friends of Acadia, a Bar Harbor-based non-profit dedicated to protecting and preserving the Park and surrounding communities. About $15,000 of the Acadia funding is earmarked for environmental education. "The National Park Foundation is proud to support this innovative project that promises lasting scientific and educational value," said NPF President Jim Maddy. "We are especially pleased that the genetic methods used at Acadia may be applicable in other parks and that the project is forging important links with local communities. 
--------
743-> The Suspect Confessed. Case Closed? Not Necessarily, Researcher Says
Contact:  Doug Fizel Public Affairs Office                                     (202) 336-5700 public. affairs@apa.org (email) EMBARGO:  NOT FOR RELEASE UNTIL 6:00 PM (EST), FEBRUARY 28, 1997 THE SUSPECT CONFESSED. CASE CLOSED? NOT NECESSARILY, RESEARCHER SAYS Even Modern Non-Violent Interrogation Techniques Can Produce                                           False Confessions WASHINGTON -- The days of bright lights and rubber hoses as tools to obtain confessions from criminal suspects may be gone, but the more modern methods used by police to get suspects to confess may be no less powerful.  And, according to psychologist Saul M. Kassin, Ph.D., of Williams College, "available research suggests that the criminal justice system currently does not afford adequate protection to people branded as suspects and there are serious dangers associated with the use of confession evidence." In an article in the March issue of the American Psychological Association's (APA) journal American Psychologist, Dr. Kassin notes that the use of physical force to obtain confessions has given way to more psychologically oriented techniques, such as "feigned sympathy and friendship, appeals to God and religion, the use of informants, the presentation of false evidence and other forms of trickery and deception." The most commonly used interrogation techniques, Dr. Kassin says, fall into two general categories: maximization and minimization.   The aim of maximization is to intimidate a suspect into confessing by "overstating the seriousness of the offense and the magnitude of the charges and even making false or exaggerated claims about the evidence."  Minimization aims to lull the suspect into a false sense of security by "offering sympathy, tolerance, face-saving excuses, and moral justification; by blaming the victim or an accomplice; and by underplaying the seriousness or magnitude of the charges." While trial judges reject confessions that were elicited by explicit threats of harsh punishment or promises of leniency in sentencing, they often do not exclude confessions for which positive and negative consequences are merely implied, Dr. Kassin says.  And the result, he says, is an unknown number of instances where people confess to crimes they didn't commit. Dr. Kassin cites several historical cases of people giving false confessions to escape aversive interrogation, to gain a promised reward or because they came to believe they had committed the crime.  The most recent and well-documented case of false confession was Paul Ingram, a former deputy sheriff in Olympia, Washington who "after 23 interrogations, which extended for five months, was detained, hypnotized, provided with graphic crime details, told by a police psychologist that sex offenders typically repress their offenses, and urged by the minister of his church to confess," eventually "recalled" raping his daughter, sexual abuse and satanic crimes that included the slaughter of newborn babies. There was no physical evidence to suggest that the crimes had even occurred, Dr. Kassin notes, but Paul Ingram was sentenced to 20 years in jail, where he remains. While Paul Ingram may have suffered from an unusually high degree of suggestibility, Dr. Kassin describes laboratory experiments involving college students that demonstrate the relative ease with which innocent persons can be induced not only to admit guilt, but to adopt the false belief that they are guilty and even confabulate details to fit that newly created belief (at least in a low-stakes, non-criminal situation). In the experiment, participants were instructed to type letters into a computer as they were read off by a confederate at either a slow or fast pace.  The participants were warned not to touch the ALT key on the keyboard or else the computer would malfunction and data would be lost.  In each case, the computer suddenly "crashed" and the experimenter accused the participant of hitting the ALT key.  In all cases, the participant at first denied hitting the key (and none actually had hit the key), but half the time the confederate claimed to have witnessed the participant hitting the key and half the time the confederate claimed not to have seen what happened.  The experimenter then hand-wrote a standardized confession and prodded the partipants to sign it. Overall, 69 percent signed it and 28 percent believed they were actually guilty.  Compliance was highest among those who had been typing the letters at the faster pace and whose "witness" claimed that they had hit the ALT key: 100 percent of them signed the confession, 65 percent believed they were guilty and 35 percent confabulated details to fit their belief. This is important, Dr. Kassin says, because confession evidence -- even confession evidence that has been withdrawn or recanted -- can have enormous influence on juries.  Even when a judge rules that a disputed confession was coerced and not voluntary and instructs the jury to discount it, evidence from mock juror experiments suggests that jurors will often be persuaded by it anyway.  "In short," Dr. Kassin notes, "confession evidence is so inherently prejudicial that people do not fully discount the information even when it is logically and legally appropriate to do so."        Article:  "The Psychology of Confession Evidence" by Saul M. Kassin, Ph.D., Williams College, in American Psychologist, Vol. 52, No. 3. (Full text available from the APA Public Affairs Office.) The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists.  APA's membership includes more than 142,000 researchers, educators, clinicians, consultants and students.  Through its divisions in 49 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. #       #       # 
--------
744-> UT-Houston Scientists Shed Light On How Memories Are Formed
HOUSTON (February 28, 1997)--Neuroscientists at The University of Texas-Houston Health Science Center are a step closer to understanding the processes underlying learning and memory. In a report in the February 28 issue of Science magazine they describe how a protein molecule, transforming growth factor-beta (TGF-beta), induces changes in neurons similar to those associated with learning. This work may have implications for the treatment of learning disabilities in people whose nervous systems have been compromised by disease, injury or aging. Researchers led by John H. Byrne, Ph.D., professor and chairman, department of neurobiology and anatomy, UT-Houston Medical School, set out to explore the phenomenon by which learning strengthens the connections between neurons, an event observed when long-term memory is formed. Using an experimental system based on the defensive withdrawal reflex of the snail, Aplysia, the team tested the hypothesis that growth factor TGF-beta, which is known to be important in early development of the nervous system, also plays a key role in long-term memory. TGF-beta was introduced and was found to produce stronger electrical nerve cell connections when measured 24 hours and 48 hours later. These persistent changes are similar to those recorded in animals whose enhanced withdrawal response is triggered by behavioral training. TGF-beta's effects were limited to long-term memory: testing soon after its application failed to show a significant change. Eric R. Kandel, M.D., senior investigator at the Howard Hughes Medical Institute, Columbia University, believes this work represents a major advance in understanding of the molecular mechanisms involved in memory. He comments, "In an elegant series of experiments, the Houston team have shown that TGF-beta can induce long-term facilitation in the sensory motor neurons of Aplysia. Moreover, the response was selectively blocked by inhibitors of TGF-beta. Here is the first direct evidence that the growth of new synaptic connections between nerve cells might involve a class of neurotrophic growth factors important in development and therefore provide another important bridge between developmental processes on the one hand and memory storage on the other. These studies also provide some of the first insights into the molecules that are important in establishing the structural changes that occur with long-term memory." The Science paper authored by F. Zhang et al. adds to the body of work aiming to explain the complex chain of events linking learning, memory, proteins and genes. Byrne points out that only recently have scientists demonstrated that there are common factors in the molecular mechanisms of learning and memory and those which determine the 'patterning' and connectivity of the nervous system. He explains, "Physical development of the nervous system begins in the embryo and continues until after birth. While some neuroanatomists working in the late 19th century suspected that learning involved changes to the structure of the nervous system, the prevailing belief was that the two were totally separate. We now know that not only does learning involve physical changes in the way cells communicate, but that those changes utilize mechanisms common to the actual formation of the nervous system. The discovery that transforming growth factor TGF-beta, earlier shown to play an important developmental role, can also simulate an effect normally acquired only after learning, opens the door to the possibility of developing new therapies for those who suffer from stroke, brain injuries or Alzheimer1s disease." This research, funded by the National Institutes of Health and conducted primarily at UT-Houston Health Science Center, also involved Dr. Arnold Eskin of the department of biochemical and biophysical sciences at the University of Houston, a long-standing collaborator of Byrne. In addition to chairing the Medical School department, Byrne is director of the UT-Houston Neuroscience Research Center, an organization representing over 200 faculty members, scientists and clinicians engaged in diverse, multidisciplinary research in the neurobehavioral sciences. Note: The paper by Fan Zhang, Shogo Endo, Leonard J. Cleary, Arnold Eskin and John H. Byrne (corresponding author) entitled, Role of Transforming Growth Factor-ß in Long-Term Synaptic Facilitation in Aplysia, is published in Science, February 28, 1997.
--------
745-> NCAR Scientist Elected To National Academy Of Engineering
1997-7 FOR IMMEDIATE RELEASE: February 26, 1997 Contact: Anatta UCAR Communications Boulder, CO 80307-3000 Telephone: 303-497-8604 E-mail: anatta@ucar.edu NCAR Scientist Elected to National Academy of Engineering BOULDER--Margaret LeMone, a senior scientist at the National Center for Atmospheric Research (NCAR) in Boulder, Colorado, has just been elected a member of the National Academy of Engineering (NAE). Election to the academy is one of the highest professional distinctions accorded engineers and other technical specialists, recognizing those who demonstrate "unusual accomplishment in the pioneering of new and developing fields of technology." She will be inducted during a ceremony at the next annual NAE meeting in Washington, D.C., on October 7. LeMone is an observational meteorologist who studies the behavior of large, organized storm systems and other aspects of the lowest kilometer of the atmosphere, called the planetary boundary layer. She is one of 46 women inducted into the 1,893-member academy since its creation in 1964. Her election recognizes her "for advances in understanding the dynamics of the planetary boundary layer and its role in the predictability of atmospheric processes." The academy's letter arrived deep inside a large box with several books. Once she realized it was the election announcement, LeMone was "completely surprised. It's quite an honor." LeMone earned a bachelor's degree in mathematics from the University of Missouri and a Ph.D. in atmospheric sciences from the University of Washington. She came to NCAR as a postdoctoral Fellow in 1972. She is a Fellow of the American Association for the Advancement of Science and the American Meteorological Society (AMS) and has served on research committees and advisory boards for those organizations as well as the National Research Council. She served as editor of the Journal of the Atmospheric Sciences and received its editor's award in 1989. LeMone was the founding chair (1975-78) of the AMS Board on Women and Minorities. LeMone has contributed her expertise to three textbooks and an elementary school science series. Three of her articles appear in the World Book Encyclopedia (1989-present). She has made numerous presentations to students, mentored teachers in Project LEARN (Laboratory Experience in Atmospheric Research at NCAR), and served as a coach for Odyssey of the Mind. She is currently co-principal investigator for the second phase of Project LEARN. NCAR is managed by the University Corporation for Atmospheric Research under sponsorship by the National Science Foundation. -The End- Writer: Zhenya Gallon photo available Find this press release on the World Wide Web at http://www.ucar.edu/ucargen/press/LeMone.html To receive UCAR and NCAR press releases by e-mail, telephone 303-497-8601 or e-mail butterwo@ucar.edu
--------
746-> Adaptive Optics Gives Earth-Based Telescopes, Weapons Hubble-like Vision
WINSTON-SALEM, N.C. (2/27/1997) -- The Hubble Space Telescope isn’t the only stargazer getting better eyes to view the universe. A Wake Forest University professor's applied mathematics are part of new adaptive optics technology producing "Hubble-like" improvements in the sight of ground-based telescopes and new laser weapons. Adaptive optics combines powerful lasers, high-speed computers, active mirrors that can rapidly alter their shape, and Robert J. Plemmons’ problem-solving mathematical algorithms to reconstruct images distorted by Earth’s atmosphere. By analyzing light returning from bright stars such as Vega or artificial stars created by shining a laser into the night sky, scientists can diminish the distorting effects of Earth’s atmosphere. The result: telescopes that can see 50 to 100 times more detail and laser-guided weapons better able to zap enemy missiles. "Atmospheric effects are continuously changing so when you deblur an image, you have to do billions and billions of computations fast," said Plemmons, Z. Smith Reynolds Professor of Mathematics and Computer Science at Wake Forest. "When we look at a distant galaxy, the light from it travels, say, several million years to reach Earth but only gets blurred in the last few microseconds. That's the basic problem of atmospheric imaging." No fewer than 10 telescopes are adding adaptive optics systems to improve their view, including what is now the highest-resolution telescope on Earth: the Air Force Phillips Laboratory’s 3.5-meter, $27 million instrument at the Starfire Optical Range in New Mexico. Equipped with adaptive optics in January under a project supported by the Air Force Office of Scientific Research (AFOSR) and the National Science Foundation, the telescope can track softball-sized objects traveling 1,000 miles above the surface. Plemmons’ algorithms, developed in more than 25 years of research for the Defense Department, are also being used to overcome wind, hot air and other atmospheric turbulence that could affect the aim of the Air Force’s $1.1-billion Airborne Laser Weapons System (ABL), designed to fire a laser through the nose of an aircraft to zap enemy missiles.  Astronomer Horace Babcock first proposed the idea of adaptive optics in 1953, but the first experiments did not begin until the 1970s. Only in the 1980s, with the Strategic Defense Initiative (SDI), or "Star Wars," did Plemmons and other adaptive optics researchers gain substantial funding. Ironically, the declassification of SDI work in 1991 has revolutionized ground-based astronomy. "Whether you are trying to shine a laser on a target or get a sharp image of something in orbit, you have the same problems," said Maj. Scott Shreck, manager of the AFOSR's computational mathematics program.  Better eyes for the heavens also help the Air Force keep better tabs on spy satellites or protect space shuttle crews and satellites from orbiting space junk. "Some of this space junk will cause trouble when it comes down," Plemmons said. "Some U.S. and old Soviet satellites have  nuclear power systems, so we want to know where they are." Twinkling stars and other annoying effects of the Earth’s atmosphere on light has confounded stargazers since the invention of the telescope. It was Christian Huygens, the inventor of the pendulum clock, who first noticed in the 17th century that heavenly bodies quivered in telescopic view through no fault of the telescope. Sir Isaac Newton observed in 1704: "The only remedy is a most serene and quiet air." Iraqi Scuds and other missile threats have now made Newton’s "remedy" a national defense priority. "We don't yet have a good ballistic missile defense system against Scud-type threats," said Plemmons, who testified before Congress last spring on the need for more basic science research to avoid the kind of mathematical errors that sent an Iraqi Scud into a U.S. Army barracks in Dhahran, Saudi Arabia , on Feb. 25, 1991, killing 28 Americans. "It’s not enough to just hit a target," Plemmons said. "The idea behind the ABL program is to image the nose cone of an incoming missile and fire the laser from the aircraft at the fuel supply behind the nose cone -- where it’s most vulnerable -- and before the missile reaches its zenith, when it’s still over enemy territory." Author of more than 150 papers and five books on computational mathematics, Plemmons envisions the day when the math of adaptive optics will allow ground-based telescopes to possess the same imaging accuracy as the Hubble. For now, he said both the Hubble and ground-based telescopes have roles in the exploration of  the universe’s mysteries. The larger mirrors of ground-based telescopes allow them to see the bigger picture of celestial bodies, whole planets and stars. The pristine vacuum of space allows the Hubble to better inspect individual areas and gather ultraviolet, X-ray and other light Earth’s atmosphere blocks out. "One doesn’t exclude the other," Plemmons said. "We need both." Note: A WWW version of this release can be viewed via http://www.wfu.edu/wfunews/clips.htm Printing-quality images of the Plemmons photo are also available by calling the Wake Forest University News Bureau at 910-759-5237. 
--------
747-> New Book Challenges Scientific Validity Of Multiple Personality Disorder
Contact: Doug Fizel, Deputy Director, Public Affairs E-mail: public.affairs@apa.org, Phone: (202) 336-5700 Institution: American Psychological Association New Book Challenges Scientific Validity Of Multiple Personality Disorder Date: January 1, 1997 Contact: Doug Fizel Public Affairs Office (202) 336-5700 public.affairs@apa.org (e-mail) NEW BOOK CHALLENGES SCIENTIFIC LEGITIMACY OF MULTIPLE PERSONALITY DISORDER "Multiple Identities and False Memories: A Sociocognitive Perspective" Likely to Stimulate Professional Debate WASHINGTON -- Since the mid-1970s there has been tremendous growth in the diagnosis of Multiple Personality Disorder (MPD) -- the development of sometimes hundreds of separate personalities within the same body, often ascribed to childhood physical or sexual abuse. But according to research psychologist Nicholas P. Spanos, Ph.D., Multiple Personality Disorder (recently renamed Dissociative Identity Disorder or DID), is not a "disease" at all, but a "social construction" that serves the various purposes of MPD patients, their therapists and elements of society. He recommends that the diagnosis be abandoned. "Multiple Identities and False Memories: A Sociocognitive Perspective," published by the American Psychological Association (APA), was written by Dr. Spanos shortly before his death in a plane crash in 1994. It is a wide-ranging and thoroughly documented examination of the scientific literature on the phenomenon of Multiple Personality Disorder and its possible connection to recovered memories of childhood sexual abuse, reports of satanic ritual abuse, past-life regression and claims of alien abduction. One of the common threads running through these phenomena is the use of hypnosis to retrieve "lost" memories and reveal hidden identities. Dr. Spanos, who was one of the world's leading experts on the study of hypnosis, offers his conclusion that some of the most common beliefs about hypnosis simply are not true. For example, Dr. Spanos cites and describes the many studies that demonstrate that hypnosis does not produce a unique state of consciousness (i.e., a trance state) and does not cause people to lose control of their senses, thought processes or behavior. Nor does it improve the accuracy of recall. "Hypnotic behavior," he writes, "is a goal-directed social action and is much more ordinary than it initially appears." And, he argues, it is the misunderstanding of what hypnosis is -- and is not -- that is the base on which current theories of MPD, as well as past-life regression and many of the therapies to recover "lost" memories, rests. Dr. Spanos examines the concept of "multiple identity" as it has manifested itself through history and across cultures, examines the social, cultural and political contexts in which it has arisen and concludes that the current "disease theory" of MPD, with its association with childhood physical and especially sexual abuse, cannot "provide a general account of this phenomenon that takes into consideration its cross-cultural and trans-historical manifestations." He notes, for example, that the symptomatology of MPD itself has changed over time. In the 19th century, MPD patients typically displayed no more than two or three "alter" personalities, all of which were human, and many of them engaged in some form of transitional behavior, such as sleep or convulsions, to switch from one "alter" to another. Today, MPD patients display many more "alters," sometimes into the hundreds, and sometimes those "alters" are animals or reincarnated past lives, and the patients rarely engage in any transitional behavior when switching between and among them. What has changed, Dr. Spanos argues, is not the "disease," but the social, political and economic contexts in which the phenomenon of multiple identity has occurred over time and across cultures. In 16th- and 17th-century Europe, for example, there were frequent occurrences of people -- usually women -- displaying more than one personality. The difference between now and then, he notes, is that in earlier times, "alter" personalities were considered demons and were diagnosed and treated (through exorcism) by priests. Meanwhile, in other cultures and in other times, there have been "spirit mediums," whose bodies were supposedly inhabited by the personalities of the dead so they could communicate with the living. Whether enactments of multiple identities serve the purpose of promoting a religion (or denigrating another), identifying "witches," defrauding credulous customers or simply getting care and attention for someone who feels they don't have enough, Dr. Spanos argues that those enactments are guided by rules and expectations, specific to the time and culture in which they are manifest, that are understood and given legitimacy by both the authority figures involved (be they members of the clergy or psychotherapists) and the observing audience. For example, he notes that in today's North American culture, the concept of MPD is generally understood and widely accepted; it has been described and portrayed in numerous books, movies, documentaries and on daytime TV talk shows and techniques for diagnosing it and treating it are presented at workshops and conferences. But, he points out, there is little if any evidence that MPD occurs spontaneously, and while the number of those who diagnose and treat it has grown tremendously in the past two decades, many psychotherapists with long experience have never seen a case of it. Dr. Spanos cites surveys suggesting that most of the cases of MPD have been generated by relatively few therapists. Why Here? Why Now? Why MPD has become so prevalent in late-20th Century North America is a complicated issue, Dr. Spanos writes. He contends that this has come about because of several factors, including a convergence of several powerful social forces. General interest in MPD itself was renewed in the late 1950s and the early 1960s by the popular book and movie about a woman with MPD, The Three Faces of Eve. By the early 1970s there was growing societal awareness and concern about the issue of child abuse; at first physical abuse and then later child sexual abuse, culminating in accusations of mass molestation and even ritual abuse of children in daycare centers. The enormously popular book and TV movie Sybil in 1973 (about another woman with MPD) helped bring the two issues -- MPD and child abuse -- together in the public mind. Two other important phenomena occurred during the 1970s and 1980s, Dr. Spanos notes: the growth of the feminist movement, whose social goals of such things as the right to abortion, pay equity, encouragement of women to become economically self- sufficient were (and are) opposed by another growing social and political force: the religious right. Ironically, Dr. Spanos observes, elements of both forces have come to embrace the modern association between MPD and childhood sexual abuse; some feminists believe that MPD, which rarely occurs in men, brings recognition to the problem of the sexual abuse of women while some on the religious right see MPD as evidence of the existence of sexually abusive satanic cults. Book: Multiple Identities and False Memories: A Sociocognitive Perspective by Nicholas P. Spanos, Ph.D., 352 pp, $29.95, American Psychological Association. Order Department 1-800-374-2721. The American Psychological Association (APA), in Washington, DC, is the largest scientific and professional organization representing psychology in the United States and is the world's largest association of psychologists. APA's membership includes more than 142,000 researchers, educators, clinicians, consultants and students. Through its divisions in 49 subfields of psychology and affiliations with 58 state, territorial and Canadian provincial associations, APA works to advance psychology as a science, as a profession and as a means of promoting human welfare. # # #
--------
748-> NIAID Funds Pediatric AIDS Clinical Trials Group
The National Institute of Allergy and Infectious Diseases(NIAID) has awarded 23 four-year grants to continue the work ofthe Pediatric AIDS Clinical Trials Group (ACTG). A nationwideclinical trials network, the group evaluates improved strategiesto prevent infants of infected mothers from acquiring HIV inutero or during birth, and for treating children and adolescentsalready infected with the virus. First-year funding for the newawards totals $32 million. The money will support 21 AIDS Clinical Trials Units (ACTUs,listed below), a Statistical and Data Management Center, and anew Pediatric ACTG Coordinating and Operations Center. The latterwill provide scientific and managerial leadership and performcentralized, advanced laboratory studies. Through June 1996, 9,870 cases of AIDS in children andadolescents as old as 19 years had been reported to the U.S.Centers for Disease Control and Prevention (CDC). Of the 7,296cases in children under age 13, nine out of 10 patients acquiredHIV perinatally from their infected mothers. These data reinforcethe need to develop better strategies to prevent and treatmother-to-infant HIV transmission. "The Pediatric ACTG brings together a superbly qualifiedgroup of investigators focused on the special problems ofpreventing and treating AIDS and associated opportunisticinfections in infants, children and adolescents," commentsNIAID Director Anthony S. Fauci, M.D. "We are confident thatthe Pediatric ACTG will continue to make significantcontributions to improving the lives of all young people infectedwith HIV." Stephen A. Spector, M.D., principal investigator of theUniversity of California at San Diego ACTU, will be Group Leaderof the Pediatric ACTG. As such, he will direct its Coordinatingand Operations Center, which will be managed by Social andScientific Systems in Bethesda, Md. "The restructured Pediatric ACTG will greatly enhance ourability to conduct trials that address questions of high publichealth and scientific priority," says Dr. Spector. One grouppriority is to incorporate pathogenesis-based research intoclinical trials. These studies will enable the ACTU investigatorsto better define the course of disease in children and to analyzehow HIV infection and its treatments affect the developing immunesystem. The Pediatric ACTG is uniquely suited to carry out suchstudies because they require integrating clinical and laboratoryresearch. The Statistical and Data Management Center will be headed byRichard Gelber, Ph.D., of the Harvard School of Public Health. The 21 clinical trials sites include 20 of the 22 currentNIAID- sponsored Pediatric ACTUs and one new site in Alabama. Thefunding level for the Pediatric ACTG is consistent with therecommendations of the Report of the NIH AIDS Research ProgramEvaluation Working Group, chaired by Princeton virologist ArnoldLevine, Ph.D. This report--an external review of the NIH AIDSprogram issued by the NIH Office of AIDS Research in1996--recommended a decreased level of funding for the PediatricACTG given the changing epidemiology of HIV infection in childrenin the United States. In addition to the NIAID-sponsored components of the PediatricACTG, the National Institute of Child Health and HumanDevelopment (NICHD) currently funds 33 smaller clinical trialssites. The NICHD investigators participate in group committeesand protocol development teams, enroll patients and share thesame scientific group leadership as NIAID. Together, these 54clinical sites provide the structure and resources for addressingthe Pediatric ACTG's goals. Moreover, through the Ryan White Service Program, the U.S.Public Health Service enhances pediatric AIDS clinical researchby providing resources such as day care and travel money tofacilitate the participation of HIV-infected women and childrenin NIH-sponsored clinical research. Health care providersreceiving funds from this program are located near 20 of the 21NIAID clinical sites and can easily make patient referrals to thegroup's trials. As of February 1997, the Pediatric ACTG had initiated 60trials, and 27 studies are now recruiting patients. Cumulativeenrollment since 1987 totals 10,867 children, adolescents andpregnant women. Among its most significant contributions, thegroup has: 1) demonstrated that antiretroviral therapy given toHIV-infected pregnant women and their newborns can reduce therisk of perinatal transmission by two thirds; 2) showed that IVIGcan effectively prevent serious bacterial infections in childrenwith HIV; 3) demonstrated that ddI or ddI plus AZT are superiorto AZT monotherapy for children with symptomatic HIV infection orAIDS; and 4) developed guidelines for preventing Pneumocystiscarinii pneumonia in HIV-infected children. The original NIAID ACTG established in 1987 included two sitesthat enrolled children with AIDS. Additional pediatric sites wereadded in 1988 and 1989, and again in 1992. Followingrecommendations of an independent advisory panel, the Adult andPediatric ACTGs will now operate separately. Currently there are30 adult clinical sites. For information on Pediatric ACTG trials currently open toenrollment, call the AIDS Clinical Trials Information Service at1-800-TRIALS-A (1-800-874-2572), Monday through Friday, 9:00 a.m.to 7:00 p.m. Eastern time. Bilingual health specialists areavailable to talk to Spanish-speaking callers. NIAID and NICHD are components of the National Institutes ofHealth (NIH). NIAID conducts and supports research aimed atpreventing, diagnosing and treating illnesses such as AIDS andother sexually transmitted diseases, tuberculosis, asthma andallergies. NIH is an agency of the U.S. Department of Health andHuman Services. ### Press releases, fact sheets and othermaterials from NIAID are available on the Internet via the NIAIDhome page at http://www.niaid.nih.gov. NIAID PEDIATRIC AIDS CLINICAL TRIALS UNITS AND PRINCIPALINVESTIGATORS ALABAMA University of Alabama at Birmingham Robert Pass, M.D. CALIFORNIA University of California at Los Angeles Yvonne J.Bryson, M.D. University of California at San Diego Stephen A. Spector, M.D. University of California at San Francisco Diane W. Wara, M.D. DISTRICT OF COLUMBIA Children's National Medical Center JohnL. Sever, M.D., Ph.D. FLORIDA University of Miami School of Medicine Gwendolyn B.Scott, M.D. ILLINOIS Children's Memorial Hospital Ram Yogev, M.D. LOUISIANA Tulane University School of Medicine Russell VanDyke, M.D. MARYLAND Johns Hopkins University Andrea Ruff, M.D. MASSACHUSETTS Children's Hospital Kenneth McIntosh, M.D. University of Massachusetts Medical Center John L. Sullivan,M.D. NEW JERSEY UMDNJ-New Jersey Medical School James Oleske, M.D.,M.P.H. NEW YORK Bronx-Lebanon Hospital Center Andrew A. Wiznia, M.D. Columbia University Anne A. Gershon, M.D. New York University Medical Center William Borkowsky, M.D. NORTH CAROLINA Duke University Medical Center Ross McKinney,Jr., M.D. PENNSYLVANIA Children's Hospital of Philadelphia Stuart E.Starr, M.D. PUERTO RICO University of Puerto Rico Clemente Diaz, M.D. TENNESSEE St. Jude Children's Research Hospital Walter Hughes,M.D. TEXAS Baylor College of Medicine William T. Shearer, M.D.,Ph.D. WASHINGTON Children's Hospital and Medical Center Lisa M.Frenkel, M.D.
--------
749-> Study Confirms That Combination Treatment Using a Protease Inhibitor Can Delay HIV Disease Progression and Death
Research supported by the National Institute of Allergy andInfectious Diseases (NIAID) has demonstrated that in patients with advanced HIV disease the combination of a protease inhibitor plus two nucleoside analogue reverse transcriptase inhibitors (RTIs) is significantly more effective in reducing the occurrence of AIDS-defining illnesses or death than two RTIs alone.  The study, known as ACTG 320, was designed to determine the efficacy and safety of the protease inhibitor indinavir when given in combination with zidovudine (ZDV) [or stavudine (d4T)] and lamivudine (3TC), as compared to ZDV (or d4T) plus 3TC. As a result of recent data showing the dramatic effectivenessof protease inhibitors in lowering viral burden, strategies usingprotease inhibitors in combination with other drugs are being widely used. "The results of ACTG 320 confirm the importance of including protease inhibitors in treatment strategies for patients with advanced HIV disease," says Anthony S. Fauci, M.D., NIAID director.  "Significantly, the current study provides additional evidence that combination approaches using protease inhibitors can reduce the risk of death." Preliminary results of the study were reviewed Feb. 18, 1997,by an independent data and safety monitoring board, whichrecommended early termination of enrollment and closure of thestudy.  They based this recommendation on the significant benefit of the triple combination including indinavir in delaying disease progression and death. "The further, significant reduction in disease progressionconferred by indinavir when given as part of a three-drug combination illustrates the rapid progress that the field of HIV therapeutics has made in the last two years and suggests that further benefits can be achieved with regimens of  ever-increasing potency," commented Scott Hammer, M.D., protocol chair of ACTG 320. Volunteers in the study had CD4+ T cell counts below 200 per cubic millimeter (mm3) of blood at study entry and had taken ZDV for at least three months, but had received less than one week of 3TC and no protease inhibitors.  The mean baseline CD4+ T cell count of the participants was 86 cells/mm.3  They were randomized to receive either the combination of ZDV (600 mg/day), 3TC (300 mg/day) and indinavir (2400 mg/day), or ZDV plus 3TC plus placebo.  Participants intolerant to ZDV could use stavudine (d4T), and those developing toxicities or experiencing mild disease progression were allowed tochange to other approved nucleoside analogues.  The majority of participants received ZDV and 3TC for the duration of the study. A total of 1,156 HIV-infected volunteers participated in ACTG320.  Participants were enrolled at 33 sites of the NIAID-supported AIDS Clinical Trials Group, and at seven sites of the National Hemophilia Foundation.  They were followed for a median of 38 weeks, with some patients being followed for up to one year.  Further studies are needed to understand the long-term impact of this triple combination.  Sub-studies of ACTG 320 are currently being analyzed, including a study of how the various treatments affect the amount of virus in patients' blood and to characterize the development of drug resistance in the different treatment arms. Survival and a delay in disease progression were significantlybetter in patients receiving triple combination therapy.  In that group, AIDS-defining illnesses, including opportunistic infections and cancers, and deaths were decreased by approximately half. Sixty-three instances of disease progression (including AIDS-defining illnesses and deaths) occurred in volunteers on the ZDV/3TC arm versus 33 in volunteers on the triple combination arm. The benefit was statistically significant for the subset of patients with CD4+ T cell counts less than 50/mm3 and there was a similar trend for patients with CD4 counts between 50 cells/mm3 and 200 cells/mm3.  There were 18 deaths in the double therapy arm versus eight deaths in the triple therapy arm. In addition, the safety of each treatment regimen was closelymonitored.  There were no major differences in the safety or toxicity of the two treatment regimens and the study medications were well-tolerated. The drugs used in this study were provided by theirmanufacturers: Merck & Co., Inc. (indinavir/Crixivan), GlaxoWellcome, Inc. (ZDV/Retrovir and 3TC/Epivir), and Bristol-Myers Squibb Co. (d4T/Zerit and ddI/Videx).  Merck also provided financial support for the study. NIAID, a component of the National Institutes of Health (NIH),supports scientists and scientific studies at universities, medicalschools and research institutions in the United States and abroad.  As part of its efforts to improve the quality and duration of life of HIV-infected individuals, the Institute supports four diverse AIDS clinical trials programs: the Adult AIDS Clinical Trials Group, the Pediatric AIDS Clinical Trials Group (PACTG), the Terry Beirn Community Programs for Clinical Research on AIDS (CPCRA), and the Division of Intramural Research clinical trials program on the NIH campus.  NIH is an agency of the U.S. Department of Health and Human Services.                                      ###NIAID press releases, fact sheets and other materials areavailable on the Internet via the NIAID home page athttp://www.niaid.nih.gov.
--------
750-> Asthma And Allergy--The Revenge Of The Viral Nerd?
Johns Hopkins Medical Institutions Office Of Communications and Public Affairs On Line: 76520@compuserve.com Media contact: Michael Purdy, (410) 955-8725 E-mail:  mpurdy@welchlink.welch.jhu.edu February 21, 1997 "This suggests we might one day be able to reduce the incidence of allergy and asthma by vaccinating children against mild childhood viral diseases that traditionally haven't received much attention." ASTHMA AND ALLERGY--THE REVENGE OF THE VIRAL NERD?New Evidence Links Mild Infections to Development of Allergy and Asthma Johns Hopkins scientists have found the first hard evidence that viral infections can help cause asthma and allergies, a connection long suspected but never directly confirmed in the lab. Hopkins researchers showed that weak viral infections can cause immune system B cells to produce immunoglobin E or IgE, a protein that orchestrates the reactions that cause allergies and many cases of asthma. "This suggests we might one day be able to reduce the incidence of allergy and asthma by vaccinating children against mild childhood viral diseases that traditionally haven't received much attention," says Farhad Imani, Ph.D., instructor of medicine, who presents his results at the annual meetings of the American Academy of Allergy, Asthma and Immunology. "We've suspected that there might be a connection since the late  70s, when studies found that kids who had more viral infections were more likely to have asthma and allergy later in life," says Imani.  More recent animal studies have shown that viral infection can increase IgE levels in the blood. In test tube studies, Imani and his colleagues exposed human B cells, which recognize and attack a particular type of intruder, to rhino and vaccinia viruses.  B cells normally attack germs with immunoglobins type M or G (IgM or IgG).  Imani found that after viral infections, many of the cells switched to making IgE. "Basically, if you have a group of B cells that is producing IgE, you're going to be allergic to whatever that group of B cells is sensitive to," Imani explains. Ironically, stronger viruses capable of causing serious disease were less likely to trigger the switch to IgE than wimpier viruses rapidly defeated by the immune system. "This appears to be because the weaker viruses activate anti-viral protein kinase, a protein that the B cell uses to defend itself," Imani explains.  "This kinase also helps stimulate the start of IgE production in the B cell." The more sophisticated viruses have found ways to evade the kinase, but many simpler viruses still cannot avoid it. "These weaker viruses might not cause much suffering during the infection, but they could be causing pain farther down the road by helping the development of allergies." Imani plans further studies both to determine which viruses will switch on IgE and to flesh out the link between the activation of anti-viral protein kinase and the start of IgE production. The study was funded by the American Lung Association, the National Institutes of Health, and the Hopkins School of Medicine.  Other authors were Kelly Rager, Branimir Catipovic, M.D., Vincenzo Casolaro, M.D., David Proud, Ph.D., J.O. Langland, Ph.D., Bertram Jacobs, Ph.D., and David Marsh, Ph.D. --JHMI-- Johns Hopkins Medical Institutions news releases can be accessed on-line through the following services: To enroll in our direct e-mail news release service, call 410-955-4288. World Wide Web at http://infonet.welch.jhu.edu/news/news_releases CompuServe in the SciNews-MedNews library of the Journalism Forum under file extension ".JHM"; also in NASW Online in same forum. JHMI toll-free Health NewsFeed BBS at 1-800-JHH-0046. Quadnet: send email to: news@quad-net.com.   In the body of the message type
--------
751-> Home Monitoring System Helps Congestive Heart Failure Patients Avoid Hospital Stays
Chicago, IL (Feb. 18, 1997) -- With the aging of the baby boomgeneration the prevalence of congestive heart failure, alreadythe most common cause of readmission to hospitals, is expected tonearly double over the next 40 years and could become a majordrain on health care resources. Congestive heart failure patientsoften require frequent hospitalizations, each costing about$10,000. But a physician at the University of Illinois at ChicagoMedical Center has an innovative solution to this looming healthcare problem. Dr. Boaz Avitall, director of cardiacelectrophysiology at UIC, working with Advanced Medical Devicesof Milwaukee, developed a system called the Home Health Monitorthat closely monitors congestive heart failure patients in theirhomes several times daily, resulting in fewer readmissions to thehospital and substantially lower health-care costs. [The systemreceived FDA approval Feb. 11, 1997.] In a pilot study conducted by Avitall, the hospitalreadmission rate for 35 congestive heart failure patients usingthe system was just 14 percent over a six-month period, comparedto the national readmission average of 42 percent over athree-month period. Patients reported the system was easy andconvenient to use. The cost per patient for the Home Health Monitor is $408($6.28/day) compared to the average $1,000-2,000 cost of homecare for congestive heart failure patients which provides for 10to 20 visits. The Home Health Monitor includes a computerized centralmonitoring station at the UIC Medical Center staffed 24 hours aday by cardiology nurses and technicians, with cardiology fellowsand attending physicians on call. The system's hardware in thepatient's home consists of a small, portable monitor, a scale for body weight, an automatic blood pressure cuff, afinger probe to measure blood-oxygen levels and pulse rate and aglucose meter. When the patient takes his or her measurements,the monitor stores the data and then automatically transmits itover the patient's existing telephone line to the station forreview. Any patient who does not transmit data within 24 hours iscontacted by telephone. "The Home Health Monitor provides rapid and earlydetection of any complications before they become severe andrequire hospitalization," says Avitall. "It also makespatients feel more secure in their home environment by havingcontinous contact with the Medical Center. "For example, the system detects increases in body weightor changes in blood pressure, common indicators of problems incongestive heart failure patients," explains Avitall."Any time the system picks up a deviation in a patient'svital sign from a pre-set level, an alarm will sound at theMedical Center station, prompting a follow-up call to thepatient. In cases of elevated body weight or blood pressure, thepatient's physician can adjust the patient's medication." Avitall says the Home Health Monitor teaches patients tocomply with diet and medication requirements."Non-compliance and ignorance of their disease are often thecauses for patient readmissions," says Avitall. "Wecall our patients every week to discuss their vital signs and letthem know if they are doing well or make suggestions on how theycan do a better job of following their diet and medicationregimens." Congestive heart failure is the primary diagnosis for morethan 750,000 hospital admissions annually in the United States,requiring a total of nearly six million hospital in-patient days.A 1994 study concluded that the total cost of avoidable,unncessary hospital readmissions for congestive heart failure inthe United States was more than $600 million a year.
--------
752-> Researchers Reveal Architecture Of Protein From First Known Oncogene
Contact: Peta Gillyatt, Public Information Officer E-mail: paffairs@warren.med.harvard.edu, Phone: (617) 432-0442 Institution: Harvard Medical School Researchers Reveal Architecture Of Protein From First Known Oncogene BOSTON--Twenty-seven years after the first human cancer-causing gene was discovered, scientists can finally take a hard look at Src, the protein it produces. Researchers led by Howard Hughes investigator Stephen Harrison and Harvard Medical School colleague Michael Eck will display the crystal structure of human Src in the February 13 Nature. This work, illuminating the highest resolution structure ever of a protein of its class, will help drug designers understand Src in atomic detail. Since Src closely resembles eight other members of its family, this long-sought structure establishes general principles for how these complex proteins fold up their amino acid chain to regulate their important but dangerous biochemical work in the cell. Indeed, a structure of a second family member published by other researchers in the same issue of Nature confirms these principles. Rational drug design has been much touted as the smart, new way to find drugs more quickly, but the driving force behind it is really structural biology. Without a 3-D view of how the atoms of a protein implicated in disease arrange themselves in molecular space, rational drug designers are poking in the dark, trying to shoot bullets at a target they can1t see. Many researchers in academia and industry have tried to elucidate the structure of Src, and several pharmaceutical companies are searching for inhibitors for tyrosine kinases, the class of enzymes of which Src is a flagship member. These still elusive inhibitors could treat not only cancer, but potentially transplant rejection and autoimmune diseases, as well. The protein Src comes as a Dr. Jeckyll-Mr. Hyde pair. Its benevolent form helps control growth and division, but mutations can turn it into an oncogene. This villain often enters cells via a virus, the context in which it was discovered in 1970. Since this Nobel-prize-winning research, Src has become a household name among bioscientsts. 3Src is a granddaddy of famous proteins,2 says Eck, assistant professor of biological chemistry and molecular pharmacology. In hundreds of studies, researchers have zoomed in on its normal and subverted functions in ever greater detail. Normal Src conveys growth signals from the cell1s outside to its inside. It does so by tacking phosphate groups onto tyrosine amino acids in other proteins, in a process called phosphorylation. Previous research suggested that Src, much like a switch, occurs in the 3off2 state most of the time and that stimulation flips it to the 3on2 state. Scientists also have known that cancer-causing mutations lock Src in the 3on2 position, sending it into a growth-promoting frenzy. But how exactly does this work? Src must be a sort of multiplex switch, for it receives different types of input and, in response, turns on or off. More than scientific curiosity, this question is key to attempts to interfere therapeutically, says Harrison. 3Now at least we have a first view of this class of switch,2 says Harrison, who is also professor at Harvard. Most people think of proteins simply as tiny blobs. But when Eck, Harrison, and postdoc Wenquin Xu scrutinized the structure of Src, they realized that it is a formidable product of nano-engineering. 3Src is a fancy little machine. It has an incredible amount of information technology built into a tiny package, where every bit matters and is used creatively,2 says Eck. Src consists of four lobes: Two lobes make up the kinase performing the protein1s ultimate function, and two others, dubbed SH2 and SH3, regulate the kinase and help Src travel to its site of action within the cell. Previous research had visualized parts of Src, but this is the first study that puts them together into a broader vista of how the parts interact. To their surprise, the researchers found that several mechanisms are at work simultaneously to keep Src idle, says Eck. For one, the four lobes are connected by short 3linker2 stretches, like pearls on a string. The crystal structure reveals that when Src is in the 3off2 state, the string is curled up into a compact ball, with the molecule1s tail end wrapped around the SH2 lobe in a tight embrace. This crunched conformation pulls shut the cleft between the two kinase lobes, the site where the enzymeÐwhen activeÐengulfs and phosphorylates its target. For another, the SH3 domain turns its binding surface inward and snuggles up against the surface of one of the stretches linking two lobes. This atomic interaction in effect hides SH3 from the proteins it would bind in the active state of Src, preventing SH3 from facing outward, where it could encounter those proteins. The tail reaching around SH2 similarly locks away this lobe. Thirdly, a crucial stretch of protein helix, located above the active site, is squeezed out of position. Together, these and more mechanisms serve to keep a lid on Src. At the same time, they keep it poised to spring into action, much like a Jack-in-the-box. That is because these intramolecular ties are weak, says Eck. When a growth signal comes along, it probably offers stronger, more attractive binding surfaces for one of Src1s many sensitive spots, unraveling and activating the protein. The details of how Src gets turned on require still more research, Eck adds. But the structure has already shown that some of the known mutations making Src cancerous disturb this web of inhibitory ties, letting the Jack permanently out of the box. Says Eck: 3Src looks like an oncogene product waiting to happen. Because everything is so interdependent, you can imagine that disrupting any of its internal ties might cause the house of cards to fall.2 Editors, please note: a four-color print or electronic file of the Src structure are available on request. --END--
--------
753-> Protective Effect Of Progestin In Hormone Replacement Therapy Appears to be Dose-Related
To help protect against endometrial cancer, women who takeestrogen replacement therapy should also take progestin at least10 days a month, say researchers at the University of Washington.Progestins are hormones that oppose the effects of estrogen onthe endometrial cells that line the uterus. Dr. Shirley Beresford, associate professor of epidemiology,and Dr. Noel Weiss, professor of epidemiology, published resultsof their study in The Lancet on Feb. 15. Taking estrogen after menopause can significantly reducewomen's risk of heart disease and osteoporosis, but sinceestrogen stimulates the growth of the endometrial cells, estrogenreplacement therapy can also increase the risk of endometrialcancer. Although endometrial cancer is relatively rare -- even withthe increased risk associated with estrogen therapy -- andalthough it is usually curable, this side effect is cause forconcern. Therefore, many estrogen replacement regimens nowinclude taking a progestin at least several days a month. To determine how well this strategy works and which dosingregimens are best, the researchers interviewed 832 women who hadhad endometrial cancer and 1,114 women who had not, about theirmedical history and use of hormone replacement therapy. They found that women who took estrogen without also takingprogestin had a four-fold increase in risk of endometrial cancer,compared to women who had never taken hormone replacement therapyor had taken it for less than six months. By contrast, there was only small increase in risk ofendometrial cancer in women who took progestin along with theirestrogen therapy. "This apparent protective effect seems to depend a greatdeal on how many days a month the women took the progestin,"said Beresford. For women who took progestin for 10 days or twoweeks a month, there was no statistically increased risk ofendometrial cancer. But among those who took progestin for fewerthan 10 days a month, the risk was three times higher compared tonon-users. "Women taking the combination therapy should be sure takeit for at least 10 days a month," said Weiss. While cautioning that their results are preliminary, theresearchers also report evidence that the protective effect ofprogestin may diminish over the long term. They found that evenamong women who took progestin for 10 days or two weeks a month,those who took the combination therapy for more than five yearshad a 2.5 times greater risk of endometrial cancer compared towomen who had never taken hormones. "This finding of increased risk associated with long useof estrogen combined with cyclic progestin therapy is new, andneeds to be replicated by other investigators," commentedBeresford. The researchers also noted that their study does not provideinformation on women who take combined therapy every day of themonth. "The risk of endometrial cancer is small, occurring inless than one woman in a thousand each year," said Weiss."Even with hormone replacement therapy, the risk remainssmall. The cancer is almost always contained in the uterus and isusually curable." Co-authors of the study are Lynda Voigt, auxiliary faculty inepidemiology, and Barbara McKnight, professor of biostatistics.The research was funded by grants from the National CancerInstitute.
--------
754-> Sugar, Suckling Trigger Natural Pain Control
University of Maryland at Baltimore NEWS Office for External Affairs l 511 West Lombard Street lBaltimore, Maryland 21201-1691 For information, interviews contact: Jennifer Donovan phone: (410) 706-7946; pager: (410) 407-6873 email:JenniferD@oia-2.ab.umd.edu EMBARGOED for release February 17, 1997, 5 p.m. EST SUGAR, SUCKLING TRIGGER NATURAL PAIN CONTROL People come equipped with built-in pain control mechanisms.The tricky part is switching them on. Neuroscientists at theUniversity of Maryland at Baltimore have found that sugar andsuckling activate natural pain-modulating systems in babies. Theyalso learned that this mechanism is controlled at least partly inthe spinal cord. Although their research was conducted on a ratmodel, the findings could lead to new ways to stimulate naturalpain-control mechanisms in human infants following injury andinflammation. Dr. Ronald Dubner, Dr. Ke Ren and colleagues reporton a study of the underlying mechanisms, spinal cord involvementand developmental implications of the power of sugar water andsuckling to reduce sensitivity to pain, in the February 18, 1997issue of The Proceedings of the National Academy of Sciences.Dubner is chairman of oral and craniofacial biological sciencesat the University of Maryland Dental School, where Ren is anassistant professor. "Pain is a serious clinical problem inpremature, newborn and young infants," Dubner said."Fear that anesthetic agents produce respiratory depressionand low blood pressure often result in insufficient pain control.These studies will lead to a better understanding of thedevelopment of analgesic mechanisms and provide new clinicalapproaches for engaging endogenous analgesic mechanisms inpremature, newborn and young infants." (MORE) Pain Control - 2 Dubner, Ren and colleagues evaluated the effectiveness ofsugar water and suckling on responses to heat and pressure of10-day-old rats with inflamed forepaws. They found that five to10 minutes of suckling combined with three minutes of sugar watergiven by mouth doubled the baby rats’ forepaw tolerance topain. The suckling-sugar treatment did not reduce hindpawsensitivity to the same stimuli. Study results suggest that the parts of the central nervoussystem controlling upper and lower extremities mature atdifferent rates, Dubner said. This information could be vital tothe development of effective clinical pain-control for infants. The neuroscientists also measured the expression of a proteincalled Fos, which is produced by neurons firing in response topainful stimuli. They found that the suckling and sugar treatmentsignificantly reduced the amount of Fos in the upper spinalcolumn, where the response to forepaw inflammation and pain iscontrolled. Fos expression in the lower spine after hindpawinflammation did not drop significantly. Very little has been known about where the neurons for painsensitivity are located. This outcome indicates that themechanism for the reduced sensitivity to pain that results fromsuckling and sugar resides at least in part in the spinal column,Dubner said. "These studies suggest that there is aninteraction between the nerves that transmit perception of tasteand touch in the mouth and pain-modulating circuits in thebrain," he said. "Future studies will need to analyzethe contribution of each component, including feeding sucrose,non-nutritive suckling and maternal contact." The research was supported by National Institutes of Healthgrants and a Research Scientist Award. ### g:\releases\pnasdub
--------
755-> UF Researchers Test Massage Therapy For Treatment Of Chronic Sickle Cell Pain
FOR IMMEDIATE RELEASE By Melanie Fridl Ross GAINESVILLE, Fla.---University of Florida physicians hope the healing power of hands and a healthy dose of relaxation will help people who suffer from the debilitating pain associated with sickle cell disease.        	Researchers are testing weekly massage therapy and teaching relaxation techniques to help patients cope with chronic pain. Sickle cell disease is an inherited disorder of hemoglobin, the oxygen-carrying molecule in red blood cells. It is especially prevalent among black Americans: About 1 in 600 has a form of the disease, which is characterized by sickle-shaped red blood cells that logjam in vessels. The clogged cells decrease blood flow to various organs, which can cause intense discomfort. "Many physicians are concerned about the long-term use of medication to manage this sort of pain because it is chronic -- that's why alternative pain control methods are highly desirable," says Michael Robinson, a clinical psychologist at UF's College of Health Professions. "However, there is little data available on their effectiveness, even as nontraditional medical interventions gain popularity. This is an attempt to put two such approaches to a rigorous scientific test." Sickle cell disease is noted for two types of pain. One is referred to as sickle cell crisis, characterized by sudden episodes of severe pain in the legs, arms or back that often require hospitalization and treatment with potent medications. The other type of pain occurs on a regular basis and consists of achiness that varies in intensity. Participants 18 and older will be randomized to weekly hourlong sessions of massage therapy or relaxation therapy, which they will attend at the UF Shands Cancer Center. Researchers will record pain levels and function before and after the study. After six weeks, patients will be allowed to choose the treatment  option they did not receive for another six weeks.  A licensed massage therapist who also is trained in relaxation therapy will administer the treatments.  People with sickle cell trait are not eligible to participate in the pilot study, which is funded by the American Massage Therapy Association Foundation. Relaxation training consists of a series of exercises that gently tense and relax muscles in a specified sequence throughout the body. Patients learn the difference between tense and relaxed muscles, and then learn the ability to relax. Relaxation is defined by decreased muscle tension and respiration, lower blood pressure and heart rate, and increased blood flow. "This is physiologic relaxation," said Robinson, "not the layperson's idea of 'I'll have a beer in front of the TV to relax.' "We anticipate both treatments will be effective to some degree, but we hope to determine which is the most effective means of treating the chronic pain," he added.        	Dr. Richard Lottenberg, chief of the division of hematology and oncology at UF's College of Medicine, said the treatments are a logical choice because so much of sickle cell pain stems from the musculoskeletal system.        	"We feel it is important to address these patients' pain problems so that we can improve their ability to carry out their own lives, interact with their families and maintain employment.
--------
756-> Pioneering Surgery At UIC Medical Center Saves Twins
CHICAGO, Ill. (2/13/1997) -- 	A condition once considered hopeless for 6,000 identical twin babies eachyear in the United States is now being treated with a new, pioneering lasersurgical procedure developed by Dr. Julian E. De Lia, associate professor of obstetrics and gynecology at the Universityof Illinois at Chicago Medical Center. The condition, twin-to-twin transfusion syndrome, occurs when identicaltwins share a single placenta, with blood vessel connections allowingpassage of blood from one twin into the other.  In severe cases, the"donor" twin becomes very anemic and the "recipient" twin becomesoverloaded with fluid and develops heart failure.  Without treatment, themost likely outcome is death of one or both twins.  Or, if the twinssurvive, birth defects or cerebral palsy can result. De Lia is one of only a handful of surgeons around the world who performthis procedure, with patients coming to him from 20 states and Canada.  Hesaw his first case of twin-to-twin transfusion syndrome in 1983 at theUniversity of Utah Medical Center.  Over the next several years, he didresearch and developed an in-utero laser surgical technique that he beganusing in 1988. In the procedure, the mother is given anesthesia and a thin,telescope-like device called a fetoscope is inserted into the abdomenthrough a small incision.  The placental vessels connecting the twins canbe seen through the fetoscope.  De Lia then fires a surgical laser at thevessels through the fetoscope to seal or cauterize the connecting vessels.The procedure takes only 30 to 45 minutes. De Lia has performed about 70 of the operations, including seven since hecame to the UIC Medical Center last September.  In about 75 to 80 percentof the cases at least one twin survived, and in 65 to 70 percent both twinssurvived, with neurological damage occurring in less than 5 percent of thebabies and with no ill effects on the mothers. "Twins are a special blessing to most people, and it's a double tragedyif they end up losing both children," says De Lia. "So for me, it's verygratifying to save these lives. "I've come up with something that, a few years ago, did not exist inmedicine.  Now that we're have perfected this procedure, I face thechallenges of teaching others how to perform the surgery and disseminatinginformation to parents and the medical community about its availability." (Editors:	For more information, call Danny Chun, (312) 996-2269. Internet:dchun@uic.edu) Danny Chun (dchun@uic.edu)Media Relations/University of Illinois at ChicagoColleges of Medicine, Nursing, DentistryPH: 312-996-2269   FAX: 312-996-3754Office of Public Affairs (M/C 288)601 South Morgan StreetChicago, IL  60607
--------
757-> Cause Found For Great Lakes Trout Reproduction Failure
SEATTLE (2/13/97)-- For 30 years, efforts to re-establish reproducing populations of lake trout in four of the five Great Lakes have failed. Now a University of Wisconsin-Madison researcher thinks he knows why: toxic chemicals. The levels of dioxin and related chemicals in Lake Ontario were high enough from 1945 to 1975 to have resulted in zero survival of lake trout sac fry, according to Richard E. Peterson, a toxicology professor at the UW-Madison School of Pharmacy. Female fish accumulate dioxin-like chemicals in their bodies and transfer some of these toxins to their eggs, he said. At high enough concentrations, Peterson said these contaminants can cause all of the fish’s offspring to die within three weeks of hatching. The highest concentrations of dioxins and similar toxic industrial contaminants generally are found in the Great Lakes' largest trout and salmon, especially in the long-lived lake trout. Peterson’s findings are based on more than a decade of laboratory research supported by the National Sea Grant College Program and recently completed studies in collaboration with Philip M. Cook of the U.S. Environmental Protection Agency (EPA). "Our data suggest that dioxins and related chemicals may have contributed to the extinction of lake trout in Lake Ontario prior to 1960 and to the recruitment failure of stocked lake trout since then," Peterson announced at a national Sea Grant news briefing today in Seattle. "But the good news is that declining levels of these contaminants and signs of general ecosystem recovery suggest that significant recruitment of lake trout through natural reproduction may start occurring in Lake Ontario and the other Great Lakes in the near future." Once the dominant species in the Great Lakes, native lake trout populations collapsed during the 1940s under the one-two punch of over-fishing and predation by parasitic sea lampreys. By the mid-1950s, the species was deemed extinct in all of the lakes except for a few isolated remnant populations in Lake Superior. After the sea lamprey was brought under control in the 1960s, state and federal fishery managers began stocking the Great Lakes with an average of four million lake trout annually, and they banned commercial harvest of the fish except by tribal operations. Although the stocked fish reached sexual maturity and produced fertilized eggs, the recruitment of yearling lake trout into the population has been negligible in each of the Great Lakes except Superior, the uppermost and most pristine lake in the chain. The reasons for this recruitment failure could include other environmental and biological factors, the UW-Madison researcher said, "but toxic contaminants are the closest we've got to a smoking gun so far." Of the species of Great Lakes fish Peterson tested, he found lake trout were the most sensitive to TCDD (2,3,7,8-tetrachlorodibenzo-p-dioxin), the most toxic form of dioxin. He discovered that TCDD levels in lake trout eggs as low as 30 parts per trillion (ppt) caused observable increases in sac fry mortality, and 100 percent mortality occurred at TCDD levels above 100 ppt. The sac fry die from an accumulation of excess fluid in the yolk sac (yolk sac edema) and around the heart (pericardial edema), obstructed blood flow (ischemia), hemorrhaging, and a deformed skull (craniofacial malformations) -- conditions resembling blue sac disease, a fatal disease usually seen in only a very small percentage of wild trout sac fry. While contaminant levels have dropped dramatically over the last decade, lake trout and other sport fish in the Great Lakes -- as well as those in most other U.S. lakes and rivers -- still contain detectable levels of TCDD and related toxins, including various forms of PCDD (polychlorinated dibenzo-p-dioxin), PCDF (polychlorinated dibenzofuran) and PCB (polychlorinated biphenyl). Peterson’s research shows that, in the early stages of life, fish are particularly vulnerable to the toxic effects of these chemicals, which he found act in an additive fashion. A notable spin-off of Peterson’s Sea Grant research was his determination, with EPA support, of TCDD Toxicity Equivalence Factors (TEFs) for individual dioxin-like chemicals, based on their ability to cause fish embryo mortality. TEF values permit an accurate evaluation of the cumulative risks to the early development of fish posed by low concentrations of dioxin-like chemicals in their eggs, he said, adding that the EPA is proposing to adopt the TEF approach to more precisely assess the risks these chemical pose to wild fish populations. Peterson developed the TEF method as a way to convert the concentrations of several different dioxin-like chemicals found in Lake Ontario lake trout eggs to the equivalent concentration of TCDD. EPA’s Cook then estimated the historical concentrations in the eggs based on the concentrations of these chemicals found in Lake Ontario bottom sediment cores covering the 1930 to 1987 period. The EPA analysis showed that contamination of Lake Ontario by TCDD-like chemicals began in the 1930s and peaked in the late 1960s. Sac fry hatched from the lake trout eggs collected from Lake Ontario, the last lake in the Great Lakes chain, continued to exhibit blue sac disease-like symptoms up to the middle 1980s, Peterson said. While no blue sac symptoms were evident in fry hatched from Lake Ontario lake trout eggs in 1991, Peterson said that "even at sub-lethal levels, TCDD and similar chemical contaminants may be compromising the survival of swim-up fry in the environment." He noted that dioxins and PCBs have been identified as possible endocrine disrupters -- chemicals that alter the action of natural hormones and interfere with normal reproduction and development in fish -- the focus of Peterson’s current Sea Grant research. However, a hopeful sign was last year’s declaration by the U.S.-Canadian Great Lakes Fishery Commission that self-sustaining lake trout populations had been restored to most waters of Lake Superior. As a result, lake trout from federal hatcheries are no longer being stocked in that lake. # # # # Created in 1966, Sea Grant is a national network of 29 university-based programs of research, outreach and education dedicated to the protection and sustainable use of the United States' coastal, ocean and Great Lakes resources. The National Sea Grant Network is a partnership of participating coastal states, private industry and the National Sea Grant College Program, National Oceanic & Atmospheric Administration, U.S. Department of Commerce. 
--------
